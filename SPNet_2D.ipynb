{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/-motion-artifacts/blob/master/SPNet_2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Not Used"
      ],
      "metadata": {
        "id": "uzErIbtjtb4I"
      },
      "id": "uzErIbtjtb4I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfdaf50",
      "metadata": {
        "id": "1dfdaf50"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self,mode='rgb'):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet50, self).__init__()\n",
        "        if(mode=='rgb'):\n",
        "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        elif(mode=='rgbd'):\n",
        "            self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        elif(mode==\"share\"):\n",
        "            self.conv1=nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "            self.conv1_d=nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        else:\n",
        "            raise \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64, 3)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
        "        self.layer3_1 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
        "        self.layer4_1 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
        "\n",
        "        self.inplanes = 512\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x1 = self.layer3_1(x)\n",
        "        x1 = self.layer4_1(x1)\n",
        "\n",
        "        return x1, x1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eval Dataset"
      ],
      "metadata": {
        "id": "dOJNz-jmt_8t"
      },
      "id": "dOJNz-jmt_8t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0d700f",
      "metadata": {
        "id": "ea0d700f"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "class EvalDataset(data.Dataset):\n",
        "    def __init__(self, img_root, label_root):\n",
        "        \n",
        "        self.image_path = list(map(lambda x: os.path.join(img_root, x), sorted(os.listdir(img_root))))\n",
        "        self.label_path = list(map(lambda x: os.path.join(label_root, x), sorted(os.listdir(label_root))))\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        pred = Image.open(self.image_path[item]).convert('L')\n",
        "\n",
        "        gt = Image.open(self.label_path[item]).convert('L')\n",
        "        # print(self.image_path[item], self.label_path[item])\n",
        "        if pred.size != gt.size:\n",
        "            pred = pred.resize(gt.size, Image.BILINEAR)\n",
        "        return pred, gt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EVAL Fun"
      ],
      "metadata": {
        "id": "Jh8YLwd1uQ98"
      },
      "id": "Jh8YLwd1uQ98"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85ca25c",
      "metadata": {
        "id": "f85ca25c"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Sep 29 17:21:18 2020\n",
        "\n",
        "@author: taozhou\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "## basic funcs\n",
        "###############################################################################\n",
        "\n",
        "def fun_eval_e(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        score = torch.zeros(num).cuda()\n",
        "    else:\n",
        "        score = torch.zeros(num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        \n",
        "        fm = y_pred - y_pred.mean()\n",
        "        gt = y - y.mean()\n",
        "        align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "        enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "        score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)        \n",
        "    return score.max()\n",
        "\n",
        "\n",
        "def fun_eval_pr(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "    else:\n",
        "        prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        y_temp = (y_pred >= thlist[i]).float()\n",
        "        tp = (y_temp * y).sum()\n",
        "        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "    return prec, recall\n",
        "    \n",
        "\n",
        "def fun_S_object(pred, gt):\n",
        "        \n",
        "    fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "    bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "    o_fg = fun_object(fg, gt)\n",
        "    o_bg = fun_object(bg, 1-gt)\n",
        "    u = gt.mean()\n",
        "    Q = u * o_fg + (1-u) * o_bg\n",
        "    return Q\n",
        "\n",
        "\n",
        "def fun_object(pred, gt):\n",
        "    \n",
        "    temp = pred[gt == 1]\n",
        "    x = temp.mean()\n",
        "    sigma_x = temp.std()\n",
        "    score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "    return score\n",
        "\n",
        "\n",
        "def fun_S_region(pred, gt):\n",
        "    \n",
        "    X, Y = fun_centroid(gt)\n",
        "    gt1, gt2, gt3, gt4, w1, w2, w3, w4 = fun_divideGT(gt, X, Y)\n",
        "    p1, p2, p3, p4 = fun_dividePrediction(pred, X, Y)\n",
        "    Q1 = fun_ssim(p1, gt1)\n",
        "    Q2 = fun_ssim(p2, gt2)\n",
        "    Q3 = fun_ssim(p3, gt3)\n",
        "    Q4 = fun_ssim(p4, gt4)\n",
        "    Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "    \n",
        "    return Q\n",
        "    \n",
        "def fun_centroid(gt, cuda=True):\n",
        "    \n",
        "    rows, cols = gt.size()[-2:]\n",
        "    gt = gt.view(rows, cols)\n",
        "    \n",
        "    if gt.sum() == 0:\n",
        "        \n",
        "        if cuda:\n",
        "            X = torch.eye(1).cuda() * round(cols / 2)\n",
        "            Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "        else:\n",
        "            X = torch.eye(1) * round(cols / 2)\n",
        "            Y = torch.eye(1) * round(rows / 2)\n",
        "    \n",
        "    else:\n",
        "        total = gt.sum()\n",
        "        \n",
        "        if cuda:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "        else:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            \n",
        "        X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "        Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        \n",
        "    return X.long(), Y.long()\n",
        "  \n",
        "    \n",
        "def fun_divideGT(gt, X, Y):\n",
        "    \n",
        "    h, w = gt.size()[-2:]\n",
        "    area = h*w\n",
        "    gt   = gt.view(h, w)\n",
        "    LT   = gt[:Y, :X]\n",
        "    RT   = gt[:Y, X:w]\n",
        "    LB   = gt[Y:h, :X]\n",
        "    RB   = gt[Y:h, X:w]\n",
        "    X    = X.float()\n",
        "    Y    = Y.float()\n",
        "    w1   = X * Y / area\n",
        "    w2   = (w - X) * Y / area\n",
        "    w3   = X * (h - Y) / area\n",
        "    w4   = 1 - w1 - w2 - w3\n",
        "    \n",
        "    return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "def fun_dividePrediction(pred, X, Y):\n",
        "    \n",
        "    h, w = pred.size()[-2:]\n",
        "    pred = pred.view(h, w)\n",
        "    LT = pred[:Y, :X]\n",
        "    RT = pred[:Y, X:w]\n",
        "    LB = pred[Y:h, :X]\n",
        "    RB = pred[Y:h, X:w]\n",
        "        \n",
        "    return LT, RT, LB, RB\n",
        "\n",
        "\n",
        "def fun_ssim(pred, gt):\n",
        "    \n",
        "    gt       = gt.float()\n",
        "    h, w     = pred.size()[-2:]\n",
        "    N        = h*w\n",
        "    x        = pred.mean()\n",
        "    y        = gt.mean()\n",
        "    sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "    aplha = 4 * x * y *sigma_xy\n",
        "    beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "    \n",
        "    if aplha != 0:\n",
        "        Q = aplha / (beta + 1e-20)\n",
        "    elif aplha == 0 and beta == 0:\n",
        "        Q = 1.0\n",
        "    else:\n",
        "        Q = 0\n",
        "    \n",
        "    return Q\n",
        "\n",
        "###############################################################################\n",
        "## metric funcs\n",
        "###############################################################################\n",
        "def eval_mae(pred,gt,cuda=True):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "#        else:\n",
        "#            pred = trans(pred)\n",
        "#            gt = trans(gt)\n",
        "                \n",
        "        mae = torch.abs(pred - gt).mean()\n",
        "        \n",
        "    return mae.cpu().detach().numpy()\n",
        "                \n",
        "\n",
        "def eval_Smeasure(pred,gt,cuda=True):\n",
        "    \n",
        "    alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "\n",
        "        \n",
        "        y = gt.mean()\n",
        "        \n",
        "        ##\n",
        "        if y == 0:\n",
        "            x = pred.mean()\n",
        "            Q = 1.0 - x\n",
        "        elif y == 1:\n",
        "            x = pred.mean()\n",
        "            Q = x\n",
        "        else:\n",
        "            Q = alpha * fun_S_object(pred, gt) + (1-alpha) * fun_S_region(pred, gt)\n",
        "            if Q.item() < 0:\n",
        "                Q = torch.FLoatTensor([0.0])\n",
        "                \n",
        "    return Q.item()\n",
        "\n",
        "                \n",
        "def eval_fmeasure(pred, gt, cuda=True):\n",
        "    print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "    \n",
        "    beta2 = 0.3\n",
        "    avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "    \n",
        "    ##    \n",
        "    with torch.no_grad():\n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        if cuda:\n",
        "            pred = trans(pred).cuda()\n",
        "            gt = trans(gt).cuda()\n",
        "        else:\n",
        "            pred = trans(pred)\n",
        "            gt = trans(gt)\n",
        "                \n",
        "        prec, recall = fun_eval_pr(pred, gt, 255)\n",
        "\n",
        "    return prec, recall\n",
        "              \n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        return mae,s\n",
        "        \n",
        "        #max_f = self.Eval_fmeasure()\n",
        "        #max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    \n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Evaluater"
      ],
      "metadata": {
        "id": "YBlVUwChuigX"
      },
      "id": "YBlVUwChuigX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f7b939",
      "metadata": {
        "id": "d8f7b939"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        \n",
        "        \n",
        "        max_f = self.Eval_fmeasure()\n",
        "        max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        return mae,s,max_f,max_e\n",
        "    \n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        #print('eval[MAE]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_mae, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e.item()\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Start From here"
      ],
      "metadata": {
        "id": "Yi0B7EXmtiVb"
      },
      "id": "Yi0B7EXmtiVb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3846c946",
      "metadata": {
        "id": "3846c946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687e4689-532a-4f41-87f0-af5ea4adce9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.5.1-py2.py3-none-any.whl (125 kB)\n",
            "\u001b[K     |████████████████████████████████| 125 kB 7.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.6)\n",
            "Requirement already satisfied: protobuf<=3.20.1,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf<=3.20.1,>=3.8.0->tensorboardX) (1.15.0)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.5.1\n"
          ]
        }
      ],
      "source": [
        "#train\n",
        "!pip install tensorboardX --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/TrainDataset_update.zip\", 'r') (depth_art_less)\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/traindataset.zip\", 'r') (depth_more_art)\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/traindataset_only_depth.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "aBtOfacIz2qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1d5d5e7-9279-4959-e27c-4c24925230df"
      },
      "id": "aBtOfacIz2qa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/TestDataset_update.zip\", 'r') (depth_art_less)\n",
        "#zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/testdataset.zip\", 'r')\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/testdataset_only_depth.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "kgP-kzKD48IW"
      },
      "id": "kgP-kzKD48IW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rest2Net model"
      ],
      "metadata": {
        "id": "T7c0BF7hggkP"
      },
      "id": "T7c0BF7hggkP"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9NJ4zYYPgevn"
      },
      "id": "9NJ4zYYPgevn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068f0375",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "068f0375",
        "outputId": "ada6ea7c-c37b-492e-ead5-35948f8334ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "__all__ = ['Res2Net', 'res2net50_v1b', 'res2net101_v1b']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'res2net50_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth',\n",
        "    'res2net101_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net101_v1b_26w_4s-0812c246.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Bottle2neck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale = 4, stype='normal'):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            inplanes: input channel dimensionality\n",
        "            planes: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            downsample: None when stride = 1\n",
        "            baseWidth: basic width of conv3x3\n",
        "            scale: number of scale.\n",
        "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
        "        \"\"\"\n",
        "        super(Bottle2neck, self).__init__()\n",
        "\n",
        "        width = int(math.floor(planes * (baseWidth/64.0)))\n",
        "        self.conv1 = nn.Conv2d(inplanes, width*scale, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(width*scale)\n",
        "        \n",
        "        if scale == 1:\n",
        "          self.nums = 1\n",
        "        else:\n",
        "          self.nums = scale -1\n",
        "        if stype == 'stage':\n",
        "            self.pool = nn.AvgPool2d(kernel_size=3, stride = stride, padding=1)\n",
        "        convs = []\n",
        "        bns = []\n",
        "        for i in range(self.nums):\n",
        "          convs.append(nn.Conv2d(width, width, kernel_size=3, stride = stride, padding=1, bias=False))\n",
        "          bns.append(nn.BatchNorm2d(width))\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.bns = nn.ModuleList(bns)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(width*scale, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stype = stype\n",
        "        self.scale = scale\n",
        "        self.width  = width\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        spx = torch.split(out, self.width, 1)\n",
        "        for i in range(self.nums):\n",
        "          if i==0 or self.stype=='stage':\n",
        "            sp = spx[i]\n",
        "          else:\n",
        "            sp = sp + spx[i]\n",
        "          sp = self.convs[i](sp)\n",
        "          sp = self.relu(self.bns[i](sp))\n",
        "          if i==0:\n",
        "            out = sp\n",
        "          else:\n",
        "            out = torch.cat((out, sp), 1)\n",
        "        if self.scale != 1 and self.stype=='normal':\n",
        "          out = torch.cat((out, spx[self.nums]),1)\n",
        "        elif self.scale != 1 and self.stype=='stage':\n",
        "          out = torch.cat((out, self.pool(spx[self.nums])),1)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Res2Net(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net, self).__init__()\n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "        x5 = self.avgpool(x4)\n",
        "        x6 = x5.view(x5.size(0), -1)\n",
        "        x7 = self.fc(x6)\n",
        "\n",
        "        return x7\n",
        "\n",
        "\n",
        "\n",
        "class Res2Net_Ours(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net_Ours, self).__init__()\n",
        "        \n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "       \n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "\n",
        "        return x0,x1,x2,x3,x4\n",
        "    \n",
        "    \n",
        "\n",
        "def res2net50_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net152_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 8, 36, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net152_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "def Res2Net_model(ind=50):\n",
        "    \n",
        "    if ind == 50:\n",
        "        model_base = res2net50_v1b(pretrained=True)\n",
        "        model      = res2net50_v1b_Ours()\n",
        "\n",
        "    if ind == 101:\n",
        "        model_base = res2net101_v1b(pretrained=True)\n",
        "        model      = res2net101_v1b_Ours()\n",
        "        \n",
        "        \n",
        "    pretrained_dict = model_base.state_dict()\n",
        "    model_dict      = model.state_dict()\n",
        "    \n",
        "    pretrained_dict =  {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    \n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = torch.rand(1, 3, 352, 352)\n",
        "    model = res2net50_v1b_26w_4s(pretrained=False)\n",
        "    model = model\n",
        "    print(model(images).size())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SPNet Model"
      ],
      "metadata": {
        "id": "s4hii4cPtsxM"
      },
      "id": "s4hii4cPtsxM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe5d415",
      "metadata": {
        "id": "bbe5d415"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def maxpool():\n",
        "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    return pool\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
        "                              kernel_size=kernel_size, stride=stride,\n",
        "                              padding=padding, dilation=dilation, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#Global Contextual module\n",
        "class GCM(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(GCM, self).__init__()\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.branch0 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "        )\n",
        "        self.branch1 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=3, dilation=3)\n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 5), padding=(0, 2)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(5, 1), padding=(2, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=5, dilation=5)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=7, dilation=7)\n",
        "        )\n",
        "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
        "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.branch0(x)\n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "\n",
        "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
        "\n",
        "        x = self.relu(x_cat + self.conv_res(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "class CIM0(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM0, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "\n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "\n",
        "    def forward(self, rgb, depth):\n",
        "        \n",
        "        ################################\n",
        "        \n",
        "        x_rgb = self.layer_10(rgb)\n",
        "        x_dep = self.layer_20(depth)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb)\n",
        "        dep_w = nn.Sigmoid()(x_dep)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = rgb.mul(dep_w)\n",
        "        x_dep_w = depth.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + rgb\n",
        "        x_dep_r = x_dep_w + depth\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "         \n",
        "        return out1\n",
        "\n",
        "\n",
        "class CIM(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.reduc_1 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        self.reduc_2 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        self.layer_ful2 = nn.Sequential(nn.Conv2d(out_dim+out_dim//2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "\n",
        "    def forward(self, rgb, depth, xx):\n",
        "        \n",
        "        ################################\n",
        "        x_rgb = self.reduc_1(rgb)\n",
        "        x_dep = self.reduc_2(depth)\n",
        "        \n",
        "        x_rgb1 = self.layer_10(x_rgb)\n",
        "        x_dep1 = self.layer_20(x_dep)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb1)\n",
        "        dep_w = nn.Sigmoid()(x_dep1)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = x_rgb.mul(dep_w)\n",
        "        x_dep_w = x_dep.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + x_rgb\n",
        "        x_dep_r = x_dep_w + x_dep\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "        out2 = self.layer_ful2(torch.cat([out1,xx],dim=1))\n",
        "         \n",
        "        return out2\n",
        "\n",
        "\n",
        "\n",
        "class MFA(nn.Module):    \n",
        "    def __init__(self,in_dim):\n",
        "        super(MFA, self).__init__()\n",
        "         \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        self.layer_cat1 = nn.Sequential(nn.Conv2d(in_dim*2, in_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(in_dim),)        \n",
        "        \n",
        "    def forward(self, x_ful, x1, x2):\n",
        "        \n",
        "        ################################\n",
        "    \n",
        "        x_ful_1 = x_ful.mul(x1)\n",
        "        x_ful_2 = x_ful.mul(x2)\n",
        "        \n",
        "     \n",
        "        x_ful_w = self.layer_cat1(torch.cat([x_ful_1, x_ful_2],dim=1))\n",
        "        out     = self.relu(x_ful + x_ful_w)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "   \n",
        "###############################################################################\n",
        "\n",
        "class SPNet(nn.Module):\n",
        "    def __init__(self, channel=32,ind=50):\n",
        "        super(SPNet, self).__init__()\n",
        "        \n",
        "       \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.upsample_2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.upsample_4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        self.upsample_8 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        \n",
        "        #Backbone model\n",
        "        #Backbone model\n",
        "        self.layer_rgb  = Res2Net_model(ind)\n",
        "        self.layer_dep  = Res2Net_model(ind)\n",
        "        \n",
        "        self.layer_dep0 = nn.Conv2d(1, 3, kernel_size=1)\n",
        "        \n",
        "        ###############################################\n",
        "        # funsion encoders #\n",
        "        ###############################################\n",
        "        self.fu_0 = CIM0(64, 64)#\n",
        "        \n",
        "        self.fu_1 = CIM(256, 128) #MixedFusion_Block_IMfusion\n",
        "        self.pool_fu_1 = maxpool()\n",
        "        \n",
        "        self.fu_2 = CIM(512, 256)\n",
        "        self.pool_fu_2 = maxpool()\n",
        "        \n",
        "        self.fu_3 = CIM(1024, 512)\n",
        "        self.pool_fu_3 = maxpool()\n",
        "\n",
        "        self.fu_4 = CIM(2048, 1024)\n",
        "        self.pool_fu_4 = maxpool()\n",
        "        \n",
        "        \n",
        "        ###############################################\n",
        "        # decoders #\n",
        "        ###############################################\n",
        "        \n",
        "        ## rgb\n",
        "        self.rgb_conv_4   = nn.Sequential(BasicConv2d(2048,    256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.rgb_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.rgb_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.rgb_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.rgb_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.rgb_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## depth\n",
        "        self.dep_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.dep_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.dep_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.dep_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.dep_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.dep_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## fusion\n",
        "        self.ful_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_4    = GCM(1024,  channel)\n",
        "        \n",
        "        self.ful_conv_3   = nn.Sequential(BasicConv2d(1024+32*3, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_3    = GCM(512+32,  channel)\n",
        "\n",
        "        self.ful_conv_2   = nn.Sequential(BasicConv2d(512+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_2    = GCM(256+32,  channel)\n",
        "\n",
        "        self.ful_conv_1   = nn.Sequential(BasicConv2d(256+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_1    = GCM(128+32,  channel)\n",
        "\n",
        "        self.ful_conv_0   = nn.Sequential(BasicConv2d(128+32*3, 64, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.ful_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        self.ful_layer4   = MFA(channel)\n",
        "        self.ful_layer3   = MFA(channel)\n",
        "        self.ful_layer2   = MFA(channel)\n",
        "        self.ful_layer1   = MFA(channel)\n",
        "        self.ful_layer0   = MFA(channel)\n",
        "        \n",
        "                \n",
        "\n",
        "    def forward(self, imgs, depths):\n",
        "        \n",
        "        img_0, img_1, img_2, img_3, img_4 = self.layer_rgb(imgs)\n",
        "        dep_0, dep_1, dep_2, dep_3, dep_4 = self.layer_dep(self.layer_dep0(depths))\n",
        "        \n",
        "    \n",
        "      \n",
        "        ####################################################\n",
        "        ## fusion\n",
        "        ####################################################\n",
        "        ful_0    = self.fu_0(img_0, dep_0)\n",
        "        ful_1    = self.fu_1(img_1, dep_1, ful_0)\n",
        "        ful_2    = self.fu_2(img_2, dep_2, self.pool_fu_1(ful_1))\n",
        "        ful_3    = self.fu_3(img_3, dep_3, self.pool_fu_2(ful_2))\n",
        "        ful_4    = self.fu_4(img_4, dep_4, self.pool_fu_3(ful_3))\n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder rgb\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_rgb_42    = self.rgb_gcm_4(img_4)\n",
        "        \n",
        "        x_rgb_3_cat = torch.cat([img_3, self.upsample_2(x_rgb_42)], dim=1)\n",
        "        x_rgb_32    = self.rgb_gcm_3(x_rgb_3_cat)\n",
        "        \n",
        "        x_rgb_2_cat = torch.cat([img_2, self.upsample_2(x_rgb_32)], dim=1)\n",
        "        x_rgb_22    = self.rgb_gcm_2(x_rgb_2_cat)        \n",
        "\n",
        "        x_rgb_1_cat = torch.cat([img_1, self.upsample_2(x_rgb_22)], dim=1)\n",
        "        x_rgb_12    = self.rgb_gcm_1(x_rgb_1_cat)     \n",
        "\n",
        "        x_rgb_0_cat = torch.cat([img_0, x_rgb_12], dim=1)\n",
        "        x_rgb_02    = self.rgb_gcm_0(x_rgb_0_cat)     \n",
        "        rgb_out     = self.upsample_4(self.rgb_conv_out(x_rgb_02))\n",
        "        \n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder depth\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_dep_42    = self.dep_gcm_4(dep_4)\n",
        "        \n",
        "        x_dep_3_cat = torch.cat([dep_3, self.upsample_2(x_dep_42)], dim=1)\n",
        "        x_dep_32    = self.dep_gcm_3(x_dep_3_cat)\n",
        "        \n",
        "        x_dep_2_cat = torch.cat([dep_2, self.upsample_2(x_dep_32)], dim=1)\n",
        "        x_dep_22    = self.dep_gcm_2(x_dep_2_cat)        \n",
        "\n",
        "        x_dep_1_cat = torch.cat([dep_1, self.upsample_2(x_dep_22)], dim=1)\n",
        "        x_dep_12    = self.dep_gcm_1(x_dep_1_cat)     \n",
        "\n",
        "        x_dep_0_cat = torch.cat([dep_0, x_dep_12], dim=1)\n",
        "        x_dep_02    = self.dep_gcm_0(x_dep_0_cat)     \n",
        "        dep_out     = self.upsample_4(self.dep_conv_out(x_dep_02))\n",
        "        \n",
        "\n",
        "        ####################################################\n",
        "        ## decoder fusion\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_ful_42    = self.ful_gcm_4(ful_4)\n",
        "        \n",
        "        x_ful_3_cat = torch.cat([ful_3, self.ful_layer3(self.upsample_2(x_ful_42),self.upsample_2(x_rgb_42),self.upsample_2(x_dep_42))], dim=1)\n",
        "        x_ful_32    = self.ful_gcm_3(x_ful_3_cat)\n",
        "        \n",
        "        x_ful_2_cat = torch.cat([ful_2, self.ful_layer2(self.upsample_2(x_ful_32),self.upsample_2(x_rgb_32),self.upsample_2(x_dep_32))], dim=1)\n",
        "        x_ful_22    = self.ful_gcm_2(x_ful_2_cat)        \n",
        "\n",
        "        x_ful_1_cat = torch.cat([ful_1, self.ful_layer1(self.upsample_2(x_ful_22),self.upsample_2(x_rgb_22),self.upsample_2(x_dep_22))], dim=1)\n",
        "        x_ful_12    = self.ful_gcm_1(x_ful_1_cat)     \n",
        "\n",
        "        x_ful_0_cat = torch.cat([ful_0, self.ful_layer0(x_ful_12, x_rgb_12, x_dep_12)], dim=1)\n",
        "        x_ful_02    = self.ful_gcm_0(x_ful_0_cat)     \n",
        "        ful_out     = self.upsample_4(self.ful_conv_out(x_ful_02))\n",
        "\n",
        "\n",
        "        return rgb_out, dep_out, ful_out\n",
        "    \n",
        "    \n",
        "\n",
        "    def _make_agant_layer(self, inplanes, planes):\n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, planes, kernel_size=1,\n",
        "                      stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return layers\n",
        "\n",
        "    def _make_transpose(self, block, planes, blocks, stride=1):\n",
        "        upsample = None\n",
        "        if stride != 1:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.inplanes, planes,\n",
        "                                   kernel_size=2, stride=stride,\n",
        "                                   padding=0, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        elif self.inplanes != planes:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, self.inplanes))\n",
        "\n",
        "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
        "        self.inplanes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "   \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Preparation"
      ],
      "metadata": {
        "id": "058fmV_VtzGY"
      },
      "id": "058fmV_VtzGY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d4d20a",
      "metadata": {
        "id": "e8d4d20a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "#several data augumentation strategies\n",
        "def cv_random_flip(img, label,depth):\n",
        "    flip_flag = random.randint(0, 1)\n",
        "    # flip_flag2= random.randint(0,1)\n",
        "    #left right flip\n",
        "    if flip_flag == 1:\n",
        "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        depth = depth.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    #top bottom flip\n",
        "    # if flip_flag2==1:\n",
        "    #     img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     label = label.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     depth = depth.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    return img, label, depth\n",
        "def randomCrop(image, label,depth):\n",
        "    border=30\n",
        "    image_width = image.size[0]\n",
        "    image_height = image.size[1]\n",
        "    crop_win_width = np.random.randint(image_width-border , image_width)\n",
        "    crop_win_height = np.random.randint(image_height-border , image_height)\n",
        "    random_region = (\n",
        "        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n",
        "        (image_height + crop_win_height) >> 1)\n",
        "    return image.crop(random_region), label.crop(random_region),depth.crop(random_region)\n",
        "def randomRotation(image,label,depth):\n",
        "    mode=Image.BICUBIC\n",
        "    if random.random()>0.8:\n",
        "        random_angle = np.random.randint(-15, 15)\n",
        "        image=image.rotate(random_angle, mode)\n",
        "        label=label.rotate(random_angle, mode)\n",
        "        depth=depth.rotate(random_angle, mode)\n",
        "    return image,label,depth\n",
        "def colorEnhance(image):\n",
        "    bright_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Brightness(image).enhance(bright_intensity)\n",
        "    contrast_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Contrast(image).enhance(contrast_intensity)\n",
        "    color_intensity=random.randint(0,20)/10.0\n",
        "    image=ImageEnhance.Color(image).enhance(color_intensity)\n",
        "    sharp_intensity=random.randint(0,30)/10.0\n",
        "    image=ImageEnhance.Sharpness(image).enhance(sharp_intensity)\n",
        "    return image\n",
        "def randomGaussian(image, mean=0.1, sigma=0.35):\n",
        "    def gaussianNoisy(im, mean=mean, sigma=sigma):\n",
        "        for _i in range(len(im)):\n",
        "            im[_i] += random.gauss(mean, sigma)\n",
        "        return im\n",
        "    img = np.asarray(image)\n",
        "    width, height = img.shape\n",
        "    img = gaussianNoisy(img[:].flatten(), mean, sigma)\n",
        "    img = img.reshape([width, height])\n",
        "    return Image.fromarray(np.uint8(img))\n",
        "def randomPeper(img):\n",
        "\n",
        "    img=np.array(img)\n",
        "    noiseNum=int(0.0015*img.shape[0]*img.shape[1])\n",
        "    for i in range(noiseNum):\n",
        "\n",
        "        randX=random.randint(0,img.shape[0]-1)  \n",
        "\n",
        "        randY=random.randint(0,img.shape[1]-1)  \n",
        "\n",
        "        if random.randint(0,1)==0:  \n",
        "\n",
        "            img[randX,randY]=0  \n",
        "\n",
        "        else:  \n",
        "\n",
        "            img[randX,randY]=255 \n",
        "    return Image.fromarray(img)  \n",
        "\n",
        "# dataset for training\n",
        "#The current loader is not using the normalized depth maps for training and test. If you use the normalized depth maps\n",
        "#(e.g., 0 represents background and 1 represents foreground.), the performance will be further improved.\n",
        "\n",
        "class SalObjDataset(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                    or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        print('SalObjDat', )\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "        depth=self.binary_loader(self.depths[index])\n",
        "        image,gt,depth =cv_random_flip(image,gt,depth)\n",
        "        image,gt,depth=randomCrop(image, gt,depth)\n",
        "        image,gt,depth=randomRotation(image, gt,depth)\n",
        "        image=colorEnhance(image)\n",
        "        # gt=randomGaussian(gt)\n",
        "        gt=randomPeper(gt)\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "        depth=self.depths_transform(depth)\n",
        "        \n",
        "        return image, gt, depth\n",
        "\n",
        "    def filter_files(self):\n",
        "        print('SalObjDataset', self.images, self.gts)\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 0919\n",
        "#\n",
        "\n",
        "class SalObjDataset_var(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        \n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "\n",
        "class SalObjDataset_var_unlabel(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.png')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "#dataloader for training\n",
        "def get_loader(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "    print(image_root, gt_root, depth_root)\n",
        "    dataset = SalObjDataset(image_root, gt_root, depth_root,trainsize)\n",
        "    print(dataset)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#dataloader for training2\n",
        "## 09-19-2020\n",
        "def get_loader_var(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_loader_var_unlabel(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var_unlabel(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#test dataset and loader\n",
        "class test_dataset:\n",
        "    def __init__(self, image_root, gt_root,depth_root, testsize):\n",
        "        self.testsize = testsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                       or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((self.testsize, self.testsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.ToTensor()\n",
        "        # self.gt_transform = transforms.Compose([\n",
        "        #     transforms.Resize((self.trainsize, self.trainsize)),\n",
        "        #     transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.testsize, self.testsize)),transforms.ToTensor()])\n",
        "        self.size = len(self.images)\n",
        "        self.index = 0\n",
        "\n",
        "    def load_data(self):\n",
        "        image = self.rgb_loader(self.images[self.index])\n",
        "        image = self.transform(image).unsqueeze(0)\n",
        "        gt = self.binary_loader(self.gts[self.index])\n",
        "        depth=self.binary_loader(self.depths[self.index])\n",
        "        depth=self.depths_transform(depth).unsqueeze(0)\n",
        "        name = self.images[self.index].split('/')[-1]\n",
        "        image_for_post=self.rgb_loader(self.images[self.index])\n",
        "        image_for_post=image_for_post.resize(gt.size)\n",
        "        if name.endswith('.jpg'):\n",
        "            name = name.split('.jpg')[0] + '.png'\n",
        "        self.index += 1\n",
        "        self.index = self.index % self.size\n",
        "        return image, gt,depth, name,np.array(image_for_post)\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arguments"
      ],
      "metadata": {
        "id": "LUJnH8uehSdS"
      },
      "id": "LUJnH8uehSdS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9aaf3c",
      "metadata": {
        "id": "8b9aaf3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "def arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--epoch',       type=int,   default=500,   help='epoch number')\n",
        "  parser.add_argument('--lr',          type=float, default=1e-4,  help='learning rate')\n",
        "  parser.add_argument('--batchsize',   type=int,   default=4,    help='training batch size')\n",
        "  parser.add_argument('--trainsize',   type=int,   default=352,   help='training dataset size')\n",
        "  parser.add_argument('--clip',        type=float, default=0.5,   help='gradient clipping margin')\n",
        "  parser.add_argument('--lw',          type=float, default=0.001, help='weight')\n",
        "  parser.add_argument('--decay_rate',  type=float, default=0.1,   help='decay rate of learning rate')\n",
        "  parser.add_argument('--decay_epoch', type=int,   default=60,    help='every n epochs decay learning rate')\n",
        "  parser.add_argument('--load',        type=str,   default=None,  help='train from checkpoints')\n",
        "  parser.add_argument('--gpu_id',      type=str,   default='0',   help='train use gpu')\n",
        "\n",
        "  parser.add_argument('--rgb_label_root',      type=str, default='/content/tmp/traindataset_only_depth/RGB/',           help='the training rgb images root')\n",
        "  parser.add_argument('--depth_label_root',    type=str, default='/content/tmp/traindataset_only_depth/depth/',         help='the training depth images root')\n",
        "  parser.add_argument('--gt_label_root',       type=str, default='/content/tmp/traindataset_only_depth/GT/',            help='the training gt images root')\n",
        "\n",
        "  parser.add_argument('--val_rgb_root',        type=str, default='/content/tmp/testdataset_only_depth/NJU2K/RGB/',      help='the test rgb images root')\n",
        "  parser.add_argument('--val_depth_root',      type=str, default='/content/tmp/testdataset_only_depth/NJU2K/depth/',    help='the test depth images root')\n",
        "  parser.add_argument('--val_gt_root',         type=str, default='/content/tmp/testdataset_only_depth/NJU2K/GT/',       help='the test gt images root')\n",
        "\n",
        "  parser.add_argument('--save_path',           type=str, default='/content/drive/MyDrive/Checkpoint/SPNet_new/',    help='the path to save models and logs')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = arguments()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Arguments"
      ],
      "metadata": {
        "id": "7h0k91q6nmO5"
      },
      "id": "7h0k91q6nmO5"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import argparse\n",
        "\n",
        "def arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--epoch',       type=int,   default=50,   help='epoch number')\n",
        "  parser.add_argument('--lr',          type=float, default=1e-4,  help='learning rate')\n",
        "  parser.add_argument('--batchsize',   type=int,   default=4,    help='training batch size')\n",
        "  parser.add_argument('--trainsize',   type=int,   default=352,   help='training dataset size')\n",
        "  parser.add_argument('--clip',        type=float, default=0.5,   help='gradient clipping margin')\n",
        "  parser.add_argument('--lw',          type=float, default=0.001, help='weight')\n",
        "  parser.add_argument('--decay_rate',  type=float, default=0.1,   help='decay rate of learning rate')\n",
        "  parser.add_argument('--decay_epoch', type=int,   default=60,    help='every n epochs decay learning rate')\n",
        "  parser.add_argument('--load',        type=str,   default=None,  help='train from checkpoints')\n",
        "  parser.add_argument('--gpu_id',      type=str,   default='0',   help='train use gpu')\n",
        "\n",
        "  parser.add_argument('--rgb_label_root',      type=str, default='/content/tmp/traindataset_only_depth/RGB/',           help='the training rgb images root')\n",
        "  parser.add_argument('--depth_label_root',    type=str, default='/content/tmp/traindataset_only_depth/depth/',         help='the training depth images root')\n",
        "  parser.add_argument('--gt_label_root',       type=str, default='/content/tmp/traindataset_only_depth/GT/',            help='the training gt images root')\n",
        "\n",
        "  parser.add_argument('--val_rgb_root',        type=str, default='/content/tmp/testdataset_only_depth/NJU2K/RGB/',      help='the test rgb images root')\n",
        "  parser.add_argument('--val_depth_root',      type=str, default='/content/tmp/testdataset_only_depth/NJU2K/depth/',    help='the test depth images root')\n",
        "  parser.add_argument('--val_gt_root',         type=str, default='/content/tmp/testdataset_only_depth/NJU2K/GT/',       help='the test gt images root')\n",
        "\n",
        "  parser.add_argument('--save_path',           type=str, default='/content/drive/MyDrive/Checkpoint/SPNet_new/',    help='the path to save models and logs')\n",
        "  \n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = arguments()\n"
      ],
      "metadata": {
        "id": "q6JXXug0nfbf"
      },
      "id": "q6JXXug0nfbf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Util"
      ],
      "metadata": {
        "id": "Oa-0JCsFuqZ2"
      },
      "id": "Oa-0JCsFuqZ2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff850acd",
      "metadata": {
        "id": "ff850acd"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n",
        "    decay = decay_rate ** (epoch // decay_epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = decay*init_lr\n",
        "        lr=param_group['lr']\n",
        "    return lr\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install piq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HtLwuPELEqb",
        "outputId": "09ba6022-237c-4dfb-b3c5-0cbcde0cf675"
      },
      "id": "9HtLwuPELEqb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting piq\n",
            "  Downloading piq-0.7.0-py3-none-any.whl (139 kB)\n",
            "\u001b[K     |████████████████████████████████| 139 kB 8.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision!=0.9.*,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from piq) (0.12.0+cu113)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.11.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (4.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (3.0.4)\n",
            "Installing collected packages: piq\n",
            "Successfully installed piq-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PSNR:\n",
        "    \"\"\"Peak Signal to Noise Ratio\n",
        "    img1 and img2 have range [0, 255]\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.name = \"PSNR\"\n",
        "\n",
        "    @staticmethod\n",
        "    def __call__(img1, img2):\n",
        "        mse = torch.mean((img1 - img2) ** 2)\n",
        "        return 20 * torch.log10(255.0 / torch.sqrt(mse))"
      ],
      "metadata": {
        "id": "pApBbp9KS_Uw"
      },
      "id": "pApBbp9KS_Uw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Test Graph"
      ],
      "metadata": {
        "id": "YFUDrC8aYOI8"
      },
      "id": "YFUDrC8aYOI8"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "CE = torch.nn.MSELoss()\n",
        "ssim = PSNR()\n",
        "\n",
        "def perceptual_loss(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def perceptual_loss_detach(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask.detach())\n",
        "    return loss\n",
        "\n",
        "def combine_loss(mask, pred):\n",
        "    L1 = torch.nn.L1Loss()\n",
        "    L2 = torch.nn.SmoothL1Loss()\n",
        "    loss =  1.0 * ( L1(pred, mask) + L2(pred, mask))\n",
        "    return loss\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = ssim(gts, pre_res[0]) \n",
        "            loss2    = ssim(gts, pre_res[1])\n",
        "            loss3    = ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += gts.size(0)\n",
        "            total2 += gts.size(1)\n",
        "            total3 += gts.size(2)\n",
        "            correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            #correct1 += predicted1.eq(images).sum().item()\n",
        "            #correct2 += predicted2.eq(gts).sum().item()\n",
        "            #correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += float(torch.sum(predicted == image.data))\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_text_output_graph.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xvwwXLUtYM-N",
        "outputId": "4436699d-dd58-4526-f35c-f8aa7be6baaa"
      },
      "id": "xvwwXLUtYM-N",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f26d7253210>\n",
            "60\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-03 19:01:11.700726 Epoch [001/050], Step [0001/0060], Loss1: 50.1188 Loss2: 49.5087 Loss3: 55.1905\n",
            "2022-07-03 19:01:36.285043 Epoch [001/050], Step [0050/0060], Loss1: 38.1656 Loss2: 34.9522 Loss3: 37.1440\n",
            "2022-07-03 19:01:41.279283 Epoch [001/050], Step [0060/0060], Loss1: 37.8216 Loss2: 34.8546 Loss3: 36.5618\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.6291982668922061 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-07-03 19:01:46.992928 Epoch [002/050], Step [0001/0060], Loss1: 37.9492 Loss2: 34.8453 Loss3: 36.8983\n",
            "2022-07-03 19:02:11.539960 Epoch [002/050], Step [0050/0060], Loss1: 36.5174 Loss2: 34.1139 Loss3: 35.4222\n",
            "2022-07-03 19:02:16.522194 Epoch [002/050], Step [0060/0060], Loss1: 36.2639 Loss2: 33.9933 Loss3: 35.4493\n",
            "Epoch: 2 MAE: 0.5646302254490123 ####  bestMAE: 0.6291982668922061 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-07-03 19:02:24.653614 Epoch [003/050], Step [0001/0060], Loss1: 36.2599 Loss2: 34.0198 Loss3: 35.2720\n",
            "2022-07-03 19:02:49.214614 Epoch [003/050], Step [0050/0060], Loss1: 35.3469 Loss2: 33.3104 Loss3: 34.7746\n",
            "2022-07-03 19:02:54.194566 Epoch [003/050], Step [0060/0060], Loss1: 35.1668 Loss2: 33.1186 Loss3: 34.3918\n",
            "Epoch: 3 MAE: 0.46427753670505756 ####  bestMAE: 0.5646302254490123 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-07-03 19:03:04.492546 Epoch [004/050], Step [0001/0060], Loss1: 35.1766 Loss2: 33.1124 Loss3: 34.4595\n",
            "2022-07-03 19:03:29.011664 Epoch [004/050], Step [0050/0060], Loss1: 34.5554 Loss2: 32.5695 Loss3: 33.7740\n",
            "2022-07-03 19:03:33.995617 Epoch [004/050], Step [0060/0060], Loss1: 34.4539 Loss2: 32.4781 Loss3: 33.6496\n",
            "Epoch: 4 MAE: 0.4025644744388641 ####  bestMAE: 0.46427753670505756 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-07-03 19:03:42.204924 Epoch [005/050], Step [0001/0060], Loss1: 34.4258 Loss2: 32.4511 Loss3: 33.6201\n",
            "2022-07-03 19:04:06.690048 Epoch [005/050], Step [0050/0060], Loss1: 34.0292 Loss2: 31.9999 Loss3: 33.1780\n",
            "2022-07-03 19:04:11.671410 Epoch [005/050], Step [0060/0060], Loss1: 33.9071 Loss2: 31.9120 Loss3: 33.0824\n",
            "Epoch: 5 MAE: 0.5371459621853297 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "2022-07-03 19:04:19.806448 Epoch [006/050], Step [0001/0060], Loss1: 33.8523 Loss2: 31.9162 Loss3: 33.0372\n",
            "2022-07-03 19:04:44.337897 Epoch [006/050], Step [0050/0060], Loss1: 33.4629 Loss2: 31.4914 Loss3: 32.6516\n",
            "2022-07-03 19:04:49.316259 Epoch [006/050], Step [0060/0060], Loss1: 33.3321 Loss2: 31.4151 Loss3: 32.5376\n",
            "Epoch: 6 MAE: 0.4886197652261725 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "2022-07-03 19:04:55.184177 Epoch [007/050], Step [0001/0060], Loss1: 33.3597 Loss2: 31.4214 Loss3: 32.5553\n",
            "2022-07-03 19:05:21.103811 Epoch [007/050], Step [0050/0060], Loss1: 32.8831 Loss2: 31.0465 Loss3: 32.1654\n",
            "2022-07-03 19:05:26.089055 Epoch [007/050], Step [0060/0060], Loss1: 32.7715 Loss2: 30.9750 Loss3: 32.0617\n",
            "Epoch: 7 MAE: 0.4792733034002718 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "2022-07-03 19:05:31.904039 Epoch [008/050], Step [0001/0060], Loss1: 32.8591 Loss2: 31.0226 Loss3: 32.1443\n",
            "2022-07-03 19:05:56.372891 Epoch [008/050], Step [0050/0060], Loss1: 32.3111 Loss2: 30.6336 Loss3: 31.7011\n",
            "2022-07-03 19:06:01.372311 Epoch [008/050], Step [0060/0060], Loss1: 32.2237 Loss2: 30.5545 Loss3: 31.6401\n",
            "Epoch: 8 MAE: 0.4753295422104931 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "2022-07-03 19:06:07.151294 Epoch [009/050], Step [0001/0060], Loss1: 32.2282 Loss2: 30.5539 Loss3: 31.6334\n",
            "2022-07-03 19:06:31.688910 Epoch [009/050], Step [0050/0060], Loss1: 31.8168 Loss2: 30.2296 Loss3: 31.2811\n",
            "2022-07-03 19:06:36.676192 Epoch [009/050], Step [0060/0060], Loss1: 31.7437 Loss2: 30.1746 Loss3: 31.2138\n",
            "Epoch: 9 MAE: 0.412098456690551 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "2022-07-03 19:06:42.473524 Epoch [010/050], Step [0001/0060], Loss1: 31.7208 Loss2: 30.1557 Loss3: 31.2024\n",
            "2022-07-03 19:07:06.962049 Epoch [010/050], Step [0050/0060], Loss1: 31.3691 Loss2: 29.8493 Loss3: 30.8741\n",
            "2022-07-03 19:07:11.944760 Epoch [010/050], Step [0060/0060], Loss1: 31.3326 Loss2: 29.7927 Loss3: 30.8179\n",
            "Epoch: 10 MAE: 0.3575121767558748 ####  bestMAE: 0.4025644744388641 bestEpoch: 4\n",
            "best epoch:10\n",
            "2022-07-03 19:07:22.523258 Epoch [011/050], Step [0001/0060], Loss1: 31.3413 Loss2: 29.7859 Loss3: 30.8272\n",
            "2022-07-03 19:07:47.615003 Epoch [011/050], Step [0050/0060], Loss1: 30.9624 Loss2: 29.4756 Loss3: 30.4921\n",
            "2022-07-03 19:07:52.603553 Epoch [011/050], Step [0060/0060], Loss1: 30.8807 Loss2: 29.4149 Loss3: 30.4241\n",
            "Epoch: 11 MAE: 0.3769984153464988 ####  bestMAE: 0.3575121767558748 bestEpoch: 10\n",
            "2022-07-03 19:07:58.338418 Epoch [012/050], Step [0001/0060], Loss1: 30.9135 Loss2: 29.4156 Loss3: 30.4529\n",
            "2022-07-03 19:08:22.837239 Epoch [012/050], Step [0050/0060], Loss1: 30.5759 Loss2: 29.2152 Loss3: 30.1302\n",
            "2022-07-03 19:08:27.829172 Epoch [012/050], Step [0060/0060], Loss1: 30.4718 Loss2: 29.0824 Loss3: 30.0464\n",
            "Epoch: 12 MAE: 0.40199675100821036 ####  bestMAE: 0.3575121767558748 bestEpoch: 10\n",
            "2022-07-03 19:08:33.629091 Epoch [013/050], Step [0001/0060], Loss1: 30.4749 Loss2: 29.0841 Loss3: 30.0455\n",
            "2022-07-03 19:08:58.190520 Epoch [013/050], Step [0050/0060], Loss1: 30.1621 Loss2: 28.7899 Loss3: 29.7564\n",
            "2022-07-03 19:09:03.181756 Epoch [013/050], Step [0060/0060], Loss1: 30.1167 Loss2: 28.7565 Loss3: 29.7075\n",
            "Epoch: 13 MAE: 0.29346933536428615 ####  bestMAE: 0.3575121767558748 bestEpoch: 10\n",
            "best epoch:13\n",
            "2022-07-03 19:09:11.710809 Epoch [014/050], Step [0001/0060], Loss1: 30.1071 Loss2: 28.7331 Loss3: 29.6988\n",
            "2022-07-03 19:09:36.386073 Epoch [014/050], Step [0050/0060], Loss1: 29.8120 Loss2: 28.4471 Loss3: 29.4353\n",
            "2022-07-03 19:09:41.482959 Epoch [014/050], Step [0060/0060], Loss1: 29.7126 Loss2: 28.3895 Loss3: 29.3349\n",
            "Epoch: 14 MAE: 0.2725343647709598 ####  bestMAE: 0.29346933536428615 bestEpoch: 13\n",
            "best epoch:14\n",
            "2022-07-03 19:09:49.842576 Epoch [015/050], Step [0001/0060], Loss1: 29.6961 Loss2: 28.3810 Loss3: 29.3227\n",
            "2022-07-03 19:10:14.345010 Epoch [015/050], Step [0050/0060], Loss1: 29.4291 Loss2: 28.1281 Loss3: 29.0643\n",
            "2022-07-03 19:10:19.324456 Epoch [015/050], Step [0060/0060], Loss1: 29.3529 Loss2: 28.0635 Loss3: 28.9999\n",
            "Epoch: 15 MAE: 0.2743057745474356 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "2022-07-03 19:10:27.825953 Epoch [016/050], Step [0001/0060], Loss1: 29.3409 Loss2: 28.0597 Loss3: 28.9885\n",
            "2022-07-03 19:10:52.335805 Epoch [016/050], Step [0050/0060], Loss1: 29.0805 Loss2: 27.8452 Loss3: 28.7353\n",
            "2022-07-03 19:10:57.337970 Epoch [016/050], Step [0060/0060], Loss1: 29.0121 Loss2: 27.7655 Loss3: 28.6736\n",
            "Epoch: 16 MAE: 0.3994559507016782 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "2022-07-03 19:11:03.032249 Epoch [017/050], Step [0001/0060], Loss1: 28.9947 Loss2: 27.7548 Loss3: 28.6631\n",
            "2022-07-03 19:11:27.510384 Epoch [017/050], Step [0050/0060], Loss1: 28.7409 Loss2: 27.5103 Loss3: 28.4119\n",
            "2022-07-03 19:11:32.489555 Epoch [017/050], Step [0060/0060], Loss1: 28.6790 Loss2: 27.4512 Loss3: 28.3564\n",
            "Epoch: 17 MAE: 0.40345885806613485 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "2022-07-03 19:11:38.216520 Epoch [018/050], Step [0001/0060], Loss1: 28.6571 Loss2: 27.4363 Loss3: 28.3379\n",
            "2022-07-03 19:12:03.617513 Epoch [018/050], Step [0050/0060], Loss1: 28.3789 Loss2: 27.1941 Loss3: 28.0790\n",
            "2022-07-03 19:12:08.610194 Epoch [018/050], Step [0060/0060], Loss1: 28.3454 Loss2: 27.1557 Loss3: 28.0555\n",
            "Epoch: 18 MAE: 0.4979653698552854 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "2022-07-03 19:12:14.309332 Epoch [019/050], Step [0001/0060], Loss1: 28.3337 Loss2: 27.1527 Loss3: 28.0339\n",
            "2022-07-03 19:12:38.939278 Epoch [019/050], Step [0050/0060], Loss1: 28.0719 Loss2: 26.9117 Loss3: 27.7851\n",
            "2022-07-03 19:12:43.938107 Epoch [019/050], Step [0060/0060], Loss1: 27.9979 Loss2: 26.8521 Loss3: 27.7184\n",
            "Epoch: 19 MAE: 0.4454486822703527 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "2022-07-03 19:12:49.721223 Epoch [020/050], Step [0001/0060], Loss1: 27.9935 Loss2: 26.8457 Loss3: 27.7138\n",
            "2022-07-03 19:13:14.186509 Epoch [020/050], Step [0050/0060], Loss1: 27.7349 Loss2: 26.6138 Loss3: 27.4716\n",
            "2022-07-03 19:13:19.181215 Epoch [020/050], Step [0060/0060], Loss1: 27.7218 Loss2: 26.6071 Loss3: 27.4378\n",
            "Epoch: 20 MAE: 0.15817527730628927 ####  bestMAE: 0.2725343647709598 bestEpoch: 14\n",
            "best epoch:20\n",
            "2022-07-03 19:13:30.239719 Epoch [021/050], Step [0001/0060], Loss1: 27.6984 Loss2: 26.5634 Loss3: 27.4189\n",
            "2022-07-03 19:13:54.758552 Epoch [021/050], Step [0050/0060], Loss1: 27.4486 Loss2: 26.3498 Loss3: 27.1948\n",
            "2022-07-03 19:13:59.797050 Epoch [021/050], Step [0060/0060], Loss1: 27.3973 Loss2: 26.2991 Loss3: 27.1478\n",
            "Epoch: 21 MAE: 0.14163955587558644 ####  bestMAE: 0.15817527730628927 bestEpoch: 20\n",
            "best epoch:21\n",
            "2022-07-03 19:14:10.483574 Epoch [022/050], Step [0001/0060], Loss1: 27.3747 Loss2: 26.2847 Loss3: 27.1282\n",
            "2022-07-03 19:14:34.974758 Epoch [022/050], Step [0050/0060], Loss1: 27.1618 Loss2: 26.0870 Loss3: 26.9227\n",
            "2022-07-03 19:14:39.953186 Epoch [022/050], Step [0060/0060], Loss1: 27.0826 Loss2: 26.0329 Loss3: 26.8488\n",
            "Epoch: 22 MAE: 0.20588205044862457 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:14:45.579477 Epoch [023/050], Step [0001/0060], Loss1: 27.0942 Loss2: 26.0378 Loss3: 26.8574\n",
            "2022-07-03 19:15:10.151623 Epoch [023/050], Step [0050/0060], Loss1: 26.8372 Loss2: 25.8027 Loss3: 26.6172\n",
            "2022-07-03 19:15:15.147496 Epoch [023/050], Step [0060/0060], Loss1: 26.7947 Loss2: 25.7558 Loss3: 26.5748\n",
            "Epoch: 23 MAE: 0.18010732741582963 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:15:20.749674 Epoch [024/050], Step [0001/0060], Loss1: 26.7851 Loss2: 25.7600 Loss3: 26.5659\n",
            "2022-07-03 19:15:45.276386 Epoch [024/050], Step [0050/0060], Loss1: 26.5720 Loss2: 25.5361 Loss3: 26.3521\n",
            "2022-07-03 19:15:50.307187 Epoch [024/050], Step [0060/0060], Loss1: 26.5066 Loss2: 25.4924 Loss3: 26.3016\n",
            "Epoch: 24 MAE: 0.17738834037982604 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:15:55.967090 Epoch [025/050], Step [0001/0060], Loss1: 26.5065 Loss2: 25.5059 Loss3: 26.2996\n",
            "2022-07-03 19:16:20.650314 Epoch [025/050], Step [0050/0060], Loss1: 26.2748 Loss2: 25.2838 Loss3: 26.0796\n",
            "2022-07-03 19:16:25.696131 Epoch [025/050], Step [0060/0060], Loss1: 26.2312 Loss2: 25.2374 Loss3: 26.0365\n",
            "Epoch: 25 MAE: 0.30064820506585355 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:16:33.602403 Epoch [026/050], Step [0001/0060], Loss1: 26.2249 Loss2: 25.2333 Loss3: 26.0310\n",
            "2022-07-03 19:16:58.131739 Epoch [026/050], Step [0050/0060], Loss1: 26.0041 Loss2: 25.0321 Loss3: 25.8190\n",
            "2022-07-03 19:17:03.121231 Epoch [026/050], Step [0060/0060], Loss1: 25.9594 Loss2: 24.9855 Loss3: 25.7765\n",
            "Epoch: 26 MAE: 0.2803746032714843 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:17:08.703335 Epoch [027/050], Step [0001/0060], Loss1: 25.9557 Loss2: 24.9841 Loss3: 25.7727\n",
            "2022-07-03 19:17:33.191757 Epoch [027/050], Step [0050/0060], Loss1: 25.7390 Loss2: 24.7843 Loss3: 25.5654\n",
            "2022-07-03 19:17:38.179110 Epoch [027/050], Step [0060/0060], Loss1: 25.6987 Loss2: 24.7479 Loss3: 25.5275\n",
            "Epoch: 27 MAE: 0.21448174794514982 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:17:43.783707 Epoch [028/050], Step [0001/0060], Loss1: 25.6914 Loss2: 24.7365 Loss3: 25.5192\n",
            "2022-07-03 19:18:08.305406 Epoch [028/050], Step [0050/0060], Loss1: 25.4769 Loss2: 24.5429 Loss3: 25.3146\n",
            "2022-07-03 19:18:13.294516 Epoch [028/050], Step [0060/0060], Loss1: 25.4618 Loss2: 24.5113 Loss3: 25.2863\n",
            "Epoch: 28 MAE: 0.33655625863050037 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:18:18.875632 Epoch [029/050], Step [0001/0060], Loss1: 25.4310 Loss2: 24.4974 Loss3: 25.2666\n",
            "2022-07-03 19:18:43.701197 Epoch [029/050], Step [0050/0060], Loss1: 25.2260 Loss2: 24.3016 Loss3: 25.0702\n",
            "2022-07-03 19:18:48.681354 Epoch [029/050], Step [0060/0060], Loss1: 25.2154 Loss2: 24.2751 Loss3: 25.0460\n",
            "Epoch: 29 MAE: 0.44086302439371744 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:18:54.344160 Epoch [030/050], Step [0001/0060], Loss1: 25.1771 Loss2: 24.2625 Loss3: 25.0242\n",
            "2022-07-03 19:19:18.837881 Epoch [030/050], Step [0050/0060], Loss1: 24.9760 Loss2: 24.0870 Loss3: 24.8313\n",
            "2022-07-03 19:19:23.824123 Epoch [030/050], Step [0060/0060], Loss1: 24.9298 Loss2: 24.0302 Loss3: 24.7874\n",
            "Epoch: 30 MAE: 0.3750628070730381 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:19:31.856885 Epoch [031/050], Step [0001/0060], Loss1: 24.9572 Loss2: 24.0389 Loss3: 24.8003\n",
            "2022-07-03 19:19:56.346288 Epoch [031/050], Step [0050/0060], Loss1: 24.7295 Loss2: 23.8459 Loss3: 24.5944\n",
            "2022-07-03 19:20:01.321448 Epoch [031/050], Step [0060/0060], Loss1: 24.7027 Loss2: 23.8147 Loss3: 24.5660\n",
            "Epoch: 31 MAE: 0.273376655982285 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:20:06.937135 Epoch [032/050], Step [0001/0060], Loss1: 24.7022 Loss2: 23.8161 Loss3: 24.5707\n",
            "2022-07-03 19:20:31.408899 Epoch [032/050], Step [0050/0060], Loss1: 24.4889 Loss2: 23.6218 Loss3: 24.3626\n",
            "2022-07-03 19:20:36.449687 Epoch [032/050], Step [0060/0060], Loss1: 24.4744 Loss2: 23.5844 Loss3: 24.3243\n",
            "Epoch: 32 MAE: 0.3323908978416806 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:20:43.135211 Epoch [033/050], Step [0001/0060], Loss1: 24.4456 Loss2: 23.5794 Loss3: 24.3203\n",
            "2022-07-03 19:21:07.669972 Epoch [033/050], Step [0050/0060], Loss1: 24.2502 Loss2: 23.4026 Loss3: 24.1331\n",
            "2022-07-03 19:21:12.671080 Epoch [033/050], Step [0060/0060], Loss1: 24.2169 Loss2: 23.3683 Loss3: 24.0992\n",
            "Epoch: 33 MAE: 0.34116227266018967 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:21:18.400318 Epoch [034/050], Step [0001/0060], Loss1: 24.2098 Loss2: 23.3645 Loss3: 24.0933\n",
            "2022-07-03 19:21:42.874045 Epoch [034/050], Step [0050/0060], Loss1: 24.0173 Loss2: 23.1846 Loss3: 23.9099\n",
            "2022-07-03 19:21:47.860941 Epoch [034/050], Step [0060/0060], Loss1: 23.9825 Loss2: 23.1484 Loss3: 23.8745\n",
            "Epoch: 34 MAE: 0.27219661773197235 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:21:53.490396 Epoch [035/050], Step [0001/0060], Loss1: 23.9944 Loss2: 23.1493 Loss3: 23.8808\n",
            "2022-07-03 19:22:18.024249 Epoch [035/050], Step [0050/0060], Loss1: 23.7934 Loss2: 22.9745 Loss3: 23.6919\n",
            "2022-07-03 19:22:23.002491 Epoch [035/050], Step [0060/0060], Loss1: 23.7697 Loss2: 22.9346 Loss3: 23.6574\n",
            "Epoch: 35 MAE: 0.24844270736452143 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:22:30.852296 Epoch [036/050], Step [0001/0060], Loss1: 23.7596 Loss2: 22.9336 Loss3: 23.6582\n",
            "2022-07-03 19:22:55.639513 Epoch [036/050], Step [0050/0060], Loss1: 23.5725 Loss2: 22.7565 Loss3: 23.4778\n",
            "2022-07-03 19:23:00.623241 Epoch [036/050], Step [0060/0060], Loss1: 23.5536 Loss2: 22.7361 Loss3: 23.4564\n",
            "Epoch: 36 MAE: 0.4119297027587891 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:23:06.235482 Epoch [037/050], Step [0001/0060], Loss1: 23.5247 Loss2: 22.7271 Loss3: 23.4349\n",
            "2022-07-03 19:23:30.718773 Epoch [037/050], Step [0050/0060], Loss1: 23.3565 Loss2: 22.5527 Loss3: 23.2692\n",
            "2022-07-03 19:23:35.719121 Epoch [037/050], Step [0060/0060], Loss1: 23.3190 Loss2: 22.5163 Loss3: 23.2371\n",
            "Epoch: 37 MAE: 0.347389963947276 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:23:41.319262 Epoch [038/050], Step [0001/0060], Loss1: 23.3291 Loss2: 22.5206 Loss3: 23.2491\n",
            "2022-07-03 19:24:05.815460 Epoch [038/050], Step [0050/0060], Loss1: 23.1312 Loss2: 22.3445 Loss3: 23.0524\n",
            "2022-07-03 19:24:10.804366 Epoch [038/050], Step [0060/0060], Loss1: 23.0939 Loss2: 22.3140 Loss3: 23.0179\n",
            "Epoch: 38 MAE: 0.3257842301060912 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:24:16.386440 Epoch [039/050], Step [0001/0060], Loss1: 23.0910 Loss2: 22.3073 Loss3: 23.0127\n",
            "2022-07-03 19:24:40.865500 Epoch [039/050], Step [0050/0060], Loss1: 22.9351 Loss2: 22.1591 Loss3: 22.8699\n",
            "2022-07-03 19:24:45.856026 Epoch [039/050], Step [0060/0060], Loss1: 22.8864 Loss2: 22.1114 Loss3: 22.8146\n",
            "Epoch: 39 MAE: 0.37079290803778114 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:24:51.504335 Epoch [040/050], Step [0001/0060], Loss1: 22.8813 Loss2: 22.1067 Loss3: 22.8099\n",
            "2022-07-03 19:25:16.313449 Epoch [040/050], Step [0050/0060], Loss1: 22.7041 Loss2: 21.9485 Loss3: 22.6397\n",
            "2022-07-03 19:25:21.312050 Epoch [040/050], Step [0060/0060], Loss1: 22.6746 Loss2: 21.9112 Loss3: 22.6096\n",
            "Epoch: 40 MAE: 0.32025001566246053 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:25:29.438201 Epoch [041/050], Step [0001/0060], Loss1: 22.6820 Loss2: 21.9174 Loss3: 22.6155\n",
            "2022-07-03 19:25:53.953380 Epoch [041/050], Step [0050/0060], Loss1: 22.5148 Loss2: 21.7594 Loss3: 22.4525\n",
            "2022-07-03 19:25:58.942971 Epoch [041/050], Step [0060/0060], Loss1: 22.4671 Loss2: 21.7187 Loss3: 22.4098\n",
            "Epoch: 41 MAE: 0.33204359993102056 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:26:04.555570 Epoch [042/050], Step [0001/0060], Loss1: 22.4662 Loss2: 21.7177 Loss3: 22.4067\n",
            "2022-07-03 19:26:29.077410 Epoch [042/050], Step [0050/0060], Loss1: 22.3024 Loss2: 21.5719 Loss3: 22.2501\n",
            "2022-07-03 19:26:34.054970 Epoch [042/050], Step [0060/0060], Loss1: 22.2902 Loss2: 21.5457 Loss3: 22.2308\n",
            "Epoch: 42 MAE: 0.40143594812463834 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:26:39.806504 Epoch [043/050], Step [0001/0060], Loss1: 22.2739 Loss2: 21.5309 Loss3: 22.2194\n",
            "2022-07-03 19:27:04.268735 Epoch [043/050], Step [0050/0060], Loss1: 22.1140 Loss2: 21.3823 Loss3: 22.0622\n",
            "2022-07-03 19:27:09.431373 Epoch [043/050], Step [0060/0060], Loss1: 22.0778 Loss2: 21.3474 Loss3: 22.0253\n",
            "Epoch: 43 MAE: 0.31427816602918834 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:27:15.677140 Epoch [044/050], Step [0001/0060], Loss1: 22.0626 Loss2: 21.3399 Loss3: 22.0159\n",
            "2022-07-03 19:27:40.201206 Epoch [044/050], Step [0050/0060], Loss1: 21.9106 Loss2: 21.1850 Loss3: 21.8588\n",
            "2022-07-03 19:27:45.186627 Epoch [044/050], Step [0060/0060], Loss1: 21.8667 Loss2: 21.1554 Loss3: 21.8254\n",
            "Epoch: 44 MAE: 0.3226337029189661 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:27:50.775775 Epoch [045/050], Step [0001/0060], Loss1: 21.8758 Loss2: 21.1599 Loss3: 21.8325\n",
            "2022-07-03 19:28:15.288749 Epoch [045/050], Step [0050/0060], Loss1: 21.7151 Loss2: 21.0055 Loss3: 21.6723\n",
            "2022-07-03 19:28:20.274491 Epoch [045/050], Step [0060/0060], Loss1: 21.6756 Loss2: 20.9740 Loss3: 21.6406\n",
            "Epoch: 45 MAE: 0.32340554131401905 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:28:28.440204 Epoch [046/050], Step [0001/0060], Loss1: 21.6728 Loss2: 20.9752 Loss3: 21.6359\n",
            "2022-07-03 19:28:52.948689 Epoch [046/050], Step [0050/0060], Loss1: 21.5330 Loss2: 20.8356 Loss3: 21.4892\n",
            "2022-07-03 19:28:57.941989 Epoch [046/050], Step [0060/0060], Loss1: 21.4970 Loss2: 20.7897 Loss3: 21.4508\n",
            "Epoch: 46 MAE: 0.3003701721675814 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:29:03.680673 Epoch [047/050], Step [0001/0060], Loss1: 21.4826 Loss2: 20.7919 Loss3: 21.4525\n",
            "2022-07-03 19:29:28.469351 Epoch [047/050], Step [0050/0060], Loss1: 21.3326 Loss2: 20.6469 Loss3: 21.2952\n",
            "2022-07-03 19:29:33.465140 Epoch [047/050], Step [0060/0060], Loss1: 21.3021 Loss2: 20.6246 Loss3: 21.2738\n",
            "Epoch: 47 MAE: 0.3679620329034391 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:29:39.047956 Epoch [048/050], Step [0001/0060], Loss1: 21.2880 Loss2: 20.6132 Loss3: 21.2636\n",
            "2022-07-03 19:30:03.547067 Epoch [048/050], Step [0050/0060], Loss1: 21.1359 Loss2: 20.4662 Loss3: 21.1146\n",
            "2022-07-03 19:30:08.529830 Epoch [048/050], Step [0060/0060], Loss1: 21.1203 Loss2: 20.4505 Loss3: 21.0988\n",
            "Epoch: 48 MAE: 0.37749308752635163 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n",
            "2022-07-03 19:30:14.186767 Epoch [049/050], Step [0001/0060], Loss1: 21.1033 Loss2: 20.4393 Loss3: 21.0830\n",
            "2022-07-03 19:30:38.647469 Epoch [049/050], Step [0050/0060], Loss1: 20.9535 Loss2: 20.2987 Loss3: 20.9389\n",
            "2022-07-03 19:30:43.634561 Epoch [049/050], Step [0060/0060], Loss1: 20.9235 Loss2: 20.2662 Loss3: 20.9086\n",
            "Epoch: 49 MAE: 0.3808357561706866 ####  bestMAE: 0.14163955587558644 bestEpoch: 21\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-msssim\n",
        "from pytorch_msssim import ssim, ms_ssim, SSIM, MS_SSIM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dD8q2EO1jul_",
        "outputId": "b96abf81-8fa1-4591-b4af-7d98a40143df"
      },
      "id": "dD8q2EO1jul_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-msssim\n",
            "  Downloading pytorch_msssim-0.2.1-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-msssim) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-msssim) (4.1.1)\n",
            "Installing collected packages: pytorch-msssim\n",
            "Successfully installed pytorch-msssim-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "CE = torch.nn.MSELoss()\n",
        "\n",
        "def perceptual_loss(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def perceptual_loss_detach(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask.detach())\n",
        "    return loss\n",
        "\n",
        "def combine_loss(mask, pred):\n",
        "    L1 = torch.nn.L1Loss()\n",
        "    L2 = torch.nn.SmoothL1Loss()\n",
        "    loss =  1.0 * ( L1(pred, mask) + L2(pred, mask))\n",
        "    return loss\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = ms_ssim( gts, pre_res[0], data_range=255, size_average=True)\n",
        "            loss2    = ms_ssim(gts, pre_res[1], data_range=255, size_average=True)\n",
        "            loss3    = ms_ssim(gts, pre_res[2], data_range=255, size_average=True)\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.mean().backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += gts.size(0)\n",
        "            total2 += gts.size(1)\n",
        "            total3 += gts.size(2)\n",
        "            correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            #correct1 += predicted1.eq(images).sum().item()\n",
        "            #correct2 += predicted2.eq(gts).sum().item()\n",
        "            #correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += float(torch.sum(predicted == image.data))\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_text_output_graph.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eq6ad64djqd7",
        "outputId": "108dc74f-4378-4791-d767-2202ed9a9832"
      },
      "id": "eq6ad64djqd7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f271a5e6910>\n",
            "60\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-07-03 19:57:09.833444 Epoch [001/050], Step [0001/0060], Loss1: 0.9875 Loss2: 0.9585 Loss3: 0.9715\n",
            "2022-07-03 19:57:35.671219 Epoch [001/050], Step [0050/0060], Loss1: 0.8424 Loss2: 0.7166 Loss3: 0.7728\n",
            "2022-07-03 19:57:40.925751 Epoch [001/050], Step [0060/0060], Loss1: 0.7724 Loss2: 0.5153 Loss3: 0.5672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.6716934284835896 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-07-03 19:57:46.646471 Epoch [002/050], Step [0001/0060], Loss1: 0.7601 Loss2: 0.5273 Loss3: 0.5366\n",
            "2022-07-03 19:58:12.652358 Epoch [002/050], Step [0050/0060], Loss1: 0.6420 Loss2: 0.4726 Loss3: 0.4285\n",
            "2022-07-03 19:58:17.930445 Epoch [002/050], Step [0060/0060], Loss1: 0.8073 Loss2: 0.5071 Loss3: 0.7408\n",
            "Epoch: 2 MAE: 0.6503171640224559 ####  bestMAE: 0.6716934284835896 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-07-03 19:58:27.830867 Epoch [003/050], Step [0001/0060], Loss1: 0.7546 Loss2: 0.3726 Loss3: 0.5994\n",
            "2022-07-03 19:58:54.656771 Epoch [003/050], Step [0050/0060], Loss1: 0.7288 Loss2: 0.2975 Loss3: 0.5153\n",
            "2022-07-03 19:58:59.937942 Epoch [003/050], Step [0060/0060], Loss1: 0.7618 Loss2: 0.4599 Loss3: 0.6443\n",
            "Epoch: 3 MAE: 0.6324983021569628 ####  bestMAE: 0.6503171640224559 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-07-03 19:59:08.289638 Epoch [004/050], Step [0001/0060], Loss1: 0.8172 Loss2: 0.6305 Loss3: 0.7096\n",
            "2022-07-03 19:59:34.144370 Epoch [004/050], Step [0050/0060], Loss1: 0.5979 Loss2: 0.2980 Loss3: 0.3555\n",
            "2022-07-03 19:59:39.431198 Epoch [004/050], Step [0060/0060], Loss1: 0.5558 Loss2: 0.2038 Loss3: 0.3648\n",
            "Epoch: 4 MAE: 0.6411815736155032 ####  bestMAE: 0.6324983021569628 bestEpoch: 3\n",
            "2022-07-03 19:59:45.336469 Epoch [005/050], Step [0001/0060], Loss1: 0.5078 Loss2: 0.3061 Loss3: 0.4745\n",
            "2022-07-03 20:00:11.272664 Epoch [005/050], Step [0050/0060], Loss1: 0.5628 Loss2: 0.3117 Loss3: 0.4906\n",
            "2022-07-03 20:00:16.549458 Epoch [005/050], Step [0060/0060], Loss1: 0.6999 Loss2: 0.3183 Loss3: 0.5015\n",
            "Epoch: 5 MAE: 0.6036663745698475 ####  bestMAE: 0.6324983021569628 bestEpoch: 3\n",
            "best epoch:5\n",
            "2022-07-03 20:00:27.328854 Epoch [006/050], Step [0001/0060], Loss1: 0.5520 Loss2: 0.2945 Loss3: 0.3958\n",
            "2022-07-03 20:00:53.668778 Epoch [006/050], Step [0050/0060], Loss1: 0.6456 Loss2: 0.0000 Loss3: 0.3495\n",
            "2022-07-03 20:00:58.938684 Epoch [006/050], Step [0060/0060], Loss1: 0.6732 Loss2: 0.2801 Loss3: 0.4680\n",
            "Epoch: 6 MAE: 0.5866818931619956 ####  bestMAE: 0.6036663745698475 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-07-03 20:01:07.266511 Epoch [007/050], Step [0001/0060], Loss1: 0.3535 Loss2: 0.0000 Loss3: 0.1608\n",
            "2022-07-03 20:01:33.242656 Epoch [007/050], Step [0050/0060], Loss1: 0.3713 Loss2: 0.2176 Loss3: 0.3296\n",
            "2022-07-03 20:01:38.554363 Epoch [007/050], Step [0060/0060], Loss1: 0.5081 Loss2: 0.1283 Loss3: 0.3028\n",
            "Epoch: 7 MAE: 0.5511164920544497 ####  bestMAE: 0.5866818931619956 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-07-03 20:01:46.937846 Epoch [008/050], Step [0001/0060], Loss1: 0.5295 Loss2: 0.4169 Loss3: 0.6304\n",
            "2022-07-03 20:02:12.836251 Epoch [008/050], Step [0050/0060], Loss1: 0.6892 Loss2: 0.2534 Loss3: 0.3300\n",
            "2022-07-03 20:02:18.114275 Epoch [008/050], Step [0060/0060], Loss1: 0.5322 Loss2: 0.2637 Loss3: 0.3319\n",
            "Epoch: 8 MAE: 0.5207809900354459 ####  bestMAE: 0.5511164920544497 bestEpoch: 7\n",
            "best epoch:8\n",
            "2022-07-03 20:02:26.427814 Epoch [009/050], Step [0001/0060], Loss1: 0.5263 Loss2: 0.1389 Loss3: 0.3307\n",
            "2022-07-03 20:02:52.899264 Epoch [009/050], Step [0050/0060], Loss1: 0.3957 Loss2: 0.1632 Loss3: 0.1701\n",
            "2022-07-03 20:02:58.172741 Epoch [009/050], Step [0060/0060], Loss1: 0.3822 Loss2: 0.1573 Loss3: 0.1649\n",
            "Epoch: 9 MAE: 0.5540992268557271 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:03:04.023306 Epoch [010/050], Step [0001/0060], Loss1: 0.4663 Loss2: 0.1279 Loss3: 0.2836\n",
            "2022-07-03 20:03:29.979695 Epoch [010/050], Step [0050/0060], Loss1: 0.5240 Loss2: 0.0000 Loss3: 0.1362\n",
            "2022-07-03 20:03:35.253255 Epoch [010/050], Step [0060/0060], Loss1: 0.3113 Loss2: 0.0000 Loss3: 0.2720\n",
            "Epoch: 10 MAE: 0.5451279429279309 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:03:43.656372 Epoch [011/050], Step [0001/0060], Loss1: 0.4768 Loss2: 0.1080 Loss3: 0.2718\n",
            "2022-07-03 20:04:09.652848 Epoch [011/050], Step [0050/0060], Loss1: 0.4067 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:04:14.925368 Epoch [011/050], Step [0060/0060], Loss1: 0.3429 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 11 MAE: 0.5548117993874524 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:04:20.829181 Epoch [012/050], Step [0001/0060], Loss1: 0.3992 Loss2: 0.2627 Loss3: 0.1532\n",
            "2022-07-03 20:04:46.736659 Epoch [012/050], Step [0050/0060], Loss1: 0.3712 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:04:52.015328 Epoch [012/050], Step [0060/0060], Loss1: 0.3890 Loss2: 0.2319 Loss3: 0.1557\n",
            "Epoch: 12 MAE: 0.5468733215332032 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:04:58.355275 Epoch [013/050], Step [0001/0060], Loss1: 0.5633 Loss2: 0.3166 Loss3: 0.4057\n",
            "2022-07-03 20:05:24.535330 Epoch [013/050], Step [0050/0060], Loss1: 0.2769 Loss2: 0.0000 Loss3: 0.1187\n",
            "2022-07-03 20:05:29.814821 Epoch [013/050], Step [0060/0060], Loss1: 0.5016 Loss2: 0.1218 Loss3: 0.2465\n",
            "Epoch: 13 MAE: 0.5489175479626528 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:05:35.610574 Epoch [014/050], Step [0001/0060], Loss1: 0.2018 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:06:01.519945 Epoch [014/050], Step [0050/0060], Loss1: 0.4194 Loss2: 0.0000 Loss3: 0.1240\n",
            "2022-07-03 20:06:06.801984 Epoch [014/050], Step [0060/0060], Loss1: 0.3893 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 14 MAE: 0.5404824594971994 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:06:12.642265 Epoch [015/050], Step [0001/0060], Loss1: 0.3238 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:06:38.559704 Epoch [015/050], Step [0050/0060], Loss1: 0.1787 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:06:43.843660 Epoch [015/050], Step [0060/0060], Loss1: 0.1791 Loss2: 0.1290 Loss3: 0.1433\n",
            "Epoch: 15 MAE: 0.544637602952422 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:06:52.527135 Epoch [016/050], Step [0001/0060], Loss1: 0.3153 Loss2: 0.0000 Loss3: 0.1209\n",
            "2022-07-03 20:07:18.809444 Epoch [016/050], Step [0050/0060], Loss1: 0.1754 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:07:24.098108 Epoch [016/050], Step [0060/0060], Loss1: 0.1794 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 16 MAE: 0.5387628319149925 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:07:29.859625 Epoch [017/050], Step [0001/0060], Loss1: 0.1787 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:07:55.829079 Epoch [017/050], Step [0050/0060], Loss1: 0.3496 Loss2: 0.1505 Loss3: 0.0000\n",
            "2022-07-03 20:08:01.121153 Epoch [017/050], Step [0060/0060], Loss1: 0.3854 Loss2: 0.1518 Loss3: 0.1283\n",
            "Epoch: 17 MAE: 0.5326822504921565 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:08:06.926702 Epoch [018/050], Step [0001/0060], Loss1: 0.4706 Loss2: 0.0858 Loss3: 0.2169\n",
            "2022-07-03 20:08:32.998685 Epoch [018/050], Step [0050/0060], Loss1: 0.3518 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:08:38.279745 Epoch [018/050], Step [0060/0060], Loss1: 0.4630 Loss2: 0.1206 Loss3: 0.2494\n",
            "Epoch: 18 MAE: 0.5247590362710297 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "2022-07-03 20:08:44.086548 Epoch [019/050], Step [0001/0060], Loss1: 0.4703 Loss2: 0.0000 Loss3: 0.1130\n",
            "2022-07-03 20:09:10.042188 Epoch [019/050], Step [0050/0060], Loss1: 0.1824 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:09:15.319781 Epoch [019/050], Step [0060/0060], Loss1: 0.1828 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 19 MAE: 0.5194516871215172 ####  bestMAE: 0.5207809900354459 bestEpoch: 8\n",
            "best epoch:19\n",
            "2022-07-03 20:09:24.687524 Epoch [020/050], Step [0001/0060], Loss1: 0.1845 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:09:50.657691 Epoch [020/050], Step [0050/0060], Loss1: 0.3247 Loss2: 0.0000 Loss3: 0.0894\n",
            "2022-07-03 20:09:55.933361 Epoch [020/050], Step [0060/0060], Loss1: 0.3146 Loss2: 0.1193 Loss3: 0.1087\n",
            "Epoch: 20 MAE: 0.5199097559691735 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:10:04.064729 Epoch [021/050], Step [0001/0060], Loss1: 0.2565 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:10:30.045588 Epoch [021/050], Step [0050/0060], Loss1: 0.1712 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:10:35.325290 Epoch [021/050], Step [0060/0060], Loss1: 0.1676 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 21 MAE: 0.5256786907539167 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:10:41.096597 Epoch [022/050], Step [0001/0060], Loss1: 0.1669 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:11:07.055202 Epoch [022/050], Step [0050/0060], Loss1: 0.1682 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:11:12.328475 Epoch [022/050], Step [0060/0060], Loss1: 0.3858 Loss2: 0.1374 Loss3: 0.1284\n",
            "Epoch: 22 MAE: 0.5226005715667887 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:11:18.076134 Epoch [023/050], Step [0001/0060], Loss1: 0.3737 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:11:44.344512 Epoch [023/050], Step [0050/0060], Loss1: 0.1592 Loss2: 0.0000 Loss3: 0.1882\n",
            "2022-07-03 20:11:49.625167 Epoch [023/050], Step [0060/0060], Loss1: 0.1556 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 23 MAE: 0.5483131780069341 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:11:55.352618 Epoch [024/050], Step [0001/0060], Loss1: 0.1583 Loss2: 0.0000 Loss3: 0.1166\n",
            "2022-07-03 20:12:21.284190 Epoch [024/050], Step [0050/0060], Loss1: 0.1437 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:12:26.551429 Epoch [024/050], Step [0060/0060], Loss1: 0.1607 Loss2: 0.0000 Loss3: 0.0964\n",
            "Epoch: 24 MAE: 0.5316836911156065 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:12:32.319951 Epoch [025/050], Step [0001/0060], Loss1: 0.1497 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:12:58.284780 Epoch [025/050], Step [0050/0060], Loss1: 0.1432 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:13:03.560849 Epoch [025/050], Step [0060/0060], Loss1: 0.1434 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 25 MAE: 0.542616782213645 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:13:12.823663 Epoch [026/050], Step [0001/0060], Loss1: 0.2387 Loss2: 0.1092 Loss3: 0.1071\n",
            "2022-07-03 20:13:38.789163 Epoch [026/050], Step [0050/0060], Loss1: 0.1325 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:13:44.491969 Epoch [026/050], Step [0060/0060], Loss1: 0.2303 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 26 MAE: 0.5381469427845464 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:13:51.368753 Epoch [027/050], Step [0001/0060], Loss1: 0.1328 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:14:17.474653 Epoch [027/050], Step [0050/0060], Loss1: 0.1325 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:14:22.753557 Epoch [027/050], Step [0060/0060], Loss1: 0.1346 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 27 MAE: 0.5459050068527302 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:14:28.513728 Epoch [028/050], Step [0001/0060], Loss1: 0.1295 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:14:54.550557 Epoch [028/050], Step [0050/0060], Loss1: 0.1343 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:14:59.831863 Epoch [028/050], Step [0060/0060], Loss1: 0.1269 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 28 MAE: 0.536535404750279 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:15:05.565217 Epoch [029/050], Step [0001/0060], Loss1: 0.1288 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:15:31.489489 Epoch [029/050], Step [0050/0060], Loss1: 0.2665 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:15:36.773831 Epoch [029/050], Step [0060/0060], Loss1: 0.1252 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 29 MAE: 0.5380591692243304 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:15:42.540611 Epoch [030/050], Step [0001/0060], Loss1: 0.1220 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:16:08.848128 Epoch [030/050], Step [0050/0060], Loss1: 0.2441 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:16:14.131916 Epoch [030/050], Step [0060/0060], Loss1: 0.1235 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 30 MAE: 0.5377729514793113 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:16:23.043218 Epoch [031/050], Step [0001/0060], Loss1: 0.1215 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:16:48.956962 Epoch [031/050], Step [0050/0060], Loss1: 0.1172 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:16:54.237447 Epoch [031/050], Step [0060/0060], Loss1: 0.1167 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 31 MAE: 0.5342852056594122 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:16:59.887626 Epoch [032/050], Step [0001/0060], Loss1: 0.1184 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:17:25.804654 Epoch [032/050], Step [0050/0060], Loss1: 0.1097 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:17:31.095707 Epoch [032/050], Step [0060/0060], Loss1: 0.1180 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 32 MAE: 0.5406304762098525 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:17:36.809103 Epoch [033/050], Step [0001/0060], Loss1: 0.1097 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:18:02.799767 Epoch [033/050], Step [0050/0060], Loss1: 0.1090 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:18:08.407095 Epoch [033/050], Step [0060/0060], Loss1: 0.1094 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 33 MAE: 0.5393770514594185 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:18:15.620990 Epoch [034/050], Step [0001/0060], Loss1: 0.1086 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:18:41.573736 Epoch [034/050], Step [0050/0060], Loss1: 0.1038 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:18:46.861379 Epoch [034/050], Step [0060/0060], Loss1: 0.1019 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 34 MAE: 0.5317694939507378 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:18:52.602078 Epoch [035/050], Step [0001/0060], Loss1: 0.1018 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:19:18.573551 Epoch [035/050], Step [0050/0060], Loss1: 0.0996 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:19:23.864284 Epoch [035/050], Step [0060/0060], Loss1: 0.1022 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 35 MAE: 0.538278705253803 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:19:32.281765 Epoch [036/050], Step [0001/0060], Loss1: 0.0990 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:19:58.223544 Epoch [036/050], Step [0050/0060], Loss1: 0.0965 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:20:03.499482 Epoch [036/050], Step [0060/0060], Loss1: 0.0959 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 36 MAE: 0.5424209271789227 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:20:09.285365 Epoch [037/050], Step [0001/0060], Loss1: 0.0982 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:20:36.273447 Epoch [037/050], Step [0050/0060], Loss1: 0.0915 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:20:41.577600 Epoch [037/050], Step [0060/0060], Loss1: 0.0930 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 37 MAE: 0.5393156836777137 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:20:47.328289 Epoch [038/050], Step [0001/0060], Loss1: 0.0935 Loss2: 0.0000 Loss3: 0.1299\n",
            "2022-07-03 20:21:13.284289 Epoch [038/050], Step [0050/0060], Loss1: 0.0871 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:21:18.570851 Epoch [038/050], Step [0060/0060], Loss1: 0.0885 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 38 MAE: 0.5830170783794746 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:21:24.387133 Epoch [039/050], Step [0001/0060], Loss1: 0.0835 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:21:50.331443 Epoch [039/050], Step [0050/0060], Loss1: 0.0813 Loss2: 0.1118 Loss3: 0.1257\n",
            "2022-07-03 20:21:55.604586 Epoch [039/050], Step [0060/0060], Loss1: 0.2137 Loss2: 0.0929 Loss3: 0.1070\n",
            "Epoch: 39 MAE: 0.5887855925383391 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:22:01.374547 Epoch [040/050], Step [0001/0060], Loss1: 0.0834 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:22:27.690943 Epoch [040/050], Step [0050/0060], Loss1: 0.1764 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:22:33.047070 Epoch [040/050], Step [0060/0060], Loss1: 0.0799 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 40 MAE: 0.5810852712802786 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:22:41.072324 Epoch [041/050], Step [0001/0060], Loss1: 0.0792 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:23:07.058124 Epoch [041/050], Step [0050/0060], Loss1: 0.0779 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:23:12.347142 Epoch [041/050], Step [0060/0060], Loss1: 0.0778 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 41 MAE: 0.576781324759993 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "2022-07-03 20:23:18.133178 Epoch [042/050], Step [0001/0060], Loss1: 0.0822 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:23:44.039523 Epoch [042/050], Step [0050/0060], Loss1: 0.0770 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:23:49.316545 Epoch [042/050], Step [0060/0060], Loss1: 0.0752 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 42 MAE: 0.4825390964084202 ####  bestMAE: 0.5194516871215172 bestEpoch: 19\n",
            "best epoch:42\n",
            "2022-07-03 20:23:57.572768 Epoch [043/050], Step [0001/0060], Loss1: 0.0775 Loss2: 0.1198 Loss3: 0.1098\n",
            "2022-07-03 20:24:23.563971 Epoch [043/050], Step [0050/0060], Loss1: 0.0701 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:24:28.854444 Epoch [043/050], Step [0060/0060], Loss1: 0.0724 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 43 MAE: 0.4866684823818309 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:24:35.283522 Epoch [044/050], Step [0001/0060], Loss1: 0.0725 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:25:02.213346 Epoch [044/050], Step [0050/0060], Loss1: 0.0721 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:25:07.496223 Epoch [044/050], Step [0060/0060], Loss1: 0.0688 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 44 MAE: 0.4868002674567007 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:25:13.271815 Epoch [045/050], Step [0001/0060], Loss1: 0.0705 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:25:39.243115 Epoch [045/050], Step [0050/0060], Loss1: 0.0691 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:25:44.530713 Epoch [045/050], Step [0060/0060], Loss1: 0.0765 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 45 MAE: 0.4914845453494439 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:25:52.777741 Epoch [046/050], Step [0001/0060], Loss1: 0.0682 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:26:18.730641 Epoch [046/050], Step [0050/0060], Loss1: 0.0712 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:26:24.009244 Epoch [046/050], Step [0060/0060], Loss1: 0.0684 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 46 MAE: 0.49525035313197546 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:26:29.671879 Epoch [047/050], Step [0001/0060], Loss1: 0.0675 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:26:56.233674 Epoch [047/050], Step [0050/0060], Loss1: 0.0663 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:27:01.533367 Epoch [047/050], Step [0060/0060], Loss1: 0.0640 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 47 MAE: 0.486370871407645 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:27:07.224598 Epoch [048/050], Step [0001/0060], Loss1: 0.0714 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:27:33.135763 Epoch [048/050], Step [0050/0060], Loss1: 0.0593 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:27:38.414534 Epoch [048/050], Step [0060/0060], Loss1: 0.0616 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 48 MAE: 0.4899080629701967 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n",
            "2022-07-03 20:27:44.173326 Epoch [049/050], Step [0001/0060], Loss1: 0.0608 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:28:10.130397 Epoch [049/050], Step [0050/0060], Loss1: 0.0590 Loss2: 0.0000 Loss3: 0.0000\n",
            "2022-07-03 20:28:15.428406 Epoch [049/050], Step [0060/0060], Loss1: 0.0596 Loss2: 0.0000 Loss3: 0.0000\n",
            "Epoch: 49 MAE: 0.4898553071198638 ####  bestMAE: 0.4825390964084202 bestEpoch: 42\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/pytorch/pytorch.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9NBtChJy8Vy",
        "outputId": "e95fabd9-9f3e-4ae3-c786-1c4a5001b60a"
      },
      "id": "f9NBtChJy8Vy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/pytorch/pytorch.git\n",
            "  Cloning https://github.com/pytorch/pytorch.git to /tmp/pip-req-build-029alv_4\n",
            "  Running command git clone -q https://github.com/pytorch/pytorch.git /tmp/pip-req-build-029alv_4\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hcanceled\u001b[31mERROR: Operation cancelled by user\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install piq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sADANJNs2r0Y",
        "outputId": "f5618c7e-ab08-4358-fa41-d897b1517647"
      },
      "id": "sADANJNs2r0Y",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: piq in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
            "Requirement already satisfied: torchvision!=0.9.*,>=0.6.1 in /usr/local/lib/python3.7/dist-packages (from piq) (0.12.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (4.1.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (2.23.0)\n",
            "Requirement already satisfied: torch==1.11.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.11.0+cu113)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision!=0.9.*,>=0.6.1->piq) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision!=0.9.*,>=0.6.1->piq) (2022.6.15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import device\n",
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "from piq import LPIPS\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "CE = torch.nn.MSELoss()\n",
        "loss_fn_alex = LPIPS(replace_pooling = True, distance ='mse', reduction= 'mean', std= [0.229, 0.224, 0.225])\n",
        "\n",
        "def perceptual_loss(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def perceptual_loss_detach(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask.detach())\n",
        "    return loss\n",
        "\n",
        "def combine_loss(mask, pred):\n",
        "    L1 = torch.nn.L1Loss()\n",
        "    L2 = torch.nn.SmoothL1Loss()\n",
        "    loss =  1.0 * ( L1(pred, mask) + L2(pred, mask))\n",
        "    return loss\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            #loss1    = ms_ssim( gts, pre_res[0], data_range=255, size_average=True)\n",
        "            #loss2    = ms_ssim(gts, pre_res[1], data_range=255, size_average=True)\n",
        "            #loss3    = ms_ssim(gts, pre_res[2], data_range=255, size_average=True)\n",
        "            device = torch.device(\"cuda:0\")\n",
        "\n",
        "            loss1 = loss_fn_alex(gts, pre_res[0])\n",
        "            loss2 = loss_fn_alex(gts, pre_res[1])\n",
        "            loss3 = loss_fn_alex(gts, pre_res[2])\n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.mean().backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.data\n",
        "            running_loss2 += loss2.data\n",
        "            running_loss3 += loss3.data\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += gts.size(0)\n",
        "            total2 += gts.size(1)\n",
        "            total3 += gts.size(2)\n",
        "            correct1 += float(torch.sum(predicted1 == gts.data))\n",
        "            correct2 += float(torch.sum(predicted2 == gts.data))\n",
        "            correct3 += float(torch.sum(predicted3 == gts.data))\n",
        "            #correct1 += predicted1.eq(images).sum().item()\n",
        "            #correct2 += predicted2.eq(gts).sum().item()\n",
        "            #correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = torch.sum(gt + loss + predicted)\n",
        "            total += images.size(0)\n",
        "            correct += float(correct1 + correct2 + correct3)\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu1= correct1/total1\n",
        "        accu2= correct2/total2\n",
        "        accu3= correct3/total3 \n",
        "        accu = correct/total\n",
        "           \n",
        "        train_accu1.append(round(accu1, 3))\n",
        "        train_accu2.append(round(accu2, 3))\n",
        "        train_accu3.append(round(accu3, 3))\n",
        "        train_losses1.append(float(train_loss1))\n",
        "        train_losses2.append(float(train_loss2))\n",
        "        train_losses3.append(float(train_loss3))\n",
        "        train_accu.append(round(accu, 3))\n",
        "        train_losses.append(float(train_loss))\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0.0\n",
        "\n",
        "    correct1 = 0.0\n",
        "    correct2 = 0.0\n",
        "    correct3 = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            pre1, pre2, predicted = pre_res\n",
        "            #outputs = float(torch.sum(gt + depth + predicted))\n",
        "            total += test_loader.size\n",
        "\n",
        "            #correct1 += float(torch.sum(pre1 == image.data))\n",
        "            #correct2 += float(torch.sum(pre2 == image.data))\n",
        "            #correct3 += float(torch.sum(predicted == image.data))\n",
        "\n",
        "            correct += float(torch.sum(predicted == image.data))\n",
        "            #correct += float(torch.sum(predicted == image).item())\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu= 100 * correct/total\n",
        "        val_accu.append(round(accu, 3))\n",
        "        val_losses.append(float(val_loss))\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                #torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_text_output_graph.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('Acc')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-')\n",
        "plt.plot(val_accu,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LEaZ_2elxxRX",
        "outputId": "5052b141-d44f-4847-dba0-d2071813ecc2"
      },
      "id": "LEaZ_2elxxRX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f271a6bf350>\n",
            "60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start train...\n",
            "2022-07-03 21:40:57.956979 Epoch [001/050], Step [0001/0060], Loss1: 0.6784 Loss2: 0.6355 Loss3: 0.6483\n",
            "2022-07-03 21:41:39.620314 Epoch [001/050], Step [0050/0060], Loss1: 0.3825 Loss2: 0.4320 Loss3: 0.3618\n",
            "2022-07-03 21:41:48.037919 Epoch [001/050], Step [0060/0060], Loss1: 0.3634 Loss2: 0.4071 Loss3: 0.3374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.2610295906268731 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-07-03 21:41:54.654907 Epoch [002/050], Step [0001/0060], Loss1: 0.3468 Loss2: 0.4148 Loss3: 0.3259\n",
            "2022-07-03 21:42:36.042344 Epoch [002/050], Step [0050/0060], Loss1: 0.2598 Loss2: 0.3260 Loss3: 0.2094\n",
            "2022-07-03 21:42:44.633823 Epoch [002/050], Step [0060/0060], Loss1: 0.2499 Loss2: 0.3276 Loss3: 0.2183\n",
            "Epoch: 2 MAE: 0.35873245743847393 ####  bestMAE: 0.2610295906268731 bestEpoch: 0\n",
            "2022-07-03 21:42:51.238494 Epoch [003/050], Step [0001/0060], Loss1: 0.2563 Loss2: 0.3285 Loss3: 0.2133\n",
            "2022-07-03 21:43:32.815862 Epoch [003/050], Step [0050/0060], Loss1: 0.2271 Loss2: 0.2862 Loss3: 0.1720\n",
            "2022-07-03 21:43:41.237981 Epoch [003/050], Step [0060/0060], Loss1: 0.2080 Loss2: 0.2727 Loss3: 0.1575\n",
            "Epoch: 3 MAE: 0.463875329456632 ####  bestMAE: 0.2610295906268731 bestEpoch: 0\n",
            "2022-07-03 21:43:47.861527 Epoch [004/050], Step [0001/0060], Loss1: 0.2201 Loss2: 0.2824 Loss3: 0.1729\n",
            "2022-07-03 21:44:29.111155 Epoch [004/050], Step [0050/0060], Loss1: 0.1962 Loss2: 0.2529 Loss3: 0.1612\n",
            "2022-07-03 21:44:37.512981 Epoch [004/050], Step [0060/0060], Loss1: 0.1885 Loss2: 0.2473 Loss3: 0.1566\n",
            "Epoch: 4 MAE: 0.30079049549405534 ####  bestMAE: 0.2610295906268731 bestEpoch: 0\n",
            "2022-07-03 21:44:44.078822 Epoch [005/050], Step [0001/0060], Loss1: 0.1859 Loss2: 0.2325 Loss3: 0.1491\n",
            "2022-07-03 21:45:25.359976 Epoch [005/050], Step [0050/0060], Loss1: 0.1723 Loss2: 0.2220 Loss3: 0.1429\n",
            "2022-07-03 21:45:33.782528 Epoch [005/050], Step [0060/0060], Loss1: 0.1811 Loss2: 0.2315 Loss3: 0.1558\n",
            "Epoch: 5 MAE: 0.18712129259866378 ####  bestMAE: 0.2610295906268731 bestEpoch: 0\n",
            "best epoch:5\n",
            "2022-07-03 21:45:47.779059 Epoch [006/050], Step [0001/0060], Loss1: 0.1829 Loss2: 0.2433 Loss3: 0.1521\n",
            "2022-07-03 21:46:29.005700 Epoch [006/050], Step [0050/0060], Loss1: 0.1686 Loss2: 0.2220 Loss3: 0.1384\n",
            "2022-07-03 21:46:37.404080 Epoch [006/050], Step [0060/0060], Loss1: 0.1679 Loss2: 0.2078 Loss3: 0.1394\n",
            "Epoch: 6 MAE: 0.12429469729226734 ####  bestMAE: 0.18712129259866378 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-07-03 21:46:46.338286 Epoch [007/050], Step [0001/0060], Loss1: 0.1757 Loss2: 0.2354 Loss3: 0.1561\n",
            "2022-07-03 21:47:27.556185 Epoch [007/050], Step [0050/0060], Loss1: 0.1634 Loss2: 0.2159 Loss3: 0.1445\n",
            "2022-07-03 21:47:36.095265 Epoch [007/050], Step [0060/0060], Loss1: 0.1533 Loss2: 0.1978 Loss3: 0.1344\n",
            "Epoch: 7 MAE: 0.11831741968790686 ####  bestMAE: 0.12429469729226734 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-07-03 21:47:45.180970 Epoch [008/050], Step [0001/0060], Loss1: 0.1635 Loss2: 0.2045 Loss3: 0.1393\n",
            "2022-07-03 21:48:27.112168 Epoch [008/050], Step [0050/0060], Loss1: 0.1655 Loss2: 0.2132 Loss3: 0.1457\n",
            "2022-07-03 21:48:35.512289 Epoch [008/050], Step [0060/0060], Loss1: 0.1540 Loss2: 0.2030 Loss3: 0.1351\n",
            "Epoch: 8 MAE: 0.19195891112877575 ####  bestMAE: 0.11831741968790686 bestEpoch: 7\n",
            "2022-07-03 21:48:42.052318 Epoch [009/050], Step [0001/0060], Loss1: 0.1591 Loss2: 0.2051 Loss3: 0.1368\n",
            "2022-07-03 21:49:23.303259 Epoch [009/050], Step [0050/0060], Loss1: 0.1506 Loss2: 0.1801 Loss3: 0.1291\n",
            "2022-07-03 21:49:31.711472 Epoch [009/050], Step [0060/0060], Loss1: 0.1648 Loss2: 0.2116 Loss3: 0.1440\n",
            "Epoch: 9 MAE: 0.11874184663964331 ####  bestMAE: 0.11831741968790686 bestEpoch: 7\n",
            "2022-07-03 21:49:38.201906 Epoch [010/050], Step [0001/0060], Loss1: 0.1609 Loss2: 0.2104 Loss3: 0.1429\n",
            "2022-07-03 21:50:19.642661 Epoch [010/050], Step [0050/0060], Loss1: 0.1654 Loss2: 0.2109 Loss3: 0.1436\n",
            "2022-07-03 21:50:28.049641 Epoch [010/050], Step [0060/0060], Loss1: 0.1443 Loss2: 0.1777 Loss3: 0.1264\n",
            "Epoch: 10 MAE: 0.11914458834935751 ####  bestMAE: 0.11831741968790686 bestEpoch: 7\n",
            "2022-07-03 21:50:37.027314 Epoch [011/050], Step [0001/0060], Loss1: 0.1489 Loss2: 0.2011 Loss3: 0.1314\n",
            "2022-07-03 21:51:18.270195 Epoch [011/050], Step [0050/0060], Loss1: 0.1577 Loss2: 0.1853 Loss3: 0.1388\n",
            "2022-07-03 21:51:26.671021 Epoch [011/050], Step [0060/0060], Loss1: 0.1517 Loss2: 0.1993 Loss3: 0.1346\n",
            "Epoch: 11 MAE: 0.10084440150588911 ####  bestMAE: 0.11831741968790686 bestEpoch: 7\n",
            "best epoch:11\n",
            "2022-07-03 21:51:35.692934 Epoch [012/050], Step [0001/0060], Loss1: 0.1457 Loss2: 0.1990 Loss3: 0.1315\n",
            "2022-07-03 21:52:17.403116 Epoch [012/050], Step [0050/0060], Loss1: 0.1531 Loss2: 0.2003 Loss3: 0.1330\n",
            "2022-07-03 21:52:25.869441 Epoch [012/050], Step [0060/0060], Loss1: 0.1512 Loss2: 0.1844 Loss3: 0.1312\n",
            "Epoch: 12 MAE: 0.11368394296636025 ####  bestMAE: 0.10084440150588911 bestEpoch: 11\n",
            "2022-07-03 21:52:32.369285 Epoch [013/050], Step [0001/0060], Loss1: 0.1509 Loss2: 0.1919 Loss3: 0.1336\n",
            "2022-07-03 21:53:13.731970 Epoch [013/050], Step [0050/0060], Loss1: 0.1536 Loss2: 0.1951 Loss3: 0.1321\n",
            "2022-07-03 21:53:22.142162 Epoch [013/050], Step [0060/0060], Loss1: 0.1604 Loss2: 0.2029 Loss3: 0.1405\n",
            "Epoch: 13 MAE: 0.09963214939864223 ####  bestMAE: 0.10084440150588911 bestEpoch: 11\n",
            "best epoch:13\n",
            "2022-07-03 21:53:32.562936 Epoch [014/050], Step [0001/0060], Loss1: 0.1455 Loss2: 0.1815 Loss3: 0.1290\n",
            "2022-07-03 21:54:13.800707 Epoch [014/050], Step [0050/0060], Loss1: 0.1407 Loss2: 0.1932 Loss3: 0.1191\n",
            "2022-07-03 21:54:22.310713 Epoch [014/050], Step [0060/0060], Loss1: 0.1352 Loss2: 0.1629 Loss3: 0.1185\n",
            "Epoch: 14 MAE: 0.24064546040126258 ####  bestMAE: 0.09963214939864223 bestEpoch: 13\n",
            "2022-07-03 21:54:29.937772 Epoch [015/050], Step [0001/0060], Loss1: 0.1422 Loss2: 0.1984 Loss3: 0.1262\n",
            "2022-07-03 21:55:11.173296 Epoch [015/050], Step [0050/0060], Loss1: 0.1392 Loss2: 0.1760 Loss3: 0.1257\n",
            "2022-07-03 21:55:19.576900 Epoch [015/050], Step [0060/0060], Loss1: 0.1355 Loss2: 0.1900 Loss3: 0.1243\n",
            "Epoch: 15 MAE: 0.10239866044786243 ####  bestMAE: 0.09963214939864223 bestEpoch: 13\n",
            "2022-07-03 21:55:28.331648 Epoch [016/050], Step [0001/0060], Loss1: 0.1543 Loss2: 0.1872 Loss3: 0.1355\n",
            "2022-07-03 21:56:09.607666 Epoch [016/050], Step [0050/0060], Loss1: 0.1440 Loss2: 0.1833 Loss3: 0.1260\n",
            "2022-07-03 21:56:18.012544 Epoch [016/050], Step [0060/0060], Loss1: 0.1435 Loss2: 0.1790 Loss3: 0.1267\n",
            "Epoch: 16 MAE: 0.08445424710632005 ####  bestMAE: 0.09963214939864223 bestEpoch: 13\n",
            "best epoch:16\n",
            "2022-07-03 21:56:27.037811 Epoch [017/050], Step [0001/0060], Loss1: 0.1338 Loss2: 0.1676 Loss3: 0.1141\n",
            "2022-07-03 21:57:08.680567 Epoch [017/050], Step [0050/0060], Loss1: 0.1486 Loss2: 0.1938 Loss3: 0.1320\n",
            "2022-07-03 21:57:17.080280 Epoch [017/050], Step [0060/0060], Loss1: 0.1452 Loss2: 0.1968 Loss3: 0.1265\n",
            "Epoch: 17 MAE: 0.09685501265147373 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 21:57:23.533245 Epoch [018/050], Step [0001/0060], Loss1: 0.1415 Loss2: 0.1729 Loss3: 0.1220\n",
            "2022-07-03 21:58:04.733230 Epoch [018/050], Step [0050/0060], Loss1: 0.1412 Loss2: 0.1784 Loss3: 0.1251\n",
            "2022-07-03 21:58:13.125231 Epoch [018/050], Step [0060/0060], Loss1: 0.1442 Loss2: 0.1733 Loss3: 0.1267\n",
            "Epoch: 18 MAE: 0.09276758643054453 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 21:58:19.571940 Epoch [019/050], Step [0001/0060], Loss1: 0.1389 Loss2: 0.1892 Loss3: 0.1232\n",
            "2022-07-03 21:59:01.014362 Epoch [019/050], Step [0050/0060], Loss1: 0.1393 Loss2: 0.1739 Loss3: 0.1228\n",
            "2022-07-03 21:59:09.560129 Epoch [019/050], Step [0060/0060], Loss1: 0.1362 Loss2: 0.1787 Loss3: 0.1224\n",
            "Epoch: 19 MAE: 0.09215915710207016 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 21:59:16.047335 Epoch [020/050], Step [0001/0060], Loss1: 0.1365 Loss2: 0.1687 Loss3: 0.1209\n",
            "2022-07-03 21:59:57.256453 Epoch [020/050], Step [0050/0060], Loss1: 0.1403 Loss2: 0.1686 Loss3: 0.1204\n",
            "2022-07-03 22:00:05.667385 Epoch [020/050], Step [0060/0060], Loss1: 0.1402 Loss2: 0.1779 Loss3: 0.1219\n",
            "Epoch: 20 MAE: 0.1779635770484884 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 22:00:14.561609 Epoch [021/050], Step [0001/0060], Loss1: 0.1339 Loss2: 0.1661 Loss3: 0.1171\n",
            "2022-07-03 22:00:55.840578 Epoch [021/050], Step [0050/0060], Loss1: 0.1298 Loss2: 0.1531 Loss3: 0.1127\n",
            "2022-07-03 22:01:04.451878 Epoch [021/050], Step [0060/0060], Loss1: 0.1330 Loss2: 0.1727 Loss3: 0.1178\n",
            "Epoch: 21 MAE: 0.095596125466483 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 22:01:11.239588 Epoch [022/050], Step [0001/0060], Loss1: 0.1352 Loss2: 0.1663 Loss3: 0.1187\n",
            "2022-07-03 22:01:52.467525 Epoch [022/050], Step [0050/0060], Loss1: 0.1433 Loss2: 0.1845 Loss3: 0.1246\n",
            "2022-07-03 22:02:00.859928 Epoch [022/050], Step [0060/0060], Loss1: 0.1343 Loss2: 0.1634 Loss3: 0.1173\n",
            "Epoch: 22 MAE: 0.10193063695594748 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "2022-07-03 22:02:07.357644 Epoch [023/050], Step [0001/0060], Loss1: 0.1376 Loss2: 0.1790 Loss3: 0.1195\n",
            "2022-07-03 22:02:48.607521 Epoch [023/050], Step [0050/0060], Loss1: 0.1340 Loss2: 0.1728 Loss3: 0.1158\n",
            "2022-07-03 22:02:57.022928 Epoch [023/050], Step [0060/0060], Loss1: 0.1389 Loss2: 0.1777 Loss3: 0.1187\n",
            "Epoch: 23 MAE: 0.07721986417417175 ####  bestMAE: 0.08445424710632005 bestEpoch: 16\n",
            "best epoch:23\n",
            "2022-07-03 22:03:06.084266 Epoch [024/050], Step [0001/0060], Loss1: 0.1341 Loss2: 0.1533 Loss3: 0.1138\n",
            "2022-07-03 22:03:47.562484 Epoch [024/050], Step [0050/0060], Loss1: 0.1327 Loss2: 0.1603 Loss3: 0.1170\n",
            "2022-07-03 22:03:55.982662 Epoch [024/050], Step [0060/0060], Loss1: 0.1328 Loss2: 0.1743 Loss3: 0.1157\n",
            "Epoch: 24 MAE: 0.0852627270814603 ####  bestMAE: 0.07721986417417175 bestEpoch: 23\n",
            "2022-07-03 22:04:02.563773 Epoch [025/050], Step [0001/0060], Loss1: 0.1331 Loss2: 0.1706 Loss3: 0.1161\n",
            "2022-07-03 22:04:43.784054 Epoch [025/050], Step [0050/0060], Loss1: 0.1185 Loss2: 0.1460 Loss3: 0.1027\n",
            "2022-07-03 22:04:52.187655 Epoch [025/050], Step [0060/0060], Loss1: 0.1309 Loss2: 0.1565 Loss3: 0.1138\n",
            "Epoch: 25 MAE: 0.07431084163605219 ####  bestMAE: 0.07721986417417175 bestEpoch: 23\n",
            "best epoch:25\n",
            "2022-07-03 22:05:03.969636 Epoch [026/050], Step [0001/0060], Loss1: 0.1262 Loss2: 0.1747 Loss3: 0.1127\n",
            "2022-07-03 22:05:45.634357 Epoch [026/050], Step [0050/0060], Loss1: 0.1289 Loss2: 0.1667 Loss3: 0.1119\n",
            "2022-07-03 22:05:54.040484 Epoch [026/050], Step [0060/0060], Loss1: 0.1283 Loss2: 0.1563 Loss3: 0.1117\n",
            "Epoch: 26 MAE: 0.07319293279496449 ####  bestMAE: 0.07431084163605219 bestEpoch: 25\n",
            "best epoch:26\n",
            "2022-07-03 22:06:02.807000 Epoch [027/050], Step [0001/0060], Loss1: 0.1323 Loss2: 0.1682 Loss3: 0.1167\n",
            "2022-07-03 22:06:44.040569 Epoch [027/050], Step [0050/0060], Loss1: 0.1438 Loss2: 0.1686 Loss3: 0.1222\n",
            "2022-07-03 22:06:52.439029 Epoch [027/050], Step [0060/0060], Loss1: 0.1272 Loss2: 0.1567 Loss3: 0.1097\n",
            "Epoch: 27 MAE: 0.08625759069251004 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:06:58.589041 Epoch [028/050], Step [0001/0060], Loss1: 0.1185 Loss2: 0.1533 Loss3: 0.1036\n",
            "2022-07-03 22:07:40.070469 Epoch [028/050], Step [0050/0060], Loss1: 0.1241 Loss2: 0.1615 Loss3: 0.1068\n",
            "2022-07-03 22:07:48.482812 Epoch [028/050], Step [0060/0060], Loss1: 0.1414 Loss2: 0.1916 Loss3: 0.1242\n",
            "Epoch: 28 MAE: 0.08962943273877337 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:07:54.633293 Epoch [029/050], Step [0001/0060], Loss1: 0.1342 Loss2: 0.1727 Loss3: 0.1165\n",
            "2022-07-03 22:08:35.865660 Epoch [029/050], Step [0050/0060], Loss1: 0.1367 Loss2: 0.1720 Loss3: 0.1189\n",
            "2022-07-03 22:08:44.272549 Epoch [029/050], Step [0060/0060], Loss1: 0.1223 Loss2: 0.1578 Loss3: 0.1071\n",
            "Epoch: 29 MAE: 0.07748908305294301 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:08:50.403478 Epoch [030/050], Step [0001/0060], Loss1: 0.1365 Loss2: 0.1749 Loss3: 0.1190\n",
            "2022-07-03 22:09:31.689915 Epoch [030/050], Step [0050/0060], Loss1: 0.1253 Loss2: 0.1569 Loss3: 0.1112\n",
            "2022-07-03 22:09:40.335857 Epoch [030/050], Step [0060/0060], Loss1: 0.1204 Loss2: 0.1441 Loss3: 0.1037\n",
            "Epoch: 30 MAE: 0.07525656543711505 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:09:49.917441 Epoch [031/050], Step [0001/0060], Loss1: 0.1314 Loss2: 0.1612 Loss3: 0.1135\n",
            "2022-07-03 22:10:31.139601 Epoch [031/050], Step [0050/0060], Loss1: 0.1284 Loss2: 0.1611 Loss3: 0.1115\n",
            "2022-07-03 22:10:39.551200 Epoch [031/050], Step [0060/0060], Loss1: 0.1375 Loss2: 0.1779 Loss3: 0.1193\n",
            "Epoch: 31 MAE: 0.13295542177069125 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:10:45.819309 Epoch [032/050], Step [0001/0060], Loss1: 0.1308 Loss2: 0.1607 Loss3: 0.1123\n",
            "2022-07-03 22:11:27.082368 Epoch [032/050], Step [0050/0060], Loss1: 0.1182 Loss2: 0.1637 Loss3: 0.1046\n",
            "2022-07-03 22:11:35.612979 Epoch [032/050], Step [0060/0060], Loss1: 0.1363 Loss2: 0.1620 Loss3: 0.1168\n",
            "Epoch: 32 MAE: 0.0773049305608033 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "2022-07-03 22:11:41.788814 Epoch [033/050], Step [0001/0060], Loss1: 0.1237 Loss2: 0.1547 Loss3: 0.1054\n",
            "2022-07-03 22:12:23.216871 Epoch [033/050], Step [0050/0060], Loss1: 0.1324 Loss2: 0.1596 Loss3: 0.1141\n",
            "2022-07-03 22:12:31.618268 Epoch [033/050], Step [0060/0060], Loss1: 0.1348 Loss2: 0.1699 Loss3: 0.1174\n",
            "Epoch: 33 MAE: 0.06302157396992679 ####  bestMAE: 0.07319293279496449 bestEpoch: 26\n",
            "best epoch:33\n",
            "2022-07-03 22:12:41.598939 Epoch [034/050], Step [0001/0060], Loss1: 0.1357 Loss2: 0.1658 Loss3: 0.1155\n",
            "2022-07-03 22:13:22.863364 Epoch [034/050], Step [0050/0060], Loss1: 0.1282 Loss2: 0.1587 Loss3: 0.1113\n",
            "2022-07-03 22:13:31.265238 Epoch [034/050], Step [0060/0060], Loss1: 0.1235 Loss2: 0.1511 Loss3: 0.1084\n",
            "Epoch: 34 MAE: 0.07120616090360773 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:13:37.371679 Epoch [035/050], Step [0001/0060], Loss1: 0.1271 Loss2: 0.1534 Loss3: 0.1106\n",
            "2022-07-03 22:14:18.875532 Epoch [035/050], Step [0050/0060], Loss1: 0.1201 Loss2: 0.1508 Loss3: 0.1041\n",
            "2022-07-03 22:14:27.276912 Epoch [035/050], Step [0060/0060], Loss1: 0.1279 Loss2: 0.1651 Loss3: 0.1091\n",
            "Epoch: 35 MAE: 0.0730303293056589 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:14:35.927181 Epoch [036/050], Step [0001/0060], Loss1: 0.1206 Loss2: 0.1435 Loss3: 0.1024\n",
            "2022-07-03 22:15:17.196372 Epoch [036/050], Step [0050/0060], Loss1: 0.1421 Loss2: 0.1824 Loss3: 0.1210\n",
            "2022-07-03 22:15:25.595474 Epoch [036/050], Step [0060/0060], Loss1: 0.1178 Loss2: 0.1450 Loss3: 0.0999\n",
            "Epoch: 36 MAE: 0.06783250697706113 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:15:31.743954 Epoch [037/050], Step [0001/0060], Loss1: 0.1261 Loss2: 0.1501 Loss3: 0.1068\n",
            "2022-07-03 22:16:13.189127 Epoch [037/050], Step [0050/0060], Loss1: 0.1318 Loss2: 0.1550 Loss3: 0.1119\n",
            "2022-07-03 22:16:21.601749 Epoch [037/050], Step [0060/0060], Loss1: 0.1164 Loss2: 0.1535 Loss3: 0.1010\n",
            "Epoch: 37 MAE: 0.06730070901295497 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:16:27.770334 Epoch [038/050], Step [0001/0060], Loss1: 0.1261 Loss2: 0.1572 Loss3: 0.1075\n",
            "2022-07-03 22:17:09.018641 Epoch [038/050], Step [0050/0060], Loss1: 0.1332 Loss2: 0.1621 Loss3: 0.1150\n",
            "2022-07-03 22:17:17.415310 Epoch [038/050], Step [0060/0060], Loss1: 0.1356 Loss2: 0.1689 Loss3: 0.1148\n",
            "Epoch: 38 MAE: 0.06577561827563734 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:17:23.617646 Epoch [039/050], Step [0001/0060], Loss1: 0.1207 Loss2: 0.1451 Loss3: 0.1020\n",
            "2022-07-03 22:18:04.860635 Epoch [039/050], Step [0050/0060], Loss1: 0.1081 Loss2: 0.1378 Loss3: 0.0936\n",
            "2022-07-03 22:18:13.259057 Epoch [039/050], Step [0060/0060], Loss1: 0.1321 Loss2: 0.1728 Loss3: 0.1122\n",
            "Epoch: 39 MAE: 0.06899079110887317 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:18:20.252748 Epoch [040/050], Step [0001/0060], Loss1: 0.1254 Loss2: 0.1458 Loss3: 0.1048\n",
            "2022-07-03 22:19:01.588282 Epoch [040/050], Step [0050/0060], Loss1: 0.1277 Loss2: 0.1643 Loss3: 0.1084\n",
            "2022-07-03 22:19:09.990134 Epoch [040/050], Step [0060/0060], Loss1: 0.1198 Loss2: 0.1447 Loss3: 0.1019\n",
            "Epoch: 40 MAE: 0.06758495381269503 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:19:18.727697 Epoch [041/050], Step [0001/0060], Loss1: 0.1292 Loss2: 0.1535 Loss3: 0.1085\n",
            "2022-07-03 22:19:59.922709 Epoch [041/050], Step [0050/0060], Loss1: 0.1278 Loss2: 0.1696 Loss3: 0.1080\n",
            "2022-07-03 22:20:08.337173 Epoch [041/050], Step [0060/0060], Loss1: 0.1269 Loss2: 0.1530 Loss3: 0.1068\n",
            "Epoch: 41 MAE: 0.06879549526032946 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:20:14.555672 Epoch [042/050], Step [0001/0060], Loss1: 0.1326 Loss2: 0.1697 Loss3: 0.1130\n",
            "2022-07-03 22:20:55.972588 Epoch [042/050], Step [0050/0060], Loss1: 0.1178 Loss2: 0.1613 Loss3: 0.1017\n",
            "2022-07-03 22:21:04.372137 Epoch [042/050], Step [0060/0060], Loss1: 0.1293 Loss2: 0.1597 Loss3: 0.1100\n",
            "Epoch: 42 MAE: 0.07274855255449891 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:21:10.520367 Epoch [043/050], Step [0001/0060], Loss1: 0.1314 Loss2: 0.1635 Loss3: 0.1123\n",
            "2022-07-03 22:21:51.741378 Epoch [043/050], Step [0050/0060], Loss1: 0.1428 Loss2: 0.1643 Loss3: 0.1197\n",
            "2022-07-03 22:22:00.136181 Epoch [043/050], Step [0060/0060], Loss1: 0.1206 Loss2: 0.1467 Loss3: 0.1032\n",
            "Epoch: 43 MAE: 0.08011382108012208 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:22:06.212774 Epoch [044/050], Step [0001/0060], Loss1: 0.1212 Loss2: 0.1514 Loss3: 0.1035\n",
            "2022-07-03 22:22:47.769370 Epoch [044/050], Step [0050/0060], Loss1: 0.1138 Loss2: 0.1431 Loss3: 0.0974\n",
            "2022-07-03 22:22:56.180505 Epoch [044/050], Step [0060/0060], Loss1: 0.1235 Loss2: 0.1594 Loss3: 0.1041\n",
            "Epoch: 44 MAE: 0.07266131194180281 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:23:02.357261 Epoch [045/050], Step [0001/0060], Loss1: 0.1142 Loss2: 0.1415 Loss3: 0.0972\n",
            "2022-07-03 22:23:43.601511 Epoch [045/050], Step [0050/0060], Loss1: 0.1266 Loss2: 0.1545 Loss3: 0.1104\n",
            "2022-07-03 22:23:52.005081 Epoch [045/050], Step [0060/0060], Loss1: 0.1199 Loss2: 0.1517 Loss3: 0.1069\n",
            "Epoch: 45 MAE: 0.08432381811596097 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:24:00.485477 Epoch [046/050], Step [0001/0060], Loss1: 0.1294 Loss2: 0.1539 Loss3: 0.1093\n",
            "2022-07-03 22:24:41.737656 Epoch [046/050], Step [0050/0060], Loss1: 0.1200 Loss2: 0.1515 Loss3: 0.1035\n",
            "2022-07-03 22:24:50.395112 Epoch [046/050], Step [0060/0060], Loss1: 0.1294 Loss2: 0.1617 Loss3: 0.1104\n",
            "Epoch: 46 MAE: 0.07053961400632507 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:24:58.746904 Epoch [047/050], Step [0001/0060], Loss1: 0.1207 Loss2: 0.1436 Loss3: 0.1017\n",
            "2022-07-03 22:25:40.002846 Epoch [047/050], Step [0050/0060], Loss1: 0.1261 Loss2: 0.1543 Loss3: 0.1093\n",
            "2022-07-03 22:25:48.402635 Epoch [047/050], Step [0060/0060], Loss1: 0.1226 Loss2: 0.1527 Loss3: 0.1041\n",
            "Epoch: 47 MAE: 0.08284550500294519 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:25:54.503952 Epoch [048/050], Step [0001/0060], Loss1: 0.1178 Loss2: 0.1478 Loss3: 0.1012\n",
            "2022-07-03 22:26:35.776531 Epoch [048/050], Step [0050/0060], Loss1: 0.1311 Loss2: 0.1660 Loss3: 0.1076\n",
            "2022-07-03 22:26:44.184113 Epoch [048/050], Step [0060/0060], Loss1: 0.1259 Loss2: 0.1534 Loss3: 0.1038\n",
            "Epoch: 48 MAE: 0.07822346329058288 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n",
            "2022-07-03 22:26:50.388428 Epoch [049/050], Step [0001/0060], Loss1: 0.1221 Loss2: 0.1439 Loss3: 0.1030\n",
            "2022-07-03 22:27:31.932347 Epoch [049/050], Step [0050/0060], Loss1: 0.1283 Loss2: 0.1562 Loss3: 0.1098\n",
            "2022-07-03 22:27:40.336431 Epoch [049/050], Step [0060/0060], Loss1: 0.1285 Loss2: 0.1563 Loss3: 0.1065\n",
            "Epoch: 49 MAE: 0.06983587426483316 ####  bestMAE: 0.06302157396992679 bestEpoch: 33\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Train Model"
      ],
      "metadata": {
        "id": "AMemLR14hkVD"
      },
      "id": "AMemLR14hkVD"
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Combine Loss 100 epoches"
      ],
      "metadata": {
        "id": "NxOlAzw77xmU"
      },
      "id": "NxOlAzw77xmU"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "CE = torch.nn.MSELoss()\n",
        "\n",
        "def perceptual_loss(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def perceptual_loss_detach(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask.detach())\n",
        "    return loss\n",
        "\n",
        "def combine_loss(mask, pred):\n",
        "    L1 = torch.nn.L1Loss()\n",
        "    L2 = torch.nn.SmoothL1Loss()\n",
        "    loss =  1.0 * ( L1(pred, mask) + L2(pred, mask))\n",
        "    return loss\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = combine_loss(gts, pre_res[0]) \n",
        "            loss2    = combine_loss(gts, pre_res[1])\n",
        "            loss3    = combine_loss(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Combine_Loss_only_with_RGB_as_depth.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-o')\n",
        "plt.plot(train_losses1,'-o')\n",
        "plt.plot(train_losses2,'-o')\n",
        "plt.plot(train_losses3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-o')\n",
        "plt.plot(train_accu1,'-o')\n",
        "plt.plot(train_accu2,'-o')\n",
        "plt.plot(train_accu3,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a8bd7c69089e4bd0b11a23ec27cbffde",
            "6e045aa3b74145c39d1799c85fee1e78",
            "466c965df9f24ee3a2b75c6165e5a851",
            "3b2603c87bed40cd8a1fa20588c64051",
            "d4bca09a737644d0b20691701b69f104",
            "3a1861a7ec2d402db71b1d72b82cf6a7",
            "4c0fb88312cc4b5c8253b85cd43b3d20",
            "fa5a7b11554f4cd393f77d86fe12dde1",
            "8ec4343d491746f3bb271c532201078e",
            "a2c2e0ea902d4c768248a852669931a4",
            "861c39e852c24ae49c8e22c287fc90cf"
          ]
        },
        "id": "Q5XGXtBhum5b",
        "outputId": "928ad10c-073a-4e27-fa21-812f9dabbc84"
      },
      "id": "Q5XGXtBhum5b",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8bd7c69089e4bd0b11a23ec27cbffde"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fc4bd4f2310>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "Start train...\n",
            "2022-06-19 21:24:22.208757 Epoch [001/100], Step [0001/0060], Loss1: 0.5368 Loss2: 1.1359 Loss3: 0.5247\n",
            "2022-06-19 21:24:46.919346 Epoch [001/100], Step [0050/0060], Loss1: 0.1232 Loss2: 0.0960 Loss3: 0.1089\n",
            "2022-06-19 21:24:51.949978 Epoch [001/100], Step [0060/0060], Loss1: 0.0995 Loss2: 0.0962 Loss3: 0.0817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.23950264138519436 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-19 21:25:01.049175 Epoch [002/100], Step [0001/0060], Loss1: 0.1020 Loss2: 0.0895 Loss3: 0.0858\n",
            "2022-06-19 21:25:25.735055 Epoch [002/100], Step [0050/0060], Loss1: 0.0707 Loss2: 0.0711 Loss3: 0.0698\n",
            "2022-06-19 21:25:30.766012 Epoch [002/100], Step [0060/0060], Loss1: 0.0708 Loss2: 0.0672 Loss3: 0.0585\n",
            "Epoch: 2 MAE: 0.23674373767994072 ####  bestMAE: 0.23950264138519436 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-19 21:25:38.449922 Epoch [003/100], Step [0001/0060], Loss1: 0.0900 Loss2: 0.1063 Loss3: 0.1013\n",
            "2022-06-19 21:26:03.350183 Epoch [003/100], Step [0050/0060], Loss1: 0.0833 Loss2: 0.0730 Loss3: 0.0744\n",
            "2022-06-19 21:26:08.379935 Epoch [003/100], Step [0060/0060], Loss1: 0.0581 Loss2: 0.0678 Loss3: 0.0522\n",
            "Epoch: 3 MAE: 0.14279665992373514 ####  bestMAE: 0.23674373767994072 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-06-19 21:26:16.271907 Epoch [004/100], Step [0001/0060], Loss1: 0.0717 Loss2: 0.0660 Loss3: 0.0492\n",
            "2022-06-19 21:26:41.220752 Epoch [004/100], Step [0050/0060], Loss1: 0.0559 Loss2: 0.0562 Loss3: 0.0426\n",
            "2022-06-19 21:26:46.246474 Epoch [004/100], Step [0060/0060], Loss1: 0.0526 Loss2: 0.0571 Loss3: 0.0426\n",
            "Epoch: 4 MAE: 0.11964363168787072 ####  bestMAE: 0.14279665992373514 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-06-19 21:26:53.930567 Epoch [005/100], Step [0001/0060], Loss1: 0.0570 Loss2: 0.0647 Loss3: 0.0419\n",
            "2022-06-19 21:27:18.868070 Epoch [005/100], Step [0050/0060], Loss1: 0.0585 Loss2: 0.0655 Loss3: 0.0439\n",
            "2022-06-19 21:27:23.896622 Epoch [005/100], Step [0060/0060], Loss1: 0.0549 Loss2: 0.0487 Loss3: 0.0400\n",
            "Epoch: 5 MAE: 0.1316688501267206 ####  bestMAE: 0.11964363168787072 bestEpoch: 4\n",
            "2022-06-19 21:27:31.558962 Epoch [006/100], Step [0001/0060], Loss1: 0.0522 Loss2: 0.0506 Loss3: 0.0390\n",
            "2022-06-19 21:27:56.615939 Epoch [006/100], Step [0050/0060], Loss1: 0.0487 Loss2: 0.0524 Loss3: 0.0383\n",
            "2022-06-19 21:28:01.631876 Epoch [006/100], Step [0060/0060], Loss1: 0.0482 Loss2: 0.0471 Loss3: 0.0385\n",
            "Epoch: 6 MAE: 0.11493759720413774 ####  bestMAE: 0.11964363168787072 bestEpoch: 4\n",
            "best epoch:6\n",
            "2022-06-19 21:28:09.463185 Epoch [007/100], Step [0001/0060], Loss1: 0.0561 Loss2: 0.0540 Loss3: 0.0332\n",
            "2022-06-19 21:28:34.371588 Epoch [007/100], Step [0050/0060], Loss1: 0.0596 Loss2: 0.0646 Loss3: 0.0437\n",
            "2022-06-19 21:28:39.389385 Epoch [007/100], Step [0060/0060], Loss1: 0.0461 Loss2: 0.0501 Loss3: 0.0349\n",
            "Epoch: 7 MAE: 0.11037938708350774 ####  bestMAE: 0.11493759720413774 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-06-19 21:28:47.035601 Epoch [008/100], Step [0001/0060], Loss1: 0.0512 Loss2: 0.0630 Loss3: 0.0402\n",
            "2022-06-19 21:29:11.960277 Epoch [008/100], Step [0050/0060], Loss1: 0.0424 Loss2: 0.0447 Loss3: 0.0348\n",
            "2022-06-19 21:29:16.999531 Epoch [008/100], Step [0060/0060], Loss1: 0.0423 Loss2: 0.0482 Loss3: 0.0367\n",
            "Epoch: 8 MAE: 0.11266277747179464 ####  bestMAE: 0.11037938708350774 bestEpoch: 7\n",
            "2022-06-19 21:29:22.433390 Epoch [009/100], Step [0001/0060], Loss1: 0.0428 Loss2: 0.0442 Loss3: 0.0357\n",
            "2022-06-19 21:29:47.069249 Epoch [009/100], Step [0050/0060], Loss1: 0.0421 Loss2: 0.0461 Loss3: 0.0333\n",
            "2022-06-19 21:29:52.087804 Epoch [009/100], Step [0060/0060], Loss1: 0.0389 Loss2: 0.0446 Loss3: 0.0290\n",
            "Epoch: 9 MAE: 0.12237175976788556 ####  bestMAE: 0.11037938708350774 bestEpoch: 7\n",
            "2022-06-19 21:29:57.539894 Epoch [010/100], Step [0001/0060], Loss1: 0.0405 Loss2: 0.0437 Loss3: 0.0311\n",
            "2022-06-19 21:30:22.185473 Epoch [010/100], Step [0050/0060], Loss1: 0.0380 Loss2: 0.0473 Loss3: 0.0369\n",
            "2022-06-19 21:30:27.193066 Epoch [010/100], Step [0060/0060], Loss1: 0.0384 Loss2: 0.0510 Loss3: 0.0326\n",
            "Epoch: 10 MAE: 0.10402677546102532 ####  bestMAE: 0.11037938708350774 bestEpoch: 7\n",
            "best epoch:10\n",
            "2022-06-19 21:30:37.119137 Epoch [011/100], Step [0001/0060], Loss1: 0.0369 Loss2: 0.0409 Loss3: 0.0315\n",
            "2022-06-19 21:31:02.293439 Epoch [011/100], Step [0050/0060], Loss1: 0.0456 Loss2: 0.0467 Loss3: 0.0366\n",
            "2022-06-19 21:31:07.315314 Epoch [011/100], Step [0060/0060], Loss1: 0.0357 Loss2: 0.0422 Loss3: 0.0286\n",
            "Epoch: 11 MAE: 0.10120312776515093 ####  bestMAE: 0.10402677546102532 bestEpoch: 10\n",
            "best epoch:11\n",
            "2022-06-19 21:31:15.004186 Epoch [012/100], Step [0001/0060], Loss1: 0.0364 Loss2: 0.0400 Loss3: 0.0305\n",
            "2022-06-19 21:31:39.926043 Epoch [012/100], Step [0050/0060], Loss1: 0.0342 Loss2: 0.0380 Loss3: 0.0275\n",
            "2022-06-19 21:31:44.935635 Epoch [012/100], Step [0060/0060], Loss1: 0.0357 Loss2: 0.0420 Loss3: 0.0286\n",
            "Epoch: 12 MAE: 0.10360736493711116 ####  bestMAE: 0.10120312776515093 bestEpoch: 11\n",
            "2022-06-19 21:31:50.411600 Epoch [013/100], Step [0001/0060], Loss1: 0.0345 Loss2: 0.0400 Loss3: 0.0291\n",
            "2022-06-19 21:32:15.183867 Epoch [013/100], Step [0050/0060], Loss1: 0.0346 Loss2: 0.0429 Loss3: 0.0287\n",
            "2022-06-19 21:32:20.207359 Epoch [013/100], Step [0060/0060], Loss1: 0.0361 Loss2: 0.0386 Loss3: 0.0288\n",
            "Epoch: 13 MAE: 0.1032516134352911 ####  bestMAE: 0.10120312776515093 bestEpoch: 11\n",
            "2022-06-19 21:32:25.688712 Epoch [014/100], Step [0001/0060], Loss1: 0.0338 Loss2: 0.0382 Loss3: 0.0262\n",
            "2022-06-19 21:32:50.330695 Epoch [014/100], Step [0050/0060], Loss1: 0.0351 Loss2: 0.0374 Loss3: 0.0279\n",
            "2022-06-19 21:32:55.363614 Epoch [014/100], Step [0060/0060], Loss1: 0.0355 Loss2: 0.0437 Loss3: 0.0306\n",
            "Epoch: 14 MAE: 0.10084690043535183 ####  bestMAE: 0.10120312776515093 bestEpoch: 11\n",
            "best epoch:14\n",
            "2022-06-19 21:33:03.469124 Epoch [015/100], Step [0001/0060], Loss1: 0.0370 Loss2: 0.0434 Loss3: 0.0301\n",
            "2022-06-19 21:33:28.507006 Epoch [015/100], Step [0050/0060], Loss1: 0.0344 Loss2: 0.0369 Loss3: 0.0267\n",
            "2022-06-19 21:33:33.535392 Epoch [015/100], Step [0060/0060], Loss1: 0.0336 Loss2: 0.0389 Loss3: 0.0258\n",
            "Epoch: 15 MAE: 0.1078511967734685 ####  bestMAE: 0.10084690043535183 bestEpoch: 14\n",
            "2022-06-19 21:33:41.089173 Epoch [016/100], Step [0001/0060], Loss1: 0.0365 Loss2: 0.0363 Loss3: 0.0282\n",
            "2022-06-19 21:34:06.004954 Epoch [016/100], Step [0050/0060], Loss1: 0.0312 Loss2: 0.0397 Loss3: 0.0254\n",
            "2022-06-19 21:34:11.036909 Epoch [016/100], Step [0060/0060], Loss1: 0.0341 Loss2: 0.0361 Loss3: 0.0256\n",
            "Epoch: 16 MAE: 0.0973157990672601 ####  bestMAE: 0.10084690043535183 bestEpoch: 14\n",
            "best epoch:16\n",
            "2022-06-19 21:34:18.729034 Epoch [017/100], Step [0001/0060], Loss1: 0.0306 Loss2: 0.0367 Loss3: 0.0251\n",
            "2022-06-19 21:34:43.672891 Epoch [017/100], Step [0050/0060], Loss1: 0.0335 Loss2: 0.0392 Loss3: 0.0259\n",
            "2022-06-19 21:34:48.696095 Epoch [017/100], Step [0060/0060], Loss1: 0.0320 Loss2: 0.0371 Loss3: 0.0281\n",
            "Epoch: 17 MAE: 0.09443851602140556 ####  bestMAE: 0.0973157990672601 bestEpoch: 16\n",
            "best epoch:17\n",
            "2022-06-19 21:34:56.340467 Epoch [018/100], Step [0001/0060], Loss1: 0.0343 Loss2: 0.0400 Loss3: 0.0282\n",
            "2022-06-19 21:35:21.213064 Epoch [018/100], Step [0050/0060], Loss1: 0.0364 Loss2: 0.0350 Loss3: 0.0317\n",
            "2022-06-19 21:35:26.229655 Epoch [018/100], Step [0060/0060], Loss1: 0.0348 Loss2: 0.0368 Loss3: 0.0274\n",
            "Epoch: 18 MAE: 0.09766148713530688 ####  bestMAE: 0.09443851602140556 bestEpoch: 17\n",
            "2022-06-19 21:35:31.640775 Epoch [019/100], Step [0001/0060], Loss1: 0.0309 Loss2: 0.0408 Loss3: 0.0262\n",
            "2022-06-19 21:35:56.342254 Epoch [019/100], Step [0050/0060], Loss1: 0.0379 Loss2: 0.0422 Loss3: 0.0292\n",
            "2022-06-19 21:36:01.375628 Epoch [019/100], Step [0060/0060], Loss1: 0.0365 Loss2: 0.0357 Loss3: 0.0267\n",
            "Epoch: 19 MAE: 0.08856027895811372 ####  bestMAE: 0.09443851602140556 bestEpoch: 17\n",
            "best epoch:19\n",
            "2022-06-19 21:36:09.011551 Epoch [020/100], Step [0001/0060], Loss1: 0.0338 Loss2: 0.0407 Loss3: 0.0289\n",
            "2022-06-19 21:36:33.994026 Epoch [020/100], Step [0050/0060], Loss1: 0.0313 Loss2: 0.0425 Loss3: 0.0284\n",
            "2022-06-19 21:36:39.018761 Epoch [020/100], Step [0060/0060], Loss1: 0.0312 Loss2: 0.0351 Loss3: 0.0252\n",
            "Epoch: 20 MAE: 0.08683754471874741 ####  bestMAE: 0.08856027895811372 bestEpoch: 19\n",
            "best epoch:20\n",
            "2022-06-19 21:36:48.936855 Epoch [021/100], Step [0001/0060], Loss1: 0.0301 Loss2: 0.0364 Loss3: 0.0236\n",
            "2022-06-19 21:37:14.150628 Epoch [021/100], Step [0050/0060], Loss1: 0.0337 Loss2: 0.0398 Loss3: 0.0282\n",
            "2022-06-19 21:37:19.176933 Epoch [021/100], Step [0060/0060], Loss1: 0.0290 Loss2: 0.0377 Loss3: 0.0263\n",
            "Epoch: 21 MAE: 0.10063276896401058 ####  bestMAE: 0.08683754471874741 bestEpoch: 20\n",
            "2022-06-19 21:37:24.649403 Epoch [022/100], Step [0001/0060], Loss1: 0.0340 Loss2: 0.0410 Loss3: 0.0272\n",
            "2022-06-19 21:37:49.227923 Epoch [022/100], Step [0050/0060], Loss1: 0.0281 Loss2: 0.0338 Loss3: 0.0230\n",
            "2022-06-19 21:37:54.254671 Epoch [022/100], Step [0060/0060], Loss1: 0.0287 Loss2: 0.0353 Loss3: 0.0230\n",
            "Epoch: 22 MAE: 0.08520020247767214 ####  bestMAE: 0.08683754471874741 bestEpoch: 20\n",
            "best epoch:22\n",
            "2022-06-19 21:38:01.904486 Epoch [023/100], Step [0001/0060], Loss1: 0.0291 Loss2: 0.0371 Loss3: 0.0245\n",
            "2022-06-19 21:38:26.870201 Epoch [023/100], Step [0050/0060], Loss1: 0.0310 Loss2: 0.0364 Loss3: 0.0243\n",
            "2022-06-19 21:38:31.896609 Epoch [023/100], Step [0060/0060], Loss1: 0.0318 Loss2: 0.0371 Loss3: 0.0282\n",
            "Epoch: 23 MAE: 0.08887178007257049 ####  bestMAE: 0.08520020247767214 bestEpoch: 22\n",
            "2022-06-19 21:38:37.364313 Epoch [024/100], Step [0001/0060], Loss1: 0.0298 Loss2: 0.0411 Loss3: 0.0296\n",
            "2022-06-19 21:39:02.055585 Epoch [024/100], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0317 Loss3: 0.0223\n",
            "2022-06-19 21:39:07.080776 Epoch [024/100], Step [0060/0060], Loss1: 0.0267 Loss2: 0.0361 Loss3: 0.0237\n",
            "Epoch: 24 MAE: 0.08838997987212328 ####  bestMAE: 0.08520020247767214 bestEpoch: 22\n",
            "2022-06-19 21:39:12.543623 Epoch [025/100], Step [0001/0060], Loss1: 0.0331 Loss2: 0.0384 Loss3: 0.0278\n",
            "2022-06-19 21:39:37.160671 Epoch [025/100], Step [0050/0060], Loss1: 0.0298 Loss2: 0.0348 Loss3: 0.0240\n",
            "2022-06-19 21:39:42.177808 Epoch [025/100], Step [0060/0060], Loss1: 0.0301 Loss2: 0.0347 Loss3: 0.0243\n",
            "Epoch: 25 MAE: 0.08327927725655691 ####  bestMAE: 0.08520020247767214 bestEpoch: 22\n",
            "best epoch:25\n",
            "2022-06-19 21:39:51.769276 Epoch [026/100], Step [0001/0060], Loss1: 0.0303 Loss2: 0.0360 Loss3: 0.0236\n",
            "2022-06-19 21:40:17.197407 Epoch [026/100], Step [0050/0060], Loss1: 0.0297 Loss2: 0.0356 Loss3: 0.0252\n",
            "2022-06-19 21:40:22.213015 Epoch [026/100], Step [0060/0060], Loss1: 0.0279 Loss2: 0.0345 Loss3: 0.0249\n",
            "Epoch: 26 MAE: 0.09009761174519859 ####  bestMAE: 0.08327927725655691 bestEpoch: 25\n",
            "2022-06-19 21:40:27.716385 Epoch [027/100], Step [0001/0060], Loss1: 0.0294 Loss2: 0.0335 Loss3: 0.0240\n",
            "2022-06-19 21:40:52.410048 Epoch [027/100], Step [0050/0060], Loss1: 0.0310 Loss2: 0.0363 Loss3: 0.0265\n",
            "2022-06-19 21:40:57.452149 Epoch [027/100], Step [0060/0060], Loss1: 0.0276 Loss2: 0.0360 Loss3: 0.0229\n",
            "Epoch: 27 MAE: 0.08146088156119854 ####  bestMAE: 0.08327927725655691 bestEpoch: 25\n",
            "best epoch:27\n",
            "2022-06-19 21:41:05.202041 Epoch [028/100], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0350 Loss3: 0.0231\n",
            "2022-06-19 21:41:30.161215 Epoch [028/100], Step [0050/0060], Loss1: 0.0285 Loss2: 0.0333 Loss3: 0.0224\n",
            "2022-06-19 21:41:35.176174 Epoch [028/100], Step [0060/0060], Loss1: 0.0296 Loss2: 0.0357 Loss3: 0.0237\n",
            "Epoch: 28 MAE: 0.08512241696554515 ####  bestMAE: 0.08146088156119854 bestEpoch: 27\n",
            "2022-06-19 21:41:40.629486 Epoch [029/100], Step [0001/0060], Loss1: 0.0280 Loss2: 0.0332 Loss3: 0.0241\n",
            "2022-06-19 21:42:05.297521 Epoch [029/100], Step [0050/0060], Loss1: 0.0298 Loss2: 0.0309 Loss3: 0.0243\n",
            "2022-06-19 21:42:10.319789 Epoch [029/100], Step [0060/0060], Loss1: 0.0291 Loss2: 0.0326 Loss3: 0.0254\n",
            "Epoch: 29 MAE: 0.07937494883461602 ####  bestMAE: 0.08146088156119854 bestEpoch: 27\n",
            "best epoch:29\n",
            "2022-06-19 21:42:18.095584 Epoch [030/100], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0358 Loss3: 0.0232\n",
            "2022-06-19 21:42:42.981362 Epoch [030/100], Step [0050/0060], Loss1: 0.0282 Loss2: 0.0318 Loss3: 0.0227\n",
            "2022-06-19 21:42:48.013386 Epoch [030/100], Step [0060/0060], Loss1: 0.0336 Loss2: 0.0407 Loss3: 0.0268\n",
            "Epoch: 30 MAE: 0.08605056883796813 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:42:57.035666 Epoch [031/100], Step [0001/0060], Loss1: 0.0322 Loss2: 0.0334 Loss3: 0.0261\n",
            "2022-06-19 21:43:21.967905 Epoch [031/100], Step [0050/0060], Loss1: 0.0280 Loss2: 0.0340 Loss3: 0.0239\n",
            "2022-06-19 21:43:26.989338 Epoch [031/100], Step [0060/0060], Loss1: 0.0273 Loss2: 0.0357 Loss3: 0.0232\n",
            "Epoch: 31 MAE: 0.08372655121737688 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:43:32.446172 Epoch [032/100], Step [0001/0060], Loss1: 0.0285 Loss2: 0.0326 Loss3: 0.0239\n",
            "2022-06-19 21:43:57.096938 Epoch [032/100], Step [0050/0060], Loss1: 0.0277 Loss2: 0.0319 Loss3: 0.0241\n",
            "2022-06-19 21:44:02.138444 Epoch [032/100], Step [0060/0060], Loss1: 0.0283 Loss2: 0.0342 Loss3: 0.0238\n",
            "Epoch: 32 MAE: 0.08368925104696283 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:44:07.580416 Epoch [033/100], Step [0001/0060], Loss1: 0.0309 Loss2: 0.0396 Loss3: 0.0285\n",
            "2022-06-19 21:44:32.190078 Epoch [033/100], Step [0050/0060], Loss1: 0.0292 Loss2: 0.0332 Loss3: 0.0220\n",
            "2022-06-19 21:44:37.209900 Epoch [033/100], Step [0060/0060], Loss1: 0.0308 Loss2: 0.0351 Loss3: 0.0258\n",
            "Epoch: 33 MAE: 0.07985938894685614 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:44:42.613110 Epoch [034/100], Step [0001/0060], Loss1: 0.0249 Loss2: 0.0306 Loss3: 0.0214\n",
            "2022-06-19 21:45:07.222169 Epoch [034/100], Step [0050/0060], Loss1: 0.0293 Loss2: 0.0310 Loss3: 0.0217\n",
            "2022-06-19 21:45:12.232082 Epoch [034/100], Step [0060/0060], Loss1: 0.0275 Loss2: 0.0335 Loss3: 0.0235\n",
            "Epoch: 34 MAE: 0.0856852969416866 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:45:18.326642 Epoch [035/100], Step [0001/0060], Loss1: 0.0271 Loss2: 0.0326 Loss3: 0.0235\n",
            "2022-06-19 21:45:43.066225 Epoch [035/100], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0307 Loss3: 0.0215\n",
            "2022-06-19 21:45:48.089707 Epoch [035/100], Step [0060/0060], Loss1: 0.0295 Loss2: 0.0323 Loss3: 0.0233\n",
            "Epoch: 35 MAE: 0.08812946248937535 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:45:55.537980 Epoch [036/100], Step [0001/0060], Loss1: 0.0256 Loss2: 0.0303 Loss3: 0.0221\n",
            "2022-06-19 21:46:20.192297 Epoch [036/100], Step [0050/0060], Loss1: 0.0267 Loss2: 0.0326 Loss3: 0.0231\n",
            "2022-06-19 21:46:25.200479 Epoch [036/100], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0321 Loss3: 0.0222\n",
            "Epoch: 36 MAE: 0.08328184450744952 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:46:30.592988 Epoch [037/100], Step [0001/0060], Loss1: 0.0267 Loss2: 0.0323 Loss3: 0.0219\n",
            "2022-06-19 21:46:55.221420 Epoch [037/100], Step [0050/0060], Loss1: 0.0261 Loss2: 0.0303 Loss3: 0.0214\n",
            "2022-06-19 21:47:00.228953 Epoch [037/100], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0322 Loss3: 0.0213\n",
            "Epoch: 37 MAE: 0.07968435751698004 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:47:05.586472 Epoch [038/100], Step [0001/0060], Loss1: 0.0266 Loss2: 0.0351 Loss3: 0.0252\n",
            "2022-06-19 21:47:30.740119 Epoch [038/100], Step [0050/0060], Loss1: 0.0241 Loss2: 0.0328 Loss3: 0.0229\n",
            "2022-06-19 21:47:36.093995 Epoch [038/100], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0324 Loss3: 0.0219\n",
            "Epoch: 38 MAE: 0.08223704232109917 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:47:41.489936 Epoch [039/100], Step [0001/0060], Loss1: 0.0253 Loss2: 0.0317 Loss3: 0.0230\n",
            "2022-06-19 21:48:06.098971 Epoch [039/100], Step [0050/0060], Loss1: 0.0276 Loss2: 0.0297 Loss3: 0.0229\n",
            "2022-06-19 21:48:11.119605 Epoch [039/100], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0341 Loss3: 0.0221\n",
            "Epoch: 39 MAE: 0.08537296295166015 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:48:16.486141 Epoch [040/100], Step [0001/0060], Loss1: 0.0278 Loss2: 0.0310 Loss3: 0.0232\n",
            "2022-06-19 21:48:41.041281 Epoch [040/100], Step [0050/0060], Loss1: 0.0263 Loss2: 0.0345 Loss3: 0.0235\n",
            "2022-06-19 21:48:46.043768 Epoch [040/100], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0321 Loss3: 0.0233\n",
            "Epoch: 40 MAE: 0.08353328129601856 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:48:53.603484 Epoch [041/100], Step [0001/0060], Loss1: 0.0253 Loss2: 0.0322 Loss3: 0.0220\n",
            "2022-06-19 21:49:18.168542 Epoch [041/100], Step [0050/0060], Loss1: 0.0258 Loss2: 0.0341 Loss3: 0.0241\n",
            "2022-06-19 21:49:23.181864 Epoch [041/100], Step [0060/0060], Loss1: 0.0262 Loss2: 0.0339 Loss3: 0.0228\n",
            "Epoch: 41 MAE: 0.08441414484902034 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "2022-06-19 21:49:28.596904 Epoch [042/100], Step [0001/0060], Loss1: 0.0279 Loss2: 0.0333 Loss3: 0.0244\n",
            "2022-06-19 21:49:53.804271 Epoch [042/100], Step [0050/0060], Loss1: 0.0254 Loss2: 0.0309 Loss3: 0.0229\n",
            "2022-06-19 21:49:58.827169 Epoch [042/100], Step [0060/0060], Loss1: 0.0367 Loss2: 0.0386 Loss3: 0.0328\n",
            "Epoch: 42 MAE: 0.079058753926918 ####  bestMAE: 0.07937494883461602 bestEpoch: 29\n",
            "best epoch:42\n",
            "2022-06-19 21:50:06.406748 Epoch [043/100], Step [0001/0060], Loss1: 0.0271 Loss2: 0.0304 Loss3: 0.0230\n",
            "2022-06-19 21:50:31.026797 Epoch [043/100], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0282 Loss3: 0.0207\n",
            "2022-06-19 21:50:36.043481 Epoch [043/100], Step [0060/0060], Loss1: 0.0262 Loss2: 0.0343 Loss3: 0.0238\n",
            "Epoch: 43 MAE: 0.08373286782118379 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:50:41.388745 Epoch [044/100], Step [0001/0060], Loss1: 0.0267 Loss2: 0.0321 Loss3: 0.0220\n",
            "2022-06-19 21:51:06.045480 Epoch [044/100], Step [0050/0060], Loss1: 0.0294 Loss2: 0.0297 Loss3: 0.0219\n",
            "2022-06-19 21:51:11.056272 Epoch [044/100], Step [0060/0060], Loss1: 0.0260 Loss2: 0.0304 Loss3: 0.0209\n",
            "Epoch: 44 MAE: 0.08260887832237927 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:51:16.431402 Epoch [045/100], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0295 Loss3: 0.0218\n",
            "2022-06-19 21:51:41.034103 Epoch [045/100], Step [0050/0060], Loss1: 0.0320 Loss2: 0.0314 Loss3: 0.0232\n",
            "2022-06-19 21:51:46.055988 Epoch [045/100], Step [0060/0060], Loss1: 0.0326 Loss2: 0.0342 Loss3: 0.0264\n",
            "Epoch: 45 MAE: 0.09490431074112184 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:51:54.081632 Epoch [046/100], Step [0001/0060], Loss1: 0.0322 Loss2: 0.0312 Loss3: 0.0288\n",
            "2022-06-19 21:52:19.226776 Epoch [046/100], Step [0050/0060], Loss1: 0.0307 Loss2: 0.0323 Loss3: 0.0219\n",
            "2022-06-19 21:52:24.255998 Epoch [046/100], Step [0060/0060], Loss1: 0.0310 Loss2: 0.0328 Loss3: 0.0235\n",
            "Epoch: 46 MAE: 0.08502573840832585 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:52:29.570252 Epoch [047/100], Step [0001/0060], Loss1: 0.0271 Loss2: 0.0296 Loss3: 0.0219\n",
            "2022-06-19 21:52:54.178706 Epoch [047/100], Step [0050/0060], Loss1: 0.0296 Loss2: 0.0323 Loss3: 0.0242\n",
            "2022-06-19 21:52:59.188094 Epoch [047/100], Step [0060/0060], Loss1: 0.0259 Loss2: 0.0325 Loss3: 0.0229\n",
            "Epoch: 47 MAE: 0.09420737251402841 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:53:04.506059 Epoch [048/100], Step [0001/0060], Loss1: 0.0254 Loss2: 0.0330 Loss3: 0.0241\n",
            "2022-06-19 21:53:29.142571 Epoch [048/100], Step [0050/0060], Loss1: 0.0254 Loss2: 0.0310 Loss3: 0.0214\n",
            "2022-06-19 21:53:34.195888 Epoch [048/100], Step [0060/0060], Loss1: 0.0254 Loss2: 0.0272 Loss3: 0.0222\n",
            "Epoch: 48 MAE: 0.08302891039974472 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:53:39.559901 Epoch [049/100], Step [0001/0060], Loss1: 0.0243 Loss2: 0.0292 Loss3: 0.0212\n",
            "2022-06-19 21:54:04.149176 Epoch [049/100], Step [0050/0060], Loss1: 0.0295 Loss2: 0.0351 Loss3: 0.0244\n",
            "2022-06-19 21:54:09.354721 Epoch [049/100], Step [0060/0060], Loss1: 0.0256 Loss2: 0.0313 Loss3: 0.0219\n",
            "Epoch: 49 MAE: 0.08054270789736788 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:54:15.359903 Epoch [050/100], Step [0001/0060], Loss1: 0.0262 Loss2: 0.0310 Loss3: 0.0224\n",
            "2022-06-19 21:54:40.005979 Epoch [050/100], Step [0050/0060], Loss1: 0.0305 Loss2: 0.0389 Loss3: 0.0263\n",
            "2022-06-19 21:54:45.021640 Epoch [050/100], Step [0060/0060], Loss1: 0.0243 Loss2: 0.0288 Loss3: 0.0209\n",
            "Epoch: 50 MAE: 0.08228911253510328 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:54:53.124950 Epoch [051/100], Step [0001/0060], Loss1: 0.0259 Loss2: 0.0326 Loss3: 0.0220\n",
            "2022-06-19 21:55:17.739093 Epoch [051/100], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0301 Loss3: 0.0222\n",
            "2022-06-19 21:55:22.755541 Epoch [051/100], Step [0060/0060], Loss1: 0.0285 Loss2: 0.0354 Loss3: 0.0233\n",
            "Epoch: 51 MAE: 0.08188692203905217 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:55:28.077503 Epoch [052/100], Step [0001/0060], Loss1: 0.0268 Loss2: 0.0324 Loss3: 0.0216\n",
            "2022-06-19 21:55:52.707899 Epoch [052/100], Step [0050/0060], Loss1: 0.0230 Loss2: 0.0281 Loss3: 0.0219\n",
            "2022-06-19 21:55:57.716642 Epoch [052/100], Step [0060/0060], Loss1: 0.0247 Loss2: 0.0314 Loss3: 0.0225\n",
            "Epoch: 52 MAE: 0.08952100985895392 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "2022-06-19 21:56:03.054593 Epoch [053/100], Step [0001/0060], Loss1: 0.0270 Loss2: 0.0347 Loss3: 0.0238\n",
            "2022-06-19 21:56:28.635437 Epoch [053/100], Step [0050/0060], Loss1: 0.0265 Loss2: 0.0312 Loss3: 0.0217\n",
            "2022-06-19 21:56:33.640164 Epoch [053/100], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0297 Loss3: 0.0210\n",
            "Epoch: 53 MAE: 0.07883859987612125 ####  bestMAE: 0.079058753926918 bestEpoch: 42\n",
            "best epoch:53\n",
            "2022-06-19 21:56:41.462285 Epoch [054/100], Step [0001/0060], Loss1: 0.0272 Loss2: 0.0301 Loss3: 0.0225\n",
            "2022-06-19 21:57:06.266822 Epoch [054/100], Step [0050/0060], Loss1: 0.0244 Loss2: 0.0289 Loss3: 0.0222\n",
            "2022-06-19 21:57:11.278708 Epoch [054/100], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0281 Loss3: 0.0211\n",
            "Epoch: 54 MAE: 0.07819722367342188 ####  bestMAE: 0.07883859987612125 bestEpoch: 53\n",
            "best epoch:54\n",
            "2022-06-19 21:57:20.004691 Epoch [055/100], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0280 Loss3: 0.0204\n",
            "2022-06-19 21:57:44.662560 Epoch [055/100], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0301 Loss3: 0.0203\n",
            "2022-06-19 21:57:49.667539 Epoch [055/100], Step [0060/0060], Loss1: 0.0266 Loss2: 0.0285 Loss3: 0.0224\n",
            "Epoch: 55 MAE: 0.08295034030127148 ####  bestMAE: 0.07819722367342188 bestEpoch: 54\n",
            "2022-06-19 21:57:57.295536 Epoch [056/100], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0293 Loss3: 0.0221\n",
            "2022-06-19 21:58:21.928010 Epoch [056/100], Step [0050/0060], Loss1: 0.0242 Loss2: 0.0276 Loss3: 0.0197\n",
            "2022-06-19 21:58:26.947734 Epoch [056/100], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0266 Loss3: 0.0207\n",
            "Epoch: 56 MAE: 0.08946076478907668 ####  bestMAE: 0.07819722367342188 bestEpoch: 54\n",
            "2022-06-19 21:58:33.316438 Epoch [057/100], Step [0001/0060], Loss1: 0.0251 Loss2: 0.0300 Loss3: 0.0205\n",
            "2022-06-19 21:58:58.659741 Epoch [057/100], Step [0050/0060], Loss1: 0.0242 Loss2: 0.0296 Loss3: 0.0219\n",
            "2022-06-19 21:59:03.672802 Epoch [057/100], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0315 Loss3: 0.0213\n",
            "Epoch: 57 MAE: 0.08231301191622616 ####  bestMAE: 0.07819722367342188 bestEpoch: 54\n",
            "2022-06-19 21:59:09.100398 Epoch [058/100], Step [0001/0060], Loss1: 0.0280 Loss2: 0.0314 Loss3: 0.0246\n",
            "2022-06-19 21:59:33.670483 Epoch [058/100], Step [0050/0060], Loss1: 0.0242 Loss2: 0.0319 Loss3: 0.0215\n",
            "2022-06-19 21:59:38.680151 Epoch [058/100], Step [0060/0060], Loss1: 0.0242 Loss2: 0.0315 Loss3: 0.0211\n",
            "Epoch: 58 MAE: 0.07949770493482157 ####  bestMAE: 0.07819722367342188 bestEpoch: 54\n",
            "2022-06-19 21:59:44.092498 Epoch [059/100], Step [0001/0060], Loss1: 0.0265 Loss2: 0.0346 Loss3: 0.0230\n",
            "2022-06-19 22:00:08.665157 Epoch [059/100], Step [0050/0060], Loss1: 0.0222 Loss2: 0.0286 Loss3: 0.0204\n",
            "2022-06-19 22:00:13.684251 Epoch [059/100], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0318 Loss3: 0.0224\n",
            "Epoch: 59 MAE: 0.07182348402719647 ####  bestMAE: 0.07819722367342188 bestEpoch: 54\n",
            "best epoch:59\n",
            "2022-06-19 22:00:21.372328 Epoch [060/100], Step [0001/0060], Loss1: 0.0280 Loss2: 0.0295 Loss3: 0.0232\n",
            "2022-06-19 22:00:46.117537 Epoch [060/100], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0284 Loss3: 0.0207\n",
            "2022-06-19 22:00:51.302339 Epoch [060/100], Step [0060/0060], Loss1: 0.0232 Loss2: 0.0311 Loss3: 0.0201\n",
            "Epoch: 60 MAE: 0.07709231734906555 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:00:58.868690 Epoch [061/100], Step [0001/0060], Loss1: 0.0240 Loss2: 0.0323 Loss3: 0.0210\n",
            "2022-06-19 22:01:23.536957 Epoch [061/100], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0271 Loss3: 0.0188\n",
            "2022-06-19 22:01:28.562313 Epoch [061/100], Step [0060/0060], Loss1: 0.0236 Loss2: 0.0307 Loss3: 0.0209\n",
            "Epoch: 61 MAE: 0.07794262658982049 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:01:34.008399 Epoch [062/100], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0272 Loss3: 0.0208\n",
            "2022-06-19 22:01:58.647312 Epoch [062/100], Step [0050/0060], Loss1: 0.0242 Loss2: 0.0324 Loss3: 0.0211\n",
            "2022-06-19 22:02:03.663395 Epoch [062/100], Step [0060/0060], Loss1: 0.0216 Loss2: 0.0281 Loss3: 0.0191\n",
            "Epoch: 62 MAE: 0.07723119301770728 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:02:09.081722 Epoch [063/100], Step [0001/0060], Loss1: 0.0223 Loss2: 0.0270 Loss3: 0.0194\n",
            "2022-06-19 22:02:33.709110 Epoch [063/100], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0309 Loss3: 0.0203\n",
            "2022-06-19 22:02:38.742552 Epoch [063/100], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0287 Loss3: 0.0206\n",
            "Epoch: 63 MAE: 0.07699529849662982 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:02:44.145824 Epoch [064/100], Step [0001/0060], Loss1: 0.0275 Loss2: 0.0327 Loss3: 0.0234\n",
            "2022-06-19 22:03:09.606556 Epoch [064/100], Step [0050/0060], Loss1: 0.0268 Loss2: 0.0316 Loss3: 0.0225\n",
            "2022-06-19 22:03:14.615480 Epoch [064/100], Step [0060/0060], Loss1: 0.0248 Loss2: 0.0302 Loss3: 0.0212\n",
            "Epoch: 64 MAE: 0.07730444297588693 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:03:20.060514 Epoch [065/100], Step [0001/0060], Loss1: 0.0225 Loss2: 0.0275 Loss3: 0.0198\n",
            "2022-06-19 22:03:44.692088 Epoch [065/100], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0286 Loss3: 0.0202\n",
            "2022-06-19 22:03:49.701350 Epoch [065/100], Step [0060/0060], Loss1: 0.0227 Loss2: 0.0286 Loss3: 0.0199\n",
            "Epoch: 65 MAE: 0.07934867414847882 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:03:57.265915 Epoch [066/100], Step [0001/0060], Loss1: 0.0237 Loss2: 0.0287 Loss3: 0.0206\n",
            "2022-06-19 22:04:21.978406 Epoch [066/100], Step [0050/0060], Loss1: 0.0225 Loss2: 0.0283 Loss3: 0.0200\n",
            "2022-06-19 22:04:27.000701 Epoch [066/100], Step [0060/0060], Loss1: 0.0254 Loss2: 0.0305 Loss3: 0.0223\n",
            "Epoch: 66 MAE: 0.07710250531554852 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:04:32.376020 Epoch [067/100], Step [0001/0060], Loss1: 0.0245 Loss2: 0.0311 Loss3: 0.0216\n",
            "2022-06-19 22:04:57.010662 Epoch [067/100], Step [0050/0060], Loss1: 0.0243 Loss2: 0.0313 Loss3: 0.0214\n",
            "2022-06-19 22:05:02.023199 Epoch [067/100], Step [0060/0060], Loss1: 0.0218 Loss2: 0.0288 Loss3: 0.0190\n",
            "Epoch: 67 MAE: 0.07779278139588695 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:05:07.391721 Epoch [068/100], Step [0001/0060], Loss1: 0.0237 Loss2: 0.0316 Loss3: 0.0211\n",
            "2022-06-19 22:05:33.123020 Epoch [068/100], Step [0050/0060], Loss1: 0.0233 Loss2: 0.0294 Loss3: 0.0209\n",
            "2022-06-19 22:05:38.168315 Epoch [068/100], Step [0060/0060], Loss1: 0.0226 Loss2: 0.0283 Loss3: 0.0198\n",
            "Epoch: 68 MAE: 0.08016503132209572 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:05:43.679736 Epoch [069/100], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0279 Loss3: 0.0193\n",
            "2022-06-19 22:06:08.346054 Epoch [069/100], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0283 Loss3: 0.0199\n",
            "2022-06-19 22:06:13.356467 Epoch [069/100], Step [0060/0060], Loss1: 0.0223 Loss2: 0.0269 Loss3: 0.0198\n",
            "Epoch: 69 MAE: 0.07987602223794929 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:06:18.722497 Epoch [070/100], Step [0001/0060], Loss1: 0.0227 Loss2: 0.0299 Loss3: 0.0202\n",
            "2022-06-19 22:06:43.393282 Epoch [070/100], Step [0050/0060], Loss1: 0.0231 Loss2: 0.0286 Loss3: 0.0201\n",
            "2022-06-19 22:06:48.418587 Epoch [070/100], Step [0060/0060], Loss1: 0.0244 Loss2: 0.0307 Loss3: 0.0212\n",
            "Epoch: 70 MAE: 0.07626409273298958 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:06:56.151965 Epoch [071/100], Step [0001/0060], Loss1: 0.0214 Loss2: 0.0260 Loss3: 0.0193\n",
            "2022-06-19 22:07:20.770283 Epoch [071/100], Step [0050/0060], Loss1: 0.0236 Loss2: 0.0291 Loss3: 0.0204\n",
            "2022-06-19 22:07:25.838434 Epoch [071/100], Step [0060/0060], Loss1: 0.0217 Loss2: 0.0272 Loss3: 0.0192\n",
            "Epoch: 71 MAE: 0.07828603310559792 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:07:32.705767 Epoch [072/100], Step [0001/0060], Loss1: 0.0237 Loss2: 0.0301 Loss3: 0.0210\n",
            "2022-06-19 22:07:57.502245 Epoch [072/100], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0294 Loss3: 0.0203\n",
            "2022-06-19 22:08:02.514271 Epoch [072/100], Step [0060/0060], Loss1: 0.0214 Loss2: 0.0259 Loss3: 0.0185\n",
            "Epoch: 72 MAE: 0.07925377901269018 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:08:07.893082 Epoch [073/100], Step [0001/0060], Loss1: 0.0229 Loss2: 0.0299 Loss3: 0.0202\n",
            "2022-06-19 22:08:32.573151 Epoch [073/100], Step [0050/0060], Loss1: 0.0238 Loss2: 0.0301 Loss3: 0.0208\n",
            "2022-06-19 22:08:37.579868 Epoch [073/100], Step [0060/0060], Loss1: 0.0231 Loss2: 0.0263 Loss3: 0.0191\n",
            "Epoch: 73 MAE: 0.0772613221123105 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:08:42.910768 Epoch [074/100], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0267 Loss3: 0.0196\n",
            "2022-06-19 22:09:07.505581 Epoch [074/100], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0276 Loss3: 0.0190\n",
            "2022-06-19 22:09:12.512704 Epoch [074/100], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0280 Loss3: 0.0194\n",
            "Epoch: 74 MAE: 0.07961424928493599 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:09:17.855972 Epoch [075/100], Step [0001/0060], Loss1: 0.0217 Loss2: 0.0258 Loss3: 0.0191\n",
            "2022-06-19 22:09:42.669022 Epoch [075/100], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0285 Loss3: 0.0199\n",
            "2022-06-19 22:09:47.871197 Epoch [075/100], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0271 Loss3: 0.0200\n",
            "Epoch: 75 MAE: 0.07712648043556818 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:09:55.344122 Epoch [076/100], Step [0001/0060], Loss1: 0.0213 Loss2: 0.0253 Loss3: 0.0180\n",
            "2022-06-19 22:10:19.975662 Epoch [076/100], Step [0050/0060], Loss1: 0.0259 Loss2: 0.0290 Loss3: 0.0243\n",
            "2022-06-19 22:10:24.986615 Epoch [076/100], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0260 Loss3: 0.0197\n",
            "Epoch: 76 MAE: 0.0784474869884511 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:10:30.341184 Epoch [077/100], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0285 Loss3: 0.0200\n",
            "2022-06-19 22:10:55.019057 Epoch [077/100], Step [0050/0060], Loss1: 0.0216 Loss2: 0.0282 Loss3: 0.0194\n",
            "2022-06-19 22:11:00.036990 Epoch [077/100], Step [0060/0060], Loss1: 0.0235 Loss2: 0.0297 Loss3: 0.0210\n",
            "Epoch: 77 MAE: 0.07905573607752561 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:11:05.477865 Epoch [078/100], Step [0001/0060], Loss1: 0.0236 Loss2: 0.0295 Loss3: 0.0208\n",
            "2022-06-19 22:11:30.065376 Epoch [078/100], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0264 Loss3: 0.0190\n",
            "2022-06-19 22:11:35.078749 Epoch [078/100], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0299 Loss3: 0.0203\n",
            "Epoch: 78 MAE: 0.07756021378532288 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:11:40.435373 Epoch [079/100], Step [0001/0060], Loss1: 0.0225 Loss2: 0.0271 Loss3: 0.0196\n",
            "2022-06-19 22:12:05.820202 Epoch [079/100], Step [0050/0060], Loss1: 0.0228 Loss2: 0.0301 Loss3: 0.0205\n",
            "2022-06-19 22:12:10.842990 Epoch [079/100], Step [0060/0060], Loss1: 0.0239 Loss2: 0.0294 Loss3: 0.0208\n",
            "Epoch: 79 MAE: 0.07680334262746977 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:12:16.161381 Epoch [080/100], Step [0001/0060], Loss1: 0.0218 Loss2: 0.0274 Loss3: 0.0194\n",
            "2022-06-19 22:12:40.760346 Epoch [080/100], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0289 Loss3: 0.0200\n",
            "2022-06-19 22:12:45.765445 Epoch [080/100], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0315 Loss3: 0.0213\n",
            "Epoch: 80 MAE: 0.07779796792085839 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:12:53.451957 Epoch [081/100], Step [0001/0060], Loss1: 0.0217 Loss2: 0.0262 Loss3: 0.0191\n",
            "2022-06-19 22:13:18.073262 Epoch [081/100], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0308 Loss3: 0.0198\n",
            "2022-06-19 22:13:23.104109 Epoch [081/100], Step [0060/0060], Loss1: 0.0251 Loss2: 0.0336 Loss3: 0.0220\n",
            "Epoch: 81 MAE: 0.07790145556131998 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:13:28.491640 Epoch [082/100], Step [0001/0060], Loss1: 0.0241 Loss2: 0.0288 Loss3: 0.0210\n",
            "2022-06-19 22:13:53.159796 Epoch [082/100], Step [0050/0060], Loss1: 0.0212 Loss2: 0.0259 Loss3: 0.0183\n",
            "2022-06-19 22:13:58.180125 Epoch [082/100], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0308 Loss3: 0.0214\n",
            "Epoch: 82 MAE: 0.07957431248256137 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:14:03.576243 Epoch [083/100], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0296 Loss3: 0.0196\n",
            "2022-06-19 22:14:28.974143 Epoch [083/100], Step [0050/0060], Loss1: 0.0219 Loss2: 0.0264 Loss3: 0.0198\n",
            "2022-06-19 22:14:33.993242 Epoch [083/100], Step [0060/0060], Loss1: 0.0227 Loss2: 0.0303 Loss3: 0.0204\n",
            "Epoch: 83 MAE: 0.07962193342743731 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:14:39.435249 Epoch [084/100], Step [0001/0060], Loss1: 0.0233 Loss2: 0.0298 Loss3: 0.0202\n",
            "2022-06-19 22:15:04.105213 Epoch [084/100], Step [0050/0060], Loss1: 0.0229 Loss2: 0.0321 Loss3: 0.0204\n",
            "2022-06-19 22:15:09.122157 Epoch [084/100], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0312 Loss3: 0.0219\n",
            "Epoch: 84 MAE: 0.07897675372936107 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:15:14.480642 Epoch [085/100], Step [0001/0060], Loss1: 0.0239 Loss2: 0.0293 Loss3: 0.0208\n",
            "2022-06-19 22:15:39.136659 Epoch [085/100], Step [0050/0060], Loss1: 0.0225 Loss2: 0.0273 Loss3: 0.0201\n",
            "2022-06-19 22:15:44.160144 Epoch [085/100], Step [0060/0060], Loss1: 0.0219 Loss2: 0.0264 Loss3: 0.0193\n",
            "Epoch: 85 MAE: 0.07734143141085509 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:15:51.675954 Epoch [086/100], Step [0001/0060], Loss1: 0.0224 Loss2: 0.0270 Loss3: 0.0195\n",
            "2022-06-19 22:16:16.285237 Epoch [086/100], Step [0050/0060], Loss1: 0.0222 Loss2: 0.0258 Loss3: 0.0194\n",
            "2022-06-19 22:16:21.507880 Epoch [086/100], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0261 Loss3: 0.0192\n",
            "Epoch: 86 MAE: 0.0769572760062243 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:16:28.837353 Epoch [087/100], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0284 Loss3: 0.0206\n",
            "2022-06-19 22:16:53.668343 Epoch [087/100], Step [0050/0060], Loss1: 0.0246 Loss2: 0.0312 Loss3: 0.0215\n",
            "2022-06-19 22:16:58.670598 Epoch [087/100], Step [0060/0060], Loss1: 0.0241 Loss2: 0.0320 Loss3: 0.0208\n",
            "Epoch: 87 MAE: 0.07680781435083457 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:17:04.009581 Epoch [088/100], Step [0001/0060], Loss1: 0.0228 Loss2: 0.0281 Loss3: 0.0203\n",
            "2022-06-19 22:17:28.657119 Epoch [088/100], Step [0050/0060], Loss1: 0.0208 Loss2: 0.0247 Loss3: 0.0188\n",
            "2022-06-19 22:17:33.664699 Epoch [088/100], Step [0060/0060], Loss1: 0.0245 Loss2: 0.0295 Loss3: 0.0218\n",
            "Epoch: 88 MAE: 0.080325264400906 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:17:39.108913 Epoch [089/100], Step [0001/0060], Loss1: 0.0238 Loss2: 0.0296 Loss3: 0.0210\n",
            "2022-06-19 22:18:03.733774 Epoch [089/100], Step [0050/0060], Loss1: 0.0224 Loss2: 0.0283 Loss3: 0.0197\n",
            "2022-06-19 22:18:08.772684 Epoch [089/100], Step [0060/0060], Loss1: 0.0232 Loss2: 0.0287 Loss3: 0.0205\n",
            "Epoch: 89 MAE: 0.07930918718771963 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:18:14.162696 Epoch [090/100], Step [0001/0060], Loss1: 0.0232 Loss2: 0.0274 Loss3: 0.0194\n",
            "2022-06-19 22:18:38.971780 Epoch [090/100], Step [0050/0060], Loss1: 0.0213 Loss2: 0.0263 Loss3: 0.0192\n",
            "2022-06-19 22:18:44.106446 Epoch [090/100], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0291 Loss3: 0.0196\n",
            "Epoch: 90 MAE: 0.07954421351195644 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:18:53.330195 Epoch [091/100], Step [0001/0060], Loss1: 0.0221 Loss2: 0.0269 Loss3: 0.0193\n",
            "2022-06-19 22:19:18.018780 Epoch [091/100], Step [0050/0060], Loss1: 0.0217 Loss2: 0.0266 Loss3: 0.0191\n",
            "2022-06-19 22:19:23.035332 Epoch [091/100], Step [0060/0060], Loss1: 0.0227 Loss2: 0.0273 Loss3: 0.0201\n",
            "Epoch: 91 MAE: 0.07929949220526157 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:19:28.394108 Epoch [092/100], Step [0001/0060], Loss1: 0.0235 Loss2: 0.0306 Loss3: 0.0204\n",
            "2022-06-19 22:19:52.985005 Epoch [092/100], Step [0050/0060], Loss1: 0.0223 Loss2: 0.0279 Loss3: 0.0197\n",
            "2022-06-19 22:19:58.010108 Epoch [092/100], Step [0060/0060], Loss1: 0.0240 Loss2: 0.0302 Loss3: 0.0206\n",
            "Epoch: 92 MAE: 0.07512267693009958 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:20:03.353619 Epoch [093/100], Step [0001/0060], Loss1: 0.0234 Loss2: 0.0293 Loss3: 0.0204\n",
            "2022-06-19 22:20:27.991736 Epoch [093/100], Step [0050/0060], Loss1: 0.0214 Loss2: 0.0285 Loss3: 0.0193\n",
            "2022-06-19 22:20:33.009044 Epoch [093/100], Step [0060/0060], Loss1: 0.0229 Loss2: 0.0278 Loss3: 0.0203\n",
            "Epoch: 93 MAE: 0.08047015063977114 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:20:38.361693 Epoch [094/100], Step [0001/0060], Loss1: 0.0232 Loss2: 0.0298 Loss3: 0.0210\n",
            "2022-06-19 22:21:03.727484 Epoch [094/100], Step [0050/0060], Loss1: 0.0245 Loss2: 0.0270 Loss3: 0.0205\n",
            "2022-06-19 22:21:08.728588 Epoch [094/100], Step [0060/0060], Loss1: 0.0234 Loss2: 0.0284 Loss3: 0.0200\n",
            "Epoch: 94 MAE: 0.07874055907839822 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:21:14.135823 Epoch [095/100], Step [0001/0060], Loss1: 0.0226 Loss2: 0.0273 Loss3: 0.0202\n",
            "2022-06-19 22:21:38.806747 Epoch [095/100], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0262 Loss3: 0.0191\n",
            "2022-06-19 22:21:43.847740 Epoch [095/100], Step [0060/0060], Loss1: 0.0225 Loss2: 0.0280 Loss3: 0.0197\n",
            "Epoch: 95 MAE: 0.07972193985389019 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:21:52.371882 Epoch [096/100], Step [0001/0060], Loss1: 0.0230 Loss2: 0.0292 Loss3: 0.0205\n",
            "2022-06-19 22:22:17.035808 Epoch [096/100], Step [0050/0060], Loss1: 0.0232 Loss2: 0.0255 Loss3: 0.0208\n",
            "2022-06-19 22:22:22.065187 Epoch [096/100], Step [0060/0060], Loss1: 0.0234 Loss2: 0.0287 Loss3: 0.0206\n",
            "Epoch: 96 MAE: 0.07893589973449709 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:22:28.211288 Epoch [097/100], Step [0001/0060], Loss1: 0.0210 Loss2: 0.0255 Loss3: 0.0187\n",
            "2022-06-19 22:22:52.870472 Epoch [097/100], Step [0050/0060], Loss1: 0.0231 Loss2: 0.0311 Loss3: 0.0200\n",
            "2022-06-19 22:22:57.900979 Epoch [097/100], Step [0060/0060], Loss1: 0.0250 Loss2: 0.0317 Loss3: 0.0218\n",
            "Epoch: 97 MAE: 0.07609300547806676 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:23:04.025199 Epoch [098/100], Step [0001/0060], Loss1: 0.0222 Loss2: 0.0283 Loss3: 0.0194\n",
            "2022-06-19 22:23:29.327019 Epoch [098/100], Step [0050/0060], Loss1: 0.0226 Loss2: 0.0282 Loss3: 0.0200\n",
            "2022-06-19 22:23:34.343613 Epoch [098/100], Step [0060/0060], Loss1: 0.0221 Loss2: 0.0268 Loss3: 0.0195\n",
            "Epoch: 98 MAE: 0.07702083663334922 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n",
            "2022-06-19 22:23:39.759483 Epoch [099/100], Step [0001/0060], Loss1: 0.0215 Loss2: 0.0273 Loss3: 0.0191\n",
            "2022-06-19 22:24:04.390118 Epoch [099/100], Step [0050/0060], Loss1: 0.0220 Loss2: 0.0277 Loss3: 0.0195\n",
            "2022-06-19 22:24:09.406092 Epoch [099/100], Step [0060/0060], Loss1: 0.0243 Loss2: 0.0304 Loss3: 0.0212\n",
            "Epoch: 99 MAE: 0.07780589931225648 ####  bestMAE: 0.07182348402719647 bestEpoch: 59\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SSIM Loss Epoch 100"
      ],
      "metadata": {
        "id": "lIVqC0YW74vo"
      },
      "id": "lIVqC0YW74vo"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "train_accu = []\n",
        "train_losses = []\n",
        "train_accu1 = []\n",
        "train_accu2 = []\n",
        "train_accu3 = []\n",
        "train_losses1 = []\n",
        "train_losses2 = []\n",
        "train_losses3 = []\n",
        "val_accu = []\n",
        "val_losses = []\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "def perceptual_loss(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def perceptual_loss_detach(mask, pred):\n",
        "    loss =  1.0 * CE(pred, mask.detach())\n",
        "    return loss\n",
        "\n",
        "def combine_loss(mask, pred):\n",
        "    L1 = torch.nn.L1Loss()\n",
        "    L2 = torch.nn.SmoothL1Loss()\n",
        "    loss =  1.0 * ( L1(pred, mask) + L2(pred, mask))\n",
        "    return loss\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    running_loss = 0\n",
        "    running_loss1 = 0\n",
        "    running_loss2 = 0\n",
        "    running_loss3 = 0\n",
        "    total = 0\n",
        "    total1 = 0\n",
        "    total2 = 0\n",
        "    total3 = 0\n",
        "    correct = 0\n",
        "    correct1 = 0\n",
        "    correct2 = 0\n",
        "    correct3 = 0\n",
        "\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(gts, pre_res[0]) \n",
        "            loss2    = fun_ssim(gts, pre_res[1])\n",
        "            loss3    = fun_ssim(gts, pre_res[2])\n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "\n",
        "            #loss graph\n",
        "            running_loss1 += loss1.item()\n",
        "            running_loss2 += loss2.item()\n",
        "            running_loss3 += loss3.item()\n",
        "            predicted1 = pre_res[0]\n",
        "            predicted2 = pre_res[1]\n",
        "            predicted3 = pre_res[2]\n",
        "            total1 += images.size(0)\n",
        "            total2 += gts.size(0)\n",
        "            total3 += depths.size(0)\n",
        "            correct1 += predicted1.eq(images).sum().item()\n",
        "            correct2 += predicted2.eq(gts).sum().item()\n",
        "            correct3 += predicted3.eq(depths).sum().item()\n",
        "\n",
        "            running_loss += loss_all.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += images.size(0)\n",
        "            correct += outputs.eq(images).sum().item()\n",
        "            \n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "\n",
        "        train_loss = running_loss/len(train_loader)\n",
        "        train_loss1=running_loss1/len(train_loader)\n",
        "        train_loss2=running_loss2/len(train_loader)\n",
        "        train_loss3=running_loss3/len(train_loader)\n",
        "        accu = 100.*correct/total\n",
        "        accu1=100.*correct1/total1\n",
        "        accu2=100.*correct2/total2\n",
        "        accu3=100.*correct3/total3        \n",
        "        train_accu1.append(accu1)\n",
        "        train_accu2.append(accu2)\n",
        "        train_accu3.append(accu3)\n",
        "        train_losses1.append(train_loss1)\n",
        "        train_losses2.append(train_loss2)\n",
        "        train_losses3.append(train_loss3)\n",
        "        train_accu.append(accu)\n",
        "        train_losses.append(train_loss)\n",
        "\n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "           \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "\n",
        "            #loss graph\n",
        "            running_loss += mae_sum.item()\n",
        "            gt, loss, predicted = pre_res\n",
        "            outputs = gt + loss + predicted\n",
        "            total += test_loader.size\n",
        "            correct += outputs.eq(image).sum().item()\n",
        "\n",
        "\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "       \n",
        "        val_loss=running_loss/len(test_loader)\n",
        "        accu=100.*correct/total\n",
        "        val_accu.append(accu)\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_SSIM_Loss_500_RGB_as_depth.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n",
        "\n",
        "plt.plot(train_losses, '-')\n",
        "plt.plot(train_losses1,'-')\n",
        "plt.plot(train_losses2,'-')\n",
        "plt.plot(train_losses3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_loss','Loss1', 'Loss2', 'Loss3'])\n",
        "plt.title('Train Losses')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(train_accu, '-')\n",
        "plt.plot(train_accu1,'-')\n",
        "plt.plot(train_accu2,'-')\n",
        "plt.plot(train_accu3,'-')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('losses')\n",
        "plt.legend(['Combined_Accuracy','Acc1', 'Acc2', 'Acc3'])\n",
        "plt.title('Train Accuracy')\n",
        " \n",
        "plt.show()\n",
        "\n",
        "plt.plot(val_losses,'-o')\n",
        "plt.plot(val_accu,'-o')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend(['Losses','Accuracy'])\n",
        "plt.title('Test Losses and Accuracy')\n",
        " \n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "cebe3a3451114c998e82016ec976baf9",
            "a25746cf4cc64c9cb88363dcd6aed367",
            "8ce66d5c2f7345d9af19822d312b0d3f",
            "b24651b34dd6422183daf9edf4d4b8e5",
            "6244dc215c6b4d4bb33c771723a23617",
            "753d3d2257b940edadef9bfeb8509e3a",
            "f46970b0470443d787a3d5792cd252e7",
            "5ebce79eee354d9ab60fc6bd8ee36cd0",
            "ab56c3d8dda2446cab501d8d15eef2cc",
            "60c3d36a214d49219d57f62d899ca4d8",
            "41adb56fa0bd4209ba5572d463283fd2"
          ]
        },
        "id": "pptORPXw737R",
        "outputId": "c3ba5407-df51-453a-c2e1-5b718a5a8abc"
      },
      "id": "pptORPXw737R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cebe3a3451114c998e82016ec976baf9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data...\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "/content/tmp/traindataset_only_depth/RGB/ /content/tmp/traindataset_only_depth/GT/ /content/tmp/traindataset_only_depth/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/traindataset_only_depth/RGB/depth_00.png', '/content/tmp/traindataset_only_depth/RGB/depth_01.png', '/content/tmp/traindataset_only_depth/RGB/depth_02.png', '/content/tmp/traindataset_only_depth/RGB/depth_10.png', '/content/tmp/traindataset_only_depth/RGB/depth_100.png', '/content/tmp/traindataset_only_depth/RGB/depth_101.png', '/content/tmp/traindataset_only_depth/RGB/depth_102.png', '/content/tmp/traindataset_only_depth/RGB/depth_11.png', '/content/tmp/traindataset_only_depth/RGB/depth_110.png', '/content/tmp/traindataset_only_depth/RGB/depth_111.png', '/content/tmp/traindataset_only_depth/RGB/depth_112.png', '/content/tmp/traindataset_only_depth/RGB/depth_12.png', '/content/tmp/traindataset_only_depth/RGB/depth_120.png', '/content/tmp/traindataset_only_depth/RGB/depth_121.png', '/content/tmp/traindataset_only_depth/RGB/depth_122.png', '/content/tmp/traindataset_only_depth/RGB/depth_130.png', '/content/tmp/traindataset_only_depth/RGB/depth_131.png', '/content/tmp/traindataset_only_depth/RGB/depth_132.png', '/content/tmp/traindataset_only_depth/RGB/depth_140.png', '/content/tmp/traindataset_only_depth/RGB/depth_141.png', '/content/tmp/traindataset_only_depth/RGB/depth_142.png', '/content/tmp/traindataset_only_depth/RGB/depth_150.png', '/content/tmp/traindataset_only_depth/RGB/depth_151.png', '/content/tmp/traindataset_only_depth/RGB/depth_152.png', '/content/tmp/traindataset_only_depth/RGB/depth_160.png', '/content/tmp/traindataset_only_depth/RGB/depth_161.png', '/content/tmp/traindataset_only_depth/RGB/depth_162.png', '/content/tmp/traindataset_only_depth/RGB/depth_170.png', '/content/tmp/traindataset_only_depth/RGB/depth_171.png', '/content/tmp/traindataset_only_depth/RGB/depth_172.png', '/content/tmp/traindataset_only_depth/RGB/depth_180.png', '/content/tmp/traindataset_only_depth/RGB/depth_181.png', '/content/tmp/traindataset_only_depth/RGB/depth_182.png', '/content/tmp/traindataset_only_depth/RGB/depth_190.png', '/content/tmp/traindataset_only_depth/RGB/depth_191.png', '/content/tmp/traindataset_only_depth/RGB/depth_192.png', '/content/tmp/traindataset_only_depth/RGB/depth_20.png', '/content/tmp/traindataset_only_depth/RGB/depth_200.png', '/content/tmp/traindataset_only_depth/RGB/depth_201.png', '/content/tmp/traindataset_only_depth/RGB/depth_202.png', '/content/tmp/traindataset_only_depth/RGB/depth_21.png', '/content/tmp/traindataset_only_depth/RGB/depth_210.png', '/content/tmp/traindataset_only_depth/RGB/depth_211.png', '/content/tmp/traindataset_only_depth/RGB/depth_212.png', '/content/tmp/traindataset_only_depth/RGB/depth_22.png', '/content/tmp/traindataset_only_depth/RGB/depth_220.png', '/content/tmp/traindataset_only_depth/RGB/depth_221.png', '/content/tmp/traindataset_only_depth/RGB/depth_222.png', '/content/tmp/traindataset_only_depth/RGB/depth_230.png', '/content/tmp/traindataset_only_depth/RGB/depth_231.png', '/content/tmp/traindataset_only_depth/RGB/depth_232.png', '/content/tmp/traindataset_only_depth/RGB/depth_240.png', '/content/tmp/traindataset_only_depth/RGB/depth_241.png', '/content/tmp/traindataset_only_depth/RGB/depth_242.png', '/content/tmp/traindataset_only_depth/RGB/depth_250.png', '/content/tmp/traindataset_only_depth/RGB/depth_251.png', '/content/tmp/traindataset_only_depth/RGB/depth_252.png', '/content/tmp/traindataset_only_depth/RGB/depth_260.png', '/content/tmp/traindataset_only_depth/RGB/depth_261.png', '/content/tmp/traindataset_only_depth/RGB/depth_262.png', '/content/tmp/traindataset_only_depth/RGB/depth_270.png', '/content/tmp/traindataset_only_depth/RGB/depth_271.png', '/content/tmp/traindataset_only_depth/RGB/depth_272.png', '/content/tmp/traindataset_only_depth/RGB/depth_280.png', '/content/tmp/traindataset_only_depth/RGB/depth_281.png', '/content/tmp/traindataset_only_depth/RGB/depth_282.png', '/content/tmp/traindataset_only_depth/RGB/depth_290.png', '/content/tmp/traindataset_only_depth/RGB/depth_291.png', '/content/tmp/traindataset_only_depth/RGB/depth_292.png', '/content/tmp/traindataset_only_depth/RGB/depth_30.png', '/content/tmp/traindataset_only_depth/RGB/depth_300.png', '/content/tmp/traindataset_only_depth/RGB/depth_301.png', '/content/tmp/traindataset_only_depth/RGB/depth_302.png', '/content/tmp/traindataset_only_depth/RGB/depth_31.png', '/content/tmp/traindataset_only_depth/RGB/depth_310.png', '/content/tmp/traindataset_only_depth/RGB/depth_311.png', '/content/tmp/traindataset_only_depth/RGB/depth_312.png', '/content/tmp/traindataset_only_depth/RGB/depth_32.png', '/content/tmp/traindataset_only_depth/RGB/depth_320.png', '/content/tmp/traindataset_only_depth/RGB/depth_321.png', '/content/tmp/traindataset_only_depth/RGB/depth_322.png', '/content/tmp/traindataset_only_depth/RGB/depth_330.png', '/content/tmp/traindataset_only_depth/RGB/depth_331.png', '/content/tmp/traindataset_only_depth/RGB/depth_332.png', '/content/tmp/traindataset_only_depth/RGB/depth_340.png', '/content/tmp/traindataset_only_depth/RGB/depth_341.png', '/content/tmp/traindataset_only_depth/RGB/depth_342.png', '/content/tmp/traindataset_only_depth/RGB/depth_350.png', '/content/tmp/traindataset_only_depth/RGB/depth_351.png', '/content/tmp/traindataset_only_depth/RGB/depth_352.png', '/content/tmp/traindataset_only_depth/RGB/depth_360.png', '/content/tmp/traindataset_only_depth/RGB/depth_361.png', '/content/tmp/traindataset_only_depth/RGB/depth_362.png', '/content/tmp/traindataset_only_depth/RGB/depth_370.png', '/content/tmp/traindataset_only_depth/RGB/depth_371.png', '/content/tmp/traindataset_only_depth/RGB/depth_372.png', '/content/tmp/traindataset_only_depth/RGB/depth_380.png', '/content/tmp/traindataset_only_depth/RGB/depth_381.png', '/content/tmp/traindataset_only_depth/RGB/depth_382.png', '/content/tmp/traindataset_only_depth/RGB/depth_390.png', '/content/tmp/traindataset_only_depth/RGB/depth_391.png', '/content/tmp/traindataset_only_depth/RGB/depth_392.png', '/content/tmp/traindataset_only_depth/RGB/depth_40.png', '/content/tmp/traindataset_only_depth/RGB/depth_400.png', '/content/tmp/traindataset_only_depth/RGB/depth_401.png', '/content/tmp/traindataset_only_depth/RGB/depth_402.png', '/content/tmp/traindataset_only_depth/RGB/depth_41.png', '/content/tmp/traindataset_only_depth/RGB/depth_410.png', '/content/tmp/traindataset_only_depth/RGB/depth_411.png', '/content/tmp/traindataset_only_depth/RGB/depth_412.png', '/content/tmp/traindataset_only_depth/RGB/depth_42.png', '/content/tmp/traindataset_only_depth/RGB/depth_420.png', '/content/tmp/traindataset_only_depth/RGB/depth_421.png', '/content/tmp/traindataset_only_depth/RGB/depth_422.png', '/content/tmp/traindataset_only_depth/RGB/depth_430.png', '/content/tmp/traindataset_only_depth/RGB/depth_431.png', '/content/tmp/traindataset_only_depth/RGB/depth_432.png', '/content/tmp/traindataset_only_depth/RGB/depth_440.png', '/content/tmp/traindataset_only_depth/RGB/depth_441.png', '/content/tmp/traindataset_only_depth/RGB/depth_442.png', '/content/tmp/traindataset_only_depth/RGB/depth_450.png', '/content/tmp/traindataset_only_depth/RGB/depth_451.png', '/content/tmp/traindataset_only_depth/RGB/depth_452.png', '/content/tmp/traindataset_only_depth/RGB/depth_460.png', '/content/tmp/traindataset_only_depth/RGB/depth_461.png', '/content/tmp/traindataset_only_depth/RGB/depth_462.png', '/content/tmp/traindataset_only_depth/RGB/depth_470.png', '/content/tmp/traindataset_only_depth/RGB/depth_471.png', '/content/tmp/traindataset_only_depth/RGB/depth_472.png', '/content/tmp/traindataset_only_depth/RGB/depth_480.png', '/content/tmp/traindataset_only_depth/RGB/depth_481.png', '/content/tmp/traindataset_only_depth/RGB/depth_482.png', '/content/tmp/traindataset_only_depth/RGB/depth_490.png', '/content/tmp/traindataset_only_depth/RGB/depth_491.png', '/content/tmp/traindataset_only_depth/RGB/depth_492.png', '/content/tmp/traindataset_only_depth/RGB/depth_50.png', '/content/tmp/traindataset_only_depth/RGB/depth_500.png', '/content/tmp/traindataset_only_depth/RGB/depth_501.png', '/content/tmp/traindataset_only_depth/RGB/depth_502.png', '/content/tmp/traindataset_only_depth/RGB/depth_51.png', '/content/tmp/traindataset_only_depth/RGB/depth_510.png', '/content/tmp/traindataset_only_depth/RGB/depth_511.png', '/content/tmp/traindataset_only_depth/RGB/depth_512.png', '/content/tmp/traindataset_only_depth/RGB/depth_52.png', '/content/tmp/traindataset_only_depth/RGB/depth_520.png', '/content/tmp/traindataset_only_depth/RGB/depth_521.png', '/content/tmp/traindataset_only_depth/RGB/depth_522.png', '/content/tmp/traindataset_only_depth/RGB/depth_530.png', '/content/tmp/traindataset_only_depth/RGB/depth_531.png', '/content/tmp/traindataset_only_depth/RGB/depth_532.png', '/content/tmp/traindataset_only_depth/RGB/depth_540.png', '/content/tmp/traindataset_only_depth/RGB/depth_541.png', '/content/tmp/traindataset_only_depth/RGB/depth_542.png', '/content/tmp/traindataset_only_depth/RGB/depth_550.png', '/content/tmp/traindataset_only_depth/RGB/depth_551.png', '/content/tmp/traindataset_only_depth/RGB/depth_552.png', '/content/tmp/traindataset_only_depth/RGB/depth_560.png', '/content/tmp/traindataset_only_depth/RGB/depth_561.png', '/content/tmp/traindataset_only_depth/RGB/depth_562.png', '/content/tmp/traindataset_only_depth/RGB/depth_570.png', '/content/tmp/traindataset_only_depth/RGB/depth_571.png', '/content/tmp/traindataset_only_depth/RGB/depth_572.png', '/content/tmp/traindataset_only_depth/RGB/depth_580.png', '/content/tmp/traindataset_only_depth/RGB/depth_581.png', '/content/tmp/traindataset_only_depth/RGB/depth_582.png', '/content/tmp/traindataset_only_depth/RGB/depth_590.png', '/content/tmp/traindataset_only_depth/RGB/depth_591.png', '/content/tmp/traindataset_only_depth/RGB/depth_592.png', '/content/tmp/traindataset_only_depth/RGB/depth_60.png', '/content/tmp/traindataset_only_depth/RGB/depth_600.png', '/content/tmp/traindataset_only_depth/RGB/depth_601.png', '/content/tmp/traindataset_only_depth/RGB/depth_602.png', '/content/tmp/traindataset_only_depth/RGB/depth_61.png', '/content/tmp/traindataset_only_depth/RGB/depth_610.png', '/content/tmp/traindataset_only_depth/RGB/depth_611.png', '/content/tmp/traindataset_only_depth/RGB/depth_612.png', '/content/tmp/traindataset_only_depth/RGB/depth_62.png', '/content/tmp/traindataset_only_depth/RGB/depth_620.png', '/content/tmp/traindataset_only_depth/RGB/depth_621.png', '/content/tmp/traindataset_only_depth/RGB/depth_622.png', '/content/tmp/traindataset_only_depth/RGB/depth_630.png', '/content/tmp/traindataset_only_depth/RGB/depth_631.png', '/content/tmp/traindataset_only_depth/RGB/depth_632.png', '/content/tmp/traindataset_only_depth/RGB/depth_640.png', '/content/tmp/traindataset_only_depth/RGB/depth_641.png', '/content/tmp/traindataset_only_depth/RGB/depth_642.png', '/content/tmp/traindataset_only_depth/RGB/depth_650.png', '/content/tmp/traindataset_only_depth/RGB/depth_651.png', '/content/tmp/traindataset_only_depth/RGB/depth_652.png', '/content/tmp/traindataset_only_depth/RGB/depth_660.png', '/content/tmp/traindataset_only_depth/RGB/depth_661.png', '/content/tmp/traindataset_only_depth/RGB/depth_662.png', '/content/tmp/traindataset_only_depth/RGB/depth_670.png', '/content/tmp/traindataset_only_depth/RGB/depth_671.png', '/content/tmp/traindataset_only_depth/RGB/depth_672.png', '/content/tmp/traindataset_only_depth/RGB/depth_680.png', '/content/tmp/traindataset_only_depth/RGB/depth_681.png', '/content/tmp/traindataset_only_depth/RGB/depth_682.png', '/content/tmp/traindataset_only_depth/RGB/depth_690.png', '/content/tmp/traindataset_only_depth/RGB/depth_691.png', '/content/tmp/traindataset_only_depth/RGB/depth_692.png', '/content/tmp/traindataset_only_depth/RGB/depth_70.png', '/content/tmp/traindataset_only_depth/RGB/depth_700.png', '/content/tmp/traindataset_only_depth/RGB/depth_701.png', '/content/tmp/traindataset_only_depth/RGB/depth_702.png', '/content/tmp/traindataset_only_depth/RGB/depth_71.png', '/content/tmp/traindataset_only_depth/RGB/depth_710.png', '/content/tmp/traindataset_only_depth/RGB/depth_711.png', '/content/tmp/traindataset_only_depth/RGB/depth_712.png', '/content/tmp/traindataset_only_depth/RGB/depth_72.png', '/content/tmp/traindataset_only_depth/RGB/depth_720.png', '/content/tmp/traindataset_only_depth/RGB/depth_721.png', '/content/tmp/traindataset_only_depth/RGB/depth_722.png', '/content/tmp/traindataset_only_depth/RGB/depth_730.png', '/content/tmp/traindataset_only_depth/RGB/depth_731.png', '/content/tmp/traindataset_only_depth/RGB/depth_732.png', '/content/tmp/traindataset_only_depth/RGB/depth_740.png', '/content/tmp/traindataset_only_depth/RGB/depth_741.png', '/content/tmp/traindataset_only_depth/RGB/depth_742.png', '/content/tmp/traindataset_only_depth/RGB/depth_750.png', '/content/tmp/traindataset_only_depth/RGB/depth_751.png', '/content/tmp/traindataset_only_depth/RGB/depth_752.png', '/content/tmp/traindataset_only_depth/RGB/depth_760.png', '/content/tmp/traindataset_only_depth/RGB/depth_761.png', '/content/tmp/traindataset_only_depth/RGB/depth_762.png', '/content/tmp/traindataset_only_depth/RGB/depth_770.png', '/content/tmp/traindataset_only_depth/RGB/depth_771.png', '/content/tmp/traindataset_only_depth/RGB/depth_772.png', '/content/tmp/traindataset_only_depth/RGB/depth_780.png', '/content/tmp/traindataset_only_depth/RGB/depth_781.png', '/content/tmp/traindataset_only_depth/RGB/depth_782.png', '/content/tmp/traindataset_only_depth/RGB/depth_790.png', '/content/tmp/traindataset_only_depth/RGB/depth_791.png', '/content/tmp/traindataset_only_depth/RGB/depth_792.png', '/content/tmp/traindataset_only_depth/RGB/depth_80.png', '/content/tmp/traindataset_only_depth/RGB/depth_81.png', '/content/tmp/traindataset_only_depth/RGB/depth_82.png', '/content/tmp/traindataset_only_depth/RGB/depth_90.png', '/content/tmp/traindataset_only_depth/RGB/depth_91.png', '/content/tmp/traindataset_only_depth/RGB/depth_92.png'] ['/content/tmp/traindataset_only_depth/GT/GT_00.png', '/content/tmp/traindataset_only_depth/GT/GT_01.png', '/content/tmp/traindataset_only_depth/GT/GT_02.png', '/content/tmp/traindataset_only_depth/GT/GT_10.png', '/content/tmp/traindataset_only_depth/GT/GT_100.png', '/content/tmp/traindataset_only_depth/GT/GT_101.png', '/content/tmp/traindataset_only_depth/GT/GT_102.png', '/content/tmp/traindataset_only_depth/GT/GT_11.png', '/content/tmp/traindataset_only_depth/GT/GT_110.png', '/content/tmp/traindataset_only_depth/GT/GT_111.png', '/content/tmp/traindataset_only_depth/GT/GT_112.png', '/content/tmp/traindataset_only_depth/GT/GT_12.png', '/content/tmp/traindataset_only_depth/GT/GT_120.png', '/content/tmp/traindataset_only_depth/GT/GT_121.png', '/content/tmp/traindataset_only_depth/GT/GT_122.png', '/content/tmp/traindataset_only_depth/GT/GT_130.png', '/content/tmp/traindataset_only_depth/GT/GT_131.png', '/content/tmp/traindataset_only_depth/GT/GT_132.png', '/content/tmp/traindataset_only_depth/GT/GT_140.png', '/content/tmp/traindataset_only_depth/GT/GT_141.png', '/content/tmp/traindataset_only_depth/GT/GT_142.png', '/content/tmp/traindataset_only_depth/GT/GT_150.png', '/content/tmp/traindataset_only_depth/GT/GT_151.png', '/content/tmp/traindataset_only_depth/GT/GT_152.png', '/content/tmp/traindataset_only_depth/GT/GT_160.png', '/content/tmp/traindataset_only_depth/GT/GT_161.png', '/content/tmp/traindataset_only_depth/GT/GT_162.png', '/content/tmp/traindataset_only_depth/GT/GT_170.png', '/content/tmp/traindataset_only_depth/GT/GT_171.png', '/content/tmp/traindataset_only_depth/GT/GT_172.png', '/content/tmp/traindataset_only_depth/GT/GT_180.png', '/content/tmp/traindataset_only_depth/GT/GT_181.png', '/content/tmp/traindataset_only_depth/GT/GT_182.png', '/content/tmp/traindataset_only_depth/GT/GT_190.png', '/content/tmp/traindataset_only_depth/GT/GT_191.png', '/content/tmp/traindataset_only_depth/GT/GT_192.png', '/content/tmp/traindataset_only_depth/GT/GT_20.png', '/content/tmp/traindataset_only_depth/GT/GT_200.png', '/content/tmp/traindataset_only_depth/GT/GT_201.png', '/content/tmp/traindataset_only_depth/GT/GT_202.png', '/content/tmp/traindataset_only_depth/GT/GT_21.png', '/content/tmp/traindataset_only_depth/GT/GT_210.png', '/content/tmp/traindataset_only_depth/GT/GT_211.png', '/content/tmp/traindataset_only_depth/GT/GT_212.png', '/content/tmp/traindataset_only_depth/GT/GT_22.png', '/content/tmp/traindataset_only_depth/GT/GT_220.png', '/content/tmp/traindataset_only_depth/GT/GT_221.png', '/content/tmp/traindataset_only_depth/GT/GT_222.png', '/content/tmp/traindataset_only_depth/GT/GT_230.png', '/content/tmp/traindataset_only_depth/GT/GT_231.png', '/content/tmp/traindataset_only_depth/GT/GT_232.png', '/content/tmp/traindataset_only_depth/GT/GT_240.png', '/content/tmp/traindataset_only_depth/GT/GT_241.png', '/content/tmp/traindataset_only_depth/GT/GT_242.png', '/content/tmp/traindataset_only_depth/GT/GT_250.png', '/content/tmp/traindataset_only_depth/GT/GT_251.png', '/content/tmp/traindataset_only_depth/GT/GT_252.png', '/content/tmp/traindataset_only_depth/GT/GT_260.png', '/content/tmp/traindataset_only_depth/GT/GT_261.png', '/content/tmp/traindataset_only_depth/GT/GT_262.png', '/content/tmp/traindataset_only_depth/GT/GT_270.png', '/content/tmp/traindataset_only_depth/GT/GT_271.png', '/content/tmp/traindataset_only_depth/GT/GT_272.png', '/content/tmp/traindataset_only_depth/GT/GT_280.png', '/content/tmp/traindataset_only_depth/GT/GT_281.png', '/content/tmp/traindataset_only_depth/GT/GT_282.png', '/content/tmp/traindataset_only_depth/GT/GT_290.png', '/content/tmp/traindataset_only_depth/GT/GT_291.png', '/content/tmp/traindataset_only_depth/GT/GT_292.png', '/content/tmp/traindataset_only_depth/GT/GT_30.png', '/content/tmp/traindataset_only_depth/GT/GT_300.png', '/content/tmp/traindataset_only_depth/GT/GT_301.png', '/content/tmp/traindataset_only_depth/GT/GT_302.png', '/content/tmp/traindataset_only_depth/GT/GT_31.png', '/content/tmp/traindataset_only_depth/GT/GT_310.png', '/content/tmp/traindataset_only_depth/GT/GT_311.png', '/content/tmp/traindataset_only_depth/GT/GT_312.png', '/content/tmp/traindataset_only_depth/GT/GT_32.png', '/content/tmp/traindataset_only_depth/GT/GT_320.png', '/content/tmp/traindataset_only_depth/GT/GT_321.png', '/content/tmp/traindataset_only_depth/GT/GT_322.png', '/content/tmp/traindataset_only_depth/GT/GT_330.png', '/content/tmp/traindataset_only_depth/GT/GT_331.png', '/content/tmp/traindataset_only_depth/GT/GT_332.png', '/content/tmp/traindataset_only_depth/GT/GT_340.png', '/content/tmp/traindataset_only_depth/GT/GT_341.png', '/content/tmp/traindataset_only_depth/GT/GT_342.png', '/content/tmp/traindataset_only_depth/GT/GT_350.png', '/content/tmp/traindataset_only_depth/GT/GT_351.png', '/content/tmp/traindataset_only_depth/GT/GT_352.png', '/content/tmp/traindataset_only_depth/GT/GT_360.png', '/content/tmp/traindataset_only_depth/GT/GT_361.png', '/content/tmp/traindataset_only_depth/GT/GT_362.png', '/content/tmp/traindataset_only_depth/GT/GT_370.png', '/content/tmp/traindataset_only_depth/GT/GT_371.png', '/content/tmp/traindataset_only_depth/GT/GT_372.png', '/content/tmp/traindataset_only_depth/GT/GT_380.png', '/content/tmp/traindataset_only_depth/GT/GT_381.png', '/content/tmp/traindataset_only_depth/GT/GT_382.png', '/content/tmp/traindataset_only_depth/GT/GT_390.png', '/content/tmp/traindataset_only_depth/GT/GT_391.png', '/content/tmp/traindataset_only_depth/GT/GT_392.png', '/content/tmp/traindataset_only_depth/GT/GT_40.png', '/content/tmp/traindataset_only_depth/GT/GT_400.png', '/content/tmp/traindataset_only_depth/GT/GT_401.png', '/content/tmp/traindataset_only_depth/GT/GT_402.png', '/content/tmp/traindataset_only_depth/GT/GT_41.png', '/content/tmp/traindataset_only_depth/GT/GT_410.png', '/content/tmp/traindataset_only_depth/GT/GT_411.png', '/content/tmp/traindataset_only_depth/GT/GT_412.png', '/content/tmp/traindataset_only_depth/GT/GT_42.png', '/content/tmp/traindataset_only_depth/GT/GT_420.png', '/content/tmp/traindataset_only_depth/GT/GT_421.png', '/content/tmp/traindataset_only_depth/GT/GT_422.png', '/content/tmp/traindataset_only_depth/GT/GT_430.png', '/content/tmp/traindataset_only_depth/GT/GT_431.png', '/content/tmp/traindataset_only_depth/GT/GT_432.png', '/content/tmp/traindataset_only_depth/GT/GT_440.png', '/content/tmp/traindataset_only_depth/GT/GT_441.png', '/content/tmp/traindataset_only_depth/GT/GT_442.png', '/content/tmp/traindataset_only_depth/GT/GT_450.png', '/content/tmp/traindataset_only_depth/GT/GT_451.png', '/content/tmp/traindataset_only_depth/GT/GT_452.png', '/content/tmp/traindataset_only_depth/GT/GT_460.png', '/content/tmp/traindataset_only_depth/GT/GT_461.png', '/content/tmp/traindataset_only_depth/GT/GT_462.png', '/content/tmp/traindataset_only_depth/GT/GT_470.png', '/content/tmp/traindataset_only_depth/GT/GT_471.png', '/content/tmp/traindataset_only_depth/GT/GT_472.png', '/content/tmp/traindataset_only_depth/GT/GT_480.png', '/content/tmp/traindataset_only_depth/GT/GT_481.png', '/content/tmp/traindataset_only_depth/GT/GT_482.png', '/content/tmp/traindataset_only_depth/GT/GT_490.png', '/content/tmp/traindataset_only_depth/GT/GT_491.png', '/content/tmp/traindataset_only_depth/GT/GT_492.png', '/content/tmp/traindataset_only_depth/GT/GT_50.png', '/content/tmp/traindataset_only_depth/GT/GT_500.png', '/content/tmp/traindataset_only_depth/GT/GT_501.png', '/content/tmp/traindataset_only_depth/GT/GT_502.png', '/content/tmp/traindataset_only_depth/GT/GT_51.png', '/content/tmp/traindataset_only_depth/GT/GT_510.png', '/content/tmp/traindataset_only_depth/GT/GT_511.png', '/content/tmp/traindataset_only_depth/GT/GT_512.png', '/content/tmp/traindataset_only_depth/GT/GT_52.png', '/content/tmp/traindataset_only_depth/GT/GT_520.png', '/content/tmp/traindataset_only_depth/GT/GT_521.png', '/content/tmp/traindataset_only_depth/GT/GT_522.png', '/content/tmp/traindataset_only_depth/GT/GT_530.png', '/content/tmp/traindataset_only_depth/GT/GT_531.png', '/content/tmp/traindataset_only_depth/GT/GT_532.png', '/content/tmp/traindataset_only_depth/GT/GT_540.png', '/content/tmp/traindataset_only_depth/GT/GT_541.png', '/content/tmp/traindataset_only_depth/GT/GT_542.png', '/content/tmp/traindataset_only_depth/GT/GT_550.png', '/content/tmp/traindataset_only_depth/GT/GT_551.png', '/content/tmp/traindataset_only_depth/GT/GT_552.png', '/content/tmp/traindataset_only_depth/GT/GT_560.png', '/content/tmp/traindataset_only_depth/GT/GT_561.png', '/content/tmp/traindataset_only_depth/GT/GT_562.png', '/content/tmp/traindataset_only_depth/GT/GT_570.png', '/content/tmp/traindataset_only_depth/GT/GT_571.png', '/content/tmp/traindataset_only_depth/GT/GT_572.png', '/content/tmp/traindataset_only_depth/GT/GT_580.png', '/content/tmp/traindataset_only_depth/GT/GT_581.png', '/content/tmp/traindataset_only_depth/GT/GT_582.png', '/content/tmp/traindataset_only_depth/GT/GT_590.png', '/content/tmp/traindataset_only_depth/GT/GT_591.png', '/content/tmp/traindataset_only_depth/GT/GT_592.png', '/content/tmp/traindataset_only_depth/GT/GT_60.png', '/content/tmp/traindataset_only_depth/GT/GT_600.png', '/content/tmp/traindataset_only_depth/GT/GT_601.png', '/content/tmp/traindataset_only_depth/GT/GT_602.png', '/content/tmp/traindataset_only_depth/GT/GT_61.png', '/content/tmp/traindataset_only_depth/GT/GT_610.png', '/content/tmp/traindataset_only_depth/GT/GT_611.png', '/content/tmp/traindataset_only_depth/GT/GT_612.png', '/content/tmp/traindataset_only_depth/GT/GT_62.png', '/content/tmp/traindataset_only_depth/GT/GT_620.png', '/content/tmp/traindataset_only_depth/GT/GT_621.png', '/content/tmp/traindataset_only_depth/GT/GT_622.png', '/content/tmp/traindataset_only_depth/GT/GT_630.png', '/content/tmp/traindataset_only_depth/GT/GT_631.png', '/content/tmp/traindataset_only_depth/GT/GT_632.png', '/content/tmp/traindataset_only_depth/GT/GT_640.png', '/content/tmp/traindataset_only_depth/GT/GT_641.png', '/content/tmp/traindataset_only_depth/GT/GT_642.png', '/content/tmp/traindataset_only_depth/GT/GT_650.png', '/content/tmp/traindataset_only_depth/GT/GT_651.png', '/content/tmp/traindataset_only_depth/GT/GT_652.png', '/content/tmp/traindataset_only_depth/GT/GT_660.png', '/content/tmp/traindataset_only_depth/GT/GT_661.png', '/content/tmp/traindataset_only_depth/GT/GT_662.png', '/content/tmp/traindataset_only_depth/GT/GT_670.png', '/content/tmp/traindataset_only_depth/GT/GT_671.png', '/content/tmp/traindataset_only_depth/GT/GT_672.png', '/content/tmp/traindataset_only_depth/GT/GT_680.png', '/content/tmp/traindataset_only_depth/GT/GT_681.png', '/content/tmp/traindataset_only_depth/GT/GT_682.png', '/content/tmp/traindataset_only_depth/GT/GT_690.png', '/content/tmp/traindataset_only_depth/GT/GT_691.png', '/content/tmp/traindataset_only_depth/GT/GT_692.png', '/content/tmp/traindataset_only_depth/GT/GT_70.png', '/content/tmp/traindataset_only_depth/GT/GT_700.png', '/content/tmp/traindataset_only_depth/GT/GT_701.png', '/content/tmp/traindataset_only_depth/GT/GT_702.png', '/content/tmp/traindataset_only_depth/GT/GT_71.png', '/content/tmp/traindataset_only_depth/GT/GT_710.png', '/content/tmp/traindataset_only_depth/GT/GT_711.png', '/content/tmp/traindataset_only_depth/GT/GT_712.png', '/content/tmp/traindataset_only_depth/GT/GT_72.png', '/content/tmp/traindataset_only_depth/GT/GT_720.png', '/content/tmp/traindataset_only_depth/GT/GT_721.png', '/content/tmp/traindataset_only_depth/GT/GT_722.png', '/content/tmp/traindataset_only_depth/GT/GT_730.png', '/content/tmp/traindataset_only_depth/GT/GT_731.png', '/content/tmp/traindataset_only_depth/GT/GT_732.png', '/content/tmp/traindataset_only_depth/GT/GT_740.png', '/content/tmp/traindataset_only_depth/GT/GT_741.png', '/content/tmp/traindataset_only_depth/GT/GT_742.png', '/content/tmp/traindataset_only_depth/GT/GT_750.png', '/content/tmp/traindataset_only_depth/GT/GT_751.png', '/content/tmp/traindataset_only_depth/GT/GT_752.png', '/content/tmp/traindataset_only_depth/GT/GT_760.png', '/content/tmp/traindataset_only_depth/GT/GT_761.png', '/content/tmp/traindataset_only_depth/GT/GT_762.png', '/content/tmp/traindataset_only_depth/GT/GT_770.png', '/content/tmp/traindataset_only_depth/GT/GT_771.png', '/content/tmp/traindataset_only_depth/GT/GT_772.png', '/content/tmp/traindataset_only_depth/GT/GT_780.png', '/content/tmp/traindataset_only_depth/GT/GT_781.png', '/content/tmp/traindataset_only_depth/GT/GT_782.png', '/content/tmp/traindataset_only_depth/GT/GT_790.png', '/content/tmp/traindataset_only_depth/GT/GT_791.png', '/content/tmp/traindataset_only_depth/GT/GT_792.png', '/content/tmp/traindataset_only_depth/GT/GT_80.png', '/content/tmp/traindataset_only_depth/GT/GT_81.png', '/content/tmp/traindataset_only_depth/GT/GT_82.png', '/content/tmp/traindataset_only_depth/GT/GT_90.png', '/content/tmp/traindataset_only_depth/GT/GT_91.png', '/content/tmp/traindataset_only_depth/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f91923b8e10>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "Start train...\n",
            "2022-06-21 18:23:18.737133 Epoch [001/500], Step [0001/0060], Loss1: -0.0706 Loss2: 0.1981 Loss3: -0.0291\n",
            "2022-06-21 18:23:54.862364 Epoch [001/500], Step [0050/0060], Loss1: -0.8758 Loss2: -0.9119 Loss3: -0.9182\n",
            "2022-06-21 18:24:02.370517 Epoch [001/500], Step [0060/0060], Loss1: -0.9151 Loss2: -0.9179 Loss3: -0.9463\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.20140315383830398 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-21 18:24:12.171402 Epoch [002/500], Step [0001/0060], Loss1: -0.8883 Loss2: -0.9041 Loss3: -0.9351\n",
            "2022-06-21 18:24:49.961930 Epoch [002/500], Step [0050/0060], Loss1: -0.9260 Loss2: -0.9424 Loss3: -0.9541\n",
            "2022-06-21 18:24:57.832539 Epoch [002/500], Step [0060/0060], Loss1: -0.9360 Loss2: -0.9466 Loss3: -0.9614\n",
            "Epoch: 2 MAE: 0.16691753972775086 ####  bestMAE: 0.20140315383830398 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-21 18:25:06.721924 Epoch [003/500], Step [0001/0060], Loss1: -0.9415 Loss2: -0.9392 Loss3: -0.9663\n",
            "2022-06-21 18:25:45.009834 Epoch [003/500], Step [0050/0060], Loss1: -0.9516 Loss2: -0.9495 Loss3: -0.9687\n",
            "2022-06-21 18:25:52.775520 Epoch [003/500], Step [0060/0060], Loss1: -0.9179 Loss2: -0.9267 Loss3: -0.9459\n",
            "Epoch: 3 MAE: 0.1406693134610615 ####  bestMAE: 0.16691753972775086 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-06-21 18:26:01.707352 Epoch [004/500], Step [0001/0060], Loss1: -0.9443 Loss2: -0.9497 Loss3: -0.9619\n",
            "2022-06-21 18:26:40.111137 Epoch [004/500], Step [0050/0060], Loss1: -0.9520 Loss2: -0.9581 Loss3: -0.9731\n",
            "2022-06-21 18:26:47.909218 Epoch [004/500], Step [0060/0060], Loss1: -0.9211 Loss2: -0.9311 Loss3: -0.9613\n",
            "Epoch: 4 MAE: 0.15151968658285797 ####  bestMAE: 0.1406693134610615 bestEpoch: 3\n",
            "2022-06-21 18:26:54.424173 Epoch [005/500], Step [0001/0060], Loss1: -0.9482 Loss2: -0.9573 Loss3: -0.9734\n",
            "2022-06-21 18:27:32.540317 Epoch [005/500], Step [0050/0060], Loss1: -0.9512 Loss2: -0.9710 Loss3: -0.9727\n",
            "2022-06-21 18:27:40.338310 Epoch [005/500], Step [0060/0060], Loss1: -0.9685 Loss2: -0.9632 Loss3: -0.9754\n",
            "Epoch: 5 MAE: 0.13810993154212914 ####  bestMAE: 0.1406693134610615 bestEpoch: 3\n",
            "best epoch:5\n",
            "2022-06-21 18:27:51.430051 Epoch [006/500], Step [0001/0060], Loss1: -0.9541 Loss2: -0.9484 Loss3: -0.9694\n",
            "2022-06-21 18:28:29.997190 Epoch [006/500], Step [0050/0060], Loss1: -0.9548 Loss2: -0.9614 Loss3: -0.9739\n",
            "2022-06-21 18:28:37.818590 Epoch [006/500], Step [0060/0060], Loss1: -0.9576 Loss2: -0.9482 Loss3: -0.9730\n",
            "Epoch: 6 MAE: 0.12616596020087995 ####  bestMAE: 0.13810993154212914 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-06-21 18:28:46.822993 Epoch [007/500], Step [0001/0060], Loss1: -0.9669 Loss2: -0.9555 Loss3: -0.9776\n",
            "2022-06-21 18:29:25.225065 Epoch [007/500], Step [0050/0060], Loss1: -0.9646 Loss2: -0.9623 Loss3: -0.9805\n",
            "2022-06-21 18:29:33.040535 Epoch [007/500], Step [0060/0060], Loss1: -0.9678 Loss2: -0.9635 Loss3: -0.9804\n",
            "Epoch: 7 MAE: 0.11970476947764236 ####  bestMAE: 0.12616596020087995 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-06-21 18:29:41.855716 Epoch [008/500], Step [0001/0060], Loss1: -0.9329 Loss2: -0.9221 Loss3: -0.9633\n",
            "2022-06-21 18:30:20.172402 Epoch [008/500], Step [0050/0060], Loss1: -0.9652 Loss2: -0.9652 Loss3: -0.9818\n",
            "2022-06-21 18:30:27.970022 Epoch [008/500], Step [0060/0060], Loss1: -0.9681 Loss2: -0.9659 Loss3: -0.9790\n",
            "Epoch: 8 MAE: 0.11295542257803456 ####  bestMAE: 0.11970476947764236 bestEpoch: 7\n",
            "best epoch:8\n",
            "2022-06-21 18:30:36.813655 Epoch [009/500], Step [0001/0060], Loss1: -0.9770 Loss2: -0.9743 Loss3: -0.9870\n",
            "2022-06-21 18:31:15.130196 Epoch [009/500], Step [0050/0060], Loss1: -0.9663 Loss2: -0.9656 Loss3: -0.9812\n",
            "2022-06-21 18:31:22.929107 Epoch [009/500], Step [0060/0060], Loss1: -0.9618 Loss2: -0.9693 Loss3: -0.9835\n",
            "Epoch: 9 MAE: 0.10788732851623858 ####  bestMAE: 0.11295542257803456 bestEpoch: 8\n",
            "best epoch:9\n",
            "2022-06-21 18:31:31.660647 Epoch [010/500], Step [0001/0060], Loss1: -0.9766 Loss2: -0.9729 Loss3: -0.9855\n",
            "2022-06-21 18:32:09.976000 Epoch [010/500], Step [0050/0060], Loss1: -0.9750 Loss2: -0.9768 Loss3: -0.9870\n",
            "2022-06-21 18:32:17.797801 Epoch [010/500], Step [0060/0060], Loss1: -0.9636 Loss2: -0.9627 Loss3: -0.9723\n",
            "Epoch: 10 MAE: 0.11264590611533518 ####  bestMAE: 0.10788732851623858 bestEpoch: 9\n",
            "2022-06-21 18:32:26.515052 Epoch [011/500], Step [0001/0060], Loss1: -0.9737 Loss2: -0.9685 Loss3: -0.9843\n",
            "2022-06-21 18:33:04.909978 Epoch [011/500], Step [0050/0060], Loss1: -0.9759 Loss2: -0.9627 Loss3: -0.9816\n",
            "2022-06-21 18:33:12.695929 Epoch [011/500], Step [0060/0060], Loss1: -0.9753 Loss2: -0.9656 Loss3: -0.9846\n",
            "Epoch: 11 MAE: 0.11561460373893616 ####  bestMAE: 0.10788732851623858 bestEpoch: 9\n",
            "2022-06-21 18:33:19.389901 Epoch [012/500], Step [0001/0060], Loss1: -0.9740 Loss2: -0.9618 Loss3: -0.9749\n",
            "2022-06-21 18:33:57.591801 Epoch [012/500], Step [0050/0060], Loss1: -0.9768 Loss2: -0.9724 Loss3: -0.9859\n",
            "2022-06-21 18:34:05.392310 Epoch [012/500], Step [0060/0060], Loss1: -0.9777 Loss2: -0.9698 Loss3: -0.9855\n",
            "Epoch: 12 MAE: 0.0977023704972847 ####  bestMAE: 0.10788732851623858 bestEpoch: 9\n",
            "best epoch:12\n",
            "2022-06-21 18:34:14.258188 Epoch [013/500], Step [0001/0060], Loss1: -0.9811 Loss2: -0.9776 Loss3: -0.9884\n",
            "2022-06-21 18:34:52.565587 Epoch [013/500], Step [0050/0060], Loss1: -0.9761 Loss2: -0.9695 Loss3: -0.9833\n",
            "2022-06-21 18:35:00.368536 Epoch [013/500], Step [0060/0060], Loss1: -0.9814 Loss2: -0.9749 Loss3: -0.9882\n",
            "Epoch: 13 MAE: 0.10349300979937194 ####  bestMAE: 0.0977023704972847 bestEpoch: 12\n",
            "2022-06-21 18:35:06.878130 Epoch [014/500], Step [0001/0060], Loss1: -0.9790 Loss2: -0.9721 Loss3: -0.9854\n",
            "2022-06-21 18:35:44.965203 Epoch [014/500], Step [0050/0060], Loss1: -0.9758 Loss2: -0.9598 Loss3: -0.9834\n",
            "2022-06-21 18:35:52.734194 Epoch [014/500], Step [0060/0060], Loss1: -0.9713 Loss2: -0.9654 Loss3: -0.9819\n",
            "Epoch: 14 MAE: 0.0942311909589818 ####  bestMAE: 0.0977023704972847 bestEpoch: 12\n",
            "best epoch:14\n",
            "2022-06-21 18:36:01.484459 Epoch [015/500], Step [0001/0060], Loss1: -0.9747 Loss2: -0.9750 Loss3: -0.9864\n",
            "2022-06-21 18:36:39.872981 Epoch [015/500], Step [0050/0060], Loss1: -0.9786 Loss2: -0.9699 Loss3: -0.9848\n",
            "2022-06-21 18:36:47.645481 Epoch [015/500], Step [0060/0060], Loss1: -0.9798 Loss2: -0.9707 Loss3: -0.9838\n",
            "Epoch: 15 MAE: 0.09851305451973406 ####  bestMAE: 0.0942311909589818 bestEpoch: 14\n",
            "2022-06-21 18:36:56.334388 Epoch [016/500], Step [0001/0060], Loss1: -0.9788 Loss2: -0.9717 Loss3: -0.9849\n",
            "2022-06-21 18:37:34.647764 Epoch [016/500], Step [0050/0060], Loss1: -0.9782 Loss2: -0.9723 Loss3: -0.9858\n",
            "2022-06-21 18:37:42.449665 Epoch [016/500], Step [0060/0060], Loss1: -0.9852 Loss2: -0.9766 Loss3: -0.9884\n",
            "Epoch: 16 MAE: 0.09378522479344929 ####  bestMAE: 0.0942311909589818 bestEpoch: 14\n",
            "best epoch:16\n",
            "2022-06-21 18:37:51.161594 Epoch [017/500], Step [0001/0060], Loss1: -0.9756 Loss2: -0.9707 Loss3: -0.9842\n",
            "2022-06-21 18:38:29.423957 Epoch [017/500], Step [0050/0060], Loss1: -0.9813 Loss2: -0.9772 Loss3: -0.9888\n",
            "2022-06-21 18:38:37.203181 Epoch [017/500], Step [0060/0060], Loss1: -0.9797 Loss2: -0.9753 Loss3: -0.9877\n",
            "Epoch: 17 MAE: 0.08628806704566595 ####  bestMAE: 0.09378522479344929 bestEpoch: 16\n",
            "best epoch:17\n",
            "2022-06-21 18:38:45.765438 Epoch [018/500], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9794 Loss3: -0.9884\n",
            "2022-06-21 18:39:24.078948 Epoch [018/500], Step [0050/0060], Loss1: -0.9795 Loss2: -0.9749 Loss3: -0.9871\n",
            "2022-06-21 18:39:31.865133 Epoch [018/500], Step [0060/0060], Loss1: -0.9828 Loss2: -0.9784 Loss3: -0.9891\n",
            "Epoch: 18 MAE: 0.08350052394564186 ####  bestMAE: 0.08628806704566595 bestEpoch: 17\n",
            "best epoch:18\n",
            "2022-06-21 18:39:40.585764 Epoch [019/500], Step [0001/0060], Loss1: -0.9846 Loss2: -0.9791 Loss3: -0.9895\n",
            "2022-06-21 18:40:18.931767 Epoch [019/500], Step [0050/0060], Loss1: -0.9773 Loss2: -0.9714 Loss3: -0.9860\n",
            "2022-06-21 18:40:26.715720 Epoch [019/500], Step [0060/0060], Loss1: -0.9811 Loss2: -0.9770 Loss3: -0.9888\n",
            "Epoch: 19 MAE: 0.09081811491143767 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "2022-06-21 18:40:33.233832 Epoch [020/500], Step [0001/0060], Loss1: -0.9818 Loss2: -0.9762 Loss3: -0.9886\n",
            "2022-06-21 18:41:11.349993 Epoch [020/500], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9799 Loss3: -0.9912\n",
            "2022-06-21 18:41:19.130279 Epoch [020/500], Step [0060/0060], Loss1: -0.9800 Loss2: -0.9740 Loss3: -0.9862\n",
            "Epoch: 20 MAE: 0.08962658110119044 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "2022-06-21 18:41:28.089355 Epoch [021/500], Step [0001/0060], Loss1: -0.9829 Loss2: -0.9782 Loss3: -0.9888\n",
            "2022-06-21 18:42:06.571419 Epoch [021/500], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9792 Loss3: -0.9905\n",
            "2022-06-21 18:42:14.366230 Epoch [021/500], Step [0060/0060], Loss1: -0.9802 Loss2: -0.9680 Loss3: -0.9857\n",
            "Epoch: 21 MAE: 0.08934488952475247 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "2022-06-21 18:42:20.957876 Epoch [022/500], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9791 Loss3: -0.9884\n",
            "2022-06-21 18:42:59.154110 Epoch [022/500], Step [0050/0060], Loss1: -0.9808 Loss2: -0.9709 Loss3: -0.9842\n",
            "2022-06-21 18:43:06.946036 Epoch [022/500], Step [0060/0060], Loss1: -0.9858 Loss2: -0.9781 Loss3: -0.9907\n",
            "Epoch: 22 MAE: 0.08734399018464266 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "2022-06-21 18:43:13.603151 Epoch [023/500], Step [0001/0060], Loss1: -0.9848 Loss2: -0.9823 Loss3: -0.9892\n",
            "2022-06-21 18:43:51.844469 Epoch [023/500], Step [0050/0060], Loss1: -0.9828 Loss2: -0.9753 Loss3: -0.9880\n",
            "2022-06-21 18:43:59.640947 Epoch [023/500], Step [0060/0060], Loss1: -0.9835 Loss2: -0.9760 Loss3: -0.9884\n",
            "Epoch: 23 MAE: 0.0864956726598992 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "2022-06-21 18:44:06.394445 Epoch [024/500], Step [0001/0060], Loss1: -0.9834 Loss2: -0.9754 Loss3: -0.9872\n",
            "2022-06-21 18:44:44.604667 Epoch [024/500], Step [0050/0060], Loss1: -0.9839 Loss2: -0.9836 Loss3: -0.9897\n",
            "2022-06-21 18:44:52.384804 Epoch [024/500], Step [0060/0060], Loss1: -0.9827 Loss2: -0.9758 Loss3: -0.9873\n",
            "Epoch: 24 MAE: 0.08017726368374294 ####  bestMAE: 0.08350052394564186 bestEpoch: 18\n",
            "best epoch:24\n",
            "2022-06-21 18:45:01.120629 Epoch [025/500], Step [0001/0060], Loss1: -0.9796 Loss2: -0.9709 Loss3: -0.9857\n",
            "2022-06-21 18:45:39.615737 Epoch [025/500], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9701 Loss3: -0.9843\n",
            "2022-06-21 18:45:47.414934 Epoch [025/500], Step [0060/0060], Loss1: -0.9841 Loss2: -0.9777 Loss3: -0.9875\n",
            "Epoch: 25 MAE: 0.08913623234582328 ####  bestMAE: 0.08017726368374294 bestEpoch: 24\n",
            "2022-06-21 18:45:56.265261 Epoch [026/500], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9795 Loss3: -0.9895\n",
            "2022-06-21 18:46:34.600506 Epoch [026/500], Step [0050/0060], Loss1: -0.9811 Loss2: -0.9771 Loss3: -0.9882\n",
            "2022-06-21 18:46:42.390175 Epoch [026/500], Step [0060/0060], Loss1: -0.9832 Loss2: -0.9804 Loss3: -0.9879\n",
            "Epoch: 26 MAE: 0.09506906983713626 ####  bestMAE: 0.08017726368374294 bestEpoch: 24\n",
            "2022-06-21 18:46:48.823515 Epoch [027/500], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9820 Loss3: -0.9867\n",
            "2022-06-21 18:47:26.944937 Epoch [027/500], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9828 Loss3: -0.9900\n",
            "2022-06-21 18:47:34.703516 Epoch [027/500], Step [0060/0060], Loss1: -0.9861 Loss2: -0.9814 Loss3: -0.9891\n",
            "Epoch: 27 MAE: 0.08188380872131025 ####  bestMAE: 0.08017726368374294 bestEpoch: 24\n",
            "2022-06-21 18:47:41.160020 Epoch [028/500], Step [0001/0060], Loss1: -0.9860 Loss2: -0.9798 Loss3: -0.9896\n",
            "2022-06-21 18:48:19.306299 Epoch [028/500], Step [0050/0060], Loss1: -0.9836 Loss2: -0.9770 Loss3: -0.9879\n",
            "2022-06-21 18:48:27.069394 Epoch [028/500], Step [0060/0060], Loss1: -0.9795 Loss2: -0.9788 Loss3: -0.9873\n",
            "Epoch: 28 MAE: 0.08065151693959714 ####  bestMAE: 0.08017726368374294 bestEpoch: 24\n",
            "2022-06-21 18:48:33.547870 Epoch [029/500], Step [0001/0060], Loss1: -0.9862 Loss2: -0.9781 Loss3: -0.9902\n",
            "2022-06-21 18:49:11.727611 Epoch [029/500], Step [0050/0060], Loss1: -0.9838 Loss2: -0.9765 Loss3: -0.9884\n",
            "2022-06-21 18:49:19.504134 Epoch [029/500], Step [0060/0060], Loss1: -0.9823 Loss2: -0.9751 Loss3: -0.9864\n",
            "Epoch: 29 MAE: 0.07806515971188818 ####  bestMAE: 0.08017726368374294 bestEpoch: 24\n",
            "best epoch:29\n",
            "2022-06-21 18:49:28.278954 Epoch [030/500], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9818 Loss3: -0.9900\n",
            "2022-06-21 18:50:06.531825 Epoch [030/500], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9832 Loss3: -0.9916\n",
            "2022-06-21 18:50:14.316834 Epoch [030/500], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9833 Loss3: -0.9911\n",
            "Epoch: 30 MAE: 0.0765065796160824 ####  bestMAE: 0.07806515971188818 bestEpoch: 29\n",
            "best epoch:30\n",
            "2022-06-21 18:50:26.878791 Epoch [031/500], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9804 Loss3: -0.9897\n",
            "2022-06-21 18:51:05.436699 Epoch [031/500], Step [0050/0060], Loss1: -0.9855 Loss2: -0.9757 Loss3: -0.9887\n",
            "2022-06-21 18:51:13.224294 Epoch [031/500], Step [0060/0060], Loss1: -0.9845 Loss2: -0.9793 Loss3: -0.9892\n",
            "Epoch: 31 MAE: 0.074676413864055 ####  bestMAE: 0.0765065796160824 bestEpoch: 30\n",
            "best epoch:31\n",
            "2022-06-21 18:51:22.137121 Epoch [032/500], Step [0001/0060], Loss1: -0.9844 Loss2: -0.9762 Loss3: -0.9893\n",
            "2022-06-21 18:52:00.466243 Epoch [032/500], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9787 Loss3: -0.9890\n",
            "2022-06-21 18:52:08.275449 Epoch [032/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9817 Loss3: -0.9915\n",
            "Epoch: 32 MAE: 0.07910453705560593 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:52:14.717130 Epoch [033/500], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9812 Loss3: -0.9901\n",
            "2022-06-21 18:52:52.879200 Epoch [033/500], Step [0050/0060], Loss1: -0.9818 Loss2: -0.9736 Loss3: -0.9870\n",
            "2022-06-21 18:53:00.645595 Epoch [033/500], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9844 Loss3: -0.9909\n",
            "Epoch: 33 MAE: 0.07659825612628271 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:53:07.235976 Epoch [034/500], Step [0001/0060], Loss1: -0.9826 Loss2: -0.9768 Loss3: -0.9876\n",
            "2022-06-21 18:53:45.417653 Epoch [034/500], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9798 Loss3: -0.9883\n",
            "2022-06-21 18:53:53.200149 Epoch [034/500], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9810 Loss3: -0.9907\n",
            "Epoch: 34 MAE: 0.07872911039483613 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:53:59.705315 Epoch [035/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9839 Loss3: -0.9908\n",
            "2022-06-21 18:54:37.891004 Epoch [035/500], Step [0050/0060], Loss1: -0.9848 Loss2: -0.9757 Loss3: -0.9887\n",
            "2022-06-21 18:54:45.661620 Epoch [035/500], Step [0060/0060], Loss1: -0.9842 Loss2: -0.9789 Loss3: -0.9887\n",
            "Epoch: 35 MAE: 0.07681391811875439 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:54:54.349823 Epoch [036/500], Step [0001/0060], Loss1: -0.9853 Loss2: -0.9842 Loss3: -0.9892\n",
            "2022-06-21 18:55:32.773156 Epoch [036/500], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9833 Loss3: -0.9890\n",
            "2022-06-21 18:55:40.578279 Epoch [036/500], Step [0060/0060], Loss1: -0.9834 Loss2: -0.9783 Loss3: -0.9880\n",
            "Epoch: 36 MAE: 0.08161064713089557 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:55:47.125095 Epoch [037/500], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9793 Loss3: -0.9898\n",
            "2022-06-21 18:56:25.310534 Epoch [037/500], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9817 Loss3: -0.9889\n",
            "2022-06-21 18:56:33.089531 Epoch [037/500], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9821 Loss3: -0.9898\n",
            "Epoch: 37 MAE: 0.08343860151906492 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:56:39.618180 Epoch [038/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9830 Loss3: -0.9915\n",
            "2022-06-21 18:57:17.817214 Epoch [038/500], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9853 Loss3: -0.9916\n",
            "2022-06-21 18:57:25.616818 Epoch [038/500], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9823 Loss3: -0.9901\n",
            "Epoch: 38 MAE: 0.07848038971108734 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:57:32.066453 Epoch [039/500], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9805 Loss3: -0.9886\n",
            "2022-06-21 18:58:10.256919 Epoch [039/500], Step [0050/0060], Loss1: -0.9859 Loss2: -0.9795 Loss3: -0.9890\n",
            "2022-06-21 18:58:18.036707 Epoch [039/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9818 Loss3: -0.9902\n",
            "Epoch: 39 MAE: 0.07761665445156198 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:58:24.735655 Epoch [040/500], Step [0001/0060], Loss1: -0.9845 Loss2: -0.9775 Loss3: -0.9881\n",
            "2022-06-21 18:59:02.884432 Epoch [040/500], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9812 Loss3: -0.9895\n",
            "2022-06-21 18:59:10.664070 Epoch [040/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9838 Loss3: -0.9913\n",
            "Epoch: 40 MAE: 0.07520041077225299 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "2022-06-21 18:59:19.788835 Epoch [041/500], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9803 Loss3: -0.9904\n",
            "2022-06-21 18:59:58.121531 Epoch [041/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9812 Loss3: -0.9912\n",
            "2022-06-21 19:00:05.902520 Epoch [041/500], Step [0060/0060], Loss1: -0.9851 Loss2: -0.9793 Loss3: -0.9885\n",
            "Epoch: 41 MAE: 0.06734332210803161 ####  bestMAE: 0.074676413864055 bestEpoch: 31\n",
            "best epoch:41\n",
            "2022-06-21 19:00:14.876000 Epoch [042/500], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9824 Loss3: -0.9906\n",
            "2022-06-21 19:00:53.039259 Epoch [042/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9854 Loss3: -0.9924\n",
            "2022-06-21 19:01:00.821951 Epoch [042/500], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9776 Loss3: -0.9870\n",
            "Epoch: 42 MAE: 0.07320610217947178 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:01:07.280575 Epoch [043/500], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9839 Loss3: -0.9898\n",
            "2022-06-21 19:01:45.470593 Epoch [043/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9844 Loss3: -0.9916\n",
            "2022-06-21 19:01:53.317153 Epoch [043/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9841 Loss3: -0.9910\n",
            "Epoch: 43 MAE: 0.07298067617668676 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:02:00.074589 Epoch [044/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9844 Loss3: -0.9913\n",
            "2022-06-21 19:02:38.306142 Epoch [044/500], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9814 Loss3: -0.9901\n",
            "2022-06-21 19:02:46.078697 Epoch [044/500], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9793 Loss3: -0.9903\n",
            "Epoch: 44 MAE: 0.06878446488153366 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:02:52.732598 Epoch [045/500], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9845 Loss3: -0.9916\n",
            "2022-06-21 19:03:30.878450 Epoch [045/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9835 Loss3: -0.9913\n",
            "2022-06-21 19:03:38.648603 Epoch [045/500], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9809 Loss3: -0.9893\n",
            "Epoch: 45 MAE: 0.07176044686130743 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:03:48.406427 Epoch [046/500], Step [0001/0060], Loss1: -0.9824 Loss2: -0.9774 Loss3: -0.9873\n",
            "2022-06-21 19:04:27.029984 Epoch [046/500], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9830 Loss3: -0.9893\n",
            "2022-06-21 19:04:34.816217 Epoch [046/500], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9856 Loss3: -0.9899\n",
            "Epoch: 46 MAE: 0.07517133642126014 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:04:41.411373 Epoch [047/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9840 Loss3: -0.9921\n",
            "2022-06-21 19:05:19.598350 Epoch [047/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9848 Loss3: -0.9914\n",
            "2022-06-21 19:05:27.390436 Epoch [047/500], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9819 Loss3: -0.9900\n",
            "Epoch: 47 MAE: 0.07197371891566687 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "2022-06-21 19:05:33.989503 Epoch [048/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9854 Loss3: -0.9915\n",
            "2022-06-21 19:06:12.234782 Epoch [048/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9856 Loss3: -0.9917\n",
            "2022-06-21 19:06:20.069569 Epoch [048/500], Step [0060/0060], Loss1: -0.9855 Loss2: -0.9822 Loss3: -0.9900\n",
            "Epoch: 48 MAE: 0.06407991323521527 ####  bestMAE: 0.06734332210803161 bestEpoch: 41\n",
            "best epoch:48\n",
            "2022-06-21 19:06:30.139848 Epoch [049/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9836 Loss3: -0.9906\n",
            "2022-06-21 19:07:08.373110 Epoch [049/500], Step [0050/0060], Loss1: -0.9865 Loss2: -0.9811 Loss3: -0.9889\n",
            "2022-06-21 19:07:16.174276 Epoch [049/500], Step [0060/0060], Loss1: -0.9871 Loss2: -0.9825 Loss3: -0.9890\n",
            "Epoch: 49 MAE: 0.0702292606817982 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:07:22.911664 Epoch [050/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9848 Loss3: -0.9914\n",
            "2022-06-21 19:08:01.059878 Epoch [050/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9846 Loss3: -0.9918\n",
            "2022-06-21 19:08:08.850157 Epoch [050/500], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9763 Loss3: -0.9876\n",
            "Epoch: 50 MAE: 0.07234999162179452 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:08:17.901799 Epoch [051/500], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9822 Loss3: -0.9900\n",
            "2022-06-21 19:08:56.543751 Epoch [051/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9877 Loss3: -0.9926\n",
            "2022-06-21 19:09:04.326183 Epoch [051/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9813 Loss3: -0.9914\n",
            "Epoch: 51 MAE: 0.07157050455688799 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:09:10.951001 Epoch [052/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9850 Loss3: -0.9917\n",
            "2022-06-21 19:09:49.057373 Epoch [052/500], Step [0050/0060], Loss1: -0.9837 Loss2: -0.9742 Loss3: -0.9864\n",
            "2022-06-21 19:09:56.853082 Epoch [052/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9834 Loss3: -0.9911\n",
            "Epoch: 52 MAE: 0.07146785821864214 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:10:03.423673 Epoch [053/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9853 Loss3: -0.9918\n",
            "2022-06-21 19:10:41.616657 Epoch [053/500], Step [0050/0060], Loss1: -0.9814 Loss2: -0.9737 Loss3: -0.9840\n",
            "2022-06-21 19:10:49.382823 Epoch [053/500], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9798 Loss3: -0.9878\n",
            "Epoch: 53 MAE: 0.07262916388335051 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:10:55.908773 Epoch [054/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9850 Loss3: -0.9907\n",
            "2022-06-21 19:11:34.213578 Epoch [054/500], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9833 Loss3: -0.9898\n",
            "2022-06-21 19:11:41.964348 Epoch [054/500], Step [0060/0060], Loss1: -0.9849 Loss2: -0.9788 Loss3: -0.9876\n",
            "Epoch: 54 MAE: 0.07390398262669798 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:11:48.427719 Epoch [055/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9815 Loss3: -0.9909\n",
            "2022-06-21 19:12:26.515007 Epoch [055/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9841 Loss3: -0.9916\n",
            "2022-06-21 19:12:34.318380 Epoch [055/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9849 Loss3: -0.9893\n",
            "Epoch: 55 MAE: 0.08164274831297537 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:12:42.896116 Epoch [056/500], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9800 Loss3: -0.9877\n",
            "2022-06-21 19:13:21.219329 Epoch [056/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9859 Loss3: -0.9917\n",
            "2022-06-21 19:13:29.194103 Epoch [056/500], Step [0060/0060], Loss1: -0.9850 Loss2: -0.9785 Loss3: -0.9880\n",
            "Epoch: 56 MAE: 0.07107651871978923 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:13:36.507194 Epoch [057/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9859 Loss3: -0.9920\n",
            "2022-06-21 19:14:14.556328 Epoch [057/500], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9839 Loss3: -0.9901\n",
            "2022-06-21 19:14:22.322180 Epoch [057/500], Step [0060/0060], Loss1: -0.9873 Loss2: -0.9786 Loss3: -0.9900\n",
            "Epoch: 57 MAE: 0.073121608047889 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:14:28.774263 Epoch [058/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-21 19:15:06.945746 Epoch [058/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9849 Loss3: -0.9927\n",
            "2022-06-21 19:15:14.721673 Epoch [058/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9803 Loss3: -0.9900\n",
            "Epoch: 58 MAE: 0.07254494066591619 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:15:21.187762 Epoch [059/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9841 Loss3: -0.9912\n",
            "2022-06-21 19:15:59.435144 Epoch [059/500], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9847 Loss3: -0.9915\n",
            "2022-06-21 19:16:07.203236 Epoch [059/500], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9829 Loss3: -0.9902\n",
            "Epoch: 59 MAE: 0.07416677964427482 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:16:13.618648 Epoch [060/500], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9817 Loss3: -0.9889\n",
            "2022-06-21 19:16:51.806949 Epoch [060/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9857 Loss3: -0.9926\n",
            "2022-06-21 19:16:59.596068 Epoch [060/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9858 Loss3: -0.9912\n",
            "Epoch: 60 MAE: 0.07157446896588363 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:17:08.349386 Epoch [061/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9836 Loss3: -0.9912\n",
            "2022-06-21 19:17:46.577138 Epoch [061/500], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9829 Loss3: -0.9908\n",
            "2022-06-21 19:17:54.372606 Epoch [061/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9873 Loss3: -0.9926\n",
            "Epoch: 61 MAE: 0.07358139396344543 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:18:01.323373 Epoch [062/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9832 Loss3: -0.9907\n",
            "2022-06-21 19:18:39.780227 Epoch [062/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9830 Loss3: -0.9900\n",
            "2022-06-21 19:18:47.560921 Epoch [062/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9878 Loss3: -0.9922\n",
            "Epoch: 62 MAE: 0.07120508532044752 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:18:54.164401 Epoch [063/500], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9812 Loss3: -0.9899\n",
            "2022-06-21 19:19:32.392918 Epoch [063/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9843 Loss3: -0.9909\n",
            "2022-06-21 19:19:40.185340 Epoch [063/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9872 Loss3: -0.9931\n",
            "Epoch: 63 MAE: 0.07165568740279585 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:19:46.859677 Epoch [064/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9833 Loss3: -0.9912\n",
            "2022-06-21 19:20:25.160749 Epoch [064/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9845 Loss3: -0.9911\n",
            "2022-06-21 19:20:33.057923 Epoch [064/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9869 Loss3: -0.9918\n",
            "Epoch: 64 MAE: 0.07289161258273655 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:20:39.634935 Epoch [065/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9833 Loss3: -0.9910\n",
            "2022-06-21 19:21:17.816021 Epoch [065/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9871 Loss3: -0.9917\n",
            "2022-06-21 19:21:25.613539 Epoch [065/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9877 Loss3: -0.9930\n",
            "Epoch: 65 MAE: 0.07174776788741821 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:21:34.548769 Epoch [066/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9869 Loss3: -0.9918\n",
            "2022-06-21 19:22:12.817659 Epoch [066/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9845 Loss3: -0.9917\n",
            "2022-06-21 19:22:20.642818 Epoch [066/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9825 Loss3: -0.9909\n",
            "Epoch: 66 MAE: 0.072319558663343 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:22:27.454341 Epoch [067/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-21 19:23:05.957149 Epoch [067/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9839 Loss3: -0.9908\n",
            "2022-06-21 19:23:13.743614 Epoch [067/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9861 Loss3: -0.9928\n",
            "Epoch: 67 MAE: 0.070565458227087 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:23:20.438918 Epoch [068/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9861 Loss3: -0.9916\n",
            "2022-06-21 19:23:58.663899 Epoch [068/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9833 Loss3: -0.9904\n",
            "2022-06-21 19:24:06.443255 Epoch [068/500], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9842 Loss3: -0.9902\n",
            "Epoch: 68 MAE: 0.07226042919058016 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:24:13.079113 Epoch [069/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9874 Loss3: -0.9927\n",
            "2022-06-21 19:24:51.286417 Epoch [069/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9856 Loss3: -0.9924\n",
            "2022-06-21 19:24:59.174349 Epoch [069/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9861 Loss3: -0.9924\n",
            "Epoch: 69 MAE: 0.07165787681700693 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:25:06.484339 Epoch [070/500], Step [0001/0060], Loss1: -0.9869 Loss2: -0.9808 Loss3: -0.9892\n",
            "2022-06-21 19:25:44.635732 Epoch [070/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9843 Loss3: -0.9910\n",
            "2022-06-21 19:25:52.424469 Epoch [070/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9835 Loss3: -0.9918\n",
            "Epoch: 70 MAE: 0.0713387694686809 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:26:01.450580 Epoch [071/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9837 Loss3: -0.9911\n",
            "2022-06-21 19:26:39.643896 Epoch [071/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9862 Loss3: -0.9927\n",
            "2022-06-21 19:26:47.432425 Epoch [071/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9859 Loss3: -0.9928\n",
            "Epoch: 71 MAE: 0.07148749618933946 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:26:54.013309 Epoch [072/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-21 19:27:32.602216 Epoch [072/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9816 Loss3: -0.9902\n",
            "2022-06-21 19:27:40.374716 Epoch [072/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9868 Loss3: -0.9925\n",
            "Epoch: 72 MAE: 0.06945191186571878 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:27:46.905746 Epoch [073/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9860 Loss3: -0.9925\n",
            "2022-06-21 19:28:25.081048 Epoch [073/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9860 Loss3: -0.9918\n",
            "2022-06-21 19:28:32.869255 Epoch [073/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9821 Loss3: -0.9898\n",
            "Epoch: 73 MAE: 0.07111771063829857 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:28:39.312392 Epoch [074/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9856 Loss3: -0.9926\n",
            "2022-06-21 19:29:17.539864 Epoch [074/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9842 Loss3: -0.9911\n",
            "2022-06-21 19:29:25.316267 Epoch [074/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9878 Loss3: -0.9927\n",
            "Epoch: 74 MAE: 0.07438959313448146 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:29:31.987450 Epoch [075/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-06-21 19:30:10.282663 Epoch [075/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9836 Loss3: -0.9915\n",
            "2022-06-21 19:30:18.060884 Epoch [075/500], Step [0060/0060], Loss1: -0.9844 Loss2: -0.9797 Loss3: -0.9877\n",
            "Epoch: 75 MAE: 0.0737298968481639 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:30:26.864409 Epoch [076/500], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9796 Loss3: -0.9883\n",
            "2022-06-21 19:31:05.062075 Epoch [076/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9833 Loss3: -0.9923\n",
            "2022-06-21 19:31:12.829206 Epoch [076/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9865 Loss3: -0.9929\n",
            "Epoch: 76 MAE: 0.0718105869192295 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:31:19.496592 Epoch [077/500], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9827 Loss3: -0.9903\n",
            "2022-06-21 19:31:57.821200 Epoch [077/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9842 Loss3: -0.9915\n",
            "2022-06-21 19:32:05.742288 Epoch [077/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9839 Loss3: -0.9917\n",
            "Epoch: 77 MAE: 0.07271188574493248 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:32:12.307942 Epoch [078/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9917\n",
            "2022-06-21 19:32:50.392835 Epoch [078/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9807 Loss3: -0.9904\n",
            "2022-06-21 19:32:58.147453 Epoch [078/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9868 Loss3: -0.9924\n",
            "Epoch: 78 MAE: 0.07218397296925701 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:33:04.623441 Epoch [079/500], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9830 Loss3: -0.9894\n",
            "2022-06-21 19:33:42.718672 Epoch [079/500], Step [0050/0060], Loss1: -0.9821 Loss2: -0.9756 Loss3: -0.9862\n",
            "2022-06-21 19:33:50.479525 Epoch [079/500], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9831 Loss3: -0.9901\n",
            "Epoch: 79 MAE: 0.07247557650167474 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:33:57.011316 Epoch [080/500], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9843 Loss3: -0.9907\n",
            "2022-06-21 19:34:35.354160 Epoch [080/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9833 Loss3: -0.9917\n",
            "2022-06-21 19:34:43.126678 Epoch [080/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9865 Loss3: -0.9931\n",
            "Epoch: 80 MAE: 0.07049041167768852 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:34:53.417324 Epoch [081/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9852 Loss3: -0.9916\n",
            "2022-06-21 19:35:31.613016 Epoch [081/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9885 Loss3: -0.9931\n",
            "2022-06-21 19:35:39.417191 Epoch [081/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9847 Loss3: -0.9914\n",
            "Epoch: 81 MAE: 0.06910805338904971 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:35:46.013846 Epoch [082/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9824 Loss3: -0.9911\n",
            "2022-06-21 19:36:24.171263 Epoch [082/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9862 Loss3: -0.9926\n",
            "2022-06-21 19:36:32.083438 Epoch [082/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9853 Loss3: -0.9923\n",
            "Epoch: 82 MAE: 0.07073716955840904 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:36:40.059848 Epoch [083/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9864 Loss3: -0.9916\n",
            "2022-06-21 19:37:18.218733 Epoch [083/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-06-21 19:37:26.015083 Epoch [083/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9838 Loss3: -0.9909\n",
            "Epoch: 83 MAE: 0.07185868460034568 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:37:32.463521 Epoch [084/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9820 Loss3: -0.9900\n",
            "2022-06-21 19:38:10.606728 Epoch [084/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9866 Loss3: -0.9928\n",
            "2022-06-21 19:38:18.389313 Epoch [084/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9909\n",
            "Epoch: 84 MAE: 0.07173942076466071 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:38:24.994994 Epoch [085/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9885 Loss3: -0.9932\n",
            "2022-06-21 19:39:03.206431 Epoch [085/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9875 Loss3: -0.9927\n",
            "2022-06-21 19:39:10.974944 Epoch [085/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9862 Loss3: -0.9914\n",
            "Epoch: 85 MAE: 0.07322751549816636 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:39:20.096406 Epoch [086/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9851 Loss3: -0.9920\n",
            "2022-06-21 19:39:58.284055 Epoch [086/500], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9789 Loss3: -0.9885\n",
            "2022-06-21 19:40:06.065581 Epoch [086/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9856 Loss3: -0.9912\n",
            "Epoch: 86 MAE: 0.07316903825790165 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:40:12.601933 Epoch [087/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9859 Loss3: -0.9924\n",
            "2022-06-21 19:40:50.689864 Epoch [087/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9869 Loss3: -0.9920\n",
            "2022-06-21 19:40:58.477076 Epoch [087/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9843 Loss3: -0.9915\n",
            "Epoch: 87 MAE: 0.07142414496689249 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:41:05.571706 Epoch [088/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9798 Loss3: -0.9900\n",
            "2022-06-21 19:41:44.146064 Epoch [088/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9874 Loss3: -0.9932\n",
            "2022-06-21 19:41:51.958048 Epoch [088/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9814 Loss3: -0.9903\n",
            "Epoch: 88 MAE: 0.07311497622696814 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:41:58.670251 Epoch [089/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9843 Loss3: -0.9913\n",
            "2022-06-21 19:42:36.946820 Epoch [089/500], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9817 Loss3: -0.9900\n",
            "2022-06-21 19:42:44.727767 Epoch [089/500], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9841 Loss3: -0.9900\n",
            "Epoch: 89 MAE: 0.0718927593332119 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:42:51.303351 Epoch [090/500], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9790 Loss3: -0.9892\n",
            "2022-06-21 19:43:29.567533 Epoch [090/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9863 Loss3: -0.9928\n",
            "2022-06-21 19:43:37.404710 Epoch [090/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9826 Loss3: -0.9907\n",
            "Epoch: 90 MAE: 0.07175720603377729 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:43:46.409817 Epoch [091/500], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9820 Loss3: -0.9903\n",
            "2022-06-21 19:44:24.643655 Epoch [091/500], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9810 Loss3: -0.9901\n",
            "2022-06-21 19:44:32.443658 Epoch [091/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9853 Loss3: -0.9920\n",
            "Epoch: 91 MAE: 0.07069303769913932 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:44:38.977551 Epoch [092/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9865 Loss3: -0.9920\n",
            "2022-06-21 19:45:17.089821 Epoch [092/500], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9847 Loss3: -0.9901\n",
            "2022-06-21 19:45:24.863293 Epoch [092/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9870 Loss3: -0.9929\n",
            "Epoch: 92 MAE: 0.07046321737703193 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:45:31.453353 Epoch [093/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9852 Loss3: -0.9908\n",
            "2022-06-21 19:46:09.949106 Epoch [093/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9874 Loss3: -0.9923\n",
            "2022-06-21 19:46:17.744573 Epoch [093/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9857 Loss3: -0.9926\n",
            "Epoch: 93 MAE: 0.0711170780847943 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:46:24.448792 Epoch [094/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9848 Loss3: -0.9922\n",
            "2022-06-21 19:47:02.649092 Epoch [094/500], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9826 Loss3: -0.9902\n",
            "2022-06-21 19:47:10.426756 Epoch [094/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9866 Loss3: -0.9923\n",
            "Epoch: 94 MAE: 0.07215619208320738 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:47:17.035974 Epoch [095/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9835 Loss3: -0.9914\n",
            "2022-06-21 19:47:55.239341 Epoch [095/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9853 Loss3: -0.9915\n",
            "2022-06-21 19:48:03.115967 Epoch [095/500], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9837 Loss3: -0.9896\n",
            "Epoch: 95 MAE: 0.07163983239067925 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:48:12.414137 Epoch [096/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9871 Loss3: -0.9927\n",
            "2022-06-21 19:48:50.655229 Epoch [096/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9855 Loss3: -0.9924\n",
            "2022-06-21 19:48:58.441322 Epoch [096/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9891 Loss3: -0.9934\n",
            "Epoch: 96 MAE: 0.0713907933109021 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:49:05.095464 Epoch [097/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-06-21 19:49:43.199028 Epoch [097/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9857 Loss3: -0.9918\n",
            "2022-06-21 19:49:50.974989 Epoch [097/500], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9860 Loss3: -0.9916\n",
            "Epoch: 97 MAE: 0.07008777956483224 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:49:57.502324 Epoch [098/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9871 Loss3: -0.9927\n",
            "2022-06-21 19:50:36.002775 Epoch [098/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9855 Loss3: -0.9923\n",
            "2022-06-21 19:50:43.773007 Epoch [098/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9842 Loss3: -0.9907\n",
            "Epoch: 98 MAE: 0.07166004730910852 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:50:50.292651 Epoch [099/500], Step [0001/0060], Loss1: -0.9850 Loss2: -0.9805 Loss3: -0.9883\n",
            "2022-06-21 19:51:28.419677 Epoch [099/500], Step [0050/0060], Loss1: -0.9834 Loss2: -0.9796 Loss3: -0.9868\n",
            "2022-06-21 19:51:36.204074 Epoch [099/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9877 Loss3: -0.9931\n",
            "Epoch: 99 MAE: 0.07346061570303779 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:51:42.880853 Epoch [100/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9845 Loss3: -0.9915\n",
            "2022-06-21 19:52:21.054566 Epoch [100/500], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9843 Loss3: -0.9905\n",
            "2022-06-21 19:52:28.854660 Epoch [100/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9875 Loss3: -0.9925\n",
            "Epoch: 100 MAE: 0.0711297087694602 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:52:38.676449 Epoch [101/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9820 Loss3: -0.9916\n",
            "2022-06-21 19:53:17.045735 Epoch [101/500], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9813 Loss3: -0.9891\n",
            "2022-06-21 19:53:24.847540 Epoch [101/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9861 Loss3: -0.9924\n",
            "Epoch: 101 MAE: 0.07061669702883121 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:53:31.542510 Epoch [102/500], Step [0001/0060], Loss1: -0.9922 Loss2: -0.9887 Loss3: -0.9937\n",
            "2022-06-21 19:54:09.672773 Epoch [102/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9862 Loss3: -0.9921\n",
            "2022-06-21 19:54:17.449183 Epoch [102/500], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9855 Loss3: -0.9918\n",
            "Epoch: 102 MAE: 0.07193160667621268 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:54:24.053005 Epoch [103/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9867 Loss3: -0.9925\n",
            "2022-06-21 19:55:02.452582 Epoch [103/500], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9834 Loss3: -0.9910\n",
            "2022-06-21 19:55:10.233155 Epoch [103/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9870 Loss3: -0.9925\n",
            "Epoch: 103 MAE: 0.07341179681202722 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:55:16.744916 Epoch [104/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9864 Loss3: -0.9922\n",
            "2022-06-21 19:55:54.981378 Epoch [104/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9855 Loss3: -0.9909\n",
            "2022-06-21 19:56:02.775585 Epoch [104/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9837 Loss3: -0.9905\n",
            "Epoch: 104 MAE: 0.07323253480214922 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:56:09.477352 Epoch [105/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9859 Loss3: -0.9917\n",
            "2022-06-21 19:56:47.627505 Epoch [105/500], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9825 Loss3: -0.9900\n",
            "2022-06-21 19:56:55.402419 Epoch [105/500], Step [0060/0060], Loss1: -0.9819 Loss2: -0.9746 Loss3: -0.9858\n",
            "Epoch: 105 MAE: 0.07335775799221461 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:57:04.348279 Epoch [106/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9856 Loss3: -0.9927\n",
            "2022-06-21 19:57:42.873434 Epoch [106/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9874 Loss3: -0.9924\n",
            "2022-06-21 19:57:50.660432 Epoch [106/500], Step [0060/0060], Loss1: -0.9878 Loss2: -0.9819 Loss3: -0.9896\n",
            "Epoch: 106 MAE: 0.07203412207346116 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:57:57.186087 Epoch [107/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9860 Loss3: -0.9928\n",
            "2022-06-21 19:58:35.294940 Epoch [107/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9858 Loss3: -0.9922\n",
            "2022-06-21 19:58:43.060083 Epoch [107/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9835 Loss3: -0.9911\n",
            "Epoch: 107 MAE: 0.07090846157578563 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:58:49.724556 Epoch [108/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9866 Loss3: -0.9931\n",
            "2022-06-21 19:59:28.013997 Epoch [108/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9867 Loss3: -0.9923\n",
            "2022-06-21 19:59:35.888618 Epoch [108/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9847 Loss3: -0.9923\n",
            "Epoch: 108 MAE: 0.07240578828034576 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 19:59:42.492366 Epoch [109/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-21 20:00:20.631856 Epoch [109/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9861 Loss3: -0.9918\n",
            "2022-06-21 20:00:28.393532 Epoch [109/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9871 Loss3: -0.9926\n",
            "Epoch: 109 MAE: 0.07316907110668364 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:00:35.003500 Epoch [110/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9827 Loss3: -0.9913\n",
            "2022-06-21 20:01:13.164450 Epoch [110/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9880 Loss3: -0.9930\n",
            "2022-06-21 20:01:20.948862 Epoch [110/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9826 Loss3: -0.9904\n",
            "Epoch: 110 MAE: 0.0718982455339381 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:01:29.911718 Epoch [111/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9871 Loss3: -0.9926\n",
            "2022-06-21 20:02:08.399314 Epoch [111/500], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9870 Loss3: -0.9937\n",
            "2022-06-21 20:02:16.182571 Epoch [111/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9845 Loss3: -0.9910\n",
            "Epoch: 111 MAE: 0.07276159125030356 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:02:22.688348 Epoch [112/500], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9831 Loss3: -0.9906\n",
            "2022-06-21 20:03:00.842826 Epoch [112/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9857 Loss3: -0.9910\n",
            "2022-06-21 20:03:08.622056 Epoch [112/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9784 Loss3: -0.9893\n",
            "Epoch: 112 MAE: 0.0744155964523396 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:03:15.132322 Epoch [113/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9873 Loss3: -0.9926\n",
            "2022-06-21 20:03:53.278986 Epoch [113/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9855 Loss3: -0.9923\n",
            "2022-06-21 20:04:01.180144 Epoch [113/500], Step [0060/0060], Loss1: -0.9854 Loss2: -0.9785 Loss3: -0.9880\n",
            "Epoch: 113 MAE: 0.07168705975567854 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:04:08.306068 Epoch [114/500], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9823 Loss3: -0.9898\n",
            "2022-06-21 20:04:46.378249 Epoch [114/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9839 Loss3: -0.9905\n",
            "2022-06-21 20:04:54.127431 Epoch [114/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9865 Loss3: -0.9922\n",
            "Epoch: 114 MAE: 0.07201658132845763 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:05:00.603798 Epoch [115/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9876 Loss3: -0.9937\n",
            "2022-06-21 20:05:38.731434 Epoch [115/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9875 Loss3: -0.9923\n",
            "2022-06-21 20:05:46.518602 Epoch [115/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9840 Loss3: -0.9916\n",
            "Epoch: 115 MAE: 0.07223983905933523 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:05:55.446144 Epoch [116/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9876 Loss3: -0.9924\n",
            "2022-06-21 20:06:34.018333 Epoch [116/500], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9815 Loss3: -0.9892\n",
            "2022-06-21 20:06:41.808525 Epoch [116/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9870 Loss3: -0.9921\n",
            "Epoch: 116 MAE: 0.07254912431908662 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:06:48.344995 Epoch [117/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9862 Loss3: -0.9911\n",
            "2022-06-21 20:07:26.426436 Epoch [117/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9839 Loss3: -0.9912\n",
            "2022-06-21 20:07:34.201505 Epoch [117/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9883 Loss3: -0.9926\n",
            "Epoch: 117 MAE: 0.07067513511294411 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:07:40.768802 Epoch [118/500], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9822 Loss3: -0.9904\n",
            "2022-06-21 20:08:18.955272 Epoch [118/500], Step [0050/0060], Loss1: -0.9922 Loss2: -0.9885 Loss3: -0.9937\n",
            "2022-06-21 20:08:26.827074 Epoch [118/500], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9822 Loss3: -0.9903\n",
            "Epoch: 118 MAE: 0.07244975059751481 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:08:34.156308 Epoch [119/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9861 Loss3: -0.9921\n",
            "2022-06-21 20:09:12.407092 Epoch [119/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9841 Loss3: -0.9911\n",
            "2022-06-21 20:09:20.208210 Epoch [119/500], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9840 Loss3: -0.9913\n",
            "Epoch: 119 MAE: 0.07234870214310901 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:09:26.848851 Epoch [120/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9861 Loss3: -0.9912\n",
            "2022-06-21 20:10:04.997974 Epoch [120/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9875 Loss3: -0.9933\n",
            "2022-06-21 20:10:12.773118 Epoch [120/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9847 Loss3: -0.9905\n",
            "Epoch: 120 MAE: 0.07271180470784507 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:10:21.723951 Epoch [121/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9840 Loss3: -0.9912\n",
            "2022-06-21 20:11:00.302921 Epoch [121/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9830 Loss3: -0.9908\n",
            "2022-06-21 20:11:08.072843 Epoch [121/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9859 Loss3: -0.9915\n",
            "Epoch: 121 MAE: 0.07351864330352303 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:11:14.620334 Epoch [122/500], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9790 Loss3: -0.9882\n",
            "2022-06-21 20:11:52.749778 Epoch [122/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9874 Loss3: -0.9926\n",
            "2022-06-21 20:12:00.516910 Epoch [122/500], Step [0060/0060], Loss1: -0.9865 Loss2: -0.9809 Loss3: -0.9893\n",
            "Epoch: 122 MAE: 0.07125722067696708 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:12:07.033213 Epoch [123/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9876 Loss3: -0.9924\n",
            "2022-06-21 20:12:45.182190 Epoch [123/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9862 Loss3: -0.9923\n",
            "2022-06-21 20:12:52.970836 Epoch [123/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9867 Loss3: -0.9923\n",
            "Epoch: 123 MAE: 0.07226744566014205 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:12:59.492627 Epoch [124/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9844 Loss3: -0.9911\n",
            "2022-06-21 20:13:37.798813 Epoch [124/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9929\n",
            "2022-06-21 20:13:45.563476 Epoch [124/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9861 Loss3: -0.9927\n",
            "Epoch: 124 MAE: 0.07231647824484205 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:13:52.065374 Epoch [125/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9880 Loss3: -0.9933\n",
            "2022-06-21 20:14:30.208560 Epoch [125/500], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9883 Loss3: -0.9933\n",
            "2022-06-21 20:14:37.994560 Epoch [125/500], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9810 Loss3: -0.9890\n",
            "Epoch: 125 MAE: 0.07005686331047582 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:14:46.658426 Epoch [126/500], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9840 Loss3: -0.9901\n",
            "2022-06-21 20:15:25.127028 Epoch [126/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9876 Loss3: -0.9928\n",
            "2022-06-21 20:15:33.044119 Epoch [126/500], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9779 Loss3: -0.9897\n",
            "Epoch: 126 MAE: 0.07226021201522262 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:15:39.537807 Epoch [127/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9808 Loss3: -0.9899\n",
            "2022-06-21 20:16:17.637736 Epoch [127/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9852 Loss3: -0.9915\n",
            "2022-06-21 20:16:25.418002 Epoch [127/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9833 Loss3: -0.9914\n",
            "Epoch: 127 MAE: 0.07114988806386471 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:16:31.997233 Epoch [128/500], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9796 Loss3: -0.9883\n",
            "2022-06-21 20:17:10.116398 Epoch [128/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9874 Loss3: -0.9921\n",
            "2022-06-21 20:17:17.915683 Epoch [128/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9833 Loss3: -0.9906\n",
            "Epoch: 128 MAE: 0.07278032519829966 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:17:24.384909 Epoch [129/500], Step [0001/0060], Loss1: -0.9867 Loss2: -0.9809 Loss3: -0.9892\n",
            "2022-06-21 20:18:02.647317 Epoch [129/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9861 Loss3: -0.9915\n",
            "2022-06-21 20:18:10.403607 Epoch [129/500], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9846 Loss3: -0.9895\n",
            "Epoch: 129 MAE: 0.07479113674668407 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:18:16.974817 Epoch [130/500], Step [0001/0060], Loss1: -0.9843 Loss2: -0.9771 Loss3: -0.9871\n",
            "2022-06-21 20:18:55.080002 Epoch [130/500], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9821 Loss3: -0.9891\n",
            "2022-06-21 20:19:02.854866 Epoch [130/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9853 Loss3: -0.9926\n",
            "Epoch: 130 MAE: 0.07228131642417303 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:19:12.859077 Epoch [131/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9875 Loss3: -0.9931\n",
            "2022-06-21 20:19:51.078784 Epoch [131/500], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9876 Loss3: -0.9938\n",
            "2022-06-21 20:19:59.081701 Epoch [131/500], Step [0060/0060], Loss1: -0.9830 Loss2: -0.9755 Loss3: -0.9864\n",
            "Epoch: 131 MAE: 0.07231596855890182 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:20:06.854009 Epoch [132/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-06-21 20:20:44.969557 Epoch [132/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9849 Loss3: -0.9915\n",
            "2022-06-21 20:20:52.726367 Epoch [132/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9854 Loss3: -0.9919\n",
            "Epoch: 132 MAE: 0.07332711078502513 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:20:59.219953 Epoch [133/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9847 Loss3: -0.9909\n",
            "2022-06-21 20:21:37.451594 Epoch [133/500], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9878 Loss3: -0.9935\n",
            "2022-06-21 20:21:45.230688 Epoch [133/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9867 Loss3: -0.9918\n",
            "Epoch: 133 MAE: 0.07285075626676045 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:21:51.870810 Epoch [134/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9877 Loss3: -0.9928\n",
            "2022-06-21 20:22:30.257973 Epoch [134/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9869 Loss3: -0.9930\n",
            "2022-06-21 20:22:38.035631 Epoch [134/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9821 Loss3: -0.9916\n",
            "Epoch: 134 MAE: 0.07061314819981812 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:22:44.615937 Epoch [135/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9869 Loss3: -0.9922\n",
            "2022-06-21 20:23:22.827233 Epoch [135/500], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9804 Loss3: -0.9893\n",
            "2022-06-21 20:23:30.625583 Epoch [135/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9864 Loss3: -0.9920\n",
            "Epoch: 135 MAE: 0.07071010776297756 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:23:39.735645 Epoch [136/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9854 Loss3: -0.9913\n",
            "2022-06-21 20:24:17.967373 Epoch [136/500], Step [0050/0060], Loss1: -0.9851 Loss2: -0.9781 Loss3: -0.9882\n",
            "2022-06-21 20:24:25.762363 Epoch [136/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9871 Loss3: -0.9929\n",
            "Epoch: 136 MAE: 0.07105268685275287 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:24:32.410630 Epoch [137/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9878 Loss3: -0.9929\n",
            "2022-06-21 20:25:10.878923 Epoch [137/500], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9832 Loss3: -0.9899\n",
            "2022-06-21 20:25:18.654775 Epoch [137/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9876 Loss3: -0.9927\n",
            "Epoch: 137 MAE: 0.07057875027732242 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:25:25.176325 Epoch [138/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9882 Loss3: -0.9933\n",
            "2022-06-21 20:26:03.357860 Epoch [138/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9837 Loss3: -0.9912\n",
            "2022-06-21 20:26:11.155799 Epoch [138/500], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9823 Loss3: -0.9901\n",
            "Epoch: 138 MAE: 0.07296625051548872 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:26:17.838869 Epoch [139/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9843 Loss3: -0.9919\n",
            "2022-06-21 20:26:56.155555 Epoch [139/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9846 Loss3: -0.9903\n",
            "2022-06-21 20:27:04.024566 Epoch [139/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9870 Loss3: -0.9933\n",
            "Epoch: 139 MAE: 0.07252473805947277 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:27:10.643825 Epoch [140/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9866 Loss3: -0.9930\n",
            "2022-06-21 20:27:48.808762 Epoch [140/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9847 Loss3: -0.9903\n",
            "2022-06-21 20:27:56.601161 Epoch [140/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9832 Loss3: -0.9919\n",
            "Epoch: 140 MAE: 0.07165394520633436 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:28:05.918942 Epoch [141/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9858 Loss3: -0.9918\n",
            "2022-06-21 20:28:44.100595 Epoch [141/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9844 Loss3: -0.9910\n",
            "2022-06-21 20:28:51.907356 Epoch [141/500], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9827 Loss3: -0.9889\n",
            "Epoch: 141 MAE: 0.07300314353256629 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:28:58.619792 Epoch [142/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9858 Loss3: -0.9925\n",
            "2022-06-21 20:29:37.094914 Epoch [142/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9883 Loss3: -0.9934\n",
            "2022-06-21 20:29:44.871260 Epoch [142/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9840 Loss3: -0.9913\n",
            "Epoch: 142 MAE: 0.072081513026404 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:29:51.436827 Epoch [143/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9868 Loss3: -0.9922\n",
            "2022-06-21 20:30:29.652420 Epoch [143/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9853 Loss3: -0.9915\n",
            "2022-06-21 20:30:37.423267 Epoch [143/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9844 Loss3: -0.9922\n",
            "Epoch: 143 MAE: 0.07088885393092242 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:30:44.014111 Epoch [144/500], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9803 Loss3: -0.9887\n",
            "2022-06-21 20:31:22.256293 Epoch [144/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9869 Loss3: -0.9927\n",
            "2022-06-21 20:31:30.057858 Epoch [144/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9867 Loss3: -0.9926\n",
            "Epoch: 144 MAE: 0.07267102695646736 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:31:37.280444 Epoch [145/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9853 Loss3: -0.9914\n",
            "2022-06-21 20:32:15.582574 Epoch [145/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9849 Loss3: -0.9919\n",
            "2022-06-21 20:32:23.366841 Epoch [145/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9858 Loss3: -0.9917\n",
            "Epoch: 145 MAE: 0.07346971965971445 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:32:32.344816 Epoch [146/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9808 Loss3: -0.9906\n",
            "2022-06-21 20:33:10.575004 Epoch [146/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9862 Loss3: -0.9918\n",
            "2022-06-21 20:33:18.383776 Epoch [146/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9855 Loss3: -0.9913\n",
            "Epoch: 146 MAE: 0.07166248044008931 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:33:25.005599 Epoch [147/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9872 Loss3: -0.9916\n",
            "2022-06-21 20:34:03.615158 Epoch [147/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9853 Loss3: -0.9914\n",
            "2022-06-21 20:34:11.408534 Epoch [147/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9885 Loss3: -0.9925\n",
            "Epoch: 147 MAE: 0.07182175414272086 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:34:17.942573 Epoch [148/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9870 Loss3: -0.9924\n",
            "2022-06-21 20:34:56.155845 Epoch [148/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9858 Loss3: -0.9923\n",
            "2022-06-21 20:35:03.957325 Epoch [148/500], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9861 Loss3: -0.9912\n",
            "Epoch: 148 MAE: 0.07235275344243126 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:35:10.540677 Epoch [149/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9817 Loss3: -0.9905\n",
            "2022-06-21 20:35:48.686888 Epoch [149/500], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9844 Loss3: -0.9922\n",
            "2022-06-21 20:35:56.477953 Epoch [149/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9873 Loss3: -0.9930\n",
            "Epoch: 149 MAE: 0.07302394791254922 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:36:03.280788 Epoch [150/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9820 Loss3: -0.9910\n",
            "2022-06-21 20:36:41.728504 Epoch [150/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9850 Loss3: -0.9909\n",
            "2022-06-21 20:36:49.527910 Epoch [150/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9852 Loss3: -0.9910\n",
            "Epoch: 150 MAE: 0.07349750584395474 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:36:59.846823 Epoch [151/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9865 Loss3: -0.9915\n",
            "2022-06-21 20:37:38.091400 Epoch [151/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9864 Loss3: -0.9923\n",
            "2022-06-21 20:37:45.867640 Epoch [151/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9822 Loss3: -0.9908\n",
            "Epoch: 151 MAE: 0.07348122238482116 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:37:52.401906 Epoch [152/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-06-21 20:38:30.867427 Epoch [152/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9861 Loss3: -0.9907\n",
            "2022-06-21 20:38:38.697362 Epoch [152/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9831 Loss3: -0.9901\n",
            "Epoch: 152 MAE: 0.07173439802946867 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:38:45.512130 Epoch [153/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9882 Loss3: -0.9931\n",
            "2022-06-21 20:39:23.764822 Epoch [153/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9882 Loss3: -0.9927\n",
            "2022-06-21 20:39:31.564982 Epoch [153/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9835 Loss3: -0.9915\n",
            "Epoch: 153 MAE: 0.07191894652351499 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:39:38.317760 Epoch [154/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9856 Loss3: -0.9913\n",
            "2022-06-21 20:40:16.545269 Epoch [154/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9817 Loss3: -0.9914\n",
            "2022-06-21 20:40:24.354736 Epoch [154/500], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9840 Loss3: -0.9899\n",
            "Epoch: 154 MAE: 0.07253796370571884 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:40:31.185059 Epoch [155/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9882 Loss3: -0.9929\n",
            "2022-06-21 20:41:09.508460 Epoch [155/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9853 Loss3: -0.9909\n",
            "2022-06-21 20:41:17.303160 Epoch [155/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9849 Loss3: -0.9916\n",
            "Epoch: 155 MAE: 0.07246021992315059 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:41:26.271422 Epoch [156/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9856 Loss3: -0.9921\n",
            "2022-06-21 20:42:04.447234 Epoch [156/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9840 Loss3: -0.9904\n",
            "2022-06-21 20:42:12.242646 Epoch [156/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9841 Loss3: -0.9908\n",
            "Epoch: 156 MAE: 0.07373168627421063 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:42:18.888100 Epoch [157/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9929\n",
            "2022-06-21 20:42:57.235083 Epoch [157/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-06-21 20:43:05.246728 Epoch [157/500], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9789 Loss3: -0.9889\n",
            "Epoch: 157 MAE: 0.07428386789150336 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:43:12.024483 Epoch [158/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9863 Loss3: -0.9925\n",
            "2022-06-21 20:43:50.194445 Epoch [158/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9880 Loss3: -0.9926\n",
            "2022-06-21 20:43:57.992108 Epoch [158/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9847 Loss3: -0.9918\n",
            "Epoch: 158 MAE: 0.07333791319024625 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:44:04.532152 Epoch [159/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9861 Loss3: -0.9917\n",
            "2022-06-21 20:44:42.711740 Epoch [159/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9857 Loss3: -0.9919\n",
            "2022-06-21 20:44:50.490537 Epoch [159/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9851 Loss3: -0.9933\n",
            "Epoch: 159 MAE: 0.07080823282716135 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:44:57.266569 Epoch [160/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9851 Loss3: -0.9911\n",
            "2022-06-21 20:45:35.753154 Epoch [160/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9838 Loss3: -0.9906\n",
            "2022-06-21 20:45:43.536435 Epoch [160/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9853 Loss3: -0.9915\n",
            "Epoch: 160 MAE: 0.07309000827648023 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:45:52.521651 Epoch [161/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9882 Loss3: -0.9931\n",
            "2022-06-21 20:46:30.750847 Epoch [161/500], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9915\n",
            "2022-06-21 20:46:38.532696 Epoch [161/500], Step [0060/0060], Loss1: -0.9847 Loss2: -0.9794 Loss3: -0.9877\n",
            "Epoch: 161 MAE: 0.0724986163144389 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:46:45.127001 Epoch [162/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9856 Loss3: -0.9912\n",
            "2022-06-21 20:47:23.318411 Epoch [162/500], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9871 Loss3: -0.9923\n",
            "2022-06-21 20:47:31.306641 Epoch [162/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9879 Loss3: -0.9932\n",
            "Epoch: 162 MAE: 0.07304310889471145 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:47:38.898434 Epoch [163/500], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9819 Loss3: -0.9905\n",
            "2022-06-21 20:48:17.072851 Epoch [163/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9860 Loss3: -0.9927\n",
            "2022-06-21 20:48:24.849423 Epoch [163/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9815 Loss3: -0.9896\n",
            "Epoch: 163 MAE: 0.07327141832422328 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:48:31.363643 Epoch [164/500], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9808 Loss3: -0.9889\n",
            "2022-06-21 20:49:09.508945 Epoch [164/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9871 Loss3: -0.9924\n",
            "2022-06-21 20:49:17.289435 Epoch [164/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9862 Loss3: -0.9922\n",
            "Epoch: 164 MAE: 0.07081699008033392 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:49:23.948419 Epoch [165/500], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9873 Loss3: -0.9934\n",
            "2022-06-21 20:50:02.272318 Epoch [165/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9844 Loss3: -0.9911\n",
            "2022-06-21 20:50:10.047681 Epoch [165/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9853 Loss3: -0.9919\n",
            "Epoch: 165 MAE: 0.07230342981045841 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:50:19.991124 Epoch [166/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9869 Loss3: -0.9931\n",
            "2022-06-21 20:50:58.240969 Epoch [166/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9853 Loss3: -0.9912\n",
            "2022-06-21 20:51:06.041499 Epoch [166/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9863 Loss3: -0.9931\n",
            "Epoch: 166 MAE: 0.07167239860252099 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:51:12.641862 Epoch [167/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9831 Loss3: -0.9902\n",
            "2022-06-21 20:51:50.741402 Epoch [167/500], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9843 Loss3: -0.9908\n",
            "2022-06-21 20:51:58.523409 Epoch [167/500], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9777 Loss3: -0.9900\n",
            "Epoch: 167 MAE: 0.0732985316382514 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:52:05.449956 Epoch [168/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9841 Loss3: -0.9913\n",
            "2022-06-21 20:52:43.944542 Epoch [168/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9852 Loss3: -0.9909\n",
            "2022-06-21 20:52:51.724294 Epoch [168/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9879 Loss3: -0.9929\n",
            "Epoch: 168 MAE: 0.07276005210069122 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:52:58.251548 Epoch [169/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9852 Loss3: -0.9914\n",
            "2022-06-21 20:53:36.375432 Epoch [169/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9859 Loss3: -0.9912\n",
            "2022-06-21 20:53:44.150994 Epoch [169/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9881 Loss3: -0.9923\n",
            "Epoch: 169 MAE: 0.07153780447742923 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:53:50.662185 Epoch [170/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9874 Loss3: -0.9933\n",
            "2022-06-21 20:54:29.102875 Epoch [170/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9838 Loss3: -0.9918\n",
            "2022-06-21 20:54:36.887971 Epoch [170/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9857 Loss3: -0.9925\n",
            "Epoch: 170 MAE: 0.07339841116042366 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:54:45.934438 Epoch [171/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9842 Loss3: -0.9922\n",
            "2022-06-21 20:55:24.165613 Epoch [171/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-06-21 20:55:31.958131 Epoch [171/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9919\n",
            "Epoch: 171 MAE: 0.0733225740200628 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:55:38.496524 Epoch [172/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9847 Loss3: -0.9912\n",
            "2022-06-21 20:56:16.605000 Epoch [172/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9849 Loss3: -0.9918\n",
            "2022-06-21 20:56:24.386114 Epoch [172/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9827 Loss3: -0.9908\n",
            "Epoch: 172 MAE: 0.07172043537967418 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:56:30.976517 Epoch [173/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9875 Loss3: -0.9931\n",
            "2022-06-21 20:57:09.506343 Epoch [173/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9861 Loss3: -0.9917\n",
            "2022-06-21 20:57:17.288746 Epoch [173/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9825 Loss3: -0.9892\n",
            "Epoch: 173 MAE: 0.07234743234341737 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:57:23.750639 Epoch [174/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9872 Loss3: -0.9924\n",
            "2022-06-21 20:58:01.893188 Epoch [174/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9851 Loss3: -0.9923\n",
            "2022-06-21 20:58:09.664160 Epoch [174/500], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9811 Loss3: -0.9895\n",
            "Epoch: 174 MAE: 0.07277301112180035 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:58:16.201095 Epoch [175/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9853 Loss3: -0.9920\n",
            "2022-06-21 20:58:54.368327 Epoch [175/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9864 Loss3: -0.9924\n",
            "2022-06-21 20:59:02.273732 Epoch [175/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9874 Loss3: -0.9926\n",
            "Epoch: 175 MAE: 0.07338402324252659 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 20:59:11.360476 Epoch [176/500], Step [0001/0060], Loss1: -0.9858 Loss2: -0.9789 Loss3: -0.9883\n",
            "2022-06-21 20:59:49.674689 Epoch [176/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-06-21 20:59:57.487194 Epoch [176/500], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9827 Loss3: -0.9895\n",
            "Epoch: 176 MAE: 0.07196886133264613 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:00:04.104957 Epoch [177/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9861 Loss3: -0.9912\n",
            "2022-06-21 21:00:42.267750 Epoch [177/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9866 Loss3: -0.9929\n",
            "2022-06-21 21:00:50.045880 Epoch [177/500], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9855 Loss3: -0.9905\n",
            "Epoch: 177 MAE: 0.07260680102797414 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:00:56.735660 Epoch [178/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9862 Loss3: -0.9915\n",
            "2022-06-21 21:01:35.331652 Epoch [178/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9858 Loss3: -0.9926\n",
            "2022-06-21 21:01:43.121025 Epoch [178/500], Step [0060/0060], Loss1: -0.9875 Loss2: -0.9835 Loss3: -0.9895\n",
            "Epoch: 178 MAE: 0.0742136429983472 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:01:49.609244 Epoch [179/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9878 Loss3: -0.9929\n",
            "2022-06-21 21:02:27.816040 Epoch [179/500], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9821 Loss3: -0.9891\n",
            "2022-06-21 21:02:35.609014 Epoch [179/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9879 Loss3: -0.9929\n",
            "Epoch: 179 MAE: 0.07437366768165872 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:02:42.246357 Epoch [180/500], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9852 Loss3: -0.9904\n",
            "2022-06-21 21:03:20.447669 Epoch [180/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9848 Loss3: -0.9916\n",
            "2022-06-21 21:03:28.228406 Epoch [180/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9881 Loss3: -0.9929\n",
            "Epoch: 180 MAE: 0.07225450273544069 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:03:37.896844 Epoch [181/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9878 Loss3: -0.9923\n",
            "2022-06-21 21:04:16.366242 Epoch [181/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9863 Loss3: -0.9930\n",
            "2022-06-21 21:04:24.164537 Epoch [181/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9889 Loss3: -0.9935\n",
            "Epoch: 181 MAE: 0.07144682985134226 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:04:30.704619 Epoch [182/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9878 Loss3: -0.9932\n",
            "2022-06-21 21:05:08.837687 Epoch [182/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9855 Loss3: -0.9924\n",
            "2022-06-21 21:05:16.628570 Epoch [182/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9841 Loss3: -0.9906\n",
            "Epoch: 182 MAE: 0.07353095629858593 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:05:23.344210 Epoch [183/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9842 Loss3: -0.9908\n",
            "2022-06-21 21:06:01.713228 Epoch [183/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9821 Loss3: -0.9902\n",
            "2022-06-21 21:06:09.499434 Epoch [183/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9870 Loss3: -0.9930\n",
            "Epoch: 183 MAE: 0.07324422689972732 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:06:16.089504 Epoch [184/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9845 Loss3: -0.9908\n",
            "2022-06-21 21:06:54.261737 Epoch [184/500], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9817 Loss3: -0.9876\n",
            "2022-06-21 21:07:02.050646 Epoch [184/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9869 Loss3: -0.9927\n",
            "Epoch: 184 MAE: 0.0723081444432496 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:07:08.619206 Epoch [185/500], Step [0001/0060], Loss1: -0.9883 Loss2: -0.9820 Loss3: -0.9903\n",
            "2022-06-21 21:07:46.784343 Epoch [185/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9864 Loss3: -0.9925\n",
            "2022-06-21 21:07:54.566771 Epoch [185/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9881 Loss3: -0.9927\n",
            "Epoch: 185 MAE: 0.0720219879049473 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:08:03.653213 Epoch [186/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9829 Loss3: -0.9913\n",
            "2022-06-21 21:08:42.283779 Epoch [186/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9871 Loss3: -0.9927\n",
            "2022-06-21 21:08:50.102849 Epoch [186/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9845 Loss3: -0.9916\n",
            "Epoch: 186 MAE: 0.07205923019893587 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:08:56.708557 Epoch [187/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-06-21 21:09:34.855092 Epoch [187/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9871 Loss3: -0.9917\n",
            "2022-06-21 21:09:42.629798 Epoch [187/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9872 Loss3: -0.9929\n",
            "Epoch: 187 MAE: 0.07204211240092284 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:09:49.224445 Epoch [188/500], Step [0001/0060], Loss1: -0.9873 Loss2: -0.9822 Loss3: -0.9893\n",
            "2022-06-21 21:10:27.513950 Epoch [188/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9854 Loss3: -0.9906\n",
            "2022-06-21 21:10:35.376787 Epoch [188/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9867 Loss3: -0.9925\n",
            "Epoch: 188 MAE: 0.07272607803344729 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:10:41.919862 Epoch [189/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9866 Loss3: -0.9915\n",
            "2022-06-21 21:11:20.102601 Epoch [189/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9830 Loss3: -0.9910\n",
            "2022-06-21 21:11:27.879533 Epoch [189/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9879 Loss3: -0.9926\n",
            "Epoch: 189 MAE: 0.07294719201547127 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:11:34.709961 Epoch [190/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9866 Loss3: -0.9927\n",
            "2022-06-21 21:12:12.824450 Epoch [190/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9860 Loss3: -0.9911\n",
            "2022-06-21 21:12:20.611135 Epoch [190/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9845 Loss3: -0.9917\n",
            "Epoch: 190 MAE: 0.07296380492114517 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:12:29.563008 Epoch [191/500], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9881 Loss3: -0.9932\n",
            "2022-06-21 21:13:08.211678 Epoch [191/500], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9851 Loss3: -0.9923\n",
            "2022-06-21 21:13:16.007707 Epoch [191/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9856 Loss3: -0.9925\n",
            "Epoch: 191 MAE: 0.07280288529774498 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:13:22.806740 Epoch [192/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9908\n",
            "2022-06-21 21:14:00.956369 Epoch [192/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9864 Loss3: -0.9923\n",
            "2022-06-21 21:14:08.737903 Epoch [192/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9886 Loss3: -0.9931\n",
            "Epoch: 192 MAE: 0.07121757527507805 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:14:15.411617 Epoch [193/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9874 Loss3: -0.9922\n",
            "2022-06-21 21:14:53.664412 Epoch [193/500], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9886 Loss3: -0.9937\n",
            "2022-06-21 21:15:01.563519 Epoch [193/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9869 Loss3: -0.9923\n",
            "Epoch: 193 MAE: 0.07128707734365311 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:15:08.835962 Epoch [194/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9879 Loss3: -0.9928\n",
            "2022-06-21 21:15:47.027478 Epoch [194/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9872 Loss3: -0.9916\n",
            "2022-06-21 21:15:54.797794 Epoch [194/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9845 Loss3: -0.9918\n",
            "Epoch: 194 MAE: 0.07211128441745011 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:16:01.330019 Epoch [195/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9843 Loss3: -0.9928\n",
            "2022-06-21 21:16:39.486355 Epoch [195/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9851 Loss3: -0.9916\n",
            "2022-06-21 21:16:47.274673 Epoch [195/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9843 Loss3: -0.9905\n",
            "Epoch: 195 MAE: 0.07331960678100585 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:16:56.050046 Epoch [196/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9867 Loss3: -0.9918\n",
            "2022-06-21 21:17:34.589335 Epoch [196/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9867 Loss3: -0.9928\n",
            "2022-06-21 21:17:42.373044 Epoch [196/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9877 Loss3: -0.9925\n",
            "Epoch: 196 MAE: 0.0720846366882324 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:17:49.078921 Epoch [197/500], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9807 Loss3: -0.9886\n",
            "2022-06-21 21:18:27.246205 Epoch [197/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9883 Loss3: -0.9925\n",
            "2022-06-21 21:18:35.006040 Epoch [197/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9867 Loss3: -0.9918\n",
            "Epoch: 197 MAE: 0.07235789808646713 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:18:41.577025 Epoch [198/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9876 Loss3: -0.9926\n",
            "2022-06-21 21:19:19.764334 Epoch [198/500], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9790 Loss3: -0.9889\n",
            "2022-06-21 21:19:27.546595 Epoch [198/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9872 Loss3: -0.9932\n",
            "Epoch: 198 MAE: 0.0723307057537099 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:19:34.751802 Epoch [199/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9836 Loss3: -0.9913\n",
            "2022-06-21 21:20:13.031592 Epoch [199/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9839 Loss3: -0.9914\n",
            "2022-06-21 21:20:20.800079 Epoch [199/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9890 Loss3: -0.9930\n",
            "Epoch: 199 MAE: 0.07360755743803801 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:20:27.449829 Epoch [200/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9869 Loss3: -0.9920\n",
            "2022-06-21 21:21:05.612942 Epoch [200/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9843 Loss3: -0.9908\n",
            "2022-06-21 21:21:13.408178 Epoch [200/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9859 Loss3: -0.9932\n",
            "Epoch: 200 MAE: 0.07229501643508834 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:21:22.701238 Epoch [201/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9868 Loss3: -0.9926\n",
            "2022-06-21 21:22:01.190000 Epoch [201/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9873 Loss3: -0.9925\n",
            "2022-06-21 21:22:09.037604 Epoch [201/500], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9817 Loss3: -0.9895\n",
            "Epoch: 201 MAE: 0.07309446980713534 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:22:15.572795 Epoch [202/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9843 Loss3: -0.9916\n",
            "2022-06-21 21:22:53.669270 Epoch [202/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9861 Loss3: -0.9924\n",
            "2022-06-21 21:23:01.442939 Epoch [202/500], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9849 Loss3: -0.9909\n",
            "Epoch: 202 MAE: 0.07490367919679676 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:23:08.018963 Epoch [203/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9877 Loss3: -0.9924\n",
            "2022-06-21 21:23:46.190663 Epoch [203/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9877 Loss3: -0.9930\n",
            "2022-06-21 21:23:53.968590 Epoch [203/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9824 Loss3: -0.9906\n",
            "Epoch: 203 MAE: 0.07292301944954685 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:24:00.607456 Epoch [204/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9842 Loss3: -0.9916\n",
            "2022-06-21 21:24:38.920900 Epoch [204/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9872 Loss3: -0.9926\n",
            "2022-06-21 21:24:46.703120 Epoch [204/500], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9834 Loss3: -0.9897\n",
            "Epoch: 204 MAE: 0.0730045991221433 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:24:53.278228 Epoch [205/500], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9884 Loss3: -0.9934\n",
            "2022-06-21 21:25:31.433619 Epoch [205/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-06-21 21:25:39.219435 Epoch [205/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9827 Loss3: -0.9910\n",
            "Epoch: 205 MAE: 0.07385143350671837 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:25:48.319436 Epoch [206/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9860 Loss3: -0.9925\n",
            "2022-06-21 21:26:26.643292 Epoch [206/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9864 Loss3: -0.9924\n",
            "2022-06-21 21:26:34.573264 Epoch [206/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9848 Loss3: -0.9913\n",
            "Epoch: 206 MAE: 0.07139098283475039 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:26:42.641234 Epoch [207/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9892 Loss3: -0.9932\n",
            "2022-06-21 21:27:20.765993 Epoch [207/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9854 Loss3: -0.9910\n",
            "2022-06-21 21:27:28.558919 Epoch [207/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9852 Loss3: -0.9917\n",
            "Epoch: 207 MAE: 0.07242624651187311 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:27:35.243477 Epoch [208/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9833 Loss3: -0.9913\n",
            "2022-06-21 21:28:13.499215 Epoch [208/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9863 Loss3: -0.9920\n",
            "2022-06-21 21:28:21.302989 Epoch [208/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9861 Loss3: -0.9929\n",
            "Epoch: 208 MAE: 0.07175126999143569 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:28:28.022193 Epoch [209/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9881 Loss3: -0.9925\n",
            "2022-06-21 21:29:06.401112 Epoch [209/500], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9875 Loss3: -0.9931\n",
            "2022-06-21 21:29:14.190278 Epoch [209/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9860 Loss3: -0.9911\n",
            "Epoch: 209 MAE: 0.07295135573735313 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:29:20.935078 Epoch [210/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9876 Loss3: -0.9927\n",
            "2022-06-21 21:29:59.122853 Epoch [210/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9851 Loss3: -0.9910\n",
            "2022-06-21 21:30:06.920548 Epoch [210/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9840 Loss3: -0.9912\n",
            "Epoch: 210 MAE: 0.07298704243210888 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:30:16.014308 Epoch [211/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9868 Loss3: -0.9915\n",
            "2022-06-21 21:30:54.235873 Epoch [211/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9854 Loss3: -0.9928\n",
            "2022-06-21 21:31:02.037895 Epoch [211/500], Step [0060/0060], Loss1: -0.9860 Loss2: -0.9796 Loss3: -0.9881\n",
            "Epoch: 211 MAE: 0.07277235873792536 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:31:09.442666 Epoch [212/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9868 Loss3: -0.9922\n",
            "2022-06-21 21:31:47.819041 Epoch [212/500], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9838 Loss3: -0.9898\n",
            "2022-06-21 21:31:55.597499 Epoch [212/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9862 Loss3: -0.9912\n",
            "Epoch: 212 MAE: 0.07260186377025783 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:32:02.284183 Epoch [213/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9837 Loss3: -0.9911\n",
            "2022-06-21 21:32:40.508351 Epoch [213/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9855 Loss3: -0.9904\n",
            "2022-06-21 21:32:48.300248 Epoch [213/500], Step [0060/0060], Loss1: -0.9921 Loss2: -0.9883 Loss3: -0.9936\n",
            "Epoch: 213 MAE: 0.07181602927112077 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:32:54.858342 Epoch [214/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9865 Loss3: -0.9911\n",
            "2022-06-21 21:33:33.162367 Epoch [214/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9857 Loss3: -0.9914\n",
            "2022-06-21 21:33:40.963470 Epoch [214/500], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9837 Loss3: -0.9896\n",
            "Epoch: 214 MAE: 0.07302651864510996 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:33:47.605584 Epoch [215/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9865 Loss3: -0.9922\n",
            "2022-06-21 21:34:25.783879 Epoch [215/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9874 Loss3: -0.9926\n",
            "2022-06-21 21:34:33.576935 Epoch [215/500], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9885 Loss3: -0.9933\n",
            "Epoch: 215 MAE: 0.0719952223540614 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:34:42.722025 Epoch [216/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9863 Loss3: -0.9926\n",
            "2022-06-21 21:35:20.952922 Epoch [216/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9879 Loss3: -0.9928\n",
            "2022-06-21 21:35:28.749904 Epoch [216/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9877 Loss3: -0.9924\n",
            "Epoch: 216 MAE: 0.07289814555455768 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:35:35.428235 Epoch [217/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9856 Loss3: -0.9913\n",
            "2022-06-21 21:36:13.994713 Epoch [217/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9829 Loss3: -0.9906\n",
            "2022-06-21 21:36:21.799856 Epoch [217/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9880 Loss3: -0.9934\n",
            "Epoch: 217 MAE: 0.0726246329211684 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:36:28.612452 Epoch [218/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9855 Loss3: -0.9915\n",
            "2022-06-21 21:37:06.826218 Epoch [218/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9854 Loss3: -0.9924\n",
            "2022-06-21 21:37:14.606668 Epoch [218/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9897 Loss3: -0.9934\n",
            "Epoch: 218 MAE: 0.07188809652177117 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:37:21.282470 Epoch [219/500], Step [0001/0060], Loss1: -0.9925 Loss2: -0.9886 Loss3: -0.9937\n",
            "2022-06-21 21:37:59.509899 Epoch [219/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9826 Loss3: -0.9909\n",
            "2022-06-21 21:38:07.425068 Epoch [219/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9837 Loss3: -0.9907\n",
            "Epoch: 219 MAE: 0.07157653011342205 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:38:14.848822 Epoch [220/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9840 Loss3: -0.9908\n",
            "2022-06-21 21:38:53.019947 Epoch [220/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9856 Loss3: -0.9925\n",
            "2022-06-21 21:39:00.789932 Epoch [220/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9841 Loss3: -0.9902\n",
            "Epoch: 220 MAE: 0.07186586773584759 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:39:09.931914 Epoch [221/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9921\n",
            "2022-06-21 21:39:48.175685 Epoch [221/500], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9834 Loss3: -0.9899\n",
            "2022-06-21 21:39:55.979775 Epoch [221/500], Step [0060/0060], Loss1: -0.9866 Loss2: -0.9805 Loss3: -0.9889\n",
            "Epoch: 221 MAE: 0.07262561883875934 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:40:02.654384 Epoch [222/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9881 Loss3: -0.9929\n",
            "2022-06-21 21:40:41.171233 Epoch [222/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-06-21 21:40:48.943042 Epoch [222/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9878 Loss3: -0.9929\n",
            "Epoch: 222 MAE: 0.07274895062522284 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:40:55.590385 Epoch [223/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9876 Loss3: -0.9925\n",
            "2022-06-21 21:41:33.872289 Epoch [223/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9846 Loss3: -0.9910\n",
            "2022-06-21 21:41:41.653730 Epoch [223/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9845 Loss3: -0.9905\n",
            "Epoch: 223 MAE: 0.07316621654248112 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:41:48.339568 Epoch [224/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9846 Loss3: -0.9907\n",
            "2022-06-21 21:42:26.455253 Epoch [224/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9840 Loss3: -0.9914\n",
            "2022-06-21 21:42:34.248503 Epoch [224/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9829 Loss3: -0.9905\n",
            "Epoch: 224 MAE: 0.07357780935903073 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:42:41.408256 Epoch [225/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9833 Loss3: -0.9909\n",
            "2022-06-21 21:43:19.673977 Epoch [225/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-21 21:43:27.461195 Epoch [225/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9826 Loss3: -0.9899\n",
            "Epoch: 225 MAE: 0.07217860398469149 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:43:36.535843 Epoch [226/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9857 Loss3: -0.9925\n",
            "2022-06-21 21:44:14.880328 Epoch [226/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9877 Loss3: -0.9929\n",
            "2022-06-21 21:44:22.684949 Epoch [226/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9871 Loss3: -0.9930\n",
            "Epoch: 226 MAE: 0.0717955897094081 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:44:29.374713 Epoch [227/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9832 Loss3: -0.9918\n",
            "2022-06-21 21:45:07.968077 Epoch [227/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9885 Loss3: -0.9925\n",
            "2022-06-21 21:45:15.812584 Epoch [227/500], Step [0060/0060], Loss1: -0.9856 Loss2: -0.9787 Loss3: -0.9878\n",
            "Epoch: 227 MAE: 0.0736790328555637 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:45:22.522739 Epoch [228/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9850 Loss3: -0.9923\n",
            "2022-06-21 21:46:00.780344 Epoch [228/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9848 Loss3: -0.9917\n",
            "2022-06-21 21:46:08.572109 Epoch [228/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9817 Loss3: -0.9907\n",
            "Epoch: 228 MAE: 0.07230712456677955 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:46:15.241849 Epoch [229/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9863 Loss3: -0.9919\n",
            "2022-06-21 21:46:53.467573 Epoch [229/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9833 Loss3: -0.9900\n",
            "2022-06-21 21:47:01.246576 Epoch [229/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9877 Loss3: -0.9928\n",
            "Epoch: 229 MAE: 0.07370642556084527 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:47:07.768930 Epoch [230/500], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9788 Loss3: -0.9887\n",
            "2022-06-21 21:47:46.201196 Epoch [230/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9888 Loss3: -0.9930\n",
            "2022-06-21 21:47:53.999217 Epoch [230/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9875 Loss3: -0.9926\n",
            "Epoch: 230 MAE: 0.07447931446095622 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:48:04.209699 Epoch [231/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9870 Loss3: -0.9918\n",
            "2022-06-21 21:48:42.500129 Epoch [231/500], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9775 Loss3: -0.9889\n",
            "2022-06-21 21:48:50.297708 Epoch [231/500], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9796 Loss3: -0.9897\n",
            "Epoch: 231 MAE: 0.07225545323084272 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:48:56.911702 Epoch [232/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9816 Loss3: -0.9897\n",
            "2022-06-21 21:49:35.269433 Epoch [232/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9860 Loss3: -0.9927\n",
            "2022-06-21 21:49:43.183753 Epoch [232/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9862 Loss3: -0.9910\n",
            "Epoch: 232 MAE: 0.07256948415564483 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:49:49.738052 Epoch [233/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9866 Loss3: -0.9915\n",
            "2022-06-21 21:50:27.979548 Epoch [233/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9855 Loss3: -0.9920\n",
            "2022-06-21 21:50:35.756954 Epoch [233/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9834 Loss3: -0.9908\n",
            "Epoch: 233 MAE: 0.07343578570734256 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:50:42.404917 Epoch [234/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9857 Loss3: -0.9924\n",
            "2022-06-21 21:51:20.593076 Epoch [234/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9847 Loss3: -0.9915\n",
            "2022-06-21 21:51:28.377742 Epoch [234/500], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9888 Loss3: -0.9933\n",
            "Epoch: 234 MAE: 0.07254716020412545 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:51:35.053043 Epoch [235/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9846 Loss3: -0.9914\n",
            "2022-06-21 21:52:13.387966 Epoch [235/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9854 Loss3: -0.9925\n",
            "2022-06-21 21:52:21.188004 Epoch [235/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9925\n",
            "Epoch: 235 MAE: 0.07100081852504184 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:52:30.296405 Epoch [236/500], Step [0001/0060], Loss1: -0.9923 Loss2: -0.9895 Loss3: -0.9936\n",
            "2022-06-21 21:53:08.657762 Epoch [236/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9849 Loss3: -0.9926\n",
            "2022-06-21 21:53:16.464806 Epoch [236/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9876 Loss3: -0.9929\n",
            "Epoch: 236 MAE: 0.07310426005610714 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:53:23.111043 Epoch [237/500], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9847 Loss3: -0.9901\n",
            "2022-06-21 21:54:01.443265 Epoch [237/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-06-21 21:54:09.519392 Epoch [237/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9866 Loss3: -0.9927\n",
            "Epoch: 237 MAE: 0.07299505753491924 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:54:16.443964 Epoch [238/500], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9825 Loss3: -0.9890\n",
            "2022-06-21 21:54:54.686771 Epoch [238/500], Step [0050/0060], Loss1: -0.9894 Loss2: -0.9816 Loss3: -0.9914\n",
            "2022-06-21 21:55:02.480129 Epoch [238/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9833 Loss3: -0.9906\n",
            "Epoch: 238 MAE: 0.0722440493548358 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:55:09.317441 Epoch [239/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9863 Loss3: -0.9914\n",
            "2022-06-21 21:55:47.522565 Epoch [239/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9826 Loss3: -0.9904\n",
            "2022-06-21 21:55:55.291718 Epoch [239/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9857 Loss3: -0.9908\n",
            "Epoch: 239 MAE: 0.07445492295361068 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:56:01.936846 Epoch [240/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9858 Loss3: -0.9923\n",
            "2022-06-21 21:56:40.248320 Epoch [240/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9827 Loss3: -0.9907\n",
            "2022-06-21 21:56:48.048223 Epoch [240/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9830 Loss3: -0.9907\n",
            "Epoch: 240 MAE: 0.07324538150161662 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:56:57.109033 Epoch [241/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9876 Loss3: -0.9926\n",
            "2022-06-21 21:57:35.299812 Epoch [241/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9806 Loss3: -0.9902\n",
            "2022-06-21 21:57:43.088921 Epoch [241/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9860 Loss3: -0.9927\n",
            "Epoch: 241 MAE: 0.07308782103200435 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:57:49.654951 Epoch [242/500], Step [0001/0060], Loss1: -0.9854 Loss2: -0.9790 Loss3: -0.9881\n",
            "2022-06-21 21:58:27.836117 Epoch [242/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9870 Loss3: -0.9933\n",
            "2022-06-21 21:58:35.595423 Epoch [242/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9866 Loss3: -0.9920\n",
            "Epoch: 242 MAE: 0.07168210357585282 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:58:43.658405 Epoch [243/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9851 Loss3: -0.9918\n",
            "2022-06-21 21:59:21.991293 Epoch [243/500], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9836 Loss3: -0.9906\n",
            "2022-06-21 21:59:29.771645 Epoch [243/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9857 Loss3: -0.9909\n",
            "Epoch: 243 MAE: 0.07358471502071966 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 21:59:36.422793 Epoch [244/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-06-21 22:00:14.629745 Epoch [244/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9849 Loss3: -0.9906\n",
            "2022-06-21 22:00:22.428944 Epoch [244/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9873 Loss3: -0.9923\n",
            "Epoch: 244 MAE: 0.07314325675762519 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:00:29.245037 Epoch [245/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9875 Loss3: -0.9923\n",
            "2022-06-21 22:01:07.629193 Epoch [245/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9846 Loss3: -0.9905\n",
            "2022-06-21 22:01:15.473697 Epoch [245/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9840 Loss3: -0.9916\n",
            "Epoch: 245 MAE: 0.07449121233016727 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:01:25.294861 Epoch [246/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-06-21 22:02:03.605627 Epoch [246/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9854 Loss3: -0.9922\n",
            "2022-06-21 22:02:11.409773 Epoch [246/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9853 Loss3: -0.9919\n",
            "Epoch: 246 MAE: 0.07207891181663229 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:02:18.187153 Epoch [247/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9829 Loss3: -0.9904\n",
            "2022-06-21 22:02:56.320710 Epoch [247/500], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9878 Loss3: -0.9935\n",
            "2022-06-21 22:03:04.096117 Epoch [247/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9850 Loss3: -0.9918\n",
            "Epoch: 247 MAE: 0.07219882188019931 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:03:10.614636 Epoch [248/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9862 Loss3: -0.9917\n",
            "2022-06-21 22:03:49.349845 Epoch [248/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9868 Loss3: -0.9921\n",
            "2022-06-21 22:03:57.165152 Epoch [248/500], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9858 Loss3: -0.9909\n",
            "Epoch: 248 MAE: 0.07254945568306737 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:04:03.903443 Epoch [249/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9866 Loss3: -0.9925\n",
            "2022-06-21 22:04:42.108224 Epoch [249/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9877 Loss3: -0.9930\n",
            "2022-06-21 22:04:49.893796 Epoch [249/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9848 Loss3: -0.9920\n",
            "Epoch: 249 MAE: 0.07420716336164528 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:04:56.561962 Epoch [250/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9870 Loss3: -0.9928\n",
            "2022-06-21 22:05:34.810410 Epoch [250/500], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9771 Loss3: -0.9873\n",
            "2022-06-21 22:05:42.699649 Epoch [250/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9837 Loss3: -0.9905\n",
            "Epoch: 250 MAE: 0.07238475567449339 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:05:52.035430 Epoch [251/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9867 Loss3: -0.9921\n",
            "2022-06-21 22:06:30.359469 Epoch [251/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9872 Loss3: -0.9931\n",
            "2022-06-21 22:06:38.195127 Epoch [251/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9856 Loss3: -0.9912\n",
            "Epoch: 251 MAE: 0.07208251519177958 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:06:45.027293 Epoch [252/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9894 Loss3: -0.9931\n",
            "2022-06-21 22:07:23.228906 Epoch [252/500], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9845 Loss3: -0.9896\n",
            "2022-06-21 22:07:31.037810 Epoch [252/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9929\n",
            "Epoch: 252 MAE: 0.07375093021090069 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:07:37.777524 Epoch [253/500], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9818 Loss3: -0.9895\n",
            "2022-06-21 22:08:16.376624 Epoch [253/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9848 Loss3: -0.9918\n",
            "2022-06-21 22:08:24.147243 Epoch [253/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9881 Loss3: -0.9929\n",
            "Epoch: 253 MAE: 0.07441762192539436 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:08:30.799406 Epoch [254/500], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9814 Loss3: -0.9889\n",
            "2022-06-21 22:09:09.035380 Epoch [254/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9858 Loss3: -0.9909\n",
            "2022-06-21 22:09:16.838386 Epoch [254/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9785 Loss3: -0.9892\n",
            "Epoch: 254 MAE: 0.07366072468025973 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:09:23.491721 Epoch [255/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9925\n",
            "2022-06-21 22:10:01.694075 Epoch [255/500], Step [0050/0060], Loss1: -0.9921 Loss2: -0.9883 Loss3: -0.9934\n",
            "2022-06-21 22:10:09.512599 Epoch [255/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9865 Loss3: -0.9920\n",
            "Epoch: 255 MAE: 0.0728516783537688 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:10:19.354195 Epoch [256/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9861 Loss3: -0.9918\n",
            "2022-06-21 22:10:57.855178 Epoch [256/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9866 Loss3: -0.9928\n",
            "2022-06-21 22:11:05.659841 Epoch [256/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9866 Loss3: -0.9922\n",
            "Epoch: 256 MAE: 0.0723291377920322 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:11:12.262182 Epoch [257/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9839 Loss3: -0.9907\n",
            "2022-06-21 22:11:50.482497 Epoch [257/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9866 Loss3: -0.9927\n",
            "2022-06-21 22:11:58.310542 Epoch [257/500], Step [0060/0060], Loss1: -0.9857 Loss2: -0.9795 Loss3: -0.9880\n",
            "Epoch: 257 MAE: 0.07361055470017529 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:12:04.916918 Epoch [258/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9883 Loss3: -0.9929\n",
            "2022-06-21 22:12:43.328832 Epoch [258/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9879 Loss3: -0.9927\n",
            "2022-06-21 22:12:51.132000 Epoch [258/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9884 Loss3: -0.9930\n",
            "Epoch: 258 MAE: 0.07352878025599888 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:12:57.862042 Epoch [259/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9821 Loss3: -0.9905\n",
            "2022-06-21 22:13:36.120488 Epoch [259/500], Step [0050/0060], Loss1: -0.9891 Loss2: -0.9857 Loss3: -0.9911\n",
            "2022-06-21 22:13:43.917377 Epoch [259/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9825 Loss3: -0.9903\n",
            "Epoch: 259 MAE: 0.07302988350076021 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:13:50.599407 Epoch [260/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9845 Loss3: -0.9918\n",
            "2022-06-21 22:14:28.757406 Epoch [260/500], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9838 Loss3: -0.9904\n",
            "2022-06-21 22:14:36.533770 Epoch [260/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9882 Loss3: -0.9931\n",
            "Epoch: 260 MAE: 0.07173942429678778 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:14:46.676359 Epoch [261/500], Step [0001/0060], Loss1: -0.9919 Loss2: -0.9884 Loss3: -0.9934\n",
            "2022-06-21 22:15:25.365281 Epoch [261/500], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9827 Loss3: -0.9895\n",
            "2022-06-21 22:15:33.146900 Epoch [261/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9881 Loss3: -0.9929\n",
            "Epoch: 261 MAE: 0.07304445781405008 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:15:39.803378 Epoch [262/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9881 Loss3: -0.9926\n",
            "2022-06-21 22:16:17.889823 Epoch [262/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9878 Loss3: -0.9920\n",
            "2022-06-21 22:16:25.696021 Epoch [262/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9856 Loss3: -0.9920\n",
            "Epoch: 262 MAE: 0.07247906361938154 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:16:32.337833 Epoch [263/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9863 Loss3: -0.9914\n",
            "2022-06-21 22:17:10.653926 Epoch [263/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9835 Loss3: -0.9908\n",
            "2022-06-21 22:17:18.427716 Epoch [263/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9878 Loss3: -0.9919\n",
            "Epoch: 263 MAE: 0.07386279994217809 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:17:25.310916 Epoch [264/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9852 Loss3: -0.9914\n",
            "2022-06-21 22:18:03.515861 Epoch [264/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9864 Loss3: -0.9926\n",
            "2022-06-21 22:18:11.312232 Epoch [264/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9868 Loss3: -0.9917\n",
            "Epoch: 264 MAE: 0.07239658189198327 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:18:17.922184 Epoch [265/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9876 Loss3: -0.9927\n",
            "2022-06-21 22:18:56.155777 Epoch [265/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9870 Loss3: -0.9929\n",
            "2022-06-21 22:19:03.918893 Epoch [265/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9845 Loss3: -0.9906\n",
            "Epoch: 265 MAE: 0.07227729403783402 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:19:13.037855 Epoch [266/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9864 Loss3: -0.9923\n",
            "2022-06-21 22:19:51.795622 Epoch [266/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9871 Loss3: -0.9929\n",
            "2022-06-21 22:19:59.585366 Epoch [266/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9863 Loss3: -0.9925\n",
            "Epoch: 266 MAE: 0.07150172056975189 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:20:06.211520 Epoch [267/500], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9831 Loss3: -0.9896\n",
            "2022-06-21 22:20:44.397566 Epoch [267/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9880 Loss3: -0.9928\n",
            "2022-06-21 22:20:52.212004 Epoch [267/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9862 Loss3: -0.9923\n",
            "Epoch: 267 MAE: 0.07101291333556804 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:20:58.913475 Epoch [268/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9845 Loss3: -0.9912\n",
            "2022-06-21 22:21:37.167360 Epoch [268/500], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9808 Loss3: -0.9896\n",
            "2022-06-21 22:21:45.010183 Epoch [268/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9880 Loss3: -0.9929\n",
            "Epoch: 268 MAE: 0.07275451554192437 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:21:51.655902 Epoch [269/500], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9824 Loss3: -0.9888\n",
            "2022-06-21 22:22:29.797097 Epoch [269/500], Step [0050/0060], Loss1: -0.9882 Loss2: -0.9841 Loss3: -0.9903\n",
            "2022-06-21 22:22:37.603809 Epoch [269/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9873 Loss3: -0.9932\n",
            "Epoch: 269 MAE: 0.07271810662809501 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:22:44.261429 Epoch [270/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9890 Loss3: -0.9932\n",
            "2022-06-21 22:23:22.391782 Epoch [270/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9848 Loss3: -0.9917\n",
            "2022-06-21 22:23:30.173382 Epoch [270/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9812 Loss3: -0.9890\n",
            "Epoch: 270 MAE: 0.07307463857862684 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:23:39.227810 Epoch [271/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9853 Loss3: -0.9919\n",
            "2022-06-21 22:24:17.884894 Epoch [271/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9820 Loss3: -0.9902\n",
            "2022-06-21 22:24:25.680519 Epoch [271/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9875 Loss3: -0.9924\n",
            "Epoch: 271 MAE: 0.07319179242250148 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:24:32.326171 Epoch [272/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9854 Loss3: -0.9919\n",
            "2022-06-21 22:25:10.521017 Epoch [272/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9886 Loss3: -0.9929\n",
            "2022-06-21 22:25:18.310176 Epoch [272/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9843 Loss3: -0.9908\n",
            "Epoch: 272 MAE: 0.07361065163183464 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:25:25.021718 Epoch [273/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9844 Loss3: -0.9906\n",
            "2022-06-21 22:26:03.252094 Epoch [273/500], Step [0050/0060], Loss1: -0.9877 Loss2: -0.9814 Loss3: -0.9900\n",
            "2022-06-21 22:26:11.132926 Epoch [273/500], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9831 Loss3: -0.9903\n",
            "Epoch: 273 MAE: 0.07372518599979462 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:26:18.589761 Epoch [274/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9855 Loss3: -0.9922\n",
            "2022-06-21 22:26:56.812475 Epoch [274/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9866 Loss3: -0.9929\n",
            "2022-06-21 22:27:04.620192 Epoch [274/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9883 Loss3: -0.9931\n",
            "Epoch: 274 MAE: 0.07278286560502631 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:27:11.428158 Epoch [275/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9837 Loss3: -0.9912\n",
            "2022-06-21 22:27:49.723081 Epoch [275/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9812 Loss3: -0.9907\n",
            "2022-06-21 22:27:57.548857 Epoch [275/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9827 Loss3: -0.9904\n",
            "Epoch: 275 MAE: 0.07417768821514474 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:28:06.544591 Epoch [276/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9857 Loss3: -0.9925\n",
            "2022-06-21 22:28:45.208643 Epoch [276/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9817 Loss3: -0.9902\n",
            "2022-06-21 22:28:53.019122 Epoch [276/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9870 Loss3: -0.9928\n",
            "Epoch: 276 MAE: 0.07214001680808091 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:28:59.662321 Epoch [277/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9870 Loss3: -0.9925\n",
            "2022-06-21 22:29:37.858633 Epoch [277/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9882 Loss3: -0.9927\n",
            "2022-06-21 22:29:45.668754 Epoch [277/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9822 Loss3: -0.9905\n",
            "Epoch: 277 MAE: 0.07306986798685065 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:29:52.362796 Epoch [278/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9845 Loss3: -0.9916\n",
            "2022-06-21 22:30:30.645145 Epoch [278/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9864 Loss3: -0.9924\n",
            "2022-06-21 22:30:38.428248 Epoch [278/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9855 Loss3: -0.9918\n",
            "Epoch: 278 MAE: 0.07424492992421307 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:30:45.614758 Epoch [279/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9838 Loss3: -0.9922\n",
            "2022-06-21 22:31:23.826323 Epoch [279/500], Step [0050/0060], Loss1: -0.9874 Loss2: -0.9826 Loss3: -0.9903\n",
            "2022-06-21 22:31:31.619732 Epoch [279/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9837 Loss3: -0.9914\n",
            "Epoch: 279 MAE: 0.07210162112321804 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:31:38.225212 Epoch [280/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9850 Loss3: -0.9912\n",
            "2022-06-21 22:32:16.463668 Epoch [280/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9824 Loss3: -0.9913\n",
            "2022-06-21 22:32:24.253318 Epoch [280/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9865 Loss3: -0.9929\n",
            "Epoch: 280 MAE: 0.07124867035598356 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:32:33.467188 Epoch [281/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9867 Loss3: -0.9930\n",
            "2022-06-21 22:33:12.100395 Epoch [281/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9851 Loss3: -0.9921\n",
            "2022-06-21 22:33:19.928323 Epoch [281/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9820 Loss3: -0.9900\n",
            "Epoch: 281 MAE: 0.07319134520475197 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:33:26.523968 Epoch [282/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-06-21 22:34:04.630551 Epoch [282/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9870 Loss3: -0.9919\n",
            "2022-06-21 22:34:12.423042 Epoch [282/500], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9848 Loss3: -0.9912\n",
            "Epoch: 282 MAE: 0.07276849610464912 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:34:19.031150 Epoch [283/500], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9822 Loss3: -0.9902\n",
            "2022-06-21 22:34:57.153494 Epoch [283/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9865 Loss3: -0.9927\n",
            "2022-06-21 22:35:04.927912 Epoch [283/500], Step [0060/0060], Loss1: -0.9840 Loss2: -0.9784 Loss3: -0.9871\n",
            "Epoch: 283 MAE: 0.07195989628948234 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:35:11.598903 Epoch [284/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9871 Loss3: -0.9929\n",
            "2022-06-21 22:35:49.943474 Epoch [284/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9854 Loss3: -0.9920\n",
            "2022-06-21 22:35:57.737736 Epoch [284/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9838 Loss3: -0.9910\n",
            "Epoch: 284 MAE: 0.07262116891366462 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:36:04.396628 Epoch [285/500], Step [0001/0060], Loss1: -0.9890 Loss2: -0.9859 Loss3: -0.9911\n",
            "2022-06-21 22:36:42.484688 Epoch [285/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9868 Loss3: -0.9920\n",
            "2022-06-21 22:36:50.264965 Epoch [285/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9853 Loss3: -0.9916\n",
            "Epoch: 285 MAE: 0.07292321861105627 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:36:59.634714 Epoch [286/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9884 Loss3: -0.9927\n",
            "2022-06-21 22:37:38.181814 Epoch [286/500], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9816 Loss3: -0.9895\n",
            "2022-06-21 22:37:46.155023 Epoch [286/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9826 Loss3: -0.9903\n",
            "Epoch: 286 MAE: 0.07272687518407427 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:37:52.765972 Epoch [287/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-21 22:38:30.955270 Epoch [287/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9836 Loss3: -0.9910\n",
            "2022-06-21 22:38:38.761007 Epoch [287/500], Step [0060/0060], Loss1: -0.9859 Loss2: -0.9799 Loss3: -0.9885\n",
            "Epoch: 287 MAE: 0.07335194860185892 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:38:45.384238 Epoch [288/500], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9831 Loss3: -0.9900\n",
            "2022-06-21 22:39:23.534866 Epoch [288/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9857 Loss3: -0.9918\n",
            "2022-06-21 22:39:31.325101 Epoch [288/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9876 Loss3: -0.9931\n",
            "Epoch: 288 MAE: 0.0737484356209084 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:39:37.846186 Epoch [289/500], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9886 Loss3: -0.9931\n",
            "2022-06-21 22:40:16.131378 Epoch [289/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9835 Loss3: -0.9908\n",
            "2022-06-21 22:40:23.924348 Epoch [289/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9882 Loss3: -0.9926\n",
            "Epoch: 289 MAE: 0.07279572073113981 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:40:30.524580 Epoch [290/500], Step [0001/0060], Loss1: -0.9835 Loss2: -0.9752 Loss3: -0.9867\n",
            "2022-06-21 22:41:08.651171 Epoch [290/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9874 Loss3: -0.9928\n",
            "2022-06-21 22:41:16.446321 Epoch [290/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9850 Loss3: -0.9919\n",
            "Epoch: 290 MAE: 0.0726522449715428 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:41:25.629762 Epoch [291/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9823 Loss3: -0.9900\n",
            "2022-06-21 22:42:04.055630 Epoch [291/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9886 Loss3: -0.9927\n",
            "2022-06-21 22:42:12.101635 Epoch [291/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9875 Loss3: -0.9929\n",
            "Epoch: 291 MAE: 0.07246905579138052 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:42:19.457649 Epoch [292/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9818 Loss3: -0.9912\n",
            "2022-06-21 22:42:57.607721 Epoch [292/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9884 Loss3: -0.9934\n",
            "2022-06-21 22:43:05.393583 Epoch [292/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9860 Loss3: -0.9922\n",
            "Epoch: 292 MAE: 0.0724691156861643 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:43:12.034212 Epoch [293/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9870 Loss3: -0.9917\n",
            "2022-06-21 22:43:50.256545 Epoch [293/500], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9886 Loss3: -0.9934\n",
            "2022-06-21 22:43:58.055063 Epoch [293/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9864 Loss3: -0.9924\n",
            "Epoch: 293 MAE: 0.07213112982492596 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:44:04.696828 Epoch [294/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9872 Loss3: -0.9928\n",
            "2022-06-21 22:44:43.113097 Epoch [294/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9859 Loss3: -0.9928\n",
            "2022-06-21 22:44:50.913163 Epoch [294/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9859 Loss3: -0.9914\n",
            "Epoch: 294 MAE: 0.07268582354146969 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:44:57.717000 Epoch [295/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-21 22:45:35.940403 Epoch [295/500], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9796 Loss3: -0.9880\n",
            "2022-06-21 22:45:43.728872 Epoch [295/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9883 Loss3: -0.9930\n",
            "Epoch: 295 MAE: 0.07343894852532282 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:45:53.319884 Epoch [296/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9826 Loss3: -0.9907\n",
            "2022-06-21 22:46:31.502978 Epoch [296/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9875 Loss3: -0.9933\n",
            "2022-06-21 22:46:39.303950 Epoch [296/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9867 Loss3: -0.9931\n",
            "Epoch: 296 MAE: 0.07311586213490319 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:46:47.658895 Epoch [297/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9846 Loss3: -0.9920\n",
            "2022-06-21 22:47:26.060093 Epoch [297/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9875 Loss3: -0.9923\n",
            "2022-06-21 22:47:33.839475 Epoch [297/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9847 Loss3: -0.9921\n",
            "Epoch: 297 MAE: 0.0735467623150538 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:47:40.463887 Epoch [298/500], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9844 Loss3: -0.9899\n",
            "2022-06-21 22:48:18.670639 Epoch [298/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9871 Loss3: -0.9926\n",
            "2022-06-21 22:48:26.465003 Epoch [298/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9884 Loss3: -0.9931\n",
            "Epoch: 298 MAE: 0.07247178027238795 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:48:33.090689 Epoch [299/500], Step [0001/0060], Loss1: -0.9855 Loss2: -0.9806 Loss3: -0.9882\n",
            "2022-06-21 22:49:11.296052 Epoch [299/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9862 Loss3: -0.9919\n",
            "2022-06-21 22:49:19.076923 Epoch [299/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9892 Loss3: -0.9932\n",
            "Epoch: 299 MAE: 0.0711578938822267 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:49:25.791708 Epoch [300/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9846 Loss3: -0.9911\n",
            "2022-06-21 22:50:04.047726 Epoch [300/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9926\n",
            "2022-06-21 22:50:11.836986 Epoch [300/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9833 Loss3: -0.9906\n",
            "Epoch: 300 MAE: 0.0735090655876846 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:50:20.712500 Epoch [301/500], Step [0001/0060], Loss1: -0.9871 Loss2: -0.9824 Loss3: -0.9892\n",
            "2022-06-21 22:50:58.892080 Epoch [301/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9842 Loss3: -0.9911\n",
            "2022-06-21 22:51:06.689109 Epoch [301/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9863 Loss3: -0.9918\n",
            "Epoch: 301 MAE: 0.0718941645142893 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:51:13.860262 Epoch [302/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9875 Loss3: -0.9929\n",
            "2022-06-21 22:51:52.254285 Epoch [302/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9838 Loss3: -0.9909\n",
            "2022-06-21 22:52:00.025627 Epoch [302/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9813 Loss3: -0.9900\n",
            "Epoch: 302 MAE: 0.07363384892700842 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:52:06.660338 Epoch [303/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9843 Loss3: -0.9915\n",
            "2022-06-21 22:52:44.807361 Epoch [303/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9883 Loss3: -0.9927\n",
            "2022-06-21 22:52:52.597163 Epoch [303/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9856 Loss3: -0.9914\n",
            "Epoch: 303 MAE: 0.07449532412978077 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:52:59.325314 Epoch [304/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9820 Loss3: -0.9905\n",
            "2022-06-21 22:53:37.778457 Epoch [304/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9817 Loss3: -0.9902\n",
            "2022-06-21 22:53:45.584986 Epoch [304/500], Step [0060/0060], Loss1: -0.9870 Loss2: -0.9795 Loss3: -0.9894\n",
            "Epoch: 304 MAE: 0.07446231382864493 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:53:52.093158 Epoch [305/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9867 Loss3: -0.9931\n",
            "2022-06-21 22:54:30.363349 Epoch [305/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9819 Loss3: -0.9905\n",
            "2022-06-21 22:54:38.145263 Epoch [305/500], Step [0060/0060], Loss1: -0.9863 Loss2: -0.9795 Loss3: -0.9886\n",
            "Epoch: 305 MAE: 0.07372053161499993 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:54:48.401251 Epoch [306/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9835 Loss3: -0.9910\n",
            "2022-06-21 22:55:26.623693 Epoch [306/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9860 Loss3: -0.9924\n",
            "2022-06-21 22:55:34.406088 Epoch [306/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9843 Loss3: -0.9914\n",
            "Epoch: 306 MAE: 0.07213985221095814 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:55:41.196342 Epoch [307/500], Step [0001/0060], Loss1: -0.9861 Loss2: -0.9800 Loss3: -0.9887\n",
            "2022-06-21 22:56:19.744332 Epoch [307/500], Step [0050/0060], Loss1: -0.9922 Loss2: -0.9896 Loss3: -0.9937\n",
            "2022-06-21 22:56:27.537280 Epoch [307/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9880 Loss3: -0.9924\n",
            "Epoch: 307 MAE: 0.07286260075039332 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:56:34.233559 Epoch [308/500], Step [0001/0060], Loss1: -0.9859 Loss2: -0.9788 Loss3: -0.9891\n",
            "2022-06-21 22:57:12.402389 Epoch [308/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9883 Loss3: -0.9932\n",
            "2022-06-21 22:57:20.190084 Epoch [308/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9854 Loss3: -0.9912\n",
            "Epoch: 308 MAE: 0.07443961436155613 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:57:26.846465 Epoch [309/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9824 Loss3: -0.9899\n",
            "2022-06-21 22:58:05.092149 Epoch [309/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9881 Loss3: -0.9928\n",
            "2022-06-21 22:58:12.912077 Epoch [309/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9848 Loss3: -0.9902\n",
            "Epoch: 309 MAE: 0.07318865372390344 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:58:19.427332 Epoch [310/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9888 Loss3: -0.9927\n",
            "2022-06-21 22:58:57.656403 Epoch [310/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9879 Loss3: -0.9924\n",
            "2022-06-21 22:59:05.438730 Epoch [310/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9840 Loss3: -0.9908\n",
            "Epoch: 310 MAE: 0.07348928330436587 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 22:59:14.435012 Epoch [311/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9857 Loss3: -0.9921\n",
            "2022-06-21 22:59:52.601337 Epoch [311/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9862 Loss3: -0.9923\n",
            "2022-06-21 23:00:00.387825 Epoch [311/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9883 Loss3: -0.9935\n",
            "Epoch: 311 MAE: 0.07160400340166041 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:00:07.063352 Epoch [312/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9870 Loss3: -0.9925\n",
            "2022-06-21 23:00:45.631206 Epoch [312/500], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9876 Loss3: -0.9936\n",
            "2022-06-21 23:00:53.413483 Epoch [312/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9834 Loss3: -0.9908\n",
            "Epoch: 312 MAE: 0.07301450406432783 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:01:00.126571 Epoch [313/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9854 Loss3: -0.9930\n",
            "2022-06-21 23:01:38.376230 Epoch [313/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9866 Loss3: -0.9922\n",
            "2022-06-21 23:01:46.170607 Epoch [313/500], Step [0060/0060], Loss1: -0.9872 Loss2: -0.9812 Loss3: -0.9893\n",
            "Epoch: 313 MAE: 0.0721439555839256 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:01:52.760140 Epoch [314/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9856 Loss3: -0.9915\n",
            "2022-06-21 23:02:30.947210 Epoch [314/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9830 Loss3: -0.9907\n",
            "2022-06-21 23:02:38.826743 Epoch [314/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9846 Loss3: -0.9918\n",
            "Epoch: 314 MAE: 0.07150300444749294 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:02:45.661044 Epoch [315/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9874 Loss3: -0.9926\n",
            "2022-06-21 23:03:23.838997 Epoch [315/500], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9804 Loss3: -0.9890\n",
            "2022-06-21 23:03:31.607998 Epoch [315/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9923\n",
            "Epoch: 315 MAE: 0.0734746890597873 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:03:40.581002 Epoch [316/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-21 23:04:18.819030 Epoch [316/500], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9813 Loss3: -0.9897\n",
            "2022-06-21 23:04:26.612355 Epoch [316/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9885 Loss3: -0.9929\n",
            "Epoch: 316 MAE: 0.07267019559466648 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:04:33.214581 Epoch [317/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-06-21 23:05:11.868530 Epoch [317/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9823 Loss3: -0.9921\n",
            "2022-06-21 23:05:19.656764 Epoch [317/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9844 Loss3: -0.9910\n",
            "Epoch: 317 MAE: 0.07284114338102796 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:05:26.494327 Epoch [318/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9875 Loss3: -0.9927\n",
            "2022-06-21 23:06:04.664867 Epoch [318/500], Step [0050/0060], Loss1: -0.9858 Loss2: -0.9805 Loss3: -0.9879\n",
            "2022-06-21 23:06:12.452807 Epoch [318/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9863 Loss3: -0.9920\n",
            "Epoch: 318 MAE: 0.0707520111528023 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:06:19.104282 Epoch [319/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9847 Loss3: -0.9925\n",
            "2022-06-21 23:06:57.300636 Epoch [319/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9836 Loss3: -0.9910\n",
            "2022-06-21 23:07:05.076318 Epoch [319/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9826 Loss3: -0.9904\n",
            "Epoch: 319 MAE: 0.07170536606400102 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:07:12.551009 Epoch [320/500], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9883 Loss3: -0.9934\n",
            "2022-06-21 23:07:50.781743 Epoch [320/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9890 Loss3: -0.9928\n",
            "2022-06-21 23:07:58.582439 Epoch [320/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9862 Loss3: -0.9925\n",
            "Epoch: 320 MAE: 0.07303503793383402 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:08:07.653181 Epoch [321/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9840 Loss3: -0.9917\n",
            "2022-06-21 23:08:45.858559 Epoch [321/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9884 Loss3: -0.9929\n",
            "2022-06-21 23:08:53.635423 Epoch [321/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9876 Loss3: -0.9927\n",
            "Epoch: 321 MAE: 0.07313530260923677 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:09:00.275408 Epoch [322/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-06-21 23:09:38.861195 Epoch [322/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9883 Loss3: -0.9922\n",
            "2022-06-21 23:09:46.642690 Epoch [322/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9851 Loss3: -0.9905\n",
            "Epoch: 322 MAE: 0.07337872474912613 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:09:53.138950 Epoch [323/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9859 Loss3: -0.9915\n",
            "2022-06-21 23:10:31.308723 Epoch [323/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9870 Loss3: -0.9916\n",
            "2022-06-21 23:10:39.115390 Epoch [323/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9887 Loss3: -0.9928\n",
            "Epoch: 323 MAE: 0.07380453876717381 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:10:45.882949 Epoch [324/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9874 Loss3: -0.9927\n",
            "2022-06-21 23:11:24.072789 Epoch [324/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9860 Loss3: -0.9913\n",
            "2022-06-21 23:11:31.838560 Epoch [324/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9890 Loss3: -0.9933\n",
            "Epoch: 324 MAE: 0.07135298269766348 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:11:38.480253 Epoch [325/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9855 Loss3: -0.9911\n",
            "2022-06-21 23:12:16.903462 Epoch [325/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9852 Loss3: -0.9914\n",
            "2022-06-21 23:12:24.684125 Epoch [325/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9862 Loss3: -0.9927\n",
            "Epoch: 325 MAE: 0.07213723626717056 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:12:34.266914 Epoch [326/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9873 Loss3: -0.9927\n",
            "2022-06-21 23:13:12.456446 Epoch [326/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9927\n",
            "2022-06-21 23:13:20.231413 Epoch [326/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9848 Loss3: -0.9921\n",
            "Epoch: 326 MAE: 0.07256001220178351 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:13:26.846233 Epoch [327/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9889 Loss3: -0.9930\n",
            "2022-06-21 23:14:05.229851 Epoch [327/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9865 Loss3: -0.9926\n",
            "2022-06-21 23:14:13.093145 Epoch [327/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9853 Loss3: -0.9906\n",
            "Epoch: 327 MAE: 0.07205245865715876 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:14:19.820160 Epoch [328/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9886 Loss3: -0.9933\n",
            "2022-06-21 23:14:58.009790 Epoch [328/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9828 Loss3: -0.9917\n",
            "2022-06-21 23:15:05.802712 Epoch [328/500], Step [0060/0060], Loss1: -0.9895 Loss2: -0.9840 Loss3: -0.9913\n",
            "Epoch: 328 MAE: 0.07257487554398796 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:15:12.515244 Epoch [329/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9854 Loss3: -0.9912\n",
            "2022-06-21 23:15:50.696320 Epoch [329/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9860 Loss3: -0.9918\n",
            "2022-06-21 23:15:58.484191 Epoch [329/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9918\n",
            "Epoch: 329 MAE: 0.07371661922919057 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:16:05.122249 Epoch [330/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9885 Loss3: -0.9921\n",
            "2022-06-21 23:16:43.506122 Epoch [330/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9885 Loss3: -0.9926\n",
            "2022-06-21 23:16:51.310286 Epoch [330/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9866 Loss3: -0.9921\n",
            "Epoch: 330 MAE: 0.07333283020705772 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:17:01.524084 Epoch [331/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9827 Loss3: -0.9897\n",
            "2022-06-21 23:17:39.868724 Epoch [331/500], Step [0050/0060], Loss1: -0.9873 Loss2: -0.9822 Loss3: -0.9894\n",
            "2022-06-21 23:17:47.671110 Epoch [331/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9860 Loss3: -0.9914\n",
            "Epoch: 331 MAE: 0.07205046951455416 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:17:54.418690 Epoch [332/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9848 Loss3: -0.9920\n",
            "2022-06-21 23:18:32.580847 Epoch [332/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9877 Loss3: -0.9930\n",
            "2022-06-21 23:18:40.626242 Epoch [332/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9870 Loss3: -0.9926\n",
            "Epoch: 332 MAE: 0.07128556327214318 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:18:48.448712 Epoch [333/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9864 Loss3: -0.9927\n",
            "2022-06-21 23:19:26.694369 Epoch [333/500], Step [0050/0060], Loss1: -0.9852 Loss2: -0.9787 Loss3: -0.9881\n",
            "2022-06-21 23:19:34.488502 Epoch [333/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9851 Loss3: -0.9905\n",
            "Epoch: 333 MAE: 0.07225920525808185 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:19:41.250231 Epoch [334/500], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9892 Loss3: -0.9931\n",
            "2022-06-21 23:20:19.488322 Epoch [334/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9867 Loss3: -0.9918\n",
            "2022-06-21 23:20:27.281018 Epoch [334/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9860 Loss3: -0.9932\n",
            "Epoch: 334 MAE: 0.07275001248354637 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:20:34.033603 Epoch [335/500], Step [0001/0060], Loss1: -0.9857 Loss2: -0.9814 Loss3: -0.9881\n",
            "2022-06-21 23:21:12.468219 Epoch [335/500], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9819 Loss3: -0.9894\n",
            "2022-06-21 23:21:20.275641 Epoch [335/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9872 Loss3: -0.9919\n",
            "Epoch: 335 MAE: 0.07272507198273188 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:21:29.739034 Epoch [336/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9857 Loss3: -0.9919\n",
            "2022-06-21 23:22:08.005412 Epoch [336/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9868 Loss3: -0.9926\n",
            "2022-06-21 23:22:15.804981 Epoch [336/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9880 Loss3: -0.9931\n",
            "Epoch: 336 MAE: 0.07362311196705654 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:22:22.526981 Epoch [337/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9847 Loss3: -0.9914\n",
            "2022-06-21 23:23:00.675721 Epoch [337/500], Step [0050/0060], Loss1: -0.9846 Loss2: -0.9773 Loss3: -0.9873\n",
            "2022-06-21 23:23:08.497797 Epoch [337/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9820 Loss3: -0.9901\n",
            "Epoch: 337 MAE: 0.07401854570580539 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:23:16.721477 Epoch [338/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9851 Loss3: -0.9918\n",
            "2022-06-21 23:23:55.068528 Epoch [338/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9862 Loss3: -0.9916\n",
            "2022-06-21 23:24:02.864853 Epoch [338/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9856 Loss3: -0.9923\n",
            "Epoch: 338 MAE: 0.07322121307332681 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:24:09.680062 Epoch [339/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9877 Loss3: -0.9918\n",
            "2022-06-21 23:24:47.923401 Epoch [339/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9847 Loss3: -0.9911\n",
            "2022-06-21 23:24:55.689991 Epoch [339/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9881 Loss3: -0.9931\n",
            "Epoch: 339 MAE: 0.07298102797654571 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:25:02.347029 Epoch [340/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9855 Loss3: -0.9914\n",
            "2022-06-21 23:25:40.723174 Epoch [340/500], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9819 Loss3: -0.9893\n",
            "2022-06-21 23:25:48.521450 Epoch [340/500], Step [0060/0060], Loss1: -0.9877 Loss2: -0.9800 Loss3: -0.9897\n",
            "Epoch: 340 MAE: 0.07298930410354855 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:25:57.674828 Epoch [341/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9843 Loss3: -0.9903\n",
            "2022-06-21 23:26:35.891557 Epoch [341/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9853 Loss3: -0.9913\n",
            "2022-06-21 23:26:43.682852 Epoch [341/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9864 Loss3: -0.9919\n",
            "Epoch: 341 MAE: 0.07343096874378348 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:26:50.324384 Epoch [342/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9872 Loss3: -0.9930\n",
            "2022-06-21 23:27:28.465828 Epoch [342/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9874 Loss3: -0.9929\n",
            "2022-06-21 23:27:36.251063 Epoch [342/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9871 Loss3: -0.9922\n",
            "Epoch: 342 MAE: 0.07328383930145745 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:27:44.120051 Epoch [343/500], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9837 Loss3: -0.9902\n",
            "2022-06-21 23:28:22.550392 Epoch [343/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9820 Loss3: -0.9900\n",
            "2022-06-21 23:28:30.332838 Epoch [343/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9866 Loss3: -0.9923\n",
            "Epoch: 343 MAE: 0.07290439625896473 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:28:36.997596 Epoch [344/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9881 Loss3: -0.9933\n",
            "2022-06-21 23:29:15.164790 Epoch [344/500], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9873 Loss3: -0.9932\n",
            "2022-06-21 23:29:22.937569 Epoch [344/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9875 Loss3: -0.9927\n",
            "Epoch: 344 MAE: 0.07267540300964678 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:29:29.695334 Epoch [345/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9822 Loss3: -0.9903\n",
            "2022-06-21 23:30:07.985180 Epoch [345/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9874 Loss3: -0.9927\n",
            "2022-06-21 23:30:15.815549 Epoch [345/500], Step [0060/0060], Loss1: -0.9874 Loss2: -0.9829 Loss3: -0.9904\n",
            "Epoch: 345 MAE: 0.07206905733340632 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:30:24.755294 Epoch [346/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-06-21 23:31:02.978514 Epoch [346/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9869 Loss3: -0.9923\n",
            "2022-06-21 23:31:10.765914 Epoch [346/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9869 Loss3: -0.9920\n",
            "Epoch: 346 MAE: 0.07226425892461545 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:31:17.538802 Epoch [347/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9883 Loss3: -0.9929\n",
            "2022-06-21 23:31:55.711065 Epoch [347/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-06-21 23:32:03.506619 Epoch [347/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9852 Loss3: -0.9912\n",
            "Epoch: 347 MAE: 0.07245870549842792 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:32:10.054046 Epoch [348/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9867 Loss3: -0.9922\n",
            "2022-06-21 23:32:48.572078 Epoch [348/500], Step [0050/0060], Loss1: -0.9889 Loss2: -0.9849 Loss3: -0.9909\n",
            "2022-06-21 23:32:56.346828 Epoch [348/500], Step [0060/0060], Loss1: -0.9891 Loss2: -0.9850 Loss3: -0.9911\n",
            "Epoch: 348 MAE: 0.07286555845270716 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:33:02.937240 Epoch [349/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9829 Loss3: -0.9914\n",
            "2022-06-21 23:33:41.094123 Epoch [349/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9834 Loss3: -0.9908\n",
            "2022-06-21 23:33:48.875251 Epoch [349/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9860 Loss3: -0.9927\n",
            "Epoch: 349 MAE: 0.07237960361299059 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:33:55.468585 Epoch [350/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9874 Loss3: -0.9930\n",
            "2022-06-21 23:34:33.746678 Epoch [350/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9852 Loss3: -0.9917\n",
            "2022-06-21 23:34:41.636815 Epoch [350/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9870 Loss3: -0.9928\n",
            "Epoch: 350 MAE: 0.07331887512610703 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:34:51.128186 Epoch [351/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9865 Loss3: -0.9918\n",
            "2022-06-21 23:35:29.401544 Epoch [351/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-06-21 23:35:37.179111 Epoch [351/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9871 Loss3: -0.9930\n",
            "Epoch: 351 MAE: 0.07179401316970745 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:35:43.785267 Epoch [352/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9875 Loss3: -0.9928\n",
            "2022-06-21 23:36:21.929766 Epoch [352/500], Step [0050/0060], Loss1: -0.9867 Loss2: -0.9806 Loss3: -0.9891\n",
            "2022-06-21 23:36:29.695560 Epoch [352/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9878 Loss3: -0.9927\n",
            "Epoch: 352 MAE: 0.07219915173041126 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:36:36.267146 Epoch [353/500], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9818 Loss3: -0.9899\n",
            "2022-06-21 23:37:14.751129 Epoch [353/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9855 Loss3: -0.9915\n",
            "2022-06-21 23:37:22.522655 Epoch [353/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9842 Loss3: -0.9916\n",
            "Epoch: 353 MAE: 0.07295439795842248 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:37:29.186580 Epoch [354/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9871 Loss3: -0.9916\n",
            "2022-06-21 23:38:07.320478 Epoch [354/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9845 Loss3: -0.9908\n",
            "2022-06-21 23:38:15.101520 Epoch [354/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9849 Loss3: -0.9921\n",
            "Epoch: 354 MAE: 0.07185891272529725 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:38:21.855044 Epoch [355/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9800 Loss3: -0.9909\n",
            "2022-06-21 23:38:59.982715 Epoch [355/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9852 Loss3: -0.9918\n",
            "2022-06-21 23:39:07.831455 Epoch [355/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9867 Loss3: -0.9919\n",
            "Epoch: 355 MAE: 0.07353651405011537 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:39:17.594788 Epoch [356/500], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9875 Loss3: -0.9931\n",
            "2022-06-21 23:39:55.786816 Epoch [356/500], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9812 Loss3: -0.9896\n",
            "2022-06-21 23:40:03.569793 Epoch [356/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9840 Loss3: -0.9903\n",
            "Epoch: 356 MAE: 0.07394813850443199 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:40:10.205007 Epoch [357/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9866 Loss3: -0.9924\n",
            "2022-06-21 23:40:48.281839 Epoch [357/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9806 Loss3: -0.9905\n",
            "2022-06-21 23:40:56.059530 Epoch [357/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9870 Loss3: -0.9915\n",
            "Epoch: 357 MAE: 0.07273258441339725 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:41:02.641802 Epoch [358/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9873 Loss3: -0.9928\n",
            "2022-06-21 23:41:41.277647 Epoch [358/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9852 Loss3: -0.9920\n",
            "2022-06-21 23:41:49.054583 Epoch [358/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9842 Loss3: -0.9913\n",
            "Epoch: 358 MAE: 0.07227088393357695 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:41:55.679390 Epoch [359/500], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9830 Loss3: -0.9904\n",
            "2022-06-21 23:42:33.826575 Epoch [359/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9852 Loss3: -0.9916\n",
            "2022-06-21 23:42:41.599366 Epoch [359/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9849 Loss3: -0.9909\n",
            "Epoch: 359 MAE: 0.07273358829437737 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:42:48.261438 Epoch [360/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9866 Loss3: -0.9922\n",
            "2022-06-21 23:43:26.417809 Epoch [360/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9854 Loss3: -0.9921\n",
            "2022-06-21 23:43:34.180414 Epoch [360/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9869 Loss3: -0.9920\n",
            "Epoch: 360 MAE: 0.07374934938218856 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:43:43.683886 Epoch [361/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-06-21 23:44:22.261707 Epoch [361/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9867 Loss3: -0.9918\n",
            "2022-06-21 23:44:30.054510 Epoch [361/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9850 Loss3: -0.9905\n",
            "Epoch: 361 MAE: 0.0723213460205724 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:44:36.676508 Epoch [362/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9861 Loss3: -0.9916\n",
            "2022-06-21 23:45:14.820645 Epoch [362/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9823 Loss3: -0.9904\n",
            "2022-06-21 23:45:22.603296 Epoch [362/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9885 Loss3: -0.9930\n",
            "Epoch: 362 MAE: 0.07312835582349668 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:45:29.213243 Epoch [363/500], Step [0001/0060], Loss1: -0.9868 Loss2: -0.9819 Loss3: -0.9890\n",
            "2022-06-21 23:46:07.500915 Epoch [363/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9881 Loss3: -0.9920\n",
            "2022-06-21 23:46:15.353124 Epoch [363/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9841 Loss3: -0.9924\n",
            "Epoch: 363 MAE: 0.07319971230925708 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:46:22.112995 Epoch [364/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9860 Loss3: -0.9912\n",
            "2022-06-21 23:47:00.500265 Epoch [364/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9871 Loss3: -0.9934\n",
            "2022-06-21 23:47:08.344560 Epoch [364/500], Step [0060/0060], Loss1: -0.9920 Loss2: -0.9888 Loss3: -0.9934\n",
            "Epoch: 364 MAE: 0.07147923030550518 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:47:15.416550 Epoch [365/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9881 Loss3: -0.9925\n",
            "2022-06-21 23:47:54.027966 Epoch [365/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9865 Loss3: -0.9926\n",
            "2022-06-21 23:48:01.876945 Epoch [365/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9878 Loss3: -0.9924\n",
            "Epoch: 365 MAE: 0.07296593005064303 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:48:11.603831 Epoch [366/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9893 Loss3: -0.9932\n",
            "2022-06-21 23:48:50.781506 Epoch [366/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9875 Loss3: -0.9922\n",
            "2022-06-21 23:48:58.661743 Epoch [366/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9867 Loss3: -0.9927\n",
            "Epoch: 366 MAE: 0.07253063126215858 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:49:05.984238 Epoch [367/500], Step [0001/0060], Loss1: -0.9905 Loss2: -0.9853 Loss3: -0.9922\n",
            "2022-06-21 23:49:44.341744 Epoch [367/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9867 Loss3: -0.9923\n",
            "2022-06-21 23:49:52.218902 Epoch [367/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9869 Loss3: -0.9927\n",
            "Epoch: 367 MAE: 0.07252600594172401 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:49:59.322273 Epoch [368/500], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9839 Loss3: -0.9906\n",
            "2022-06-21 23:50:38.200507 Epoch [368/500], Step [0050/0060], Loss1: -0.9887 Loss2: -0.9837 Loss3: -0.9906\n",
            "2022-06-21 23:50:46.158106 Epoch [368/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9865 Loss3: -0.9918\n",
            "Epoch: 368 MAE: 0.07405247723614727 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:50:53.997400 Epoch [369/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9854 Loss3: -0.9921\n",
            "2022-06-21 23:51:32.618646 Epoch [369/500], Step [0050/0060], Loss1: -0.9920 Loss2: -0.9877 Loss3: -0.9932\n",
            "2022-06-21 23:51:40.441921 Epoch [369/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9843 Loss3: -0.9920\n",
            "Epoch: 369 MAE: 0.07198445976095856 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:51:47.488631 Epoch [370/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9845 Loss3: -0.9913\n",
            "2022-06-21 23:52:26.051959 Epoch [370/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9864 Loss3: -0.9922\n",
            "2022-06-21 23:52:33.948951 Epoch [370/500], Step [0060/0060], Loss1: -0.9889 Loss2: -0.9830 Loss3: -0.9909\n",
            "Epoch: 370 MAE: 0.07232005311067773 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:52:43.934104 Epoch [371/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9861 Loss3: -0.9920\n",
            "2022-06-21 23:53:23.123010 Epoch [371/500], Step [0050/0060], Loss1: -0.9892 Loss2: -0.9860 Loss3: -0.9911\n",
            "2022-06-21 23:53:31.028125 Epoch [371/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9859 Loss3: -0.9916\n",
            "Epoch: 371 MAE: 0.07260362837049694 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:53:38.447245 Epoch [372/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9854 Loss3: -0.9919\n",
            "2022-06-21 23:54:17.004962 Epoch [372/500], Step [0050/0060], Loss1: -0.9923 Loss2: -0.9898 Loss3: -0.9936\n",
            "2022-06-21 23:54:24.881009 Epoch [372/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9864 Loss3: -0.9919\n",
            "Epoch: 372 MAE: 0.0710891212988152 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:54:32.182443 Epoch [373/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9887 Loss3: -0.9926\n",
            "2022-06-21 23:55:10.777780 Epoch [373/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9849 Loss3: -0.9921\n",
            "2022-06-21 23:55:18.702606 Epoch [373/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9851 Loss3: -0.9905\n",
            "Epoch: 373 MAE: 0.07318659570482042 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:55:26.755573 Epoch [374/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9827 Loss3: -0.9906\n",
            "2022-06-21 23:56:05.331767 Epoch [374/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9829 Loss3: -0.9916\n",
            "2022-06-21 23:56:13.208669 Epoch [374/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9848 Loss3: -0.9909\n",
            "Epoch: 374 MAE: 0.07322639485515615 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:56:20.430369 Epoch [375/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9869 Loss3: -0.9915\n",
            "2022-06-21 23:56:59.052924 Epoch [375/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9925\n",
            "2022-06-21 23:57:06.899057 Epoch [375/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9879 Loss3: -0.9930\n",
            "Epoch: 375 MAE: 0.07127986272176107 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:57:17.563575 Epoch [376/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9883 Loss3: -0.9931\n",
            "2022-06-21 23:57:56.700776 Epoch [376/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9879 Loss3: -0.9928\n",
            "2022-06-21 23:58:04.582113 Epoch [376/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9853 Loss3: -0.9919\n",
            "Epoch: 376 MAE: 0.07135042094679737 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:58:11.954779 Epoch [377/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9817 Loss3: -0.9905\n",
            "2022-06-21 23:58:50.458976 Epoch [377/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9836 Loss3: -0.9908\n",
            "2022-06-21 23:58:58.312049 Epoch [377/500], Step [0060/0060], Loss1: -0.9898 Loss2: -0.9862 Loss3: -0.9915\n",
            "Epoch: 377 MAE: 0.07323390097845167 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-21 23:59:05.663589 Epoch [378/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9881 Loss3: -0.9933\n",
            "2022-06-21 23:59:44.284941 Epoch [378/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9866 Loss3: -0.9920\n",
            "2022-06-21 23:59:52.270959 Epoch [378/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9881 Loss3: -0.9928\n",
            "Epoch: 378 MAE: 0.07357115841416455 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:00:00.134574 Epoch [379/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9874 Loss3: -0.9928\n",
            "2022-06-22 00:00:38.783679 Epoch [379/500], Step [0050/0060], Loss1: -0.9870 Loss2: -0.9806 Loss3: -0.9895\n",
            "2022-06-22 00:00:46.648823 Epoch [379/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9872 Loss3: -0.9930\n",
            "Epoch: 379 MAE: 0.0718606135958717 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:00:53.960838 Epoch [380/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9869 Loss3: -0.9923\n",
            "2022-06-22 00:01:32.580101 Epoch [380/500], Step [0050/0060], Loss1: -0.9878 Loss2: -0.9828 Loss3: -0.9901\n",
            "2022-06-22 00:01:40.456719 Epoch [380/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9879 Loss3: -0.9928\n",
            "Epoch: 380 MAE: 0.07250103753710552 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:01:50.356800 Epoch [381/500], Step [0001/0060], Loss1: -0.9893 Loss2: -0.9837 Loss3: -0.9911\n",
            "2022-06-22 00:02:29.550871 Epoch [381/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9862 Loss3: -0.9915\n",
            "2022-06-22 00:02:37.426791 Epoch [381/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9845 Loss3: -0.9916\n",
            "Epoch: 381 MAE: 0.07258504241862623 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:02:44.783455 Epoch [382/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9834 Loss3: -0.9911\n",
            "2022-06-22 00:03:23.317887 Epoch [382/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9884 Loss3: -0.9926\n",
            "2022-06-22 00:03:31.176723 Epoch [382/500], Step [0060/0060], Loss1: -0.9884 Loss2: -0.9841 Loss3: -0.9901\n",
            "Epoch: 382 MAE: 0.07286273073267055 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:03:38.482904 Epoch [383/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9884 Loss3: -0.9925\n",
            "2022-06-22 00:04:17.095582 Epoch [383/500], Step [0050/0060], Loss1: -0.9879 Loss2: -0.9823 Loss3: -0.9899\n",
            "2022-06-22 00:04:24.992904 Epoch [383/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9874 Loss3: -0.9932\n",
            "Epoch: 383 MAE: 0.07256757004551156 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:04:32.859630 Epoch [384/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9862 Loss3: -0.9925\n",
            "2022-06-22 00:05:11.560336 Epoch [384/500], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9826 Loss3: -0.9897\n",
            "2022-06-22 00:05:19.467453 Epoch [384/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9923\n",
            "Epoch: 384 MAE: 0.07201851915430141 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:05:26.815280 Epoch [385/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9885 Loss3: -0.9931\n",
            "2022-06-22 00:06:05.477272 Epoch [385/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9872 Loss3: -0.9932\n",
            "2022-06-22 00:06:13.348087 Epoch [385/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9859 Loss3: -0.9916\n",
            "Epoch: 385 MAE: 0.07253587303968963 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:06:23.196793 Epoch [386/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9870 Loss3: -0.9911\n",
            "2022-06-22 00:07:02.408829 Epoch [386/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9862 Loss3: -0.9915\n",
            "2022-06-22 00:07:10.306060 Epoch [386/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9827 Loss3: -0.9911\n",
            "Epoch: 386 MAE: 0.07282535204811699 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:07:17.566774 Epoch [387/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9857 Loss3: -0.9918\n",
            "2022-06-22 00:07:56.269378 Epoch [387/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9868 Loss3: -0.9916\n",
            "2022-06-22 00:08:04.166183 Epoch [387/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9845 Loss3: -0.9912\n",
            "Epoch: 387 MAE: 0.07378008136042843 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:08:11.567633 Epoch [388/500], Step [0001/0060], Loss1: -0.9886 Loss2: -0.9844 Loss3: -0.9902\n",
            "2022-06-22 00:08:50.314472 Epoch [388/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9865 Loss3: -0.9923\n",
            "2022-06-22 00:08:58.206956 Epoch [388/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9853 Loss3: -0.9924\n",
            "Epoch: 388 MAE: 0.07306151546498457 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:09:06.377259 Epoch [389/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9839 Loss3: -0.9902\n",
            "2022-06-22 00:09:45.113913 Epoch [389/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9858 Loss3: -0.9924\n",
            "2022-06-22 00:09:52.997227 Epoch [389/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9852 Loss3: -0.9918\n",
            "Epoch: 389 MAE: 0.07152984250790227 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:10:00.298375 Epoch [390/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9874 Loss3: -0.9928\n",
            "2022-06-22 00:10:38.956513 Epoch [390/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9880 Loss3: -0.9922\n",
            "2022-06-22 00:10:46.826758 Epoch [390/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9877 Loss3: -0.9929\n",
            "Epoch: 390 MAE: 0.07163346330955546 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:10:56.827987 Epoch [391/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9844 Loss3: -0.9914\n",
            "2022-06-22 00:11:36.068739 Epoch [391/500], Step [0050/0060], Loss1: -0.9854 Loss2: -0.9780 Loss3: -0.9879\n",
            "2022-06-22 00:11:43.961774 Epoch [391/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9876 Loss3: -0.9927\n",
            "Epoch: 391 MAE: 0.07181507902801353 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:11:51.340584 Epoch [392/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-06-22 00:12:29.993879 Epoch [392/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9864 Loss3: -0.9928\n",
            "2022-06-22 00:12:37.871703 Epoch [392/500], Step [0060/0060], Loss1: -0.9868 Loss2: -0.9801 Loss3: -0.9891\n",
            "Epoch: 392 MAE: 0.07355322514892255 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:12:45.163986 Epoch [393/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9880 Loss3: -0.9924\n",
            "2022-06-22 00:13:23.858783 Epoch [393/500], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9873 Loss3: -0.9937\n",
            "2022-06-22 00:13:31.745726 Epoch [393/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9874 Loss3: -0.9928\n",
            "Epoch: 393 MAE: 0.0732376306019132 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:13:39.504816 Epoch [394/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9851 Loss3: -0.9909\n",
            "2022-06-22 00:14:18.341461 Epoch [394/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9851 Loss3: -0.9919\n",
            "2022-06-22 00:14:26.209293 Epoch [394/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9888 Loss3: -0.9938\n",
            "Epoch: 394 MAE: 0.07124728722547098 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:14:33.530890 Epoch [395/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9879 Loss3: -0.9933\n",
            "2022-06-22 00:15:12.182019 Epoch [395/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9869 Loss3: -0.9925\n",
            "2022-06-22 00:15:20.079051 Epoch [395/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9884 Loss3: -0.9933\n",
            "Epoch: 395 MAE: 0.07276467868259974 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:15:30.762422 Epoch [396/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9851 Loss3: -0.9912\n",
            "2022-06-22 00:16:09.992952 Epoch [396/500], Step [0050/0060], Loss1: -0.9900 Loss2: -0.9867 Loss3: -0.9916\n",
            "2022-06-22 00:16:17.945655 Epoch [396/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9864 Loss3: -0.9921\n",
            "Epoch: 396 MAE: 0.07435553242920569 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:16:25.418955 Epoch [397/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9887 Loss3: -0.9933\n",
            "2022-06-22 00:17:04.075435 Epoch [397/500], Step [0050/0060], Loss1: -0.9923 Loss2: -0.9892 Loss3: -0.9936\n",
            "2022-06-22 00:17:11.978929 Epoch [397/500], Step [0060/0060], Loss1: -0.9869 Loss2: -0.9794 Loss3: -0.9889\n",
            "Epoch: 397 MAE: 0.07305005189602966 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:17:19.175722 Epoch [398/500], Step [0001/0060], Loss1: -0.9918 Loss2: -0.9877 Loss3: -0.9934\n",
            "2022-06-22 00:17:57.908968 Epoch [398/500], Step [0050/0060], Loss1: -0.9875 Loss2: -0.9834 Loss3: -0.9896\n",
            "2022-06-22 00:18:05.825407 Epoch [398/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9885 Loss3: -0.9928\n",
            "Epoch: 398 MAE: 0.07238248577824341 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:18:13.390678 Epoch [399/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9841 Loss3: -0.9910\n",
            "2022-06-22 00:18:52.311383 Epoch [399/500], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9873 Loss3: -0.9921\n",
            "2022-06-22 00:19:00.199940 Epoch [399/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9858 Loss3: -0.9918\n",
            "Epoch: 399 MAE: 0.07238264744874662 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:19:07.548975 Epoch [400/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9873 Loss3: -0.9925\n",
            "2022-06-22 00:19:46.272798 Epoch [400/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9884 Loss3: -0.9928\n",
            "2022-06-22 00:19:54.166227 Epoch [400/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9858 Loss3: -0.9919\n",
            "Epoch: 400 MAE: 0.07230757667904808 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:20:04.477016 Epoch [401/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9883 Loss3: -0.9928\n",
            "2022-06-22 00:20:43.476566 Epoch [401/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9860 Loss3: -0.9919\n",
            "2022-06-22 00:20:51.641704 Epoch [401/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9863 Loss3: -0.9915\n",
            "Epoch: 401 MAE: 0.07250399069811299 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:20:59.364485 Epoch [402/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9857 Loss3: -0.9923\n",
            "2022-06-22 00:21:38.029541 Epoch [402/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9862 Loss3: -0.9928\n",
            "2022-06-22 00:21:45.927381 Epoch [402/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9866 Loss3: -0.9921\n",
            "Epoch: 402 MAE: 0.07218152116846153 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:21:53.487069 Epoch [403/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9851 Loss3: -0.9917\n",
            "2022-06-22 00:22:32.262111 Epoch [403/500], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9836 Loss3: -0.9904\n",
            "2022-06-22 00:22:40.168820 Epoch [403/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9872 Loss3: -0.9919\n",
            "Epoch: 403 MAE: 0.07257592953071394 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:22:47.754134 Epoch [404/500], Step [0001/0060], Loss1: -0.9921 Loss2: -0.9891 Loss3: -0.9934\n",
            "2022-06-22 00:23:26.747171 Epoch [404/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9866 Loss3: -0.9920\n",
            "2022-06-22 00:23:34.649150 Epoch [404/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9836 Loss3: -0.9907\n",
            "Epoch: 404 MAE: 0.07202792929593847 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:23:42.167988 Epoch [405/500], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9845 Loss3: -0.9908\n",
            "2022-06-22 00:24:20.919861 Epoch [405/500], Step [0050/0060], Loss1: -0.9876 Loss2: -0.9791 Loss3: -0.9898\n",
            "2022-06-22 00:24:28.842017 Epoch [405/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9870 Loss3: -0.9921\n",
            "Epoch: 405 MAE: 0.07164971795662373 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:24:39.474712 Epoch [406/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9869 Loss3: -0.9927\n",
            "2022-06-22 00:25:18.318083 Epoch [406/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9868 Loss3: -0.9935\n",
            "2022-06-22 00:25:26.488876 Epoch [406/500], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9803 Loss3: -0.9884\n",
            "Epoch: 406 MAE: 0.0743050696357848 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:25:34.864568 Epoch [407/500], Step [0001/0060], Loss1: -0.9875 Loss2: -0.9841 Loss3: -0.9901\n",
            "2022-06-22 00:26:13.553112 Epoch [407/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9866 Loss3: -0.9925\n",
            "2022-06-22 00:26:21.482892 Epoch [407/500], Step [0060/0060], Loss1: -0.9881 Loss2: -0.9839 Loss3: -0.9900\n",
            "Epoch: 407 MAE: 0.0725530674848607 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:26:29.060033 Epoch [408/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9889 Loss3: -0.9927\n",
            "2022-06-22 00:27:07.723124 Epoch [408/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9863 Loss3: -0.9930\n",
            "2022-06-22 00:27:15.629487 Epoch [408/500], Step [0060/0060], Loss1: -0.9917 Loss2: -0.9883 Loss3: -0.9932\n",
            "Epoch: 408 MAE: 0.07305168999565974 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:27:23.083733 Epoch [409/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9875 Loss3: -0.9932\n",
            "2022-06-22 00:28:01.915196 Epoch [409/500], Step [0050/0060], Loss1: -0.9850 Loss2: -0.9780 Loss3: -0.9873\n",
            "2022-06-22 00:28:09.804549 Epoch [409/500], Step [0060/0060], Loss1: -0.9906 Loss2: -0.9855 Loss3: -0.9922\n",
            "Epoch: 409 MAE: 0.0727733439490909 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:28:17.337059 Epoch [410/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9856 Loss3: -0.9917\n",
            "2022-06-22 00:28:56.064923 Epoch [410/500], Step [0050/0060], Loss1: -0.9905 Loss2: -0.9852 Loss3: -0.9922\n",
            "2022-06-22 00:29:03.965109 Epoch [410/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9849 Loss3: -0.9923\n",
            "Epoch: 410 MAE: 0.07279798043468012 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:29:15.093858 Epoch [411/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9870 Loss3: -0.9920\n",
            "2022-06-22 00:29:53.946624 Epoch [411/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9849 Loss3: -0.9920\n",
            "2022-06-22 00:30:02.123930 Epoch [411/500], Step [0060/0060], Loss1: -0.9882 Loss2: -0.9812 Loss3: -0.9903\n",
            "Epoch: 411 MAE: 0.07260708062106339 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:30:10.397543 Epoch [412/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9876 Loss3: -0.9928\n",
            "2022-06-22 00:30:49.030926 Epoch [412/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9852 Loss3: -0.9909\n",
            "2022-06-22 00:30:56.944636 Epoch [412/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9871 Loss3: -0.9930\n",
            "Epoch: 412 MAE: 0.07381514655219183 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:31:04.390923 Epoch [413/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9870 Loss3: -0.9914\n",
            "2022-06-22 00:31:43.123069 Epoch [413/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9876 Loss3: -0.9929\n",
            "2022-06-22 00:31:51.035652 Epoch [413/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9870 Loss3: -0.9929\n",
            "Epoch: 413 MAE: 0.07260803020820418 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:31:58.487565 Epoch [414/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9862 Loss3: -0.9926\n",
            "2022-06-22 00:32:37.545412 Epoch [414/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9859 Loss3: -0.9928\n",
            "2022-06-22 00:32:45.439134 Epoch [414/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9866 Loss3: -0.9933\n",
            "Epoch: 414 MAE: 0.07227568056217577 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:32:52.826811 Epoch [415/500], Step [0001/0060], Loss1: -0.9917 Loss2: -0.9869 Loss3: -0.9931\n",
            "2022-06-22 00:33:31.606481 Epoch [415/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9873 Loss3: -0.9922\n",
            "2022-06-22 00:33:39.484880 Epoch [415/500], Step [0060/0060], Loss1: -0.9867 Loss2: -0.9820 Loss3: -0.9891\n",
            "Epoch: 415 MAE: 0.07443278595253272 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:33:50.642486 Epoch [416/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-22 00:34:29.374044 Epoch [416/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9881 Loss3: -0.9932\n",
            "2022-06-22 00:34:37.515810 Epoch [416/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9871 Loss3: -0.9931\n",
            "Epoch: 416 MAE: 0.07089406881382856 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:34:46.533946 Epoch [417/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9860 Loss3: -0.9920\n",
            "2022-06-22 00:35:25.177228 Epoch [417/500], Step [0050/0060], Loss1: -0.9851 Loss2: -0.9800 Loss3: -0.9882\n",
            "2022-06-22 00:35:33.067113 Epoch [417/500], Step [0060/0060], Loss1: -0.9903 Loss2: -0.9870 Loss3: -0.9922\n",
            "Epoch: 417 MAE: 0.07218303085004212 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:35:40.402513 Epoch [418/500], Step [0001/0060], Loss1: -0.9840 Loss2: -0.9751 Loss3: -0.9869\n",
            "2022-06-22 00:36:19.124818 Epoch [418/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9871 Loss3: -0.9923\n",
            "2022-06-22 00:36:27.017987 Epoch [418/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9855 Loss3: -0.9922\n",
            "Epoch: 418 MAE: 0.07201927452491076 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:36:34.400814 Epoch [419/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9871 Loss3: -0.9926\n",
            "2022-06-22 00:37:13.328835 Epoch [419/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9859 Loss3: -0.9916\n",
            "2022-06-22 00:37:21.235829 Epoch [419/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9852 Loss3: -0.9918\n",
            "Epoch: 419 MAE: 0.07227046931231464 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:37:28.581553 Epoch [420/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9823 Loss3: -0.9912\n",
            "2022-06-22 00:38:07.299421 Epoch [420/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9847 Loss3: -0.9909\n",
            "2022-06-22 00:38:15.175689 Epoch [420/500], Step [0060/0060], Loss1: -0.9885 Loss2: -0.9841 Loss3: -0.9905\n",
            "Epoch: 420 MAE: 0.07451184747080324 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:38:25.660379 Epoch [421/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9865 Loss3: -0.9919\n",
            "2022-06-22 00:39:04.453704 Epoch [421/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9866 Loss3: -0.9921\n",
            "2022-06-22 00:39:12.403783 Epoch [421/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9877 Loss3: -0.9924\n",
            "Epoch: 421 MAE: 0.07194427137021665 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:39:21.653597 Epoch [422/500], Step [0001/0060], Loss1: -0.9866 Loss2: -0.9778 Loss3: -0.9889\n",
            "2022-06-22 00:40:00.540721 Epoch [422/500], Step [0050/0060], Loss1: -0.9888 Loss2: -0.9858 Loss3: -0.9910\n",
            "2022-06-22 00:40:08.460509 Epoch [422/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9878 Loss3: -0.9929\n",
            "Epoch: 422 MAE: 0.07259273932724404 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:40:15.828382 Epoch [423/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9843 Loss3: -0.9912\n",
            "2022-06-22 00:40:54.421914 Epoch [423/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9854 Loss3: -0.9925\n",
            "2022-06-22 00:41:02.224282 Epoch [423/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9841 Loss3: -0.9905\n",
            "Epoch: 423 MAE: 0.07244860800485763 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:41:09.053208 Epoch [424/500], Step [0001/0060], Loss1: -0.9888 Loss2: -0.9847 Loss3: -0.9904\n",
            "2022-06-22 00:41:47.481123 Epoch [424/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9861 Loss3: -0.9922\n",
            "2022-06-22 00:41:55.270966 Epoch [424/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9861 Loss3: -0.9923\n",
            "Epoch: 424 MAE: 0.07332964811375534 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:42:02.047288 Epoch [425/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9869 Loss3: -0.9922\n",
            "2022-06-22 00:42:40.349211 Epoch [425/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9870 Loss3: -0.9918\n",
            "2022-06-22 00:42:48.160272 Epoch [425/500], Step [0060/0060], Loss1: -0.9883 Loss2: -0.9832 Loss3: -0.9901\n",
            "Epoch: 425 MAE: 0.07307735670180547 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:42:57.302030 Epoch [426/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9836 Loss3: -0.9915\n",
            "2022-06-22 00:43:35.665886 Epoch [426/500], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9814 Loss3: -0.9885\n",
            "2022-06-22 00:43:43.482129 Epoch [426/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9865 Loss3: -0.9926\n",
            "Epoch: 426 MAE: 0.07334023087112995 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:43:50.498003 Epoch [427/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9863 Loss3: -0.9924\n",
            "2022-06-22 00:44:29.118362 Epoch [427/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9873 Loss3: -0.9921\n",
            "2022-06-22 00:44:36.906349 Epoch [427/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9862 Loss3: -0.9932\n",
            "Epoch: 427 MAE: 0.07292786800041401 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:44:43.709173 Epoch [428/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9850 Loss3: -0.9917\n",
            "2022-06-22 00:45:22.248896 Epoch [428/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9873 Loss3: -0.9930\n",
            "2022-06-22 00:45:30.161463 Epoch [428/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9853 Loss3: -0.9922\n",
            "Epoch: 428 MAE: 0.07269566964850853 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:45:37.452745 Epoch [429/500], Step [0001/0060], Loss1: -0.9865 Loss2: -0.9781 Loss3: -0.9887\n",
            "2022-06-22 00:46:16.269272 Epoch [429/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9822 Loss3: -0.9911\n",
            "2022-06-22 00:46:24.408850 Epoch [429/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9851 Loss3: -0.9922\n",
            "Epoch: 429 MAE: 0.07259064210155025 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:46:31.991550 Epoch [430/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9885 Loss3: -0.9929\n",
            "2022-06-22 00:47:10.422630 Epoch [430/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9865 Loss3: -0.9924\n",
            "2022-06-22 00:47:18.308245 Epoch [430/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9894 Loss3: -0.9930\n",
            "Epoch: 430 MAE: 0.07277964309409811 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:47:28.623660 Epoch [431/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9847 Loss3: -0.9912\n",
            "2022-06-22 00:48:07.372334 Epoch [431/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9863 Loss3: -0.9909\n",
            "2022-06-22 00:48:15.269005 Epoch [431/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9873 Loss3: -0.9930\n",
            "Epoch: 431 MAE: 0.07393614390539742 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:48:22.727853 Epoch [432/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9845 Loss3: -0.9911\n",
            "2022-06-22 00:49:01.896002 Epoch [432/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9847 Loss3: -0.9913\n",
            "2022-06-22 00:49:09.785431 Epoch [432/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9824 Loss3: -0.9913\n",
            "Epoch: 432 MAE: 0.07205188781496079 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:49:17.215425 Epoch [433/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9834 Loss3: -0.9906\n",
            "2022-06-22 00:49:55.939363 Epoch [433/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9848 Loss3: -0.9929\n",
            "2022-06-22 00:50:03.851855 Epoch [433/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9869 Loss3: -0.9920\n",
            "Epoch: 433 MAE: 0.0714784384530688 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:50:11.276040 Epoch [434/500], Step [0001/0060], Loss1: -0.9891 Loss2: -0.9852 Loss3: -0.9913\n",
            "2022-06-22 00:50:49.942322 Epoch [434/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9865 Loss3: -0.9929\n",
            "2022-06-22 00:50:58.048462 Epoch [434/500], Step [0060/0060], Loss1: -0.9834 Loss2: -0.9761 Loss3: -0.9862\n",
            "Epoch: 434 MAE: 0.07375124885922388 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:51:06.111315 Epoch [435/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9867 Loss3: -0.9920\n",
            "2022-06-22 00:51:44.845962 Epoch [435/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-22 00:51:52.741741 Epoch [435/500], Step [0060/0060], Loss1: -0.9910 Loss2: -0.9883 Loss3: -0.9927\n",
            "Epoch: 435 MAE: 0.07455255114842978 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:52:02.916566 Epoch [436/500], Step [0001/0060], Loss1: -0.9881 Loss2: -0.9819 Loss3: -0.9901\n",
            "2022-06-22 00:52:41.707992 Epoch [436/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9857 Loss3: -0.9925\n",
            "2022-06-22 00:52:49.616047 Epoch [436/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9871 Loss3: -0.9928\n",
            "Epoch: 436 MAE: 0.07257904416038874 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:52:57.022795 Epoch [437/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9868 Loss3: -0.9924\n",
            "2022-06-22 00:53:36.185393 Epoch [437/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9852 Loss3: -0.9925\n",
            "2022-06-22 00:53:44.063962 Epoch [437/500], Step [0060/0060], Loss1: -0.9862 Loss2: -0.9824 Loss3: -0.9886\n",
            "Epoch: 437 MAE: 0.07320406010541966 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:53:51.558759 Epoch [438/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9866 Loss3: -0.9929\n",
            "2022-06-22 00:54:30.269594 Epoch [438/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9867 Loss3: -0.9911\n",
            "2022-06-22 00:54:38.166506 Epoch [438/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9845 Loss3: -0.9912\n",
            "Epoch: 438 MAE: 0.072026418302425 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:54:45.499515 Epoch [439/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9884 Loss3: -0.9930\n",
            "2022-06-22 00:55:24.222939 Epoch [439/500], Step [0050/0060], Loss1: -0.9913 Loss2: -0.9870 Loss3: -0.9928\n",
            "2022-06-22 00:55:32.159986 Epoch [439/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9840 Loss3: -0.9910\n",
            "Epoch: 439 MAE: 0.0726701854524158 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:55:40.311598 Epoch [440/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9861 Loss3: -0.9926\n",
            "2022-06-22 00:56:19.033163 Epoch [440/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9875 Loss3: -0.9930\n",
            "2022-06-22 00:56:26.934185 Epoch [440/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9851 Loss3: -0.9916\n",
            "Epoch: 440 MAE: 0.07347963075789193 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:56:36.920946 Epoch [441/500], Step [0001/0060], Loss1: -0.9880 Loss2: -0.9817 Loss3: -0.9900\n",
            "2022-06-22 00:57:15.664094 Epoch [441/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9859 Loss3: -0.9914\n",
            "2022-06-22 00:57:23.568827 Epoch [441/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9857 Loss3: -0.9917\n",
            "Epoch: 441 MAE: 0.07334845129144255 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:57:30.995647 Epoch [442/500], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9834 Loss3: -0.9904\n",
            "2022-06-22 00:58:10.103390 Epoch [442/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9867 Loss3: -0.9926\n",
            "2022-06-22 00:58:18.001263 Epoch [442/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9843 Loss3: -0.9915\n",
            "Epoch: 442 MAE: 0.0729573494038254 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:58:25.391925 Epoch [443/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9826 Loss3: -0.9920\n",
            "2022-06-22 00:59:04.138565 Epoch [443/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9855 Loss3: -0.9918\n",
            "2022-06-22 00:59:12.013087 Epoch [443/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9859 Loss3: -0.9913\n",
            "Epoch: 443 MAE: 0.0731658823527987 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 00:59:19.576058 Epoch [444/500], Step [0001/0060], Loss1: -0.9907 Loss2: -0.9888 Loss3: -0.9922\n",
            "2022-06-22 00:59:58.213710 Epoch [444/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9880 Loss3: -0.9928\n",
            "2022-06-22 01:00:06.102794 Epoch [444/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9882 Loss3: -0.9934\n",
            "Epoch: 444 MAE: 0.0736310560741122 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:00:14.043718 Epoch [445/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9867 Loss3: -0.9925\n",
            "2022-06-22 01:00:52.771612 Epoch [445/500], Step [0050/0060], Loss1: -0.9869 Loss2: -0.9813 Loss3: -0.9894\n",
            "2022-06-22 01:01:00.654079 Epoch [445/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9852 Loss3: -0.9903\n",
            "Epoch: 445 MAE: 0.07311284034971206 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:01:11.475500 Epoch [446/500], Step [0001/0060], Loss1: -0.9922 Loss2: -0.9888 Loss3: -0.9935\n",
            "2022-06-22 01:01:50.225782 Epoch [446/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9872 Loss3: -0.9923\n",
            "2022-06-22 01:01:58.118806 Epoch [446/500], Step [0060/0060], Loss1: -0.9913 Loss2: -0.9874 Loss3: -0.9926\n",
            "Epoch: 446 MAE: 0.07294921658026479 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:02:05.455502 Epoch [447/500], Step [0001/0060], Loss1: -0.9864 Loss2: -0.9811 Loss3: -0.9889\n",
            "2022-06-22 01:02:44.492854 Epoch [447/500], Step [0050/0060], Loss1: -0.9919 Loss2: -0.9884 Loss3: -0.9931\n",
            "2022-06-22 01:02:52.422140 Epoch [447/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9833 Loss3: -0.9912\n",
            "Epoch: 447 MAE: 0.07196775638237204 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:02:59.844820 Epoch [448/500], Step [0001/0060], Loss1: -0.9892 Loss2: -0.9811 Loss3: -0.9910\n",
            "2022-06-22 01:03:38.560253 Epoch [448/500], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9883 Loss3: -0.9933\n",
            "2022-06-22 01:03:46.434194 Epoch [448/500], Step [0060/0060], Loss1: -0.9905 Loss2: -0.9859 Loss3: -0.9920\n",
            "Epoch: 448 MAE: 0.07300901418009766 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:03:53.953749 Epoch [449/500], Step [0001/0060], Loss1: -0.9889 Loss2: -0.9853 Loss3: -0.9911\n",
            "2022-06-22 01:04:32.583213 Epoch [449/500], Step [0050/0060], Loss1: -0.9909 Loss2: -0.9876 Loss3: -0.9923\n",
            "2022-06-22 01:04:40.435394 Epoch [449/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9860 Loss3: -0.9912\n",
            "Epoch: 449 MAE: 0.07092925248322664 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:04:47.853582 Epoch [450/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9882 Loss3: -0.9925\n",
            "2022-06-22 01:05:26.694997 Epoch [450/500], Step [0050/0060], Loss1: -0.9893 Loss2: -0.9851 Loss3: -0.9908\n",
            "2022-06-22 01:05:34.510328 Epoch [450/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9858 Loss3: -0.9931\n",
            "Epoch: 450 MAE: 0.07145299956912085 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:05:43.914269 Epoch [451/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9827 Loss3: -0.9914\n",
            "2022-06-22 01:06:22.310632 Epoch [451/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9872 Loss3: -0.9928\n",
            "2022-06-22 01:06:30.124704 Epoch [451/500], Step [0060/0060], Loss1: -0.9893 Loss2: -0.9816 Loss3: -0.9910\n",
            "Epoch: 451 MAE: 0.07360399791172573 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:06:37.022468 Epoch [452/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9865 Loss3: -0.9926\n",
            "2022-06-22 01:07:15.496821 Epoch [452/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9864 Loss3: -0.9916\n",
            "2022-06-22 01:07:23.501860 Epoch [452/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9880 Loss3: -0.9928\n",
            "Epoch: 452 MAE: 0.07434801278290927 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:07:30.493485 Epoch [453/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9860 Loss3: -0.9928\n",
            "2022-06-22 01:08:08.782311 Epoch [453/500], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9837 Loss3: -0.9902\n",
            "2022-06-22 01:08:16.608625 Epoch [453/500], Step [0060/0060], Loss1: -0.9918 Loss2: -0.9874 Loss3: -0.9931\n",
            "Epoch: 453 MAE: 0.0717474280463325 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:08:23.602597 Epoch [454/500], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9816 Loss3: -0.9900\n",
            "2022-06-22 01:09:01.917942 Epoch [454/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9857 Loss3: -0.9916\n",
            "2022-06-22 01:09:09.712240 Epoch [454/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9834 Loss3: -0.9912\n",
            "Epoch: 454 MAE: 0.07178602682850345 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:09:16.492632 Epoch [455/500], Step [0001/0060], Loss1: -0.9885 Loss2: -0.9816 Loss3: -0.9902\n",
            "2022-06-22 01:09:55.289649 Epoch [455/500], Step [0050/0060], Loss1: -0.9884 Loss2: -0.9844 Loss3: -0.9907\n",
            "2022-06-22 01:10:03.237782 Epoch [455/500], Step [0060/0060], Loss1: -0.9888 Loss2: -0.9823 Loss3: -0.9909\n",
            "Epoch: 455 MAE: 0.07121137957093578 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:10:13.218036 Epoch [456/500], Step [0001/0060], Loss1: -0.9898 Loss2: -0.9820 Loss3: -0.9914\n",
            "2022-06-22 01:10:51.931648 Epoch [456/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9874 Loss3: -0.9920\n",
            "2022-06-22 01:10:59.755212 Epoch [456/500], Step [0060/0060], Loss1: -0.9899 Loss2: -0.9861 Loss3: -0.9914\n",
            "Epoch: 456 MAE: 0.0726712578062027 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:11:06.715547 Epoch [457/500], Step [0001/0060], Loss1: -0.9897 Loss2: -0.9856 Loss3: -0.9922\n",
            "2022-06-22 01:11:45.182888 Epoch [457/500], Step [0050/0060], Loss1: -0.9880 Loss2: -0.9813 Loss3: -0.9903\n",
            "2022-06-22 01:11:53.152231 Epoch [457/500], Step [0060/0060], Loss1: -0.9892 Loss2: -0.9858 Loss3: -0.9909\n",
            "Epoch: 457 MAE: 0.07300355729602634 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:12:02.015360 Epoch [458/500], Step [0001/0060], Loss1: -0.9908 Loss2: -0.9876 Loss3: -0.9923\n",
            "2022-06-22 01:12:40.746821 Epoch [458/500], Step [0050/0060], Loss1: -0.9907 Loss2: -0.9873 Loss3: -0.9923\n",
            "2022-06-22 01:12:48.656357 Epoch [458/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9881 Loss3: -0.9931\n",
            "Epoch: 458 MAE: 0.0724271298464013 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:12:56.073685 Epoch [459/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9881 Loss3: -0.9926\n",
            "2022-06-22 01:13:34.636955 Epoch [459/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9856 Loss3: -0.9926\n",
            "2022-06-22 01:13:42.491717 Epoch [459/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9864 Loss3: -0.9923\n",
            "Epoch: 459 MAE: 0.07369918025990642 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:13:49.864617 Epoch [460/500], Step [0001/0060], Loss1: -0.9909 Loss2: -0.9871 Loss3: -0.9925\n",
            "2022-06-22 01:14:28.777706 Epoch [460/500], Step [0050/0060], Loss1: -0.9883 Loss2: -0.9843 Loss3: -0.9903\n",
            "2022-06-22 01:14:36.683455 Epoch [460/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9872 Loss3: -0.9922\n",
            "Epoch: 460 MAE: 0.07235983056366128 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:14:46.786226 Epoch [461/500], Step [0001/0060], Loss1: -0.9906 Loss2: -0.9869 Loss3: -0.9921\n",
            "2022-06-22 01:15:25.529074 Epoch [461/500], Step [0050/0060], Loss1: -0.9872 Loss2: -0.9824 Loss3: -0.9891\n",
            "2022-06-22 01:15:33.416084 Epoch [461/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9835 Loss3: -0.9914\n",
            "Epoch: 461 MAE: 0.07189427537262125 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:15:40.750532 Epoch [462/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9858 Loss3: -0.9928\n",
            "2022-06-22 01:16:19.287147 Epoch [462/500], Step [0050/0060], Loss1: -0.9886 Loss2: -0.9819 Loss3: -0.9907\n",
            "2022-06-22 01:16:27.139656 Epoch [462/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9890 Loss3: -0.9932\n",
            "Epoch: 462 MAE: 0.07214969423082139 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:16:35.682964 Epoch [463/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9863 Loss3: -0.9915\n",
            "2022-06-22 01:17:14.611636 Epoch [463/500], Step [0050/0060], Loss1: -0.9885 Loss2: -0.9848 Loss3: -0.9902\n",
            "2022-06-22 01:17:22.514052 Epoch [463/500], Step [0060/0060], Loss1: -0.9890 Loss2: -0.9816 Loss3: -0.9908\n",
            "Epoch: 463 MAE: 0.07393192614197104 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:17:29.839354 Epoch [464/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9858 Loss3: -0.9920\n",
            "2022-06-22 01:18:08.581448 Epoch [464/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9856 Loss3: -0.9923\n",
            "2022-06-22 01:18:16.452699 Epoch [464/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9866 Loss3: -0.9922\n",
            "Epoch: 464 MAE: 0.07189114641260218 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:18:23.931230 Epoch [465/500], Step [0001/0060], Loss1: -0.9901 Loss2: -0.9856 Loss3: -0.9917\n",
            "2022-06-22 01:19:02.743704 Epoch [465/500], Step [0050/0060], Loss1: -0.9902 Loss2: -0.9868 Loss3: -0.9918\n",
            "2022-06-22 01:19:10.694480 Epoch [465/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9867 Loss3: -0.9925\n",
            "Epoch: 465 MAE: 0.0733267867375934 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:19:20.518735 Epoch [466/500], Step [0001/0060], Loss1: -0.9884 Loss2: -0.9837 Loss3: -0.9904\n",
            "2022-06-22 01:19:59.277718 Epoch [466/500], Step [0050/0060], Loss1: -0.9868 Loss2: -0.9822 Loss3: -0.9888\n",
            "2022-06-22 01:20:07.179666 Epoch [466/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9847 Loss3: -0.9915\n",
            "Epoch: 466 MAE: 0.0737601633425112 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:20:14.503270 Epoch [467/500], Step [0001/0060], Loss1: -0.9870 Loss2: -0.9830 Loss3: -0.9891\n",
            "2022-06-22 01:20:53.113676 Epoch [467/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9878 Loss3: -0.9926\n",
            "2022-06-22 01:21:01.003754 Epoch [467/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9864 Loss3: -0.9924\n",
            "Epoch: 467 MAE: 0.07324091426909915 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:21:08.256904 Epoch [468/500], Step [0001/0060], Loss1: -0.9882 Loss2: -0.9817 Loss3: -0.9900\n",
            "2022-06-22 01:21:47.356425 Epoch [468/500], Step [0050/0060], Loss1: -0.9896 Loss2: -0.9858 Loss3: -0.9913\n",
            "2022-06-22 01:21:55.259619 Epoch [468/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9877 Loss3: -0.9930\n",
            "Epoch: 468 MAE: 0.07257628466086412 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:22:02.578764 Epoch [469/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9873 Loss3: -0.9929\n",
            "2022-06-22 01:22:41.261014 Epoch [469/500], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9817 Loss3: -0.9891\n",
            "2022-06-22 01:22:49.145399 Epoch [469/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9847 Loss3: -0.9919\n",
            "Epoch: 469 MAE: 0.0738934540117859 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:22:56.574412 Epoch [470/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9891 Loss3: -0.9929\n",
            "2022-06-22 01:23:35.243806 Epoch [470/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9855 Loss3: -0.9921\n",
            "2022-06-22 01:23:43.262468 Epoch [470/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9917\n",
            "Epoch: 470 MAE: 0.07220510477742192 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:23:53.671420 Epoch [471/500], Step [0001/0060], Loss1: -0.9911 Loss2: -0.9861 Loss3: -0.9926\n",
            "2022-06-22 01:24:32.465111 Epoch [471/500], Step [0050/0060], Loss1: -0.9908 Loss2: -0.9884 Loss3: -0.9923\n",
            "2022-06-22 01:24:40.364872 Epoch [471/500], Step [0060/0060], Loss1: -0.9915 Loss2: -0.9872 Loss3: -0.9929\n",
            "Epoch: 471 MAE: 0.07249426816506362 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:24:47.880200 Epoch [472/500], Step [0001/0060], Loss1: -0.9887 Loss2: -0.9832 Loss3: -0.9904\n",
            "2022-06-22 01:25:26.545395 Epoch [472/500], Step [0050/0060], Loss1: -0.9901 Loss2: -0.9857 Loss3: -0.9916\n",
            "2022-06-22 01:25:34.418612 Epoch [472/500], Step [0060/0060], Loss1: -0.9904 Loss2: -0.9855 Loss3: -0.9918\n",
            "Epoch: 472 MAE: 0.07426951277192938 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:25:41.770248 Epoch [473/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9880 Loss3: -0.9930\n",
            "2022-06-22 01:26:20.722921 Epoch [473/500], Step [0050/0060], Loss1: -0.9924 Loss2: -0.9883 Loss3: -0.9935\n",
            "2022-06-22 01:26:28.628100 Epoch [473/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9887 Loss3: -0.9926\n",
            "Epoch: 473 MAE: 0.07270182110014417 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:26:35.863588 Epoch [474/500], Step [0001/0060], Loss1: -0.9877 Loss2: -0.9821 Loss3: -0.9894\n",
            "2022-06-22 01:27:14.511947 Epoch [474/500], Step [0050/0060], Loss1: -0.9912 Loss2: -0.9877 Loss3: -0.9928\n",
            "2022-06-22 01:27:22.414423 Epoch [474/500], Step [0060/0060], Loss1: -0.9916 Loss2: -0.9868 Loss3: -0.9928\n",
            "Epoch: 474 MAE: 0.07119463335269341 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:27:29.779383 Epoch [475/500], Step [0001/0060], Loss1: -0.9916 Loss2: -0.9855 Loss3: -0.9931\n",
            "2022-06-22 01:28:08.519689 Epoch [475/500], Step [0050/0060], Loss1: -0.9918 Loss2: -0.9891 Loss3: -0.9932\n",
            "2022-06-22 01:28:16.436511 Epoch [475/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9825 Loss3: -0.9903\n",
            "Epoch: 475 MAE: 0.07430450838078895 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:28:27.491088 Epoch [476/500], Step [0001/0060], Loss1: -0.9903 Loss2: -0.9867 Loss3: -0.9921\n",
            "2022-06-22 01:29:06.572403 Epoch [476/500], Step [0050/0060], Loss1: -0.9917 Loss2: -0.9870 Loss3: -0.9931\n",
            "2022-06-22 01:29:14.446140 Epoch [476/500], Step [0060/0060], Loss1: -0.9914 Loss2: -0.9868 Loss3: -0.9929\n",
            "Epoch: 476 MAE: 0.07169569827892165 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:29:21.970985 Epoch [477/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9846 Loss3: -0.9921\n",
            "2022-06-22 01:30:00.521070 Epoch [477/500], Step [0050/0060], Loss1: -0.9923 Loss2: -0.9905 Loss3: -0.9938\n",
            "2022-06-22 01:30:08.394341 Epoch [477/500], Step [0060/0060], Loss1: -0.9919 Loss2: -0.9884 Loss3: -0.9932\n",
            "Epoch: 477 MAE: 0.07118151498219323 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:30:15.667574 Epoch [478/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9842 Loss3: -0.9917\n",
            "2022-06-22 01:30:54.489397 Epoch [478/500], Step [0050/0060], Loss1: -0.9871 Loss2: -0.9820 Loss3: -0.9891\n",
            "2022-06-22 01:31:02.408598 Epoch [478/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9856 Loss3: -0.9923\n",
            "Epoch: 478 MAE: 0.07327973083213525 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:31:09.787669 Epoch [479/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9880 Loss3: -0.9928\n",
            "2022-06-22 01:31:48.427119 Epoch [479/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9842 Loss3: -0.9924\n",
            "2022-06-22 01:31:56.294130 Epoch [479/500], Step [0060/0060], Loss1: -0.9879 Loss2: -0.9842 Loss3: -0.9900\n",
            "Epoch: 479 MAE: 0.07366367521740141 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:32:03.697518 Epoch [480/500], Step [0001/0060], Loss1: -0.9879 Loss2: -0.9819 Loss3: -0.9898\n",
            "2022-06-22 01:32:42.328818 Epoch [480/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9801 Loss3: -0.9907\n",
            "2022-06-22 01:32:50.211597 Epoch [480/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9860 Loss3: -0.9923\n",
            "Epoch: 480 MAE: 0.07286053713036593 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:33:01.322973 Epoch [481/500], Step [0001/0060], Loss1: -0.9896 Loss2: -0.9835 Loss3: -0.9914\n",
            "2022-06-22 01:33:40.537285 Epoch [481/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9851 Loss3: -0.9919\n",
            "2022-06-22 01:33:48.440581 Epoch [481/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9875 Loss3: -0.9918\n",
            "Epoch: 481 MAE: 0.07252511529064683 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:33:55.838366 Epoch [482/500], Step [0001/0060], Loss1: -0.9913 Loss2: -0.9860 Loss3: -0.9928\n",
            "2022-06-22 01:34:34.392521 Epoch [482/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9854 Loss3: -0.9928\n",
            "2022-06-22 01:34:42.240261 Epoch [482/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9857 Loss3: -0.9917\n",
            "Epoch: 482 MAE: 0.07244977153798256 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:34:49.639964 Epoch [483/500], Step [0001/0060], Loss1: -0.9915 Loss2: -0.9874 Loss3: -0.9929\n",
            "2022-06-22 01:35:28.388874 Epoch [483/500], Step [0050/0060], Loss1: -0.9881 Loss2: -0.9842 Loss3: -0.9898\n",
            "2022-06-22 01:35:36.449909 Epoch [483/500], Step [0060/0060], Loss1: -0.9901 Loss2: -0.9855 Loss3: -0.9919\n",
            "Epoch: 483 MAE: 0.07292252313523065 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:35:43.875322 Epoch [484/500], Step [0001/0060], Loss1: -0.9902 Loss2: -0.9853 Loss3: -0.9919\n",
            "2022-06-22 01:36:22.524383 Epoch [484/500], Step [0050/0060], Loss1: -0.9910 Loss2: -0.9870 Loss3: -0.9926\n",
            "2022-06-22 01:36:30.393134 Epoch [484/500], Step [0060/0060], Loss1: -0.9911 Loss2: -0.9861 Loss3: -0.9927\n",
            "Epoch: 484 MAE: 0.07262996496977628 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:36:37.621093 Epoch [485/500], Step [0001/0060], Loss1: -0.9920 Loss2: -0.9887 Loss3: -0.9934\n",
            "2022-06-22 01:37:16.282402 Epoch [485/500], Step [0050/0060], Loss1: -0.9843 Loss2: -0.9774 Loss3: -0.9874\n",
            "2022-06-22 01:37:24.206851 Epoch [485/500], Step [0060/0060], Loss1: -0.9902 Loss2: -0.9857 Loss3: -0.9920\n",
            "Epoch: 485 MAE: 0.07238826681066442 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:37:34.298773 Epoch [486/500], Step [0001/0060], Loss1: -0.9912 Loss2: -0.9862 Loss3: -0.9926\n",
            "2022-06-22 01:38:13.344188 Epoch [486/500], Step [0050/0060], Loss1: -0.9890 Loss2: -0.9846 Loss3: -0.9908\n",
            "2022-06-22 01:38:21.209182 Epoch [486/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9869 Loss3: -0.9922\n",
            "Epoch: 486 MAE: 0.07191650970903023 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:38:28.573817 Epoch [487/500], Step [0001/0060], Loss1: -0.9874 Loss2: -0.9813 Loss3: -0.9895\n",
            "2022-06-22 01:39:07.162121 Epoch [487/500], Step [0050/0060], Loss1: -0.9903 Loss2: -0.9853 Loss3: -0.9920\n",
            "2022-06-22 01:39:15.032160 Epoch [487/500], Step [0060/0060], Loss1: -0.9886 Loss2: -0.9836 Loss3: -0.9905\n",
            "Epoch: 487 MAE: 0.07326268847026524 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:39:22.508733 Epoch [488/500], Step [0001/0060], Loss1: -0.9904 Loss2: -0.9845 Loss3: -0.9919\n",
            "2022-06-22 01:40:01.140973 Epoch [488/500], Step [0050/0060], Loss1: -0.9916 Loss2: -0.9881 Loss3: -0.9932\n",
            "2022-06-22 01:40:09.131545 Epoch [488/500], Step [0060/0060], Loss1: -0.9896 Loss2: -0.9863 Loss3: -0.9915\n",
            "Epoch: 488 MAE: 0.07413105984844229 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:40:17.017798 Epoch [489/500], Step [0001/0060], Loss1: -0.9876 Loss2: -0.9830 Loss3: -0.9895\n",
            "2022-06-22 01:40:55.640502 Epoch [489/500], Step [0050/0060], Loss1: -0.9915 Loss2: -0.9858 Loss3: -0.9930\n",
            "2022-06-22 01:41:03.496025 Epoch [489/500], Step [0060/0060], Loss1: -0.9897 Loss2: -0.9848 Loss3: -0.9914\n",
            "Epoch: 489 MAE: 0.07339272408258346 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:41:10.846945 Epoch [490/500], Step [0001/0060], Loss1: -0.9872 Loss2: -0.9801 Loss3: -0.9891\n",
            "2022-06-22 01:41:49.537163 Epoch [490/500], Step [0050/0060], Loss1: -0.9897 Loss2: -0.9857 Loss3: -0.9913\n",
            "2022-06-22 01:41:57.442438 Epoch [490/500], Step [0060/0060], Loss1: -0.9912 Loss2: -0.9881 Loss3: -0.9928\n",
            "Epoch: 490 MAE: 0.07289045480193285 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:42:07.583262 Epoch [491/500], Step [0001/0060], Loss1: -0.9910 Loss2: -0.9877 Loss3: -0.9925\n",
            "2022-06-22 01:42:46.809417 Epoch [491/500], Step [0050/0060], Loss1: -0.9906 Loss2: -0.9855 Loss3: -0.9923\n",
            "2022-06-22 01:42:54.696102 Epoch [491/500], Step [0060/0060], Loss1: -0.9908 Loss2: -0.9873 Loss3: -0.9925\n",
            "Epoch: 491 MAE: 0.0740686898004441 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:43:02.182094 Epoch [492/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9855 Loss3: -0.9918\n",
            "2022-06-22 01:43:40.819775 Epoch [492/500], Step [0050/0060], Loss1: -0.9842 Loss2: -0.9796 Loss3: -0.9873\n",
            "2022-06-22 01:43:48.703139 Epoch [492/500], Step [0060/0060], Loss1: -0.9894 Loss2: -0.9845 Loss3: -0.9915\n",
            "Epoch: 492 MAE: 0.07408958233222761 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:43:56.122460 Epoch [493/500], Step [0001/0060], Loss1: -0.9914 Loss2: -0.9888 Loss3: -0.9928\n",
            "2022-06-22 01:44:34.861007 Epoch [493/500], Step [0050/0060], Loss1: -0.9856 Loss2: -0.9792 Loss3: -0.9883\n",
            "2022-06-22 01:44:42.775091 Epoch [493/500], Step [0060/0060], Loss1: -0.9876 Loss2: -0.9826 Loss3: -0.9897\n",
            "Epoch: 493 MAE: 0.07229700658687208 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:44:51.016121 Epoch [494/500], Step [0001/0060], Loss1: -0.9899 Loss2: -0.9846 Loss3: -0.9919\n",
            "2022-06-22 01:45:29.668183 Epoch [494/500], Step [0050/0060], Loss1: -0.9904 Loss2: -0.9870 Loss3: -0.9921\n",
            "2022-06-22 01:45:37.550883 Epoch [494/500], Step [0060/0060], Loss1: -0.9900 Loss2: -0.9846 Loss3: -0.9916\n",
            "Epoch: 494 MAE: 0.07349953030783032 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:45:44.845945 Epoch [495/500], Step [0001/0060], Loss1: -0.9900 Loss2: -0.9865 Loss3: -0.9918\n",
            "2022-06-22 01:46:23.448702 Epoch [495/500], Step [0050/0060], Loss1: -0.9899 Loss2: -0.9870 Loss3: -0.9916\n",
            "2022-06-22 01:46:31.330206 Epoch [495/500], Step [0060/0060], Loss1: -0.9880 Loss2: -0.9825 Loss3: -0.9900\n",
            "Epoch: 495 MAE: 0.07359767257851896 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:46:41.255560 Epoch [496/500], Step [0001/0060], Loss1: -0.9894 Loss2: -0.9850 Loss3: -0.9915\n",
            "2022-06-22 01:47:20.406483 Epoch [496/500], Step [0050/0060], Loss1: -0.9895 Loss2: -0.9846 Loss3: -0.9911\n",
            "2022-06-22 01:47:28.283555 Epoch [496/500], Step [0060/0060], Loss1: -0.9907 Loss2: -0.9888 Loss3: -0.9927\n",
            "Epoch: 496 MAE: 0.07249084735042834 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:47:35.720121 Epoch [497/500], Step [0001/0060], Loss1: -0.9895 Loss2: -0.9856 Loss3: -0.9916\n",
            "2022-06-22 01:48:14.381821 Epoch [497/500], Step [0050/0060], Loss1: -0.9911 Loss2: -0.9877 Loss3: -0.9929\n",
            "2022-06-22 01:48:22.254033 Epoch [497/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9852 Loss3: -0.9922\n",
            "Epoch: 497 MAE: 0.0718588437479009 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:48:29.580730 Epoch [498/500], Step [0001/0060], Loss1: -0.9878 Loss2: -0.9819 Loss3: -0.9899\n",
            "2022-06-22 01:49:08.263101 Epoch [498/500], Step [0050/0060], Loss1: -0.9914 Loss2: -0.9884 Loss3: -0.9928\n",
            "2022-06-22 01:49:16.186235 Epoch [498/500], Step [0060/0060], Loss1: -0.9909 Loss2: -0.9859 Loss3: -0.9926\n",
            "Epoch: 498 MAE: 0.0718723547395575 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n",
            "2022-06-22 01:49:23.681183 Epoch [499/500], Step [0001/0060], Loss1: -0.9923 Loss2: -0.9885 Loss3: -0.9937\n",
            "2022-06-22 01:50:02.568761 Epoch [499/500], Step [0050/0060], Loss1: -0.9898 Loss2: -0.9838 Loss3: -0.9917\n",
            "2022-06-22 01:50:10.457015 Epoch [499/500], Step [0060/0060], Loss1: -0.9887 Loss2: -0.9817 Loss3: -0.9907\n",
            "Epoch: 499 MAE: 0.07331485193242471 ####  bestMAE: 0.06407991323521527 bestEpoch: 48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MSE Loss"
      ],
      "metadata": {
        "id": "aigV_49C8EPw"
      },
      "id": "aigV_49C8EPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9b3f65",
      "metadata": {
        "id": "ce9b3f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b464c9ce322c4deb87401fbdff456e5b",
            "9c3e68ced9594cb793a8ca627c9fee42",
            "0e6ba296fac249f3a937f81c61002381",
            "a420e380786849bd8c93e5c6dcbe5011",
            "2f8e3ac026bd4069a6893ae987e92afa",
            "54c22447de834ff4ba3de2e7f493a719",
            "4e1eb0ce9eb44959b4f452c2f14955b0",
            "7990db7e0dc94f93aae72693e7e26f37",
            "eaba31cb4f9d4afc8d778fa3fea4fbc2",
            "9b2b824c0e434d6683bfa89198bfadda",
            "eb266d83981f4d2597a2bda3c41887a6"
          ]
        },
        "outputId": "c3ccb273-31ab-474f-ae76-38c3695ee78c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b464c9ce322c4deb87401fbdff456e5b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data...\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset_update/RGB/RGB_00.png', '/content/tmp/TrainDataset_update/RGB/RGB_01.png', '/content/tmp/TrainDataset_update/RGB/RGB_02.png', '/content/tmp/TrainDataset_update/RGB/RGB_10.png', '/content/tmp/TrainDataset_update/RGB/RGB_100.png', '/content/tmp/TrainDataset_update/RGB/RGB_101.png', '/content/tmp/TrainDataset_update/RGB/RGB_102.png', '/content/tmp/TrainDataset_update/RGB/RGB_11.png', '/content/tmp/TrainDataset_update/RGB/RGB_110.png', '/content/tmp/TrainDataset_update/RGB/RGB_111.png', '/content/tmp/TrainDataset_update/RGB/RGB_112.png', '/content/tmp/TrainDataset_update/RGB/RGB_12.png', '/content/tmp/TrainDataset_update/RGB/RGB_120.png', '/content/tmp/TrainDataset_update/RGB/RGB_121.png', '/content/tmp/TrainDataset_update/RGB/RGB_122.png', '/content/tmp/TrainDataset_update/RGB/RGB_130.png', '/content/tmp/TrainDataset_update/RGB/RGB_131.png', '/content/tmp/TrainDataset_update/RGB/RGB_132.png', '/content/tmp/TrainDataset_update/RGB/RGB_140.png', '/content/tmp/TrainDataset_update/RGB/RGB_141.png', '/content/tmp/TrainDataset_update/RGB/RGB_142.png', '/content/tmp/TrainDataset_update/RGB/RGB_150.png', '/content/tmp/TrainDataset_update/RGB/RGB_151.png', '/content/tmp/TrainDataset_update/RGB/RGB_152.png', '/content/tmp/TrainDataset_update/RGB/RGB_160.png', '/content/tmp/TrainDataset_update/RGB/RGB_161.png', '/content/tmp/TrainDataset_update/RGB/RGB_162.png', '/content/tmp/TrainDataset_update/RGB/RGB_170.png', '/content/tmp/TrainDataset_update/RGB/RGB_171.png', '/content/tmp/TrainDataset_update/RGB/RGB_172.png', '/content/tmp/TrainDataset_update/RGB/RGB_180.png', '/content/tmp/TrainDataset_update/RGB/RGB_181.png', '/content/tmp/TrainDataset_update/RGB/RGB_182.png', '/content/tmp/TrainDataset_update/RGB/RGB_190.png', '/content/tmp/TrainDataset_update/RGB/RGB_191.png', '/content/tmp/TrainDataset_update/RGB/RGB_192.png', '/content/tmp/TrainDataset_update/RGB/RGB_20.png', '/content/tmp/TrainDataset_update/RGB/RGB_200.png', '/content/tmp/TrainDataset_update/RGB/RGB_201.png', '/content/tmp/TrainDataset_update/RGB/RGB_202.png', '/content/tmp/TrainDataset_update/RGB/RGB_21.png', '/content/tmp/TrainDataset_update/RGB/RGB_210.png', '/content/tmp/TrainDataset_update/RGB/RGB_211.png', '/content/tmp/TrainDataset_update/RGB/RGB_212.png', '/content/tmp/TrainDataset_update/RGB/RGB_22.png', '/content/tmp/TrainDataset_update/RGB/RGB_220.png', '/content/tmp/TrainDataset_update/RGB/RGB_221.png', '/content/tmp/TrainDataset_update/RGB/RGB_222.png', '/content/tmp/TrainDataset_update/RGB/RGB_230.png', '/content/tmp/TrainDataset_update/RGB/RGB_231.png', '/content/tmp/TrainDataset_update/RGB/RGB_232.png', '/content/tmp/TrainDataset_update/RGB/RGB_240.png', '/content/tmp/TrainDataset_update/RGB/RGB_241.png', '/content/tmp/TrainDataset_update/RGB/RGB_242.png', '/content/tmp/TrainDataset_update/RGB/RGB_250.png', '/content/tmp/TrainDataset_update/RGB/RGB_251.png', '/content/tmp/TrainDataset_update/RGB/RGB_252.png', '/content/tmp/TrainDataset_update/RGB/RGB_260.png', '/content/tmp/TrainDataset_update/RGB/RGB_261.png', '/content/tmp/TrainDataset_update/RGB/RGB_262.png', '/content/tmp/TrainDataset_update/RGB/RGB_270.png', '/content/tmp/TrainDataset_update/RGB/RGB_271.png', '/content/tmp/TrainDataset_update/RGB/RGB_272.png', '/content/tmp/TrainDataset_update/RGB/RGB_280.png', '/content/tmp/TrainDataset_update/RGB/RGB_281.png', '/content/tmp/TrainDataset_update/RGB/RGB_282.png', '/content/tmp/TrainDataset_update/RGB/RGB_290.png', '/content/tmp/TrainDataset_update/RGB/RGB_291.png', '/content/tmp/TrainDataset_update/RGB/RGB_292.png', '/content/tmp/TrainDataset_update/RGB/RGB_30.png', '/content/tmp/TrainDataset_update/RGB/RGB_300.png', '/content/tmp/TrainDataset_update/RGB/RGB_301.png', '/content/tmp/TrainDataset_update/RGB/RGB_302.png', '/content/tmp/TrainDataset_update/RGB/RGB_31.png', '/content/tmp/TrainDataset_update/RGB/RGB_310.png', '/content/tmp/TrainDataset_update/RGB/RGB_311.png', '/content/tmp/TrainDataset_update/RGB/RGB_312.png', '/content/tmp/TrainDataset_update/RGB/RGB_32.png', '/content/tmp/TrainDataset_update/RGB/RGB_320.png', '/content/tmp/TrainDataset_update/RGB/RGB_321.png', '/content/tmp/TrainDataset_update/RGB/RGB_322.png', '/content/tmp/TrainDataset_update/RGB/RGB_330.png', '/content/tmp/TrainDataset_update/RGB/RGB_331.png', '/content/tmp/TrainDataset_update/RGB/RGB_332.png', '/content/tmp/TrainDataset_update/RGB/RGB_340.png', '/content/tmp/TrainDataset_update/RGB/RGB_341.png', '/content/tmp/TrainDataset_update/RGB/RGB_342.png', '/content/tmp/TrainDataset_update/RGB/RGB_350.png', '/content/tmp/TrainDataset_update/RGB/RGB_351.png', '/content/tmp/TrainDataset_update/RGB/RGB_352.png', '/content/tmp/TrainDataset_update/RGB/RGB_360.png', '/content/tmp/TrainDataset_update/RGB/RGB_361.png', '/content/tmp/TrainDataset_update/RGB/RGB_362.png', '/content/tmp/TrainDataset_update/RGB/RGB_370.png', '/content/tmp/TrainDataset_update/RGB/RGB_371.png', '/content/tmp/TrainDataset_update/RGB/RGB_372.png', '/content/tmp/TrainDataset_update/RGB/RGB_380.png', '/content/tmp/TrainDataset_update/RGB/RGB_381.png', '/content/tmp/TrainDataset_update/RGB/RGB_382.png', '/content/tmp/TrainDataset_update/RGB/RGB_390.png', '/content/tmp/TrainDataset_update/RGB/RGB_391.png', '/content/tmp/TrainDataset_update/RGB/RGB_392.png', '/content/tmp/TrainDataset_update/RGB/RGB_40.png', '/content/tmp/TrainDataset_update/RGB/RGB_400.png', '/content/tmp/TrainDataset_update/RGB/RGB_401.png', '/content/tmp/TrainDataset_update/RGB/RGB_402.png', '/content/tmp/TrainDataset_update/RGB/RGB_41.png', '/content/tmp/TrainDataset_update/RGB/RGB_410.png', '/content/tmp/TrainDataset_update/RGB/RGB_411.png', '/content/tmp/TrainDataset_update/RGB/RGB_412.png', '/content/tmp/TrainDataset_update/RGB/RGB_42.png', '/content/tmp/TrainDataset_update/RGB/RGB_420.png', '/content/tmp/TrainDataset_update/RGB/RGB_421.png', '/content/tmp/TrainDataset_update/RGB/RGB_422.png', '/content/tmp/TrainDataset_update/RGB/RGB_430.png', '/content/tmp/TrainDataset_update/RGB/RGB_431.png', '/content/tmp/TrainDataset_update/RGB/RGB_432.png', '/content/tmp/TrainDataset_update/RGB/RGB_440.png', '/content/tmp/TrainDataset_update/RGB/RGB_441.png', '/content/tmp/TrainDataset_update/RGB/RGB_442.png', '/content/tmp/TrainDataset_update/RGB/RGB_450.png', '/content/tmp/TrainDataset_update/RGB/RGB_451.png', '/content/tmp/TrainDataset_update/RGB/RGB_452.png', '/content/tmp/TrainDataset_update/RGB/RGB_460.png', '/content/tmp/TrainDataset_update/RGB/RGB_461.png', '/content/tmp/TrainDataset_update/RGB/RGB_462.png', '/content/tmp/TrainDataset_update/RGB/RGB_470.png', '/content/tmp/TrainDataset_update/RGB/RGB_471.png', '/content/tmp/TrainDataset_update/RGB/RGB_472.png', '/content/tmp/TrainDataset_update/RGB/RGB_480.png', '/content/tmp/TrainDataset_update/RGB/RGB_481.png', '/content/tmp/TrainDataset_update/RGB/RGB_482.png', '/content/tmp/TrainDataset_update/RGB/RGB_490.png', '/content/tmp/TrainDataset_update/RGB/RGB_491.png', '/content/tmp/TrainDataset_update/RGB/RGB_492.png', '/content/tmp/TrainDataset_update/RGB/RGB_50.png', '/content/tmp/TrainDataset_update/RGB/RGB_500.png', '/content/tmp/TrainDataset_update/RGB/RGB_501.png', '/content/tmp/TrainDataset_update/RGB/RGB_502.png', '/content/tmp/TrainDataset_update/RGB/RGB_51.png', '/content/tmp/TrainDataset_update/RGB/RGB_510.png', '/content/tmp/TrainDataset_update/RGB/RGB_511.png', '/content/tmp/TrainDataset_update/RGB/RGB_512.png', '/content/tmp/TrainDataset_update/RGB/RGB_52.png', '/content/tmp/TrainDataset_update/RGB/RGB_520.png', '/content/tmp/TrainDataset_update/RGB/RGB_521.png', '/content/tmp/TrainDataset_update/RGB/RGB_522.png', '/content/tmp/TrainDataset_update/RGB/RGB_530.png', '/content/tmp/TrainDataset_update/RGB/RGB_531.png', '/content/tmp/TrainDataset_update/RGB/RGB_532.png', '/content/tmp/TrainDataset_update/RGB/RGB_540.png', '/content/tmp/TrainDataset_update/RGB/RGB_541.png', '/content/tmp/TrainDataset_update/RGB/RGB_542.png', '/content/tmp/TrainDataset_update/RGB/RGB_550.png', '/content/tmp/TrainDataset_update/RGB/RGB_551.png', '/content/tmp/TrainDataset_update/RGB/RGB_552.png', '/content/tmp/TrainDataset_update/RGB/RGB_560.png', '/content/tmp/TrainDataset_update/RGB/RGB_561.png', '/content/tmp/TrainDataset_update/RGB/RGB_562.png', '/content/tmp/TrainDataset_update/RGB/RGB_570.png', '/content/tmp/TrainDataset_update/RGB/RGB_571.png', '/content/tmp/TrainDataset_update/RGB/RGB_572.png', '/content/tmp/TrainDataset_update/RGB/RGB_580.png', '/content/tmp/TrainDataset_update/RGB/RGB_581.png', '/content/tmp/TrainDataset_update/RGB/RGB_582.png', '/content/tmp/TrainDataset_update/RGB/RGB_590.png', '/content/tmp/TrainDataset_update/RGB/RGB_591.png', '/content/tmp/TrainDataset_update/RGB/RGB_592.png', '/content/tmp/TrainDataset_update/RGB/RGB_60.png', '/content/tmp/TrainDataset_update/RGB/RGB_600.png', '/content/tmp/TrainDataset_update/RGB/RGB_601.png', '/content/tmp/TrainDataset_update/RGB/RGB_602.png', '/content/tmp/TrainDataset_update/RGB/RGB_61.png', '/content/tmp/TrainDataset_update/RGB/RGB_610.png', '/content/tmp/TrainDataset_update/RGB/RGB_611.png', '/content/tmp/TrainDataset_update/RGB/RGB_612.png', '/content/tmp/TrainDataset_update/RGB/RGB_62.png', '/content/tmp/TrainDataset_update/RGB/RGB_620.png', '/content/tmp/TrainDataset_update/RGB/RGB_621.png', '/content/tmp/TrainDataset_update/RGB/RGB_622.png', '/content/tmp/TrainDataset_update/RGB/RGB_630.png', '/content/tmp/TrainDataset_update/RGB/RGB_631.png', '/content/tmp/TrainDataset_update/RGB/RGB_632.png', '/content/tmp/TrainDataset_update/RGB/RGB_640.png', '/content/tmp/TrainDataset_update/RGB/RGB_641.png', '/content/tmp/TrainDataset_update/RGB/RGB_642.png', '/content/tmp/TrainDataset_update/RGB/RGB_650.png', '/content/tmp/TrainDataset_update/RGB/RGB_651.png', '/content/tmp/TrainDataset_update/RGB/RGB_652.png', '/content/tmp/TrainDataset_update/RGB/RGB_660.png', '/content/tmp/TrainDataset_update/RGB/RGB_661.png', '/content/tmp/TrainDataset_update/RGB/RGB_662.png', '/content/tmp/TrainDataset_update/RGB/RGB_670.png', '/content/tmp/TrainDataset_update/RGB/RGB_671.png', '/content/tmp/TrainDataset_update/RGB/RGB_672.png', '/content/tmp/TrainDataset_update/RGB/RGB_680.png', '/content/tmp/TrainDataset_update/RGB/RGB_681.png', '/content/tmp/TrainDataset_update/RGB/RGB_682.png', '/content/tmp/TrainDataset_update/RGB/RGB_690.png', '/content/tmp/TrainDataset_update/RGB/RGB_691.png', '/content/tmp/TrainDataset_update/RGB/RGB_692.png', '/content/tmp/TrainDataset_update/RGB/RGB_70.png', '/content/tmp/TrainDataset_update/RGB/RGB_700.png', '/content/tmp/TrainDataset_update/RGB/RGB_701.png', '/content/tmp/TrainDataset_update/RGB/RGB_702.png', '/content/tmp/TrainDataset_update/RGB/RGB_71.png', '/content/tmp/TrainDataset_update/RGB/RGB_710.png', '/content/tmp/TrainDataset_update/RGB/RGB_711.png', '/content/tmp/TrainDataset_update/RGB/RGB_712.png', '/content/tmp/TrainDataset_update/RGB/RGB_72.png', '/content/tmp/TrainDataset_update/RGB/RGB_720.png', '/content/tmp/TrainDataset_update/RGB/RGB_721.png', '/content/tmp/TrainDataset_update/RGB/RGB_722.png', '/content/tmp/TrainDataset_update/RGB/RGB_730.png', '/content/tmp/TrainDataset_update/RGB/RGB_731.png', '/content/tmp/TrainDataset_update/RGB/RGB_732.png', '/content/tmp/TrainDataset_update/RGB/RGB_740.png', '/content/tmp/TrainDataset_update/RGB/RGB_741.png', '/content/tmp/TrainDataset_update/RGB/RGB_742.png', '/content/tmp/TrainDataset_update/RGB/RGB_750.png', '/content/tmp/TrainDataset_update/RGB/RGB_751.png', '/content/tmp/TrainDataset_update/RGB/RGB_752.png', '/content/tmp/TrainDataset_update/RGB/RGB_760.png', '/content/tmp/TrainDataset_update/RGB/RGB_761.png', '/content/tmp/TrainDataset_update/RGB/RGB_762.png', '/content/tmp/TrainDataset_update/RGB/RGB_770.png', '/content/tmp/TrainDataset_update/RGB/RGB_771.png', '/content/tmp/TrainDataset_update/RGB/RGB_772.png', '/content/tmp/TrainDataset_update/RGB/RGB_780.png', '/content/tmp/TrainDataset_update/RGB/RGB_781.png', '/content/tmp/TrainDataset_update/RGB/RGB_782.png', '/content/tmp/TrainDataset_update/RGB/RGB_790.png', '/content/tmp/TrainDataset_update/RGB/RGB_791.png', '/content/tmp/TrainDataset_update/RGB/RGB_792.png', '/content/tmp/TrainDataset_update/RGB/RGB_80.png', '/content/tmp/TrainDataset_update/RGB/RGB_81.png', '/content/tmp/TrainDataset_update/RGB/RGB_82.png', '/content/tmp/TrainDataset_update/RGB/RGB_90.png', '/content/tmp/TrainDataset_update/RGB/RGB_91.png', '/content/tmp/TrainDataset_update/RGB/RGB_92.png'] ['/content/tmp/TrainDataset_update/GT/GT_00.png', '/content/tmp/TrainDataset_update/GT/GT_01.png', '/content/tmp/TrainDataset_update/GT/GT_02.png', '/content/tmp/TrainDataset_update/GT/GT_10.png', '/content/tmp/TrainDataset_update/GT/GT_100.png', '/content/tmp/TrainDataset_update/GT/GT_101.png', '/content/tmp/TrainDataset_update/GT/GT_102.png', '/content/tmp/TrainDataset_update/GT/GT_11.png', '/content/tmp/TrainDataset_update/GT/GT_110.png', '/content/tmp/TrainDataset_update/GT/GT_111.png', '/content/tmp/TrainDataset_update/GT/GT_112.png', '/content/tmp/TrainDataset_update/GT/GT_12.png', '/content/tmp/TrainDataset_update/GT/GT_120.png', '/content/tmp/TrainDataset_update/GT/GT_121.png', '/content/tmp/TrainDataset_update/GT/GT_122.png', '/content/tmp/TrainDataset_update/GT/GT_130.png', '/content/tmp/TrainDataset_update/GT/GT_131.png', '/content/tmp/TrainDataset_update/GT/GT_132.png', '/content/tmp/TrainDataset_update/GT/GT_140.png', '/content/tmp/TrainDataset_update/GT/GT_141.png', '/content/tmp/TrainDataset_update/GT/GT_142.png', '/content/tmp/TrainDataset_update/GT/GT_150.png', '/content/tmp/TrainDataset_update/GT/GT_151.png', '/content/tmp/TrainDataset_update/GT/GT_152.png', '/content/tmp/TrainDataset_update/GT/GT_160.png', '/content/tmp/TrainDataset_update/GT/GT_161.png', '/content/tmp/TrainDataset_update/GT/GT_162.png', '/content/tmp/TrainDataset_update/GT/GT_170.png', '/content/tmp/TrainDataset_update/GT/GT_171.png', '/content/tmp/TrainDataset_update/GT/GT_172.png', '/content/tmp/TrainDataset_update/GT/GT_180.png', '/content/tmp/TrainDataset_update/GT/GT_181.png', '/content/tmp/TrainDataset_update/GT/GT_182.png', '/content/tmp/TrainDataset_update/GT/GT_190.png', '/content/tmp/TrainDataset_update/GT/GT_191.png', '/content/tmp/TrainDataset_update/GT/GT_192.png', '/content/tmp/TrainDataset_update/GT/GT_20.png', '/content/tmp/TrainDataset_update/GT/GT_200.png', '/content/tmp/TrainDataset_update/GT/GT_201.png', '/content/tmp/TrainDataset_update/GT/GT_202.png', '/content/tmp/TrainDataset_update/GT/GT_21.png', '/content/tmp/TrainDataset_update/GT/GT_210.png', '/content/tmp/TrainDataset_update/GT/GT_211.png', '/content/tmp/TrainDataset_update/GT/GT_212.png', '/content/tmp/TrainDataset_update/GT/GT_22.png', '/content/tmp/TrainDataset_update/GT/GT_220.png', '/content/tmp/TrainDataset_update/GT/GT_221.png', '/content/tmp/TrainDataset_update/GT/GT_222.png', '/content/tmp/TrainDataset_update/GT/GT_230.png', '/content/tmp/TrainDataset_update/GT/GT_231.png', '/content/tmp/TrainDataset_update/GT/GT_232.png', '/content/tmp/TrainDataset_update/GT/GT_240.png', '/content/tmp/TrainDataset_update/GT/GT_241.png', '/content/tmp/TrainDataset_update/GT/GT_242.png', '/content/tmp/TrainDataset_update/GT/GT_250.png', '/content/tmp/TrainDataset_update/GT/GT_251.png', '/content/tmp/TrainDataset_update/GT/GT_252.png', '/content/tmp/TrainDataset_update/GT/GT_260.png', '/content/tmp/TrainDataset_update/GT/GT_261.png', '/content/tmp/TrainDataset_update/GT/GT_262.png', '/content/tmp/TrainDataset_update/GT/GT_270.png', '/content/tmp/TrainDataset_update/GT/GT_271.png', '/content/tmp/TrainDataset_update/GT/GT_272.png', '/content/tmp/TrainDataset_update/GT/GT_280.png', '/content/tmp/TrainDataset_update/GT/GT_281.png', '/content/tmp/TrainDataset_update/GT/GT_282.png', '/content/tmp/TrainDataset_update/GT/GT_290.png', '/content/tmp/TrainDataset_update/GT/GT_291.png', '/content/tmp/TrainDataset_update/GT/GT_292.png', '/content/tmp/TrainDataset_update/GT/GT_30.png', '/content/tmp/TrainDataset_update/GT/GT_300.png', '/content/tmp/TrainDataset_update/GT/GT_301.png', '/content/tmp/TrainDataset_update/GT/GT_302.png', '/content/tmp/TrainDataset_update/GT/GT_31.png', '/content/tmp/TrainDataset_update/GT/GT_310.png', '/content/tmp/TrainDataset_update/GT/GT_311.png', '/content/tmp/TrainDataset_update/GT/GT_312.png', '/content/tmp/TrainDataset_update/GT/GT_32.png', '/content/tmp/TrainDataset_update/GT/GT_320.png', '/content/tmp/TrainDataset_update/GT/GT_321.png', '/content/tmp/TrainDataset_update/GT/GT_322.png', '/content/tmp/TrainDataset_update/GT/GT_330.png', '/content/tmp/TrainDataset_update/GT/GT_331.png', '/content/tmp/TrainDataset_update/GT/GT_332.png', '/content/tmp/TrainDataset_update/GT/GT_340.png', '/content/tmp/TrainDataset_update/GT/GT_341.png', '/content/tmp/TrainDataset_update/GT/GT_342.png', '/content/tmp/TrainDataset_update/GT/GT_350.png', '/content/tmp/TrainDataset_update/GT/GT_351.png', '/content/tmp/TrainDataset_update/GT/GT_352.png', '/content/tmp/TrainDataset_update/GT/GT_360.png', '/content/tmp/TrainDataset_update/GT/GT_361.png', '/content/tmp/TrainDataset_update/GT/GT_362.png', '/content/tmp/TrainDataset_update/GT/GT_370.png', '/content/tmp/TrainDataset_update/GT/GT_371.png', '/content/tmp/TrainDataset_update/GT/GT_372.png', '/content/tmp/TrainDataset_update/GT/GT_380.png', '/content/tmp/TrainDataset_update/GT/GT_381.png', '/content/tmp/TrainDataset_update/GT/GT_382.png', '/content/tmp/TrainDataset_update/GT/GT_390.png', '/content/tmp/TrainDataset_update/GT/GT_391.png', '/content/tmp/TrainDataset_update/GT/GT_392.png', '/content/tmp/TrainDataset_update/GT/GT_40.png', '/content/tmp/TrainDataset_update/GT/GT_400.png', '/content/tmp/TrainDataset_update/GT/GT_401.png', '/content/tmp/TrainDataset_update/GT/GT_402.png', '/content/tmp/TrainDataset_update/GT/GT_41.png', '/content/tmp/TrainDataset_update/GT/GT_410.png', '/content/tmp/TrainDataset_update/GT/GT_411.png', '/content/tmp/TrainDataset_update/GT/GT_412.png', '/content/tmp/TrainDataset_update/GT/GT_42.png', '/content/tmp/TrainDataset_update/GT/GT_420.png', '/content/tmp/TrainDataset_update/GT/GT_421.png', '/content/tmp/TrainDataset_update/GT/GT_422.png', '/content/tmp/TrainDataset_update/GT/GT_430.png', '/content/tmp/TrainDataset_update/GT/GT_431.png', '/content/tmp/TrainDataset_update/GT/GT_432.png', '/content/tmp/TrainDataset_update/GT/GT_440.png', '/content/tmp/TrainDataset_update/GT/GT_441.png', '/content/tmp/TrainDataset_update/GT/GT_442.png', '/content/tmp/TrainDataset_update/GT/GT_450.png', '/content/tmp/TrainDataset_update/GT/GT_451.png', '/content/tmp/TrainDataset_update/GT/GT_452.png', '/content/tmp/TrainDataset_update/GT/GT_460.png', '/content/tmp/TrainDataset_update/GT/GT_461.png', '/content/tmp/TrainDataset_update/GT/GT_462.png', '/content/tmp/TrainDataset_update/GT/GT_470.png', '/content/tmp/TrainDataset_update/GT/GT_471.png', '/content/tmp/TrainDataset_update/GT/GT_472.png', '/content/tmp/TrainDataset_update/GT/GT_480.png', '/content/tmp/TrainDataset_update/GT/GT_481.png', '/content/tmp/TrainDataset_update/GT/GT_482.png', '/content/tmp/TrainDataset_update/GT/GT_490.png', '/content/tmp/TrainDataset_update/GT/GT_491.png', '/content/tmp/TrainDataset_update/GT/GT_492.png', '/content/tmp/TrainDataset_update/GT/GT_50.png', '/content/tmp/TrainDataset_update/GT/GT_500.png', '/content/tmp/TrainDataset_update/GT/GT_501.png', '/content/tmp/TrainDataset_update/GT/GT_502.png', '/content/tmp/TrainDataset_update/GT/GT_51.png', '/content/tmp/TrainDataset_update/GT/GT_510.png', '/content/tmp/TrainDataset_update/GT/GT_511.png', '/content/tmp/TrainDataset_update/GT/GT_512.png', '/content/tmp/TrainDataset_update/GT/GT_52.png', '/content/tmp/TrainDataset_update/GT/GT_520.png', '/content/tmp/TrainDataset_update/GT/GT_521.png', '/content/tmp/TrainDataset_update/GT/GT_522.png', '/content/tmp/TrainDataset_update/GT/GT_530.png', '/content/tmp/TrainDataset_update/GT/GT_531.png', '/content/tmp/TrainDataset_update/GT/GT_532.png', '/content/tmp/TrainDataset_update/GT/GT_540.png', '/content/tmp/TrainDataset_update/GT/GT_541.png', '/content/tmp/TrainDataset_update/GT/GT_542.png', '/content/tmp/TrainDataset_update/GT/GT_550.png', '/content/tmp/TrainDataset_update/GT/GT_551.png', '/content/tmp/TrainDataset_update/GT/GT_552.png', '/content/tmp/TrainDataset_update/GT/GT_560.png', '/content/tmp/TrainDataset_update/GT/GT_561.png', '/content/tmp/TrainDataset_update/GT/GT_562.png', '/content/tmp/TrainDataset_update/GT/GT_570.png', '/content/tmp/TrainDataset_update/GT/GT_571.png', '/content/tmp/TrainDataset_update/GT/GT_572.png', '/content/tmp/TrainDataset_update/GT/GT_580.png', '/content/tmp/TrainDataset_update/GT/GT_581.png', '/content/tmp/TrainDataset_update/GT/GT_582.png', '/content/tmp/TrainDataset_update/GT/GT_590.png', '/content/tmp/TrainDataset_update/GT/GT_591.png', '/content/tmp/TrainDataset_update/GT/GT_592.png', '/content/tmp/TrainDataset_update/GT/GT_60.png', '/content/tmp/TrainDataset_update/GT/GT_600.png', '/content/tmp/TrainDataset_update/GT/GT_601.png', '/content/tmp/TrainDataset_update/GT/GT_602.png', '/content/tmp/TrainDataset_update/GT/GT_61.png', '/content/tmp/TrainDataset_update/GT/GT_610.png', '/content/tmp/TrainDataset_update/GT/GT_611.png', '/content/tmp/TrainDataset_update/GT/GT_612.png', '/content/tmp/TrainDataset_update/GT/GT_62.png', '/content/tmp/TrainDataset_update/GT/GT_620.png', '/content/tmp/TrainDataset_update/GT/GT_621.png', '/content/tmp/TrainDataset_update/GT/GT_622.png', '/content/tmp/TrainDataset_update/GT/GT_630.png', '/content/tmp/TrainDataset_update/GT/GT_631.png', '/content/tmp/TrainDataset_update/GT/GT_632.png', '/content/tmp/TrainDataset_update/GT/GT_640.png', '/content/tmp/TrainDataset_update/GT/GT_641.png', '/content/tmp/TrainDataset_update/GT/GT_642.png', '/content/tmp/TrainDataset_update/GT/GT_650.png', '/content/tmp/TrainDataset_update/GT/GT_651.png', '/content/tmp/TrainDataset_update/GT/GT_652.png', '/content/tmp/TrainDataset_update/GT/GT_660.png', '/content/tmp/TrainDataset_update/GT/GT_661.png', '/content/tmp/TrainDataset_update/GT/GT_662.png', '/content/tmp/TrainDataset_update/GT/GT_670.png', '/content/tmp/TrainDataset_update/GT/GT_671.png', '/content/tmp/TrainDataset_update/GT/GT_672.png', '/content/tmp/TrainDataset_update/GT/GT_680.png', '/content/tmp/TrainDataset_update/GT/GT_681.png', '/content/tmp/TrainDataset_update/GT/GT_682.png', '/content/tmp/TrainDataset_update/GT/GT_690.png', '/content/tmp/TrainDataset_update/GT/GT_691.png', '/content/tmp/TrainDataset_update/GT/GT_692.png', '/content/tmp/TrainDataset_update/GT/GT_70.png', '/content/tmp/TrainDataset_update/GT/GT_700.png', '/content/tmp/TrainDataset_update/GT/GT_701.png', '/content/tmp/TrainDataset_update/GT/GT_702.png', '/content/tmp/TrainDataset_update/GT/GT_71.png', '/content/tmp/TrainDataset_update/GT/GT_710.png', '/content/tmp/TrainDataset_update/GT/GT_711.png', '/content/tmp/TrainDataset_update/GT/GT_712.png', '/content/tmp/TrainDataset_update/GT/GT_72.png', '/content/tmp/TrainDataset_update/GT/GT_720.png', '/content/tmp/TrainDataset_update/GT/GT_721.png', '/content/tmp/TrainDataset_update/GT/GT_722.png', '/content/tmp/TrainDataset_update/GT/GT_730.png', '/content/tmp/TrainDataset_update/GT/GT_731.png', '/content/tmp/TrainDataset_update/GT/GT_732.png', '/content/tmp/TrainDataset_update/GT/GT_740.png', '/content/tmp/TrainDataset_update/GT/GT_741.png', '/content/tmp/TrainDataset_update/GT/GT_742.png', '/content/tmp/TrainDataset_update/GT/GT_750.png', '/content/tmp/TrainDataset_update/GT/GT_751.png', '/content/tmp/TrainDataset_update/GT/GT_752.png', '/content/tmp/TrainDataset_update/GT/GT_760.png', '/content/tmp/TrainDataset_update/GT/GT_761.png', '/content/tmp/TrainDataset_update/GT/GT_762.png', '/content/tmp/TrainDataset_update/GT/GT_770.png', '/content/tmp/TrainDataset_update/GT/GT_771.png', '/content/tmp/TrainDataset_update/GT/GT_772.png', '/content/tmp/TrainDataset_update/GT/GT_780.png', '/content/tmp/TrainDataset_update/GT/GT_781.png', '/content/tmp/TrainDataset_update/GT/GT_782.png', '/content/tmp/TrainDataset_update/GT/GT_790.png', '/content/tmp/TrainDataset_update/GT/GT_791.png', '/content/tmp/TrainDataset_update/GT/GT_792.png', '/content/tmp/TrainDataset_update/GT/GT_80.png', '/content/tmp/TrainDataset_update/GT/GT_81.png', '/content/tmp/TrainDataset_update/GT/GT_82.png', '/content/tmp/TrainDataset_update/GT/GT_90.png', '/content/tmp/TrainDataset_update/GT/GT_91.png', '/content/tmp/TrainDataset_update/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f66cdc8aed0>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60\n",
            "Start train...\n",
            "2022-06-09 18:47:34.722714 Epoch [001/030], Step [0001/0060], Loss1: 0.3909 Loss2: 0.2552 Loss3: 0.8783\n",
            "2022-06-09 18:48:02.234132 Epoch [001/030], Step [0050/0060], Loss1: 0.0278 Loss2: 0.0169 Loss3: 0.0153\n",
            "2022-06-09 18:48:07.775465 Epoch [001/030], Step [0060/0060], Loss1: 0.0228 Loss2: 0.0110 Loss3: 0.0086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.3358296906001985 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-09 18:48:18.758026 Epoch [002/030], Step [0001/0060], Loss1: 0.0212 Loss2: 0.0122 Loss3: 0.0095\n",
            "2022-06-09 18:48:46.062448 Epoch [002/030], Step [0050/0060], Loss1: 0.0181 Loss2: 0.0083 Loss3: 0.0077\n",
            "2022-06-09 18:48:51.609186 Epoch [002/030], Step [0060/0060], Loss1: 0.0212 Loss2: 0.0084 Loss3: 0.0077\n",
            "Epoch: 2 MAE: 0.3004963377291564 ####  bestMAE: 0.3358296906001985 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-09 18:49:08.158854 Epoch [003/030], Step [0001/0060], Loss1: 0.0170 Loss2: 0.0090 Loss3: 0.0089\n",
            "2022-06-09 18:49:36.445724 Epoch [003/030], Step [0050/0060], Loss1: 0.0117 Loss2: 0.0060 Loss3: 0.0059\n",
            "2022-06-09 18:49:41.972051 Epoch [003/030], Step [0060/0060], Loss1: 0.0124 Loss2: 0.0064 Loss3: 0.0057\n",
            "Epoch: 3 MAE: 0.2545958770267548 ####  bestMAE: 0.3004963377291564 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-06-09 18:49:51.962349 Epoch [004/030], Step [0001/0060], Loss1: 0.0111 Loss2: 0.0054 Loss3: 0.0048\n",
            "2022-06-09 18:50:20.383813 Epoch [004/030], Step [0050/0060], Loss1: 0.0101 Loss2: 0.0048 Loss3: 0.0042\n",
            "2022-06-09 18:50:25.904458 Epoch [004/030], Step [0060/0060], Loss1: 0.0109 Loss2: 0.0073 Loss3: 0.0072\n",
            "Epoch: 4 MAE: 0.20531412134725582 ####  bestMAE: 0.2545958770267548 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-06-09 18:50:37.230465 Epoch [005/030], Step [0001/0060], Loss1: 0.0116 Loss2: 0.0063 Loss3: 0.0052\n",
            "2022-06-09 18:51:05.326497 Epoch [005/030], Step [0050/0060], Loss1: 0.0109 Loss2: 0.0057 Loss3: 0.0044\n",
            "2022-06-09 18:51:10.884866 Epoch [005/030], Step [0060/0060], Loss1: 0.0090 Loss2: 0.0053 Loss3: 0.0045\n",
            "Epoch: 5 MAE: 0.21536987728542745 ####  bestMAE: 0.20531412134725582 bestEpoch: 4\n",
            "2022-06-09 18:51:21.312623 Epoch [006/030], Step [0001/0060], Loss1: 0.0094 Loss2: 0.0051 Loss3: 0.0044\n",
            "2022-06-09 18:51:49.517679 Epoch [006/030], Step [0050/0060], Loss1: 0.0100 Loss2: 0.0047 Loss3: 0.0045\n",
            "2022-06-09 18:51:55.067447 Epoch [006/030], Step [0060/0060], Loss1: 0.0082 Loss2: 0.0038 Loss3: 0.0036\n",
            "Epoch: 6 MAE: 0.1998163083999876 ####  bestMAE: 0.20531412134725582 bestEpoch: 4\n",
            "best epoch:6\n",
            "2022-06-09 18:52:05.220696 Epoch [007/030], Step [0001/0060], Loss1: 0.0098 Loss2: 0.0044 Loss3: 0.0040\n",
            "2022-06-09 18:52:33.957021 Epoch [007/030], Step [0050/0060], Loss1: 0.0073 Loss2: 0.0045 Loss3: 0.0036\n",
            "2022-06-09 18:52:39.532867 Epoch [007/030], Step [0060/0060], Loss1: 0.0059 Loss2: 0.0037 Loss3: 0.0028\n",
            "Epoch: 7 MAE: 0.1687258154248435 ####  bestMAE: 0.1998163083999876 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-06-09 18:52:49.715758 Epoch [008/030], Step [0001/0060], Loss1: 0.0089 Loss2: 0.0041 Loss3: 0.0034\n",
            "2022-06-09 18:53:18.250289 Epoch [008/030], Step [0050/0060], Loss1: 0.0065 Loss2: 0.0036 Loss3: 0.0031\n",
            "2022-06-09 18:53:23.807102 Epoch [008/030], Step [0060/0060], Loss1: 0.0082 Loss2: 0.0039 Loss3: 0.0031\n",
            "Epoch: 8 MAE: 0.16433315196365278 ####  bestMAE: 0.1687258154248435 bestEpoch: 7\n",
            "best epoch:8\n",
            "2022-06-09 18:53:33.978181 Epoch [009/030], Step [0001/0060], Loss1: 0.0083 Loss2: 0.0040 Loss3: 0.0031\n",
            "2022-06-09 18:54:02.452766 Epoch [009/030], Step [0050/0060], Loss1: 0.0061 Loss2: 0.0033 Loss3: 0.0029\n",
            "2022-06-09 18:54:07.991588 Epoch [009/030], Step [0060/0060], Loss1: 0.0069 Loss2: 0.0035 Loss3: 0.0031\n",
            "Epoch: 9 MAE: 0.17053790642470906 ####  bestMAE: 0.16433315196365278 bestEpoch: 8\n",
            "2022-06-09 18:54:15.430999 Epoch [010/030], Step [0001/0060], Loss1: 0.0066 Loss2: 0.0034 Loss3: 0.0029\n",
            "2022-06-09 18:54:42.866357 Epoch [010/030], Step [0050/0060], Loss1: 0.0066 Loss2: 0.0032 Loss3: 0.0027\n",
            "2022-06-09 18:54:48.388439 Epoch [010/030], Step [0060/0060], Loss1: 0.0054 Loss2: 0.0030 Loss3: 0.0028\n",
            "Epoch: 10 MAE: 0.16179683241263898 ####  bestMAE: 0.16433315196365278 bestEpoch: 8\n",
            "best epoch:10\n",
            "2022-06-09 18:55:01.401810 Epoch [011/030], Step [0001/0060], Loss1: 0.0056 Loss2: 0.0031 Loss3: 0.0026\n",
            "2022-06-09 18:55:30.728680 Epoch [011/030], Step [0050/0060], Loss1: 0.0049 Loss2: 0.0030 Loss3: 0.0022\n",
            "2022-06-09 18:55:36.249073 Epoch [011/030], Step [0060/0060], Loss1: 0.0065 Loss2: 0.0033 Loss3: 0.0026\n",
            "Epoch: 11 MAE: 0.1590661384945824 ####  bestMAE: 0.16179683241263898 bestEpoch: 10\n",
            "best epoch:11\n",
            "2022-06-09 18:55:46.202996 Epoch [012/030], Step [0001/0060], Loss1: 0.0056 Loss2: 0.0026 Loss3: 0.0028\n",
            "2022-06-09 18:56:14.696042 Epoch [012/030], Step [0050/0060], Loss1: 0.0070 Loss2: 0.0048 Loss3: 0.0046\n",
            "2022-06-09 18:56:20.228528 Epoch [012/030], Step [0060/0060], Loss1: 0.0055 Loss2: 0.0030 Loss3: 0.0025\n",
            "Epoch: 12 MAE: 0.15797445488985257 ####  bestMAE: 0.1590661384945824 bestEpoch: 11\n",
            "best epoch:12\n",
            "2022-06-09 18:56:30.493806 Epoch [013/030], Step [0001/0060], Loss1: 0.0064 Loss2: 0.0030 Loss3: 0.0028\n",
            "2022-06-09 18:56:58.552950 Epoch [013/030], Step [0050/0060], Loss1: 0.0056 Loss2: 0.0032 Loss3: 0.0030\n",
            "2022-06-09 18:57:04.118614 Epoch [013/030], Step [0060/0060], Loss1: 0.0057 Loss2: 0.0028 Loss3: 0.0024\n",
            "Epoch: 13 MAE: 0.14003441926663518 ####  bestMAE: 0.15797445488985257 bestEpoch: 12\n",
            "best epoch:13\n",
            "2022-06-09 18:57:14.198288 Epoch [014/030], Step [0001/0060], Loss1: 0.0071 Loss2: 0.0030 Loss3: 0.0026\n",
            "2022-06-09 18:57:42.585696 Epoch [014/030], Step [0050/0060], Loss1: 0.0051 Loss2: 0.0028 Loss3: 0.0022\n",
            "2022-06-09 18:57:48.182467 Epoch [014/030], Step [0060/0060], Loss1: 0.0050 Loss2: 0.0030 Loss3: 0.0023\n",
            "Epoch: 14 MAE: 0.14964600457085506 ####  bestMAE: 0.14003441926663518 bestEpoch: 13\n",
            "2022-06-09 18:57:55.846734 Epoch [015/030], Step [0001/0060], Loss1: 0.0057 Loss2: 0.0030 Loss3: 0.0024\n",
            "2022-06-09 18:58:23.422986 Epoch [015/030], Step [0050/0060], Loss1: 0.0061 Loss2: 0.0030 Loss3: 0.0025\n",
            "2022-06-09 18:58:28.981703 Epoch [015/030], Step [0060/0060], Loss1: 0.0056 Loss2: 0.0035 Loss3: 0.0025\n",
            "Epoch: 15 MAE: 0.14151338637821256 ####  bestMAE: 0.14003441926663518 bestEpoch: 13\n",
            "2022-06-09 18:58:39.385426 Epoch [016/030], Step [0001/0060], Loss1: 0.0057 Loss2: 0.0028 Loss3: 0.0024\n",
            "2022-06-09 18:59:08.176668 Epoch [016/030], Step [0050/0060], Loss1: 0.0063 Loss2: 0.0031 Loss3: 0.0025\n",
            "2022-06-09 18:59:13.741044 Epoch [016/030], Step [0060/0060], Loss1: 0.0057 Loss2: 0.0033 Loss3: 0.0023\n",
            "Epoch: 16 MAE: 0.1422732112016628 ####  bestMAE: 0.14003441926663518 bestEpoch: 13\n",
            "2022-06-09 18:59:21.460483 Epoch [017/030], Step [0001/0060], Loss1: 0.0052 Loss2: 0.0035 Loss3: 0.0026\n",
            "2022-06-09 18:59:48.950125 Epoch [017/030], Step [0050/0060], Loss1: 0.0060 Loss2: 0.0030 Loss3: 0.0024\n",
            "2022-06-09 18:59:54.544234 Epoch [017/030], Step [0060/0060], Loss1: 0.0055 Loss2: 0.0027 Loss3: 0.0022\n",
            "Epoch: 17 MAE: 0.13721161070324123 ####  bestMAE: 0.14003441926663518 bestEpoch: 13\n",
            "best epoch:17\n",
            "2022-06-09 19:00:04.668532 Epoch [018/030], Step [0001/0060], Loss1: 0.0040 Loss2: 0.0020 Loss3: 0.0018\n",
            "2022-06-09 19:00:33.242007 Epoch [018/030], Step [0050/0060], Loss1: 0.0047 Loss2: 0.0024 Loss3: 0.0020\n",
            "2022-06-09 19:00:38.838776 Epoch [018/030], Step [0060/0060], Loss1: 0.0042 Loss2: 0.0026 Loss3: 0.0022\n",
            "Epoch: 18 MAE: 0.138773270056992 ####  bestMAE: 0.13721161070324123 bestEpoch: 17\n",
            "2022-06-09 19:00:46.305178 Epoch [019/030], Step [0001/0060], Loss1: 0.0048 Loss2: 0.0029 Loss3: 0.0024\n",
            "2022-06-09 19:01:13.681698 Epoch [019/030], Step [0050/0060], Loss1: 0.0054 Loss2: 0.0034 Loss3: 0.0027\n",
            "2022-06-09 19:01:19.222705 Epoch [019/030], Step [0060/0060], Loss1: 0.0046 Loss2: 0.0025 Loss3: 0.0021\n",
            "Epoch: 19 MAE: 0.1369803136997122 ####  bestMAE: 0.13721161070324123 bestEpoch: 17\n",
            "best epoch:19\n",
            "2022-06-09 19:01:29.319505 Epoch [020/030], Step [0001/0060], Loss1: 0.0042 Loss2: 0.0023 Loss3: 0.0020\n",
            "2022-06-09 19:01:57.909816 Epoch [020/030], Step [0050/0060], Loss1: 0.0060 Loss2: 0.0029 Loss3: 0.0024\n",
            "2022-06-09 19:02:03.478227 Epoch [020/030], Step [0060/0060], Loss1: 0.0062 Loss2: 0.0027 Loss3: 0.0023\n",
            "Epoch: 20 MAE: 0.1352481417176585 ####  bestMAE: 0.1369803136997122 bestEpoch: 19\n",
            "best epoch:20\n",
            "2022-06-09 19:02:16.495998 Epoch [021/030], Step [0001/0060], Loss1: 0.0060 Loss2: 0.0022 Loss3: 0.0020\n",
            "2022-06-09 19:02:45.271178 Epoch [021/030], Step [0050/0060], Loss1: 0.0037 Loss2: 0.0023 Loss3: 0.0019\n",
            "2022-06-09 19:02:50.803254 Epoch [021/030], Step [0060/0060], Loss1: 0.0049 Loss2: 0.0023 Loss3: 0.0021\n",
            "Epoch: 21 MAE: 0.13212963982233927 ####  bestMAE: 0.1352481417176585 bestEpoch: 20\n",
            "best epoch:21\n",
            "2022-06-09 19:03:00.940094 Epoch [022/030], Step [0001/0060], Loss1: 0.0039 Loss2: 0.0025 Loss3: 0.0019\n",
            "2022-06-09 19:03:29.260851 Epoch [022/030], Step [0050/0060], Loss1: 0.0036 Loss2: 0.0025 Loss3: 0.0019\n",
            "2022-06-09 19:03:34.823455 Epoch [022/030], Step [0060/0060], Loss1: 0.0036 Loss2: 0.0022 Loss3: 0.0019\n",
            "Epoch: 22 MAE: 0.1346350505364635 ####  bestMAE: 0.13212963982233927 bestEpoch: 21\n",
            "2022-06-09 19:03:42.247776 Epoch [023/030], Step [0001/0060], Loss1: 0.0055 Loss2: 0.0023 Loss3: 0.0024\n",
            "2022-06-09 19:04:09.558199 Epoch [023/030], Step [0050/0060], Loss1: 0.0049 Loss2: 0.0029 Loss3: 0.0024\n",
            "2022-06-09 19:04:15.103253 Epoch [023/030], Step [0060/0060], Loss1: 0.0046 Loss2: 0.0023 Loss3: 0.0021\n",
            "Epoch: 23 MAE: 0.1317994254985184 ####  bestMAE: 0.13212963982233927 bestEpoch: 21\n",
            "best epoch:23\n",
            "2022-06-09 19:04:25.348208 Epoch [024/030], Step [0001/0060], Loss1: 0.0046 Loss2: 0.0023 Loss3: 0.0019\n",
            "2022-06-09 19:04:53.516515 Epoch [024/030], Step [0050/0060], Loss1: 0.0051 Loss2: 0.0027 Loss3: 0.0022\n",
            "2022-06-09 19:04:59.085991 Epoch [024/030], Step [0060/0060], Loss1: 0.0049 Loss2: 0.0024 Loss3: 0.0026\n",
            "Epoch: 24 MAE: 0.1372471497550843 ####  bestMAE: 0.1317994254985184 bestEpoch: 23\n",
            "2022-06-09 19:05:06.394571 Epoch [025/030], Step [0001/0060], Loss1: 0.0043 Loss2: 0.0022 Loss3: 0.0023\n",
            "2022-06-09 19:05:33.710000 Epoch [025/030], Step [0050/0060], Loss1: 0.0036 Loss2: 0.0023 Loss3: 0.0020\n",
            "2022-06-09 19:05:39.278448 Epoch [025/030], Step [0060/0060], Loss1: 0.0063 Loss2: 0.0026 Loss3: 0.0023\n",
            "Epoch: 25 MAE: 0.13330095866369826 ####  bestMAE: 0.1317994254985184 bestEpoch: 23\n",
            "2022-06-09 19:05:49.418999 Epoch [026/030], Step [0001/0060], Loss1: 0.0034 Loss2: 0.0025 Loss3: 0.0020\n",
            "2022-06-09 19:06:17.584242 Epoch [026/030], Step [0050/0060], Loss1: 0.0043 Loss2: 0.0021 Loss3: 0.0017\n",
            "2022-06-09 19:06:23.074667 Epoch [026/030], Step [0060/0060], Loss1: 0.0040 Loss2: 0.0024 Loss3: 0.0018\n",
            "Epoch: 26 MAE: 0.1259447614478056 ####  bestMAE: 0.1317994254985184 bestEpoch: 23\n",
            "best epoch:26\n",
            "2022-06-09 19:06:33.220615 Epoch [027/030], Step [0001/0060], Loss1: 0.0058 Loss2: 0.0025 Loss3: 0.0021\n",
            "2022-06-09 19:07:01.515268 Epoch [027/030], Step [0050/0060], Loss1: 0.0039 Loss2: 0.0022 Loss3: 0.0018\n",
            "2022-06-09 19:07:07.036058 Epoch [027/030], Step [0060/0060], Loss1: 0.0049 Loss2: 0.0024 Loss3: 0.0021\n",
            "Epoch: 27 MAE: 0.12220421553919557 ####  bestMAE: 0.1259447614478056 bestEpoch: 26\n",
            "best epoch:27\n",
            "2022-06-09 19:07:17.043610 Epoch [028/030], Step [0001/0060], Loss1: 0.0038 Loss2: 0.0021 Loss3: 0.0019\n",
            "2022-06-09 19:07:45.296798 Epoch [028/030], Step [0050/0060], Loss1: 0.0040 Loss2: 0.0026 Loss3: 0.0023\n",
            "2022-06-09 19:07:50.831277 Epoch [028/030], Step [0060/0060], Loss1: 0.0036 Loss2: 0.0024 Loss3: 0.0018\n",
            "Epoch: 28 MAE: 0.126553239469175 ####  bestMAE: 0.12220421553919557 bestEpoch: 27\n",
            "2022-06-09 19:07:58.156152 Epoch [029/030], Step [0001/0060], Loss1: 0.0035 Loss2: 0.0024 Loss3: 0.0019\n",
            "2022-06-09 19:08:25.338263 Epoch [029/030], Step [0050/0060], Loss1: 0.0041 Loss2: 0.0022 Loss3: 0.0019\n",
            "2022-06-09 19:08:30.858570 Epoch [029/030], Step [0060/0060], Loss1: 0.0033 Loss2: 0.0021 Loss3: 0.0017\n",
            "Epoch: 29 MAE: 0.13048633464429746 ####  bestMAE: 0.12220421553919557 bestEpoch: 27\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.MSELoss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = CE(pre_res[0], gts) \n",
        "            loss2    = CE(pre_res[1], gts)\n",
        "            loss3    = CE(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_MSE_Loss_update_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.MSELoss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary_SSIM')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(pre_res[0], gts) \n",
        "            loss2    = fun_ssim(pre_res[1], gts)\n",
        "            loss3    = fun_ssim(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_SSIM_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_SSIM_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_SSIM_Loss_updated_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJC-ZSpcG9mS",
        "outputId": "080dd4ae-5092-4f30-b71b-8a76193a2c15"
      },
      "id": "PJC-ZSpcG9mS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset_update/RGB/RGB_00.png', '/content/tmp/TrainDataset_update/RGB/RGB_01.png', '/content/tmp/TrainDataset_update/RGB/RGB_02.png', '/content/tmp/TrainDataset_update/RGB/RGB_10.png', '/content/tmp/TrainDataset_update/RGB/RGB_100.png', '/content/tmp/TrainDataset_update/RGB/RGB_101.png', '/content/tmp/TrainDataset_update/RGB/RGB_102.png', '/content/tmp/TrainDataset_update/RGB/RGB_11.png', '/content/tmp/TrainDataset_update/RGB/RGB_110.png', '/content/tmp/TrainDataset_update/RGB/RGB_111.png', '/content/tmp/TrainDataset_update/RGB/RGB_112.png', '/content/tmp/TrainDataset_update/RGB/RGB_12.png', '/content/tmp/TrainDataset_update/RGB/RGB_120.png', '/content/tmp/TrainDataset_update/RGB/RGB_121.png', '/content/tmp/TrainDataset_update/RGB/RGB_122.png', '/content/tmp/TrainDataset_update/RGB/RGB_130.png', '/content/tmp/TrainDataset_update/RGB/RGB_131.png', '/content/tmp/TrainDataset_update/RGB/RGB_132.png', '/content/tmp/TrainDataset_update/RGB/RGB_140.png', '/content/tmp/TrainDataset_update/RGB/RGB_141.png', '/content/tmp/TrainDataset_update/RGB/RGB_142.png', '/content/tmp/TrainDataset_update/RGB/RGB_150.png', '/content/tmp/TrainDataset_update/RGB/RGB_151.png', '/content/tmp/TrainDataset_update/RGB/RGB_152.png', '/content/tmp/TrainDataset_update/RGB/RGB_160.png', '/content/tmp/TrainDataset_update/RGB/RGB_161.png', '/content/tmp/TrainDataset_update/RGB/RGB_162.png', '/content/tmp/TrainDataset_update/RGB/RGB_170.png', '/content/tmp/TrainDataset_update/RGB/RGB_171.png', '/content/tmp/TrainDataset_update/RGB/RGB_172.png', '/content/tmp/TrainDataset_update/RGB/RGB_180.png', '/content/tmp/TrainDataset_update/RGB/RGB_181.png', '/content/tmp/TrainDataset_update/RGB/RGB_182.png', '/content/tmp/TrainDataset_update/RGB/RGB_190.png', '/content/tmp/TrainDataset_update/RGB/RGB_191.png', '/content/tmp/TrainDataset_update/RGB/RGB_192.png', '/content/tmp/TrainDataset_update/RGB/RGB_20.png', '/content/tmp/TrainDataset_update/RGB/RGB_200.png', '/content/tmp/TrainDataset_update/RGB/RGB_201.png', '/content/tmp/TrainDataset_update/RGB/RGB_202.png', '/content/tmp/TrainDataset_update/RGB/RGB_21.png', '/content/tmp/TrainDataset_update/RGB/RGB_210.png', '/content/tmp/TrainDataset_update/RGB/RGB_211.png', '/content/tmp/TrainDataset_update/RGB/RGB_212.png', '/content/tmp/TrainDataset_update/RGB/RGB_22.png', '/content/tmp/TrainDataset_update/RGB/RGB_220.png', '/content/tmp/TrainDataset_update/RGB/RGB_221.png', '/content/tmp/TrainDataset_update/RGB/RGB_222.png', '/content/tmp/TrainDataset_update/RGB/RGB_230.png', '/content/tmp/TrainDataset_update/RGB/RGB_231.png', '/content/tmp/TrainDataset_update/RGB/RGB_232.png', '/content/tmp/TrainDataset_update/RGB/RGB_240.png', '/content/tmp/TrainDataset_update/RGB/RGB_241.png', '/content/tmp/TrainDataset_update/RGB/RGB_242.png', '/content/tmp/TrainDataset_update/RGB/RGB_250.png', '/content/tmp/TrainDataset_update/RGB/RGB_251.png', '/content/tmp/TrainDataset_update/RGB/RGB_252.png', '/content/tmp/TrainDataset_update/RGB/RGB_260.png', '/content/tmp/TrainDataset_update/RGB/RGB_261.png', '/content/tmp/TrainDataset_update/RGB/RGB_262.png', '/content/tmp/TrainDataset_update/RGB/RGB_270.png', '/content/tmp/TrainDataset_update/RGB/RGB_271.png', '/content/tmp/TrainDataset_update/RGB/RGB_272.png', '/content/tmp/TrainDataset_update/RGB/RGB_280.png', '/content/tmp/TrainDataset_update/RGB/RGB_281.png', '/content/tmp/TrainDataset_update/RGB/RGB_282.png', '/content/tmp/TrainDataset_update/RGB/RGB_290.png', '/content/tmp/TrainDataset_update/RGB/RGB_291.png', '/content/tmp/TrainDataset_update/RGB/RGB_292.png', '/content/tmp/TrainDataset_update/RGB/RGB_30.png', '/content/tmp/TrainDataset_update/RGB/RGB_300.png', '/content/tmp/TrainDataset_update/RGB/RGB_301.png', '/content/tmp/TrainDataset_update/RGB/RGB_302.png', '/content/tmp/TrainDataset_update/RGB/RGB_31.png', '/content/tmp/TrainDataset_update/RGB/RGB_310.png', '/content/tmp/TrainDataset_update/RGB/RGB_311.png', '/content/tmp/TrainDataset_update/RGB/RGB_312.png', '/content/tmp/TrainDataset_update/RGB/RGB_32.png', '/content/tmp/TrainDataset_update/RGB/RGB_320.png', '/content/tmp/TrainDataset_update/RGB/RGB_321.png', '/content/tmp/TrainDataset_update/RGB/RGB_322.png', '/content/tmp/TrainDataset_update/RGB/RGB_330.png', '/content/tmp/TrainDataset_update/RGB/RGB_331.png', '/content/tmp/TrainDataset_update/RGB/RGB_332.png', '/content/tmp/TrainDataset_update/RGB/RGB_340.png', '/content/tmp/TrainDataset_update/RGB/RGB_341.png', '/content/tmp/TrainDataset_update/RGB/RGB_342.png', '/content/tmp/TrainDataset_update/RGB/RGB_350.png', '/content/tmp/TrainDataset_update/RGB/RGB_351.png', '/content/tmp/TrainDataset_update/RGB/RGB_352.png', '/content/tmp/TrainDataset_update/RGB/RGB_360.png', '/content/tmp/TrainDataset_update/RGB/RGB_361.png', '/content/tmp/TrainDataset_update/RGB/RGB_362.png', '/content/tmp/TrainDataset_update/RGB/RGB_370.png', '/content/tmp/TrainDataset_update/RGB/RGB_371.png', '/content/tmp/TrainDataset_update/RGB/RGB_372.png', '/content/tmp/TrainDataset_update/RGB/RGB_380.png', '/content/tmp/TrainDataset_update/RGB/RGB_381.png', '/content/tmp/TrainDataset_update/RGB/RGB_382.png', '/content/tmp/TrainDataset_update/RGB/RGB_390.png', '/content/tmp/TrainDataset_update/RGB/RGB_391.png', '/content/tmp/TrainDataset_update/RGB/RGB_392.png', '/content/tmp/TrainDataset_update/RGB/RGB_40.png', '/content/tmp/TrainDataset_update/RGB/RGB_400.png', '/content/tmp/TrainDataset_update/RGB/RGB_401.png', '/content/tmp/TrainDataset_update/RGB/RGB_402.png', '/content/tmp/TrainDataset_update/RGB/RGB_41.png', '/content/tmp/TrainDataset_update/RGB/RGB_410.png', '/content/tmp/TrainDataset_update/RGB/RGB_411.png', '/content/tmp/TrainDataset_update/RGB/RGB_412.png', '/content/tmp/TrainDataset_update/RGB/RGB_42.png', '/content/tmp/TrainDataset_update/RGB/RGB_420.png', '/content/tmp/TrainDataset_update/RGB/RGB_421.png', '/content/tmp/TrainDataset_update/RGB/RGB_422.png', '/content/tmp/TrainDataset_update/RGB/RGB_430.png', '/content/tmp/TrainDataset_update/RGB/RGB_431.png', '/content/tmp/TrainDataset_update/RGB/RGB_432.png', '/content/tmp/TrainDataset_update/RGB/RGB_440.png', '/content/tmp/TrainDataset_update/RGB/RGB_441.png', '/content/tmp/TrainDataset_update/RGB/RGB_442.png', '/content/tmp/TrainDataset_update/RGB/RGB_450.png', '/content/tmp/TrainDataset_update/RGB/RGB_451.png', '/content/tmp/TrainDataset_update/RGB/RGB_452.png', '/content/tmp/TrainDataset_update/RGB/RGB_460.png', '/content/tmp/TrainDataset_update/RGB/RGB_461.png', '/content/tmp/TrainDataset_update/RGB/RGB_462.png', '/content/tmp/TrainDataset_update/RGB/RGB_470.png', '/content/tmp/TrainDataset_update/RGB/RGB_471.png', '/content/tmp/TrainDataset_update/RGB/RGB_472.png', '/content/tmp/TrainDataset_update/RGB/RGB_480.png', '/content/tmp/TrainDataset_update/RGB/RGB_481.png', '/content/tmp/TrainDataset_update/RGB/RGB_482.png', '/content/tmp/TrainDataset_update/RGB/RGB_490.png', '/content/tmp/TrainDataset_update/RGB/RGB_491.png', '/content/tmp/TrainDataset_update/RGB/RGB_492.png', '/content/tmp/TrainDataset_update/RGB/RGB_50.png', '/content/tmp/TrainDataset_update/RGB/RGB_500.png', '/content/tmp/TrainDataset_update/RGB/RGB_501.png', '/content/tmp/TrainDataset_update/RGB/RGB_502.png', '/content/tmp/TrainDataset_update/RGB/RGB_51.png', '/content/tmp/TrainDataset_update/RGB/RGB_510.png', '/content/tmp/TrainDataset_update/RGB/RGB_511.png', '/content/tmp/TrainDataset_update/RGB/RGB_512.png', '/content/tmp/TrainDataset_update/RGB/RGB_52.png', '/content/tmp/TrainDataset_update/RGB/RGB_520.png', '/content/tmp/TrainDataset_update/RGB/RGB_521.png', '/content/tmp/TrainDataset_update/RGB/RGB_522.png', '/content/tmp/TrainDataset_update/RGB/RGB_530.png', '/content/tmp/TrainDataset_update/RGB/RGB_531.png', '/content/tmp/TrainDataset_update/RGB/RGB_532.png', '/content/tmp/TrainDataset_update/RGB/RGB_540.png', '/content/tmp/TrainDataset_update/RGB/RGB_541.png', '/content/tmp/TrainDataset_update/RGB/RGB_542.png', '/content/tmp/TrainDataset_update/RGB/RGB_550.png', '/content/tmp/TrainDataset_update/RGB/RGB_551.png', '/content/tmp/TrainDataset_update/RGB/RGB_552.png', '/content/tmp/TrainDataset_update/RGB/RGB_560.png', '/content/tmp/TrainDataset_update/RGB/RGB_561.png', '/content/tmp/TrainDataset_update/RGB/RGB_562.png', '/content/tmp/TrainDataset_update/RGB/RGB_570.png', '/content/tmp/TrainDataset_update/RGB/RGB_571.png', '/content/tmp/TrainDataset_update/RGB/RGB_572.png', '/content/tmp/TrainDataset_update/RGB/RGB_580.png', '/content/tmp/TrainDataset_update/RGB/RGB_581.png', '/content/tmp/TrainDataset_update/RGB/RGB_582.png', '/content/tmp/TrainDataset_update/RGB/RGB_590.png', '/content/tmp/TrainDataset_update/RGB/RGB_591.png', '/content/tmp/TrainDataset_update/RGB/RGB_592.png', '/content/tmp/TrainDataset_update/RGB/RGB_60.png', '/content/tmp/TrainDataset_update/RGB/RGB_600.png', '/content/tmp/TrainDataset_update/RGB/RGB_601.png', '/content/tmp/TrainDataset_update/RGB/RGB_602.png', '/content/tmp/TrainDataset_update/RGB/RGB_61.png', '/content/tmp/TrainDataset_update/RGB/RGB_610.png', '/content/tmp/TrainDataset_update/RGB/RGB_611.png', '/content/tmp/TrainDataset_update/RGB/RGB_612.png', '/content/tmp/TrainDataset_update/RGB/RGB_62.png', '/content/tmp/TrainDataset_update/RGB/RGB_620.png', '/content/tmp/TrainDataset_update/RGB/RGB_621.png', '/content/tmp/TrainDataset_update/RGB/RGB_622.png', '/content/tmp/TrainDataset_update/RGB/RGB_630.png', '/content/tmp/TrainDataset_update/RGB/RGB_631.png', '/content/tmp/TrainDataset_update/RGB/RGB_632.png', '/content/tmp/TrainDataset_update/RGB/RGB_640.png', '/content/tmp/TrainDataset_update/RGB/RGB_641.png', '/content/tmp/TrainDataset_update/RGB/RGB_642.png', '/content/tmp/TrainDataset_update/RGB/RGB_650.png', '/content/tmp/TrainDataset_update/RGB/RGB_651.png', '/content/tmp/TrainDataset_update/RGB/RGB_652.png', '/content/tmp/TrainDataset_update/RGB/RGB_660.png', '/content/tmp/TrainDataset_update/RGB/RGB_661.png', '/content/tmp/TrainDataset_update/RGB/RGB_662.png', '/content/tmp/TrainDataset_update/RGB/RGB_670.png', '/content/tmp/TrainDataset_update/RGB/RGB_671.png', '/content/tmp/TrainDataset_update/RGB/RGB_672.png', '/content/tmp/TrainDataset_update/RGB/RGB_680.png', '/content/tmp/TrainDataset_update/RGB/RGB_681.png', '/content/tmp/TrainDataset_update/RGB/RGB_682.png', '/content/tmp/TrainDataset_update/RGB/RGB_690.png', '/content/tmp/TrainDataset_update/RGB/RGB_691.png', '/content/tmp/TrainDataset_update/RGB/RGB_692.png', '/content/tmp/TrainDataset_update/RGB/RGB_70.png', '/content/tmp/TrainDataset_update/RGB/RGB_700.png', '/content/tmp/TrainDataset_update/RGB/RGB_701.png', '/content/tmp/TrainDataset_update/RGB/RGB_702.png', '/content/tmp/TrainDataset_update/RGB/RGB_71.png', '/content/tmp/TrainDataset_update/RGB/RGB_710.png', '/content/tmp/TrainDataset_update/RGB/RGB_711.png', '/content/tmp/TrainDataset_update/RGB/RGB_712.png', '/content/tmp/TrainDataset_update/RGB/RGB_72.png', '/content/tmp/TrainDataset_update/RGB/RGB_720.png', '/content/tmp/TrainDataset_update/RGB/RGB_721.png', '/content/tmp/TrainDataset_update/RGB/RGB_722.png', '/content/tmp/TrainDataset_update/RGB/RGB_730.png', '/content/tmp/TrainDataset_update/RGB/RGB_731.png', '/content/tmp/TrainDataset_update/RGB/RGB_732.png', '/content/tmp/TrainDataset_update/RGB/RGB_740.png', '/content/tmp/TrainDataset_update/RGB/RGB_741.png', '/content/tmp/TrainDataset_update/RGB/RGB_742.png', '/content/tmp/TrainDataset_update/RGB/RGB_750.png', '/content/tmp/TrainDataset_update/RGB/RGB_751.png', '/content/tmp/TrainDataset_update/RGB/RGB_752.png', '/content/tmp/TrainDataset_update/RGB/RGB_760.png', '/content/tmp/TrainDataset_update/RGB/RGB_761.png', '/content/tmp/TrainDataset_update/RGB/RGB_762.png', '/content/tmp/TrainDataset_update/RGB/RGB_770.png', '/content/tmp/TrainDataset_update/RGB/RGB_771.png', '/content/tmp/TrainDataset_update/RGB/RGB_772.png', '/content/tmp/TrainDataset_update/RGB/RGB_780.png', '/content/tmp/TrainDataset_update/RGB/RGB_781.png', '/content/tmp/TrainDataset_update/RGB/RGB_782.png', '/content/tmp/TrainDataset_update/RGB/RGB_790.png', '/content/tmp/TrainDataset_update/RGB/RGB_791.png', '/content/tmp/TrainDataset_update/RGB/RGB_792.png', '/content/tmp/TrainDataset_update/RGB/RGB_80.png', '/content/tmp/TrainDataset_update/RGB/RGB_81.png', '/content/tmp/TrainDataset_update/RGB/RGB_82.png', '/content/tmp/TrainDataset_update/RGB/RGB_90.png', '/content/tmp/TrainDataset_update/RGB/RGB_91.png', '/content/tmp/TrainDataset_update/RGB/RGB_92.png'] ['/content/tmp/TrainDataset_update/GT/GT_00.png', '/content/tmp/TrainDataset_update/GT/GT_01.png', '/content/tmp/TrainDataset_update/GT/GT_02.png', '/content/tmp/TrainDataset_update/GT/GT_10.png', '/content/tmp/TrainDataset_update/GT/GT_100.png', '/content/tmp/TrainDataset_update/GT/GT_101.png', '/content/tmp/TrainDataset_update/GT/GT_102.png', '/content/tmp/TrainDataset_update/GT/GT_11.png', '/content/tmp/TrainDataset_update/GT/GT_110.png', '/content/tmp/TrainDataset_update/GT/GT_111.png', '/content/tmp/TrainDataset_update/GT/GT_112.png', '/content/tmp/TrainDataset_update/GT/GT_12.png', '/content/tmp/TrainDataset_update/GT/GT_120.png', '/content/tmp/TrainDataset_update/GT/GT_121.png', '/content/tmp/TrainDataset_update/GT/GT_122.png', '/content/tmp/TrainDataset_update/GT/GT_130.png', '/content/tmp/TrainDataset_update/GT/GT_131.png', '/content/tmp/TrainDataset_update/GT/GT_132.png', '/content/tmp/TrainDataset_update/GT/GT_140.png', '/content/tmp/TrainDataset_update/GT/GT_141.png', '/content/tmp/TrainDataset_update/GT/GT_142.png', '/content/tmp/TrainDataset_update/GT/GT_150.png', '/content/tmp/TrainDataset_update/GT/GT_151.png', '/content/tmp/TrainDataset_update/GT/GT_152.png', '/content/tmp/TrainDataset_update/GT/GT_160.png', '/content/tmp/TrainDataset_update/GT/GT_161.png', '/content/tmp/TrainDataset_update/GT/GT_162.png', '/content/tmp/TrainDataset_update/GT/GT_170.png', '/content/tmp/TrainDataset_update/GT/GT_171.png', '/content/tmp/TrainDataset_update/GT/GT_172.png', '/content/tmp/TrainDataset_update/GT/GT_180.png', '/content/tmp/TrainDataset_update/GT/GT_181.png', '/content/tmp/TrainDataset_update/GT/GT_182.png', '/content/tmp/TrainDataset_update/GT/GT_190.png', '/content/tmp/TrainDataset_update/GT/GT_191.png', '/content/tmp/TrainDataset_update/GT/GT_192.png', '/content/tmp/TrainDataset_update/GT/GT_20.png', '/content/tmp/TrainDataset_update/GT/GT_200.png', '/content/tmp/TrainDataset_update/GT/GT_201.png', '/content/tmp/TrainDataset_update/GT/GT_202.png', '/content/tmp/TrainDataset_update/GT/GT_21.png', '/content/tmp/TrainDataset_update/GT/GT_210.png', '/content/tmp/TrainDataset_update/GT/GT_211.png', '/content/tmp/TrainDataset_update/GT/GT_212.png', '/content/tmp/TrainDataset_update/GT/GT_22.png', '/content/tmp/TrainDataset_update/GT/GT_220.png', '/content/tmp/TrainDataset_update/GT/GT_221.png', '/content/tmp/TrainDataset_update/GT/GT_222.png', '/content/tmp/TrainDataset_update/GT/GT_230.png', '/content/tmp/TrainDataset_update/GT/GT_231.png', '/content/tmp/TrainDataset_update/GT/GT_232.png', '/content/tmp/TrainDataset_update/GT/GT_240.png', '/content/tmp/TrainDataset_update/GT/GT_241.png', '/content/tmp/TrainDataset_update/GT/GT_242.png', '/content/tmp/TrainDataset_update/GT/GT_250.png', '/content/tmp/TrainDataset_update/GT/GT_251.png', '/content/tmp/TrainDataset_update/GT/GT_252.png', '/content/tmp/TrainDataset_update/GT/GT_260.png', '/content/tmp/TrainDataset_update/GT/GT_261.png', '/content/tmp/TrainDataset_update/GT/GT_262.png', '/content/tmp/TrainDataset_update/GT/GT_270.png', '/content/tmp/TrainDataset_update/GT/GT_271.png', '/content/tmp/TrainDataset_update/GT/GT_272.png', '/content/tmp/TrainDataset_update/GT/GT_280.png', '/content/tmp/TrainDataset_update/GT/GT_281.png', '/content/tmp/TrainDataset_update/GT/GT_282.png', '/content/tmp/TrainDataset_update/GT/GT_290.png', '/content/tmp/TrainDataset_update/GT/GT_291.png', '/content/tmp/TrainDataset_update/GT/GT_292.png', '/content/tmp/TrainDataset_update/GT/GT_30.png', '/content/tmp/TrainDataset_update/GT/GT_300.png', '/content/tmp/TrainDataset_update/GT/GT_301.png', '/content/tmp/TrainDataset_update/GT/GT_302.png', '/content/tmp/TrainDataset_update/GT/GT_31.png', '/content/tmp/TrainDataset_update/GT/GT_310.png', '/content/tmp/TrainDataset_update/GT/GT_311.png', '/content/tmp/TrainDataset_update/GT/GT_312.png', '/content/tmp/TrainDataset_update/GT/GT_32.png', '/content/tmp/TrainDataset_update/GT/GT_320.png', '/content/tmp/TrainDataset_update/GT/GT_321.png', '/content/tmp/TrainDataset_update/GT/GT_322.png', '/content/tmp/TrainDataset_update/GT/GT_330.png', '/content/tmp/TrainDataset_update/GT/GT_331.png', '/content/tmp/TrainDataset_update/GT/GT_332.png', '/content/tmp/TrainDataset_update/GT/GT_340.png', '/content/tmp/TrainDataset_update/GT/GT_341.png', '/content/tmp/TrainDataset_update/GT/GT_342.png', '/content/tmp/TrainDataset_update/GT/GT_350.png', '/content/tmp/TrainDataset_update/GT/GT_351.png', '/content/tmp/TrainDataset_update/GT/GT_352.png', '/content/tmp/TrainDataset_update/GT/GT_360.png', '/content/tmp/TrainDataset_update/GT/GT_361.png', '/content/tmp/TrainDataset_update/GT/GT_362.png', '/content/tmp/TrainDataset_update/GT/GT_370.png', '/content/tmp/TrainDataset_update/GT/GT_371.png', '/content/tmp/TrainDataset_update/GT/GT_372.png', '/content/tmp/TrainDataset_update/GT/GT_380.png', '/content/tmp/TrainDataset_update/GT/GT_381.png', '/content/tmp/TrainDataset_update/GT/GT_382.png', '/content/tmp/TrainDataset_update/GT/GT_390.png', '/content/tmp/TrainDataset_update/GT/GT_391.png', '/content/tmp/TrainDataset_update/GT/GT_392.png', '/content/tmp/TrainDataset_update/GT/GT_40.png', '/content/tmp/TrainDataset_update/GT/GT_400.png', '/content/tmp/TrainDataset_update/GT/GT_401.png', '/content/tmp/TrainDataset_update/GT/GT_402.png', '/content/tmp/TrainDataset_update/GT/GT_41.png', '/content/tmp/TrainDataset_update/GT/GT_410.png', '/content/tmp/TrainDataset_update/GT/GT_411.png', '/content/tmp/TrainDataset_update/GT/GT_412.png', '/content/tmp/TrainDataset_update/GT/GT_42.png', '/content/tmp/TrainDataset_update/GT/GT_420.png', '/content/tmp/TrainDataset_update/GT/GT_421.png', '/content/tmp/TrainDataset_update/GT/GT_422.png', '/content/tmp/TrainDataset_update/GT/GT_430.png', '/content/tmp/TrainDataset_update/GT/GT_431.png', '/content/tmp/TrainDataset_update/GT/GT_432.png', '/content/tmp/TrainDataset_update/GT/GT_440.png', '/content/tmp/TrainDataset_update/GT/GT_441.png', '/content/tmp/TrainDataset_update/GT/GT_442.png', '/content/tmp/TrainDataset_update/GT/GT_450.png', '/content/tmp/TrainDataset_update/GT/GT_451.png', '/content/tmp/TrainDataset_update/GT/GT_452.png', '/content/tmp/TrainDataset_update/GT/GT_460.png', '/content/tmp/TrainDataset_update/GT/GT_461.png', '/content/tmp/TrainDataset_update/GT/GT_462.png', '/content/tmp/TrainDataset_update/GT/GT_470.png', '/content/tmp/TrainDataset_update/GT/GT_471.png', '/content/tmp/TrainDataset_update/GT/GT_472.png', '/content/tmp/TrainDataset_update/GT/GT_480.png', '/content/tmp/TrainDataset_update/GT/GT_481.png', '/content/tmp/TrainDataset_update/GT/GT_482.png', '/content/tmp/TrainDataset_update/GT/GT_490.png', '/content/tmp/TrainDataset_update/GT/GT_491.png', '/content/tmp/TrainDataset_update/GT/GT_492.png', '/content/tmp/TrainDataset_update/GT/GT_50.png', '/content/tmp/TrainDataset_update/GT/GT_500.png', '/content/tmp/TrainDataset_update/GT/GT_501.png', '/content/tmp/TrainDataset_update/GT/GT_502.png', '/content/tmp/TrainDataset_update/GT/GT_51.png', '/content/tmp/TrainDataset_update/GT/GT_510.png', '/content/tmp/TrainDataset_update/GT/GT_511.png', '/content/tmp/TrainDataset_update/GT/GT_512.png', '/content/tmp/TrainDataset_update/GT/GT_52.png', '/content/tmp/TrainDataset_update/GT/GT_520.png', '/content/tmp/TrainDataset_update/GT/GT_521.png', '/content/tmp/TrainDataset_update/GT/GT_522.png', '/content/tmp/TrainDataset_update/GT/GT_530.png', '/content/tmp/TrainDataset_update/GT/GT_531.png', '/content/tmp/TrainDataset_update/GT/GT_532.png', '/content/tmp/TrainDataset_update/GT/GT_540.png', '/content/tmp/TrainDataset_update/GT/GT_541.png', '/content/tmp/TrainDataset_update/GT/GT_542.png', '/content/tmp/TrainDataset_update/GT/GT_550.png', '/content/tmp/TrainDataset_update/GT/GT_551.png', '/content/tmp/TrainDataset_update/GT/GT_552.png', '/content/tmp/TrainDataset_update/GT/GT_560.png', '/content/tmp/TrainDataset_update/GT/GT_561.png', '/content/tmp/TrainDataset_update/GT/GT_562.png', '/content/tmp/TrainDataset_update/GT/GT_570.png', '/content/tmp/TrainDataset_update/GT/GT_571.png', '/content/tmp/TrainDataset_update/GT/GT_572.png', '/content/tmp/TrainDataset_update/GT/GT_580.png', '/content/tmp/TrainDataset_update/GT/GT_581.png', '/content/tmp/TrainDataset_update/GT/GT_582.png', '/content/tmp/TrainDataset_update/GT/GT_590.png', '/content/tmp/TrainDataset_update/GT/GT_591.png', '/content/tmp/TrainDataset_update/GT/GT_592.png', '/content/tmp/TrainDataset_update/GT/GT_60.png', '/content/tmp/TrainDataset_update/GT/GT_600.png', '/content/tmp/TrainDataset_update/GT/GT_601.png', '/content/tmp/TrainDataset_update/GT/GT_602.png', '/content/tmp/TrainDataset_update/GT/GT_61.png', '/content/tmp/TrainDataset_update/GT/GT_610.png', '/content/tmp/TrainDataset_update/GT/GT_611.png', '/content/tmp/TrainDataset_update/GT/GT_612.png', '/content/tmp/TrainDataset_update/GT/GT_62.png', '/content/tmp/TrainDataset_update/GT/GT_620.png', '/content/tmp/TrainDataset_update/GT/GT_621.png', '/content/tmp/TrainDataset_update/GT/GT_622.png', '/content/tmp/TrainDataset_update/GT/GT_630.png', '/content/tmp/TrainDataset_update/GT/GT_631.png', '/content/tmp/TrainDataset_update/GT/GT_632.png', '/content/tmp/TrainDataset_update/GT/GT_640.png', '/content/tmp/TrainDataset_update/GT/GT_641.png', '/content/tmp/TrainDataset_update/GT/GT_642.png', '/content/tmp/TrainDataset_update/GT/GT_650.png', '/content/tmp/TrainDataset_update/GT/GT_651.png', '/content/tmp/TrainDataset_update/GT/GT_652.png', '/content/tmp/TrainDataset_update/GT/GT_660.png', '/content/tmp/TrainDataset_update/GT/GT_661.png', '/content/tmp/TrainDataset_update/GT/GT_662.png', '/content/tmp/TrainDataset_update/GT/GT_670.png', '/content/tmp/TrainDataset_update/GT/GT_671.png', '/content/tmp/TrainDataset_update/GT/GT_672.png', '/content/tmp/TrainDataset_update/GT/GT_680.png', '/content/tmp/TrainDataset_update/GT/GT_681.png', '/content/tmp/TrainDataset_update/GT/GT_682.png', '/content/tmp/TrainDataset_update/GT/GT_690.png', '/content/tmp/TrainDataset_update/GT/GT_691.png', '/content/tmp/TrainDataset_update/GT/GT_692.png', '/content/tmp/TrainDataset_update/GT/GT_70.png', '/content/tmp/TrainDataset_update/GT/GT_700.png', '/content/tmp/TrainDataset_update/GT/GT_701.png', '/content/tmp/TrainDataset_update/GT/GT_702.png', '/content/tmp/TrainDataset_update/GT/GT_71.png', '/content/tmp/TrainDataset_update/GT/GT_710.png', '/content/tmp/TrainDataset_update/GT/GT_711.png', '/content/tmp/TrainDataset_update/GT/GT_712.png', '/content/tmp/TrainDataset_update/GT/GT_72.png', '/content/tmp/TrainDataset_update/GT/GT_720.png', '/content/tmp/TrainDataset_update/GT/GT_721.png', '/content/tmp/TrainDataset_update/GT/GT_722.png', '/content/tmp/TrainDataset_update/GT/GT_730.png', '/content/tmp/TrainDataset_update/GT/GT_731.png', '/content/tmp/TrainDataset_update/GT/GT_732.png', '/content/tmp/TrainDataset_update/GT/GT_740.png', '/content/tmp/TrainDataset_update/GT/GT_741.png', '/content/tmp/TrainDataset_update/GT/GT_742.png', '/content/tmp/TrainDataset_update/GT/GT_750.png', '/content/tmp/TrainDataset_update/GT/GT_751.png', '/content/tmp/TrainDataset_update/GT/GT_752.png', '/content/tmp/TrainDataset_update/GT/GT_760.png', '/content/tmp/TrainDataset_update/GT/GT_761.png', '/content/tmp/TrainDataset_update/GT/GT_762.png', '/content/tmp/TrainDataset_update/GT/GT_770.png', '/content/tmp/TrainDataset_update/GT/GT_771.png', '/content/tmp/TrainDataset_update/GT/GT_772.png', '/content/tmp/TrainDataset_update/GT/GT_780.png', '/content/tmp/TrainDataset_update/GT/GT_781.png', '/content/tmp/TrainDataset_update/GT/GT_782.png', '/content/tmp/TrainDataset_update/GT/GT_790.png', '/content/tmp/TrainDataset_update/GT/GT_791.png', '/content/tmp/TrainDataset_update/GT/GT_792.png', '/content/tmp/TrainDataset_update/GT/GT_80.png', '/content/tmp/TrainDataset_update/GT/GT_81.png', '/content/tmp/TrainDataset_update/GT/GT_82.png', '/content/tmp/TrainDataset_update/GT/GT_90.png', '/content/tmp/TrainDataset_update/GT/GT_91.png', '/content/tmp/TrainDataset_update/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f38f60ba210>\n",
            "60\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-06 18:23:43.639961 Epoch [001/030], Step [0001/0060], Loss1: -0.0496 Loss2: 0.0130 Loss3: 0.0754\n",
            "2022-06-06 18:24:22.265198 Epoch [001/030], Step [0050/0060], Loss1: -0.8543 Loss2: -0.8975 Loss3: -0.9119\n",
            "2022-06-06 18:24:30.113308 Epoch [001/030], Step [0060/0060], Loss1: -0.7385 Loss2: -0.8107 Loss3: -0.8660\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.219527400385135 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-06 18:24:37.034086 Epoch [002/030], Step [0001/0060], Loss1: -0.8892 Loss2: -0.9303 Loss3: -0.9332\n",
            "2022-06-06 18:25:15.101292 Epoch [002/030], Step [0050/0060], Loss1: -0.9298 Loss2: -0.9524 Loss3: -0.9623\n",
            "2022-06-06 18:25:22.887493 Epoch [002/030], Step [0060/0060], Loss1: -0.9111 Loss2: -0.9525 Loss3: -0.9556\n",
            "Epoch: 2 MAE: 0.17134729173448346 ####  bestMAE: 0.219527400385135 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-06 18:25:32.671598 Epoch [003/030], Step [0001/0060], Loss1: -0.9437 Loss2: -0.9651 Loss3: -0.9700\n",
            "2022-06-06 18:26:11.290706 Epoch [003/030], Step [0050/0060], Loss1: -0.8988 Loss2: -0.9470 Loss3: -0.9573\n",
            "2022-06-06 18:26:19.104971 Epoch [003/030], Step [0060/0060], Loss1: -0.8947 Loss2: -0.9413 Loss3: -0.9660\n",
            "Epoch: 3 MAE: 0.16027139562778372 ####  bestMAE: 0.17134729173448346 bestEpoch: 2\n",
            "best epoch:3\n",
            "2022-06-06 18:26:28.611058 Epoch [004/030], Step [0001/0060], Loss1: -0.9546 Loss2: -0.9647 Loss3: -0.9755\n",
            "2022-06-06 18:27:06.966893 Epoch [004/030], Step [0050/0060], Loss1: -0.9414 Loss2: -0.9455 Loss3: -0.9659\n",
            "2022-06-06 18:27:14.761087 Epoch [004/030], Step [0060/0060], Loss1: -0.9226 Loss2: -0.9621 Loss3: -0.9714\n",
            "Epoch: 4 MAE: 0.1335551832088087 ####  bestMAE: 0.16027139562778372 bestEpoch: 3\n",
            "best epoch:4\n",
            "2022-06-06 18:27:24.065598 Epoch [005/030], Step [0001/0060], Loss1: -0.9538 Loss2: -0.9670 Loss3: -0.9769\n",
            "2022-06-06 18:28:02.488004 Epoch [005/030], Step [0050/0060], Loss1: -0.9595 Loss2: -0.9763 Loss3: -0.9823\n",
            "2022-06-06 18:28:10.276178 Epoch [005/030], Step [0060/0060], Loss1: -0.9371 Loss2: -0.9671 Loss3: -0.9743\n",
            "Epoch: 5 MAE: 0.11864046651850299 ####  bestMAE: 0.1335551832088087 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-06-06 18:28:21.865413 Epoch [006/030], Step [0001/0060], Loss1: -0.9383 Loss2: -0.9700 Loss3: -0.9738\n",
            "2022-06-06 18:29:00.651486 Epoch [006/030], Step [0050/0060], Loss1: -0.9636 Loss2: -0.9767 Loss3: -0.9812\n",
            "2022-06-06 18:29:08.473975 Epoch [006/030], Step [0060/0060], Loss1: -0.9527 Loss2: -0.9738 Loss3: -0.9767\n",
            "Epoch: 6 MAE: 0.11099947177543844 ####  bestMAE: 0.11864046651850299 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-06-06 18:29:18.014752 Epoch [007/030], Step [0001/0060], Loss1: -0.9578 Loss2: -0.9734 Loss3: -0.9779\n",
            "2022-06-06 18:29:56.390633 Epoch [007/030], Step [0050/0060], Loss1: -0.9538 Loss2: -0.9756 Loss3: -0.9786\n",
            "2022-06-06 18:30:04.201056 Epoch [007/030], Step [0060/0060], Loss1: -0.9503 Loss2: -0.9723 Loss3: -0.9809\n",
            "Epoch: 7 MAE: 0.10466203598749071 ####  bestMAE: 0.11099947177543844 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-06-06 18:30:13.777055 Epoch [008/030], Step [0001/0060], Loss1: -0.9496 Loss2: -0.9748 Loss3: -0.9780\n",
            "2022-06-06 18:30:52.324710 Epoch [008/030], Step [0050/0060], Loss1: -0.9421 Loss2: -0.9652 Loss3: -0.9722\n",
            "2022-06-06 18:31:00.125582 Epoch [008/030], Step [0060/0060], Loss1: -0.9708 Loss2: -0.9786 Loss3: -0.9833\n",
            "Epoch: 8 MAE: 0.10452786238735944 ####  bestMAE: 0.10466203598749071 bestEpoch: 7\n",
            "best epoch:8\n",
            "2022-06-06 18:31:09.694519 Epoch [009/030], Step [0001/0060], Loss1: -0.9660 Loss2: -0.9788 Loss3: -0.9841\n",
            "2022-06-06 18:31:48.071420 Epoch [009/030], Step [0050/0060], Loss1: -0.9590 Loss2: -0.9794 Loss3: -0.9815\n",
            "2022-06-06 18:31:55.853758 Epoch [009/030], Step [0060/0060], Loss1: -0.9622 Loss2: -0.9765 Loss3: -0.9816\n",
            "Epoch: 9 MAE: 0.08891333923138003 ####  bestMAE: 0.10452786238735944 bestEpoch: 8\n",
            "best epoch:9\n",
            "2022-06-06 18:32:05.238589 Epoch [010/030], Step [0001/0060], Loss1: -0.9619 Loss2: -0.9803 Loss3: -0.9851\n",
            "2022-06-06 18:32:43.689663 Epoch [010/030], Step [0050/0060], Loss1: -0.9677 Loss2: -0.9757 Loss3: -0.9840\n",
            "2022-06-06 18:32:51.492442 Epoch [010/030], Step [0060/0060], Loss1: -0.9697 Loss2: -0.9787 Loss3: -0.9835\n",
            "Epoch: 10 MAE: 0.09831169733925472 ####  bestMAE: 0.08891333923138003 bestEpoch: 9\n",
            "2022-06-06 18:33:00.952920 Epoch [011/030], Step [0001/0060], Loss1: -0.9657 Loss2: -0.9736 Loss3: -0.9824\n",
            "2022-06-06 18:33:39.351768 Epoch [011/030], Step [0050/0060], Loss1: -0.9606 Loss2: -0.9765 Loss3: -0.9830\n",
            "2022-06-06 18:33:47.147444 Epoch [011/030], Step [0060/0060], Loss1: -0.9435 Loss2: -0.9688 Loss3: -0.9683\n",
            "Epoch: 11 MAE: 0.09694274125275792 ####  bestMAE: 0.08891333923138003 bestEpoch: 9\n",
            "2022-06-06 18:33:54.016732 Epoch [012/030], Step [0001/0060], Loss1: -0.9564 Loss2: -0.9747 Loss3: -0.9821\n",
            "2022-06-06 18:34:32.219559 Epoch [012/030], Step [0050/0060], Loss1: -0.9453 Loss2: -0.9712 Loss3: -0.9742\n",
            "2022-06-06 18:34:39.996814 Epoch [012/030], Step [0060/0060], Loss1: -0.9487 Loss2: -0.9703 Loss3: -0.9767\n",
            "Epoch: 12 MAE: 0.09052216282597293 ####  bestMAE: 0.08891333923138003 bestEpoch: 9\n",
            "2022-06-06 18:34:47.069106 Epoch [013/030], Step [0001/0060], Loss1: -0.9716 Loss2: -0.9809 Loss3: -0.9852\n",
            "2022-06-06 18:35:25.247408 Epoch [013/030], Step [0050/0060], Loss1: -0.9549 Loss2: -0.9748 Loss3: -0.9816\n",
            "2022-06-06 18:35:33.046153 Epoch [013/030], Step [0060/0060], Loss1: -0.9708 Loss2: -0.9783 Loss3: -0.9848\n",
            "Epoch: 13 MAE: 0.09456931351353882 ####  bestMAE: 0.08891333923138003 bestEpoch: 9\n",
            "2022-06-06 18:35:40.048167 Epoch [014/030], Step [0001/0060], Loss1: -0.9624 Loss2: -0.9765 Loss3: -0.9831\n",
            "2022-06-06 18:36:18.245245 Epoch [014/030], Step [0050/0060], Loss1: -0.9584 Loss2: -0.9798 Loss3: -0.9822\n",
            "2022-06-06 18:36:26.027451 Epoch [014/030], Step [0060/0060], Loss1: -0.9774 Loss2: -0.9835 Loss3: -0.9879\n",
            "Epoch: 14 MAE: 0.08032850336145471 ####  bestMAE: 0.08891333923138003 bestEpoch: 9\n",
            "best epoch:14\n",
            "2022-06-06 18:36:35.529139 Epoch [015/030], Step [0001/0060], Loss1: -0.9674 Loss2: -0.9805 Loss3: -0.9848\n",
            "2022-06-06 18:37:13.960594 Epoch [015/030], Step [0050/0060], Loss1: -0.9717 Loss2: -0.9810 Loss3: -0.9854\n",
            "2022-06-06 18:37:21.768154 Epoch [015/030], Step [0060/0060], Loss1: -0.9746 Loss2: -0.9814 Loss3: -0.9864\n",
            "Epoch: 15 MAE: 0.08416678443787588 ####  bestMAE: 0.08032850336145471 bestEpoch: 14\n",
            "2022-06-06 18:37:31.399833 Epoch [016/030], Step [0001/0060], Loss1: -0.9671 Loss2: -0.9805 Loss3: -0.9849\n",
            "2022-06-06 18:38:09.968680 Epoch [016/030], Step [0050/0060], Loss1: -0.9735 Loss2: -0.9827 Loss3: -0.9873\n",
            "2022-06-06 18:38:17.773721 Epoch [016/030], Step [0060/0060], Loss1: -0.9668 Loss2: -0.9794 Loss3: -0.9848\n",
            "Epoch: 16 MAE: 0.08604629794125836 ####  bestMAE: 0.08032850336145471 bestEpoch: 14\n",
            "2022-06-06 18:38:24.853581 Epoch [017/030], Step [0001/0060], Loss1: -0.9658 Loss2: -0.9794 Loss3: -0.9831\n",
            "2022-06-06 18:39:03.062174 Epoch [017/030], Step [0050/0060], Loss1: -0.9639 Loss2: -0.9813 Loss3: -0.9849\n",
            "2022-06-06 18:39:10.833200 Epoch [017/030], Step [0060/0060], Loss1: -0.9675 Loss2: -0.9823 Loss3: -0.9855\n",
            "Epoch: 17 MAE: 0.08182020358938387 ####  bestMAE: 0.08032850336145471 bestEpoch: 14\n",
            "2022-06-06 18:39:17.792507 Epoch [018/030], Step [0001/0060], Loss1: -0.9748 Loss2: -0.9818 Loss3: -0.9852\n",
            "2022-06-06 18:39:56.276393 Epoch [018/030], Step [0050/0060], Loss1: -0.9664 Loss2: -0.9811 Loss3: -0.9862\n",
            "2022-06-06 18:40:04.073841 Epoch [018/030], Step [0060/0060], Loss1: -0.9701 Loss2: -0.9811 Loss3: -0.9848\n",
            "Epoch: 18 MAE: 0.08455646565351536 ####  bestMAE: 0.08032850336145471 bestEpoch: 14\n",
            "2022-06-06 18:40:11.119301 Epoch [019/030], Step [0001/0060], Loss1: -0.9773 Loss2: -0.9836 Loss3: -0.9878\n",
            "2022-06-06 18:40:49.390588 Epoch [019/030], Step [0050/0060], Loss1: -0.9808 Loss2: -0.9852 Loss3: -0.9896\n",
            "2022-06-06 18:40:57.194112 Epoch [019/030], Step [0060/0060], Loss1: -0.9770 Loss2: -0.9841 Loss3: -0.9864\n",
            "Epoch: 19 MAE: 0.07984394961563997 ####  bestMAE: 0.08032850336145471 bestEpoch: 14\n",
            "best epoch:19\n",
            "2022-06-06 18:41:06.618214 Epoch [020/030], Step [0001/0060], Loss1: -0.9649 Loss2: -0.9771 Loss3: -0.9805\n",
            "2022-06-06 18:41:44.817347 Epoch [020/030], Step [0050/0060], Loss1: -0.9653 Loss2: -0.9817 Loss3: -0.9845\n",
            "2022-06-06 18:41:52.590217 Epoch [020/030], Step [0060/0060], Loss1: -0.9738 Loss2: -0.9832 Loss3: -0.9872\n",
            "Epoch: 20 MAE: 0.0831513656131805 ####  bestMAE: 0.07984394961563997 bestEpoch: 19\n",
            "2022-06-06 18:42:04.761641 Epoch [021/030], Step [0001/0060], Loss1: -0.9781 Loss2: -0.9861 Loss3: -0.9884\n",
            "2022-06-06 18:42:43.007994 Epoch [021/030], Step [0050/0060], Loss1: -0.9723 Loss2: -0.9853 Loss3: -0.9892\n",
            "2022-06-06 18:42:50.801236 Epoch [021/030], Step [0060/0060], Loss1: -0.9769 Loss2: -0.9841 Loss3: -0.9862\n",
            "Epoch: 21 MAE: 0.08163862753166726 ####  bestMAE: 0.07984394961563997 bestEpoch: 19\n",
            "2022-06-06 18:42:57.742691 Epoch [022/030], Step [0001/0060], Loss1: -0.9657 Loss2: -0.9833 Loss3: -0.9847\n",
            "2022-06-06 18:43:35.878456 Epoch [022/030], Step [0050/0060], Loss1: -0.9676 Loss2: -0.9836 Loss3: -0.9871\n",
            "2022-06-06 18:43:43.682281 Epoch [022/030], Step [0060/0060], Loss1: -0.9780 Loss2: -0.9829 Loss3: -0.9866\n",
            "Epoch: 22 MAE: 0.07843772585429841 ####  bestMAE: 0.07984394961563997 bestEpoch: 19\n",
            "best epoch:22\n",
            "2022-06-06 18:43:53.035716 Epoch [023/030], Step [0001/0060], Loss1: -0.9762 Loss2: -0.9815 Loss3: -0.9867\n",
            "2022-06-06 18:44:31.886251 Epoch [023/030], Step [0050/0060], Loss1: -0.9755 Loss2: -0.9821 Loss3: -0.9873\n",
            "2022-06-06 18:44:39.684105 Epoch [023/030], Step [0060/0060], Loss1: -0.9689 Loss2: -0.9844 Loss3: -0.9863\n",
            "Epoch: 23 MAE: 0.085580639713025 ####  bestMAE: 0.07843772585429841 bestEpoch: 22\n",
            "2022-06-06 18:44:46.670130 Epoch [024/030], Step [0001/0060], Loss1: -0.9802 Loss2: -0.9854 Loss3: -0.9890\n",
            "2022-06-06 18:45:24.863160 Epoch [024/030], Step [0050/0060], Loss1: -0.9776 Loss2: -0.9843 Loss3: -0.9877\n",
            "2022-06-06 18:45:32.640158 Epoch [024/030], Step [0060/0060], Loss1: -0.9758 Loss2: -0.9869 Loss3: -0.9888\n",
            "Epoch: 24 MAE: 0.0776250293267467 ####  bestMAE: 0.07843772585429841 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-06-06 18:45:42.081546 Epoch [025/030], Step [0001/0060], Loss1: -0.9771 Loss2: -0.9839 Loss3: -0.9863\n",
            "2022-06-06 18:46:20.349297 Epoch [025/030], Step [0050/0060], Loss1: -0.9793 Loss2: -0.9852 Loss3: -0.9889\n",
            "2022-06-06 18:46:28.387023 Epoch [025/030], Step [0060/0060], Loss1: -0.9727 Loss2: -0.9814 Loss3: -0.9868\n",
            "Epoch: 25 MAE: 0.10102883868747288 ####  bestMAE: 0.0776250293267467 bestEpoch: 24\n",
            "2022-06-06 18:46:37.675290 Epoch [026/030], Step [0001/0060], Loss1: -0.9779 Loss2: -0.9831 Loss3: -0.9860\n",
            "2022-06-06 18:47:15.882368 Epoch [026/030], Step [0050/0060], Loss1: -0.9805 Loss2: -0.9858 Loss3: -0.9897\n",
            "2022-06-06 18:47:23.686242 Epoch [026/030], Step [0060/0060], Loss1: -0.9803 Loss2: -0.9848 Loss3: -0.9887\n",
            "Epoch: 26 MAE: 0.07885714778193721 ####  bestMAE: 0.0776250293267467 bestEpoch: 24\n",
            "2022-06-06 18:47:30.587549 Epoch [027/030], Step [0001/0060], Loss1: -0.9792 Loss2: -0.9855 Loss3: -0.9894\n",
            "2022-06-06 18:48:08.863799 Epoch [027/030], Step [0050/0060], Loss1: -0.9757 Loss2: -0.9819 Loss3: -0.9874\n",
            "2022-06-06 18:48:16.646809 Epoch [027/030], Step [0060/0060], Loss1: -0.9767 Loss2: -0.9865 Loss3: -0.9894\n",
            "Epoch: 27 MAE: 0.08149887448265439 ####  bestMAE: 0.0776250293267467 bestEpoch: 24\n",
            "2022-06-06 18:48:23.646565 Epoch [028/030], Step [0001/0060], Loss1: -0.9726 Loss2: -0.9811 Loss3: -0.9868\n",
            "2022-06-06 18:49:02.414362 Epoch [028/030], Step [0050/0060], Loss1: -0.9789 Loss2: -0.9863 Loss3: -0.9903\n",
            "2022-06-06 18:49:10.206167 Epoch [028/030], Step [0060/0060], Loss1: -0.9785 Loss2: -0.9846 Loss3: -0.9886\n",
            "Epoch: 28 MAE: 0.08136650045082056 ####  bestMAE: 0.0776250293267467 bestEpoch: 24\n",
            "2022-06-06 18:49:17.203268 Epoch [029/030], Step [0001/0060], Loss1: -0.9753 Loss2: -0.9840 Loss3: -0.9878\n",
            "2022-06-06 18:49:55.442940 Epoch [029/030], Step [0050/0060], Loss1: -0.9839 Loss2: -0.9876 Loss3: -0.9913\n",
            "2022-06-06 18:50:03.246096 Epoch [029/030], Step [0060/0060], Loss1: -0.9729 Loss2: -0.9826 Loss3: -0.9857\n",
            "Epoch: 29 MAE: 0.08075687352942411 ####  bestMAE: 0.0776250293267467 bestEpoch: 24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.L1Loss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary_Org')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = structure_loss(pre_res[0], gts) \n",
        "            loss2    = structure_loss(pre_res[1], gts)\n",
        "            loss3    = structure_loss(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_ORG_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_ORG_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_Structure_Loss_updated_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-xrFosWE6R",
        "outputId": "ae04a186-89cf-4ba7-d0e0-a57e0c739666"
      },
      "id": "VC-xrFosWE6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "/content/tmp/TrainDataset_update/RGB/ /content/tmp/TrainDataset_update/GT/ /content/tmp/TrainDataset_update/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset_update/RGB/RGB_00.png', '/content/tmp/TrainDataset_update/RGB/RGB_01.png', '/content/tmp/TrainDataset_update/RGB/RGB_02.png', '/content/tmp/TrainDataset_update/RGB/RGB_10.png', '/content/tmp/TrainDataset_update/RGB/RGB_100.png', '/content/tmp/TrainDataset_update/RGB/RGB_101.png', '/content/tmp/TrainDataset_update/RGB/RGB_102.png', '/content/tmp/TrainDataset_update/RGB/RGB_11.png', '/content/tmp/TrainDataset_update/RGB/RGB_110.png', '/content/tmp/TrainDataset_update/RGB/RGB_111.png', '/content/tmp/TrainDataset_update/RGB/RGB_112.png', '/content/tmp/TrainDataset_update/RGB/RGB_12.png', '/content/tmp/TrainDataset_update/RGB/RGB_120.png', '/content/tmp/TrainDataset_update/RGB/RGB_121.png', '/content/tmp/TrainDataset_update/RGB/RGB_122.png', '/content/tmp/TrainDataset_update/RGB/RGB_130.png', '/content/tmp/TrainDataset_update/RGB/RGB_131.png', '/content/tmp/TrainDataset_update/RGB/RGB_132.png', '/content/tmp/TrainDataset_update/RGB/RGB_140.png', '/content/tmp/TrainDataset_update/RGB/RGB_141.png', '/content/tmp/TrainDataset_update/RGB/RGB_142.png', '/content/tmp/TrainDataset_update/RGB/RGB_150.png', '/content/tmp/TrainDataset_update/RGB/RGB_151.png', '/content/tmp/TrainDataset_update/RGB/RGB_152.png', '/content/tmp/TrainDataset_update/RGB/RGB_160.png', '/content/tmp/TrainDataset_update/RGB/RGB_161.png', '/content/tmp/TrainDataset_update/RGB/RGB_162.png', '/content/tmp/TrainDataset_update/RGB/RGB_170.png', '/content/tmp/TrainDataset_update/RGB/RGB_171.png', '/content/tmp/TrainDataset_update/RGB/RGB_172.png', '/content/tmp/TrainDataset_update/RGB/RGB_180.png', '/content/tmp/TrainDataset_update/RGB/RGB_181.png', '/content/tmp/TrainDataset_update/RGB/RGB_182.png', '/content/tmp/TrainDataset_update/RGB/RGB_190.png', '/content/tmp/TrainDataset_update/RGB/RGB_191.png', '/content/tmp/TrainDataset_update/RGB/RGB_192.png', '/content/tmp/TrainDataset_update/RGB/RGB_20.png', '/content/tmp/TrainDataset_update/RGB/RGB_200.png', '/content/tmp/TrainDataset_update/RGB/RGB_201.png', '/content/tmp/TrainDataset_update/RGB/RGB_202.png', '/content/tmp/TrainDataset_update/RGB/RGB_21.png', '/content/tmp/TrainDataset_update/RGB/RGB_210.png', '/content/tmp/TrainDataset_update/RGB/RGB_211.png', '/content/tmp/TrainDataset_update/RGB/RGB_212.png', '/content/tmp/TrainDataset_update/RGB/RGB_22.png', '/content/tmp/TrainDataset_update/RGB/RGB_220.png', '/content/tmp/TrainDataset_update/RGB/RGB_221.png', '/content/tmp/TrainDataset_update/RGB/RGB_222.png', '/content/tmp/TrainDataset_update/RGB/RGB_230.png', '/content/tmp/TrainDataset_update/RGB/RGB_231.png', '/content/tmp/TrainDataset_update/RGB/RGB_232.png', '/content/tmp/TrainDataset_update/RGB/RGB_240.png', '/content/tmp/TrainDataset_update/RGB/RGB_241.png', '/content/tmp/TrainDataset_update/RGB/RGB_242.png', '/content/tmp/TrainDataset_update/RGB/RGB_250.png', '/content/tmp/TrainDataset_update/RGB/RGB_251.png', '/content/tmp/TrainDataset_update/RGB/RGB_252.png', '/content/tmp/TrainDataset_update/RGB/RGB_260.png', '/content/tmp/TrainDataset_update/RGB/RGB_261.png', '/content/tmp/TrainDataset_update/RGB/RGB_262.png', '/content/tmp/TrainDataset_update/RGB/RGB_270.png', '/content/tmp/TrainDataset_update/RGB/RGB_271.png', '/content/tmp/TrainDataset_update/RGB/RGB_272.png', '/content/tmp/TrainDataset_update/RGB/RGB_280.png', '/content/tmp/TrainDataset_update/RGB/RGB_281.png', '/content/tmp/TrainDataset_update/RGB/RGB_282.png', '/content/tmp/TrainDataset_update/RGB/RGB_290.png', '/content/tmp/TrainDataset_update/RGB/RGB_291.png', '/content/tmp/TrainDataset_update/RGB/RGB_292.png', '/content/tmp/TrainDataset_update/RGB/RGB_30.png', '/content/tmp/TrainDataset_update/RGB/RGB_300.png', '/content/tmp/TrainDataset_update/RGB/RGB_301.png', '/content/tmp/TrainDataset_update/RGB/RGB_302.png', '/content/tmp/TrainDataset_update/RGB/RGB_31.png', '/content/tmp/TrainDataset_update/RGB/RGB_310.png', '/content/tmp/TrainDataset_update/RGB/RGB_311.png', '/content/tmp/TrainDataset_update/RGB/RGB_312.png', '/content/tmp/TrainDataset_update/RGB/RGB_32.png', '/content/tmp/TrainDataset_update/RGB/RGB_320.png', '/content/tmp/TrainDataset_update/RGB/RGB_321.png', '/content/tmp/TrainDataset_update/RGB/RGB_322.png', '/content/tmp/TrainDataset_update/RGB/RGB_330.png', '/content/tmp/TrainDataset_update/RGB/RGB_331.png', '/content/tmp/TrainDataset_update/RGB/RGB_332.png', '/content/tmp/TrainDataset_update/RGB/RGB_340.png', '/content/tmp/TrainDataset_update/RGB/RGB_341.png', '/content/tmp/TrainDataset_update/RGB/RGB_342.png', '/content/tmp/TrainDataset_update/RGB/RGB_350.png', '/content/tmp/TrainDataset_update/RGB/RGB_351.png', '/content/tmp/TrainDataset_update/RGB/RGB_352.png', '/content/tmp/TrainDataset_update/RGB/RGB_360.png', '/content/tmp/TrainDataset_update/RGB/RGB_361.png', '/content/tmp/TrainDataset_update/RGB/RGB_362.png', '/content/tmp/TrainDataset_update/RGB/RGB_370.png', '/content/tmp/TrainDataset_update/RGB/RGB_371.png', '/content/tmp/TrainDataset_update/RGB/RGB_372.png', '/content/tmp/TrainDataset_update/RGB/RGB_380.png', '/content/tmp/TrainDataset_update/RGB/RGB_381.png', '/content/tmp/TrainDataset_update/RGB/RGB_382.png', '/content/tmp/TrainDataset_update/RGB/RGB_390.png', '/content/tmp/TrainDataset_update/RGB/RGB_391.png', '/content/tmp/TrainDataset_update/RGB/RGB_392.png', '/content/tmp/TrainDataset_update/RGB/RGB_40.png', '/content/tmp/TrainDataset_update/RGB/RGB_400.png', '/content/tmp/TrainDataset_update/RGB/RGB_401.png', '/content/tmp/TrainDataset_update/RGB/RGB_402.png', '/content/tmp/TrainDataset_update/RGB/RGB_41.png', '/content/tmp/TrainDataset_update/RGB/RGB_410.png', '/content/tmp/TrainDataset_update/RGB/RGB_411.png', '/content/tmp/TrainDataset_update/RGB/RGB_412.png', '/content/tmp/TrainDataset_update/RGB/RGB_42.png', '/content/tmp/TrainDataset_update/RGB/RGB_420.png', '/content/tmp/TrainDataset_update/RGB/RGB_421.png', '/content/tmp/TrainDataset_update/RGB/RGB_422.png', '/content/tmp/TrainDataset_update/RGB/RGB_430.png', '/content/tmp/TrainDataset_update/RGB/RGB_431.png', '/content/tmp/TrainDataset_update/RGB/RGB_432.png', '/content/tmp/TrainDataset_update/RGB/RGB_440.png', '/content/tmp/TrainDataset_update/RGB/RGB_441.png', '/content/tmp/TrainDataset_update/RGB/RGB_442.png', '/content/tmp/TrainDataset_update/RGB/RGB_450.png', '/content/tmp/TrainDataset_update/RGB/RGB_451.png', '/content/tmp/TrainDataset_update/RGB/RGB_452.png', '/content/tmp/TrainDataset_update/RGB/RGB_460.png', '/content/tmp/TrainDataset_update/RGB/RGB_461.png', '/content/tmp/TrainDataset_update/RGB/RGB_462.png', '/content/tmp/TrainDataset_update/RGB/RGB_470.png', '/content/tmp/TrainDataset_update/RGB/RGB_471.png', '/content/tmp/TrainDataset_update/RGB/RGB_472.png', '/content/tmp/TrainDataset_update/RGB/RGB_480.png', '/content/tmp/TrainDataset_update/RGB/RGB_481.png', '/content/tmp/TrainDataset_update/RGB/RGB_482.png', '/content/tmp/TrainDataset_update/RGB/RGB_490.png', '/content/tmp/TrainDataset_update/RGB/RGB_491.png', '/content/tmp/TrainDataset_update/RGB/RGB_492.png', '/content/tmp/TrainDataset_update/RGB/RGB_50.png', '/content/tmp/TrainDataset_update/RGB/RGB_500.png', '/content/tmp/TrainDataset_update/RGB/RGB_501.png', '/content/tmp/TrainDataset_update/RGB/RGB_502.png', '/content/tmp/TrainDataset_update/RGB/RGB_51.png', '/content/tmp/TrainDataset_update/RGB/RGB_510.png', '/content/tmp/TrainDataset_update/RGB/RGB_511.png', '/content/tmp/TrainDataset_update/RGB/RGB_512.png', '/content/tmp/TrainDataset_update/RGB/RGB_52.png', '/content/tmp/TrainDataset_update/RGB/RGB_520.png', '/content/tmp/TrainDataset_update/RGB/RGB_521.png', '/content/tmp/TrainDataset_update/RGB/RGB_522.png', '/content/tmp/TrainDataset_update/RGB/RGB_530.png', '/content/tmp/TrainDataset_update/RGB/RGB_531.png', '/content/tmp/TrainDataset_update/RGB/RGB_532.png', '/content/tmp/TrainDataset_update/RGB/RGB_540.png', '/content/tmp/TrainDataset_update/RGB/RGB_541.png', '/content/tmp/TrainDataset_update/RGB/RGB_542.png', '/content/tmp/TrainDataset_update/RGB/RGB_550.png', '/content/tmp/TrainDataset_update/RGB/RGB_551.png', '/content/tmp/TrainDataset_update/RGB/RGB_552.png', '/content/tmp/TrainDataset_update/RGB/RGB_560.png', '/content/tmp/TrainDataset_update/RGB/RGB_561.png', '/content/tmp/TrainDataset_update/RGB/RGB_562.png', '/content/tmp/TrainDataset_update/RGB/RGB_570.png', '/content/tmp/TrainDataset_update/RGB/RGB_571.png', '/content/tmp/TrainDataset_update/RGB/RGB_572.png', '/content/tmp/TrainDataset_update/RGB/RGB_580.png', '/content/tmp/TrainDataset_update/RGB/RGB_581.png', '/content/tmp/TrainDataset_update/RGB/RGB_582.png', '/content/tmp/TrainDataset_update/RGB/RGB_590.png', '/content/tmp/TrainDataset_update/RGB/RGB_591.png', '/content/tmp/TrainDataset_update/RGB/RGB_592.png', '/content/tmp/TrainDataset_update/RGB/RGB_60.png', '/content/tmp/TrainDataset_update/RGB/RGB_600.png', '/content/tmp/TrainDataset_update/RGB/RGB_601.png', '/content/tmp/TrainDataset_update/RGB/RGB_602.png', '/content/tmp/TrainDataset_update/RGB/RGB_61.png', '/content/tmp/TrainDataset_update/RGB/RGB_610.png', '/content/tmp/TrainDataset_update/RGB/RGB_611.png', '/content/tmp/TrainDataset_update/RGB/RGB_612.png', '/content/tmp/TrainDataset_update/RGB/RGB_62.png', '/content/tmp/TrainDataset_update/RGB/RGB_620.png', '/content/tmp/TrainDataset_update/RGB/RGB_621.png', '/content/tmp/TrainDataset_update/RGB/RGB_622.png', '/content/tmp/TrainDataset_update/RGB/RGB_630.png', '/content/tmp/TrainDataset_update/RGB/RGB_631.png', '/content/tmp/TrainDataset_update/RGB/RGB_632.png', '/content/tmp/TrainDataset_update/RGB/RGB_640.png', '/content/tmp/TrainDataset_update/RGB/RGB_641.png', '/content/tmp/TrainDataset_update/RGB/RGB_642.png', '/content/tmp/TrainDataset_update/RGB/RGB_650.png', '/content/tmp/TrainDataset_update/RGB/RGB_651.png', '/content/tmp/TrainDataset_update/RGB/RGB_652.png', '/content/tmp/TrainDataset_update/RGB/RGB_660.png', '/content/tmp/TrainDataset_update/RGB/RGB_661.png', '/content/tmp/TrainDataset_update/RGB/RGB_662.png', '/content/tmp/TrainDataset_update/RGB/RGB_670.png', '/content/tmp/TrainDataset_update/RGB/RGB_671.png', '/content/tmp/TrainDataset_update/RGB/RGB_672.png', '/content/tmp/TrainDataset_update/RGB/RGB_680.png', '/content/tmp/TrainDataset_update/RGB/RGB_681.png', '/content/tmp/TrainDataset_update/RGB/RGB_682.png', '/content/tmp/TrainDataset_update/RGB/RGB_690.png', '/content/tmp/TrainDataset_update/RGB/RGB_691.png', '/content/tmp/TrainDataset_update/RGB/RGB_692.png', '/content/tmp/TrainDataset_update/RGB/RGB_70.png', '/content/tmp/TrainDataset_update/RGB/RGB_700.png', '/content/tmp/TrainDataset_update/RGB/RGB_701.png', '/content/tmp/TrainDataset_update/RGB/RGB_702.png', '/content/tmp/TrainDataset_update/RGB/RGB_71.png', '/content/tmp/TrainDataset_update/RGB/RGB_710.png', '/content/tmp/TrainDataset_update/RGB/RGB_711.png', '/content/tmp/TrainDataset_update/RGB/RGB_712.png', '/content/tmp/TrainDataset_update/RGB/RGB_72.png', '/content/tmp/TrainDataset_update/RGB/RGB_720.png', '/content/tmp/TrainDataset_update/RGB/RGB_721.png', '/content/tmp/TrainDataset_update/RGB/RGB_722.png', '/content/tmp/TrainDataset_update/RGB/RGB_730.png', '/content/tmp/TrainDataset_update/RGB/RGB_731.png', '/content/tmp/TrainDataset_update/RGB/RGB_732.png', '/content/tmp/TrainDataset_update/RGB/RGB_740.png', '/content/tmp/TrainDataset_update/RGB/RGB_741.png', '/content/tmp/TrainDataset_update/RGB/RGB_742.png', '/content/tmp/TrainDataset_update/RGB/RGB_750.png', '/content/tmp/TrainDataset_update/RGB/RGB_751.png', '/content/tmp/TrainDataset_update/RGB/RGB_752.png', '/content/tmp/TrainDataset_update/RGB/RGB_760.png', '/content/tmp/TrainDataset_update/RGB/RGB_761.png', '/content/tmp/TrainDataset_update/RGB/RGB_762.png', '/content/tmp/TrainDataset_update/RGB/RGB_770.png', '/content/tmp/TrainDataset_update/RGB/RGB_771.png', '/content/tmp/TrainDataset_update/RGB/RGB_772.png', '/content/tmp/TrainDataset_update/RGB/RGB_780.png', '/content/tmp/TrainDataset_update/RGB/RGB_781.png', '/content/tmp/TrainDataset_update/RGB/RGB_782.png', '/content/tmp/TrainDataset_update/RGB/RGB_790.png', '/content/tmp/TrainDataset_update/RGB/RGB_791.png', '/content/tmp/TrainDataset_update/RGB/RGB_792.png', '/content/tmp/TrainDataset_update/RGB/RGB_80.png', '/content/tmp/TrainDataset_update/RGB/RGB_81.png', '/content/tmp/TrainDataset_update/RGB/RGB_82.png', '/content/tmp/TrainDataset_update/RGB/RGB_90.png', '/content/tmp/TrainDataset_update/RGB/RGB_91.png', '/content/tmp/TrainDataset_update/RGB/RGB_92.png'] ['/content/tmp/TrainDataset_update/GT/GT_00.png', '/content/tmp/TrainDataset_update/GT/GT_01.png', '/content/tmp/TrainDataset_update/GT/GT_02.png', '/content/tmp/TrainDataset_update/GT/GT_10.png', '/content/tmp/TrainDataset_update/GT/GT_100.png', '/content/tmp/TrainDataset_update/GT/GT_101.png', '/content/tmp/TrainDataset_update/GT/GT_102.png', '/content/tmp/TrainDataset_update/GT/GT_11.png', '/content/tmp/TrainDataset_update/GT/GT_110.png', '/content/tmp/TrainDataset_update/GT/GT_111.png', '/content/tmp/TrainDataset_update/GT/GT_112.png', '/content/tmp/TrainDataset_update/GT/GT_12.png', '/content/tmp/TrainDataset_update/GT/GT_120.png', '/content/tmp/TrainDataset_update/GT/GT_121.png', '/content/tmp/TrainDataset_update/GT/GT_122.png', '/content/tmp/TrainDataset_update/GT/GT_130.png', '/content/tmp/TrainDataset_update/GT/GT_131.png', '/content/tmp/TrainDataset_update/GT/GT_132.png', '/content/tmp/TrainDataset_update/GT/GT_140.png', '/content/tmp/TrainDataset_update/GT/GT_141.png', '/content/tmp/TrainDataset_update/GT/GT_142.png', '/content/tmp/TrainDataset_update/GT/GT_150.png', '/content/tmp/TrainDataset_update/GT/GT_151.png', '/content/tmp/TrainDataset_update/GT/GT_152.png', '/content/tmp/TrainDataset_update/GT/GT_160.png', '/content/tmp/TrainDataset_update/GT/GT_161.png', '/content/tmp/TrainDataset_update/GT/GT_162.png', '/content/tmp/TrainDataset_update/GT/GT_170.png', '/content/tmp/TrainDataset_update/GT/GT_171.png', '/content/tmp/TrainDataset_update/GT/GT_172.png', '/content/tmp/TrainDataset_update/GT/GT_180.png', '/content/tmp/TrainDataset_update/GT/GT_181.png', '/content/tmp/TrainDataset_update/GT/GT_182.png', '/content/tmp/TrainDataset_update/GT/GT_190.png', '/content/tmp/TrainDataset_update/GT/GT_191.png', '/content/tmp/TrainDataset_update/GT/GT_192.png', '/content/tmp/TrainDataset_update/GT/GT_20.png', '/content/tmp/TrainDataset_update/GT/GT_200.png', '/content/tmp/TrainDataset_update/GT/GT_201.png', '/content/tmp/TrainDataset_update/GT/GT_202.png', '/content/tmp/TrainDataset_update/GT/GT_21.png', '/content/tmp/TrainDataset_update/GT/GT_210.png', '/content/tmp/TrainDataset_update/GT/GT_211.png', '/content/tmp/TrainDataset_update/GT/GT_212.png', '/content/tmp/TrainDataset_update/GT/GT_22.png', '/content/tmp/TrainDataset_update/GT/GT_220.png', '/content/tmp/TrainDataset_update/GT/GT_221.png', '/content/tmp/TrainDataset_update/GT/GT_222.png', '/content/tmp/TrainDataset_update/GT/GT_230.png', '/content/tmp/TrainDataset_update/GT/GT_231.png', '/content/tmp/TrainDataset_update/GT/GT_232.png', '/content/tmp/TrainDataset_update/GT/GT_240.png', '/content/tmp/TrainDataset_update/GT/GT_241.png', '/content/tmp/TrainDataset_update/GT/GT_242.png', '/content/tmp/TrainDataset_update/GT/GT_250.png', '/content/tmp/TrainDataset_update/GT/GT_251.png', '/content/tmp/TrainDataset_update/GT/GT_252.png', '/content/tmp/TrainDataset_update/GT/GT_260.png', '/content/tmp/TrainDataset_update/GT/GT_261.png', '/content/tmp/TrainDataset_update/GT/GT_262.png', '/content/tmp/TrainDataset_update/GT/GT_270.png', '/content/tmp/TrainDataset_update/GT/GT_271.png', '/content/tmp/TrainDataset_update/GT/GT_272.png', '/content/tmp/TrainDataset_update/GT/GT_280.png', '/content/tmp/TrainDataset_update/GT/GT_281.png', '/content/tmp/TrainDataset_update/GT/GT_282.png', '/content/tmp/TrainDataset_update/GT/GT_290.png', '/content/tmp/TrainDataset_update/GT/GT_291.png', '/content/tmp/TrainDataset_update/GT/GT_292.png', '/content/tmp/TrainDataset_update/GT/GT_30.png', '/content/tmp/TrainDataset_update/GT/GT_300.png', '/content/tmp/TrainDataset_update/GT/GT_301.png', '/content/tmp/TrainDataset_update/GT/GT_302.png', '/content/tmp/TrainDataset_update/GT/GT_31.png', '/content/tmp/TrainDataset_update/GT/GT_310.png', '/content/tmp/TrainDataset_update/GT/GT_311.png', '/content/tmp/TrainDataset_update/GT/GT_312.png', '/content/tmp/TrainDataset_update/GT/GT_32.png', '/content/tmp/TrainDataset_update/GT/GT_320.png', '/content/tmp/TrainDataset_update/GT/GT_321.png', '/content/tmp/TrainDataset_update/GT/GT_322.png', '/content/tmp/TrainDataset_update/GT/GT_330.png', '/content/tmp/TrainDataset_update/GT/GT_331.png', '/content/tmp/TrainDataset_update/GT/GT_332.png', '/content/tmp/TrainDataset_update/GT/GT_340.png', '/content/tmp/TrainDataset_update/GT/GT_341.png', '/content/tmp/TrainDataset_update/GT/GT_342.png', '/content/tmp/TrainDataset_update/GT/GT_350.png', '/content/tmp/TrainDataset_update/GT/GT_351.png', '/content/tmp/TrainDataset_update/GT/GT_352.png', '/content/tmp/TrainDataset_update/GT/GT_360.png', '/content/tmp/TrainDataset_update/GT/GT_361.png', '/content/tmp/TrainDataset_update/GT/GT_362.png', '/content/tmp/TrainDataset_update/GT/GT_370.png', '/content/tmp/TrainDataset_update/GT/GT_371.png', '/content/tmp/TrainDataset_update/GT/GT_372.png', '/content/tmp/TrainDataset_update/GT/GT_380.png', '/content/tmp/TrainDataset_update/GT/GT_381.png', '/content/tmp/TrainDataset_update/GT/GT_382.png', '/content/tmp/TrainDataset_update/GT/GT_390.png', '/content/tmp/TrainDataset_update/GT/GT_391.png', '/content/tmp/TrainDataset_update/GT/GT_392.png', '/content/tmp/TrainDataset_update/GT/GT_40.png', '/content/tmp/TrainDataset_update/GT/GT_400.png', '/content/tmp/TrainDataset_update/GT/GT_401.png', '/content/tmp/TrainDataset_update/GT/GT_402.png', '/content/tmp/TrainDataset_update/GT/GT_41.png', '/content/tmp/TrainDataset_update/GT/GT_410.png', '/content/tmp/TrainDataset_update/GT/GT_411.png', '/content/tmp/TrainDataset_update/GT/GT_412.png', '/content/tmp/TrainDataset_update/GT/GT_42.png', '/content/tmp/TrainDataset_update/GT/GT_420.png', '/content/tmp/TrainDataset_update/GT/GT_421.png', '/content/tmp/TrainDataset_update/GT/GT_422.png', '/content/tmp/TrainDataset_update/GT/GT_430.png', '/content/tmp/TrainDataset_update/GT/GT_431.png', '/content/tmp/TrainDataset_update/GT/GT_432.png', '/content/tmp/TrainDataset_update/GT/GT_440.png', '/content/tmp/TrainDataset_update/GT/GT_441.png', '/content/tmp/TrainDataset_update/GT/GT_442.png', '/content/tmp/TrainDataset_update/GT/GT_450.png', '/content/tmp/TrainDataset_update/GT/GT_451.png', '/content/tmp/TrainDataset_update/GT/GT_452.png', '/content/tmp/TrainDataset_update/GT/GT_460.png', '/content/tmp/TrainDataset_update/GT/GT_461.png', '/content/tmp/TrainDataset_update/GT/GT_462.png', '/content/tmp/TrainDataset_update/GT/GT_470.png', '/content/tmp/TrainDataset_update/GT/GT_471.png', '/content/tmp/TrainDataset_update/GT/GT_472.png', '/content/tmp/TrainDataset_update/GT/GT_480.png', '/content/tmp/TrainDataset_update/GT/GT_481.png', '/content/tmp/TrainDataset_update/GT/GT_482.png', '/content/tmp/TrainDataset_update/GT/GT_490.png', '/content/tmp/TrainDataset_update/GT/GT_491.png', '/content/tmp/TrainDataset_update/GT/GT_492.png', '/content/tmp/TrainDataset_update/GT/GT_50.png', '/content/tmp/TrainDataset_update/GT/GT_500.png', '/content/tmp/TrainDataset_update/GT/GT_501.png', '/content/tmp/TrainDataset_update/GT/GT_502.png', '/content/tmp/TrainDataset_update/GT/GT_51.png', '/content/tmp/TrainDataset_update/GT/GT_510.png', '/content/tmp/TrainDataset_update/GT/GT_511.png', '/content/tmp/TrainDataset_update/GT/GT_512.png', '/content/tmp/TrainDataset_update/GT/GT_52.png', '/content/tmp/TrainDataset_update/GT/GT_520.png', '/content/tmp/TrainDataset_update/GT/GT_521.png', '/content/tmp/TrainDataset_update/GT/GT_522.png', '/content/tmp/TrainDataset_update/GT/GT_530.png', '/content/tmp/TrainDataset_update/GT/GT_531.png', '/content/tmp/TrainDataset_update/GT/GT_532.png', '/content/tmp/TrainDataset_update/GT/GT_540.png', '/content/tmp/TrainDataset_update/GT/GT_541.png', '/content/tmp/TrainDataset_update/GT/GT_542.png', '/content/tmp/TrainDataset_update/GT/GT_550.png', '/content/tmp/TrainDataset_update/GT/GT_551.png', '/content/tmp/TrainDataset_update/GT/GT_552.png', '/content/tmp/TrainDataset_update/GT/GT_560.png', '/content/tmp/TrainDataset_update/GT/GT_561.png', '/content/tmp/TrainDataset_update/GT/GT_562.png', '/content/tmp/TrainDataset_update/GT/GT_570.png', '/content/tmp/TrainDataset_update/GT/GT_571.png', '/content/tmp/TrainDataset_update/GT/GT_572.png', '/content/tmp/TrainDataset_update/GT/GT_580.png', '/content/tmp/TrainDataset_update/GT/GT_581.png', '/content/tmp/TrainDataset_update/GT/GT_582.png', '/content/tmp/TrainDataset_update/GT/GT_590.png', '/content/tmp/TrainDataset_update/GT/GT_591.png', '/content/tmp/TrainDataset_update/GT/GT_592.png', '/content/tmp/TrainDataset_update/GT/GT_60.png', '/content/tmp/TrainDataset_update/GT/GT_600.png', '/content/tmp/TrainDataset_update/GT/GT_601.png', '/content/tmp/TrainDataset_update/GT/GT_602.png', '/content/tmp/TrainDataset_update/GT/GT_61.png', '/content/tmp/TrainDataset_update/GT/GT_610.png', '/content/tmp/TrainDataset_update/GT/GT_611.png', '/content/tmp/TrainDataset_update/GT/GT_612.png', '/content/tmp/TrainDataset_update/GT/GT_62.png', '/content/tmp/TrainDataset_update/GT/GT_620.png', '/content/tmp/TrainDataset_update/GT/GT_621.png', '/content/tmp/TrainDataset_update/GT/GT_622.png', '/content/tmp/TrainDataset_update/GT/GT_630.png', '/content/tmp/TrainDataset_update/GT/GT_631.png', '/content/tmp/TrainDataset_update/GT/GT_632.png', '/content/tmp/TrainDataset_update/GT/GT_640.png', '/content/tmp/TrainDataset_update/GT/GT_641.png', '/content/tmp/TrainDataset_update/GT/GT_642.png', '/content/tmp/TrainDataset_update/GT/GT_650.png', '/content/tmp/TrainDataset_update/GT/GT_651.png', '/content/tmp/TrainDataset_update/GT/GT_652.png', '/content/tmp/TrainDataset_update/GT/GT_660.png', '/content/tmp/TrainDataset_update/GT/GT_661.png', '/content/tmp/TrainDataset_update/GT/GT_662.png', '/content/tmp/TrainDataset_update/GT/GT_670.png', '/content/tmp/TrainDataset_update/GT/GT_671.png', '/content/tmp/TrainDataset_update/GT/GT_672.png', '/content/tmp/TrainDataset_update/GT/GT_680.png', '/content/tmp/TrainDataset_update/GT/GT_681.png', '/content/tmp/TrainDataset_update/GT/GT_682.png', '/content/tmp/TrainDataset_update/GT/GT_690.png', '/content/tmp/TrainDataset_update/GT/GT_691.png', '/content/tmp/TrainDataset_update/GT/GT_692.png', '/content/tmp/TrainDataset_update/GT/GT_70.png', '/content/tmp/TrainDataset_update/GT/GT_700.png', '/content/tmp/TrainDataset_update/GT/GT_701.png', '/content/tmp/TrainDataset_update/GT/GT_702.png', '/content/tmp/TrainDataset_update/GT/GT_71.png', '/content/tmp/TrainDataset_update/GT/GT_710.png', '/content/tmp/TrainDataset_update/GT/GT_711.png', '/content/tmp/TrainDataset_update/GT/GT_712.png', '/content/tmp/TrainDataset_update/GT/GT_72.png', '/content/tmp/TrainDataset_update/GT/GT_720.png', '/content/tmp/TrainDataset_update/GT/GT_721.png', '/content/tmp/TrainDataset_update/GT/GT_722.png', '/content/tmp/TrainDataset_update/GT/GT_730.png', '/content/tmp/TrainDataset_update/GT/GT_731.png', '/content/tmp/TrainDataset_update/GT/GT_732.png', '/content/tmp/TrainDataset_update/GT/GT_740.png', '/content/tmp/TrainDataset_update/GT/GT_741.png', '/content/tmp/TrainDataset_update/GT/GT_742.png', '/content/tmp/TrainDataset_update/GT/GT_750.png', '/content/tmp/TrainDataset_update/GT/GT_751.png', '/content/tmp/TrainDataset_update/GT/GT_752.png', '/content/tmp/TrainDataset_update/GT/GT_760.png', '/content/tmp/TrainDataset_update/GT/GT_761.png', '/content/tmp/TrainDataset_update/GT/GT_762.png', '/content/tmp/TrainDataset_update/GT/GT_770.png', '/content/tmp/TrainDataset_update/GT/GT_771.png', '/content/tmp/TrainDataset_update/GT/GT_772.png', '/content/tmp/TrainDataset_update/GT/GT_780.png', '/content/tmp/TrainDataset_update/GT/GT_781.png', '/content/tmp/TrainDataset_update/GT/GT_782.png', '/content/tmp/TrainDataset_update/GT/GT_790.png', '/content/tmp/TrainDataset_update/GT/GT_791.png', '/content/tmp/TrainDataset_update/GT/GT_792.png', '/content/tmp/TrainDataset_update/GT/GT_80.png', '/content/tmp/TrainDataset_update/GT/GT_81.png', '/content/tmp/TrainDataset_update/GT/GT_82.png', '/content/tmp/TrainDataset_update/GT/GT_90.png', '/content/tmp/TrainDataset_update/GT/GT_91.png', '/content/tmp/TrainDataset_update/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f38de0df5d0>\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='mean' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-06 18:51:06.562970 Epoch [001/030], Step [0001/0060], Loss1: 1.4585 Loss2: 1.4642 Loss3: 1.4152\n",
            "2022-06-06 18:51:45.289606 Epoch [001/030], Step [0050/0060], Loss1: 1.1235 Loss2: 1.0987 Loss3: 1.0711\n",
            "2022-06-06 18:51:53.166664 Epoch [001/030], Step [0060/0060], Loss1: 1.0946 Loss2: 1.0742 Loss3: 1.0457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.107916930365184 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-06 18:52:00.183139 Epoch [002/030], Step [0001/0060], Loss1: 1.0737 Loss2: 1.0487 Loss3: 1.0171\n",
            "2022-06-06 18:52:38.345414 Epoch [002/030], Step [0050/0060], Loss1: 1.1010 Loss2: 1.0900 Loss3: 1.0681\n",
            "2022-06-06 18:52:46.161932 Epoch [002/030], Step [0060/0060], Loss1: 1.0117 Loss2: 0.9981 Loss3: 0.9855\n",
            "Epoch: 2 MAE: 0.078725730754711 ####  bestMAE: 0.107916930365184 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-06 18:52:55.614193 Epoch [003/030], Step [0001/0060], Loss1: 1.0032 Loss2: 0.9950 Loss3: 0.9795\n",
            "2022-06-06 18:53:34.615199 Epoch [003/030], Step [0050/0060], Loss1: 1.0417 Loss2: 1.0284 Loss3: 1.0160\n",
            "2022-06-06 18:53:42.456409 Epoch [003/030], Step [0060/0060], Loss1: 1.0862 Loss2: 1.0730 Loss3: 1.0591\n",
            "Epoch: 3 MAE: 0.08205397550391141 ####  bestMAE: 0.078725730754711 bestEpoch: 2\n",
            "2022-06-06 18:53:49.454366 Epoch [004/030], Step [0001/0060], Loss1: 0.9935 Loss2: 0.9843 Loss3: 0.9734\n",
            "2022-06-06 18:54:27.751775 Epoch [004/030], Step [0050/0060], Loss1: 1.0585 Loss2: 1.0531 Loss3: 1.0307\n",
            "2022-06-06 18:54:35.574966 Epoch [004/030], Step [0060/0060], Loss1: 0.9742 Loss2: 0.9634 Loss3: 0.9520\n",
            "Epoch: 4 MAE: 0.0875343240001214 ####  bestMAE: 0.078725730754711 bestEpoch: 2\n",
            "2022-06-06 18:54:42.719415 Epoch [005/030], Step [0001/0060], Loss1: 0.9670 Loss2: 0.9598 Loss3: 0.9468\n",
            "2022-06-06 18:55:21.334759 Epoch [005/030], Step [0050/0060], Loss1: 1.0155 Loss2: 0.9992 Loss3: 0.9919\n",
            "2022-06-06 18:55:29.165732 Epoch [005/030], Step [0060/0060], Loss1: 1.0437 Loss2: 1.0350 Loss3: 1.0201\n",
            "Epoch: 5 MAE: 0.07054994628542945 ####  bestMAE: 0.078725730754711 bestEpoch: 2\n",
            "best epoch:5\n",
            "2022-06-06 18:55:40.870972 Epoch [006/030], Step [0001/0060], Loss1: 1.0352 Loss2: 1.0272 Loss3: 1.0155\n",
            "2022-06-06 18:56:19.224160 Epoch [006/030], Step [0050/0060], Loss1: 1.0563 Loss2: 1.0455 Loss3: 1.0363\n",
            "2022-06-06 18:56:27.058781 Epoch [006/030], Step [0060/0060], Loss1: 0.9657 Loss2: 0.9616 Loss3: 0.9544\n",
            "Epoch: 6 MAE: 0.07367502949225208 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 18:56:34.046090 Epoch [007/030], Step [0001/0060], Loss1: 1.0184 Loss2: 1.0125 Loss3: 0.9993\n",
            "2022-06-06 18:57:12.384371 Epoch [007/030], Step [0050/0060], Loss1: 1.0708 Loss2: 1.0631 Loss3: 1.0547\n",
            "2022-06-06 18:57:20.206159 Epoch [007/030], Step [0060/0060], Loss1: 1.0332 Loss2: 1.0274 Loss3: 1.0190\n",
            "Epoch: 7 MAE: 0.08003772261281493 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 18:57:29.087907 Epoch [008/030], Step [0001/0060], Loss1: 1.0257 Loss2: 1.0222 Loss3: 1.0146\n",
            "2022-06-06 18:58:07.589485 Epoch [008/030], Step [0050/0060], Loss1: 1.0012 Loss2: 0.9967 Loss3: 0.9903\n",
            "2022-06-06 18:58:15.415986 Epoch [008/030], Step [0060/0060], Loss1: 0.9556 Loss2: 0.9470 Loss3: 0.9415\n",
            "Epoch: 8 MAE: 0.07502010370688462 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 18:58:22.526139 Epoch [009/030], Step [0001/0060], Loss1: 0.9744 Loss2: 0.9666 Loss3: 0.9611\n",
            "2022-06-06 18:59:00.922318 Epoch [009/030], Step [0050/0060], Loss1: 1.0056 Loss2: 0.9947 Loss3: 0.9904\n",
            "2022-06-06 18:59:08.750789 Epoch [009/030], Step [0060/0060], Loss1: 1.0550 Loss2: 1.0448 Loss3: 1.0391\n",
            "Epoch: 9 MAE: 0.07726906498903949 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 18:59:15.825016 Epoch [010/030], Step [0001/0060], Loss1: 1.0240 Loss2: 1.0153 Loss3: 1.0105\n",
            "2022-06-06 18:59:54.332126 Epoch [010/030], Step [0050/0060], Loss1: 0.9664 Loss2: 0.9609 Loss3: 0.9551\n",
            "2022-06-06 19:00:02.178729 Epoch [010/030], Step [0060/0060], Loss1: 0.9944 Loss2: 0.9814 Loss3: 0.9773\n",
            "Epoch: 10 MAE: 0.07348382404872349 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:00:11.945389 Epoch [011/030], Step [0001/0060], Loss1: 1.0008 Loss2: 0.9954 Loss3: 0.9910\n",
            "2022-06-06 19:00:50.400219 Epoch [011/030], Step [0050/0060], Loss1: 0.9585 Loss2: 0.9518 Loss3: 0.9458\n",
            "2022-06-06 19:00:58.211842 Epoch [011/030], Step [0060/0060], Loss1: 0.9490 Loss2: 0.9413 Loss3: 0.9374\n",
            "Epoch: 11 MAE: 0.0732278555915469 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:01:05.328323 Epoch [012/030], Step [0001/0060], Loss1: 1.0300 Loss2: 1.0235 Loss3: 1.0182\n",
            "2022-06-06 19:01:43.639845 Epoch [012/030], Step [0050/0060], Loss1: 1.0623 Loss2: 1.0501 Loss3: 1.0456\n",
            "2022-06-06 19:01:51.646960 Epoch [012/030], Step [0060/0060], Loss1: 1.0299 Loss2: 1.0190 Loss3: 1.0153\n",
            "Epoch: 12 MAE: 0.0783233872670976 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:02:00.396103 Epoch [013/030], Step [0001/0060], Loss1: 1.0118 Loss2: 1.0037 Loss3: 0.9997\n",
            "2022-06-06 19:02:38.770597 Epoch [013/030], Step [0050/0060], Loss1: 1.0320 Loss2: 1.0267 Loss3: 1.0217\n",
            "2022-06-06 19:02:46.578953 Epoch [013/030], Step [0060/0060], Loss1: 1.0237 Loss2: 1.0195 Loss3: 1.0136\n",
            "Epoch: 13 MAE: 0.07450783088724447 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:02:53.668091 Epoch [014/030], Step [0001/0060], Loss1: 1.0345 Loss2: 1.0247 Loss3: 1.0209\n",
            "2022-06-06 19:03:31.781235 Epoch [014/030], Step [0050/0060], Loss1: 0.9914 Loss2: 0.9875 Loss3: 0.9830\n",
            "2022-06-06 19:03:39.578149 Epoch [014/030], Step [0060/0060], Loss1: 1.0267 Loss2: 1.0185 Loss3: 1.0144\n",
            "Epoch: 14 MAE: 0.07478583472115653 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:03:46.868379 Epoch [015/030], Step [0001/0060], Loss1: 0.9685 Loss2: 0.9621 Loss3: 0.9579\n",
            "2022-06-06 19:04:25.525048 Epoch [015/030], Step [0050/0060], Loss1: 0.9607 Loss2: 0.9552 Loss3: 0.9525\n",
            "2022-06-06 19:04:33.344838 Epoch [015/030], Step [0060/0060], Loss1: 1.0191 Loss2: 1.0182 Loss3: 1.0138\n",
            "Epoch: 15 MAE: 0.07411407839053522 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:04:43.098823 Epoch [016/030], Step [0001/0060], Loss1: 1.0748 Loss2: 1.0641 Loss3: 1.0599\n",
            "2022-06-06 19:05:21.325986 Epoch [016/030], Step [0050/0060], Loss1: 1.0625 Loss2: 1.0552 Loss3: 1.0505\n",
            "2022-06-06 19:05:29.115361 Epoch [016/030], Step [0060/0060], Loss1: 1.0375 Loss2: 1.0328 Loss3: 1.0301\n",
            "Epoch: 16 MAE: 0.08083488948761472 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:05:36.175958 Epoch [017/030], Step [0001/0060], Loss1: 0.9724 Loss2: 0.9700 Loss3: 0.9670\n",
            "2022-06-06 19:06:14.376762 Epoch [017/030], Step [0050/0060], Loss1: 0.9590 Loss2: 0.9555 Loss3: 0.9511\n",
            "2022-06-06 19:06:22.363035 Epoch [017/030], Step [0060/0060], Loss1: 0.9560 Loss2: 0.9518 Loss3: 0.9480\n",
            "Epoch: 17 MAE: 0.07697674211370883 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:06:29.917398 Epoch [018/030], Step [0001/0060], Loss1: 1.0173 Loss2: 1.0071 Loss3: 1.0043\n",
            "2022-06-06 19:07:07.879556 Epoch [018/030], Step [0050/0060], Loss1: 1.0066 Loss2: 1.0019 Loss3: 0.9972\n",
            "2022-06-06 19:07:15.626389 Epoch [018/030], Step [0060/0060], Loss1: 0.9765 Loss2: 0.9700 Loss3: 0.9671\n",
            "Epoch: 18 MAE: 0.0711373322602933 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:07:22.615103 Epoch [019/030], Step [0001/0060], Loss1: 0.9131 Loss2: 0.9068 Loss3: 0.9044\n",
            "2022-06-06 19:08:00.491719 Epoch [019/030], Step [0050/0060], Loss1: 1.0225 Loss2: 1.0156 Loss3: 1.0122\n",
            "2022-06-06 19:08:08.217108 Epoch [019/030], Step [0060/0060], Loss1: 1.0118 Loss2: 1.0086 Loss3: 1.0043\n",
            "Epoch: 19 MAE: 0.07271360982662786 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:08:15.296054 Epoch [020/030], Step [0001/0060], Loss1: 1.0473 Loss2: 1.0380 Loss3: 1.0345\n",
            "2022-06-06 19:08:53.461825 Epoch [020/030], Step [0050/0060], Loss1: 1.0076 Loss2: 0.9992 Loss3: 0.9962\n",
            "2022-06-06 19:09:01.214061 Epoch [020/030], Step [0060/0060], Loss1: 0.9579 Loss2: 0.9537 Loss3: 0.9510\n",
            "Epoch: 20 MAE: 0.07404974664960591 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:09:11.625935 Epoch [021/030], Step [0001/0060], Loss1: 0.9840 Loss2: 0.9804 Loss3: 0.9764\n",
            "2022-06-06 19:09:50.297321 Epoch [021/030], Step [0050/0060], Loss1: 1.1257 Loss2: 1.1179 Loss3: 1.1134\n",
            "2022-06-06 19:09:58.129183 Epoch [021/030], Step [0060/0060], Loss1: 0.9604 Loss2: 0.9562 Loss3: 0.9539\n",
            "Epoch: 21 MAE: 0.07217246494595969 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:10:05.197536 Epoch [022/030], Step [0001/0060], Loss1: 0.9768 Loss2: 0.9744 Loss3: 0.9703\n",
            "2022-06-06 19:10:43.817163 Epoch [022/030], Step [0050/0060], Loss1: 1.0214 Loss2: 1.0150 Loss3: 1.0123\n",
            "2022-06-06 19:10:51.627873 Epoch [022/030], Step [0060/0060], Loss1: 0.9995 Loss2: 0.9925 Loss3: 0.9893\n",
            "Epoch: 22 MAE: 0.07506394340878442 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:10:58.702118 Epoch [023/030], Step [0001/0060], Loss1: 0.9832 Loss2: 0.9768 Loss3: 0.9739\n",
            "2022-06-06 19:11:36.682134 Epoch [023/030], Step [0050/0060], Loss1: 1.0881 Loss2: 1.0759 Loss3: 1.0713\n",
            "2022-06-06 19:11:44.416996 Epoch [023/030], Step [0060/0060], Loss1: 0.9699 Loss2: 0.9674 Loss3: 0.9643\n",
            "Epoch: 23 MAE: 0.0785303921169705 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:11:51.592157 Epoch [024/030], Step [0001/0060], Loss1: 0.9701 Loss2: 0.9623 Loss3: 0.9602\n",
            "2022-06-06 19:12:29.539074 Epoch [024/030], Step [0050/0060], Loss1: 1.0381 Loss2: 1.0284 Loss3: 1.0263\n",
            "2022-06-06 19:12:37.265356 Epoch [024/030], Step [0060/0060], Loss1: 0.9485 Loss2: 0.9439 Loss3: 0.9409\n",
            "Epoch: 24 MAE: 0.0737288216686753 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:12:44.417766 Epoch [025/030], Step [0001/0060], Loss1: 1.0311 Loss2: 1.0258 Loss3: 1.0237\n",
            "2022-06-06 19:13:22.536759 Epoch [025/030], Step [0050/0060], Loss1: 1.0258 Loss2: 1.0198 Loss3: 1.0169\n",
            "2022-06-06 19:13:30.265425 Epoch [025/030], Step [0060/0060], Loss1: 0.9801 Loss2: 0.9776 Loss3: 0.9738\n",
            "Epoch: 25 MAE: 0.07490962941810571 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:13:41.034077 Epoch [026/030], Step [0001/0060], Loss1: 1.0549 Loss2: 1.0457 Loss3: 1.0428\n",
            "2022-06-06 19:14:18.886592 Epoch [026/030], Step [0050/0060], Loss1: 0.9785 Loss2: 0.9734 Loss3: 0.9693\n",
            "2022-06-06 19:14:26.633902 Epoch [026/030], Step [0060/0060], Loss1: 0.9994 Loss2: 0.9923 Loss3: 0.9894\n",
            "Epoch: 26 MAE: 0.07886150561943253 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:14:33.807833 Epoch [027/030], Step [0001/0060], Loss1: 0.9492 Loss2: 0.9454 Loss3: 0.9426\n",
            "2022-06-06 19:15:12.885632 Epoch [027/030], Step [0050/0060], Loss1: 1.0281 Loss2: 1.0219 Loss3: 1.0190\n",
            "2022-06-06 19:15:20.766942 Epoch [027/030], Step [0060/0060], Loss1: 1.0321 Loss2: 1.0217 Loss3: 1.0182\n",
            "Epoch: 27 MAE: 0.07719479969569616 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:15:27.768653 Epoch [028/030], Step [0001/0060], Loss1: 1.0148 Loss2: 1.0127 Loss3: 1.0095\n",
            "2022-06-06 19:16:05.845693 Epoch [028/030], Step [0050/0060], Loss1: 0.9900 Loss2: 0.9838 Loss3: 0.9819\n",
            "2022-06-06 19:16:13.613535 Epoch [028/030], Step [0060/0060], Loss1: 1.0305 Loss2: 1.0239 Loss3: 1.0204\n",
            "Epoch: 28 MAE: 0.07544816133206482 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n",
            "2022-06-06 19:16:20.573509 Epoch [029/030], Step [0001/0060], Loss1: 0.9905 Loss2: 0.9838 Loss3: 0.9809\n",
            "2022-06-06 19:16:58.813401 Epoch [029/030], Step [0050/0060], Loss1: 0.9664 Loss2: 0.9646 Loss3: 0.9605\n",
            "2022-06-06 19:17:06.654748 Epoch [029/030], Step [0060/0060], Loss1: 1.1319 Loss2: 1.1227 Loss3: 1.1205\n",
            "Epoch: 29 MAE: 0.07413722729556776 ####  bestMAE: 0.07054994628542945 bestEpoch: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Model**"
      ],
      "metadata": {
        "id": "TIg6PIBJfD20"
      },
      "id": "TIg6PIBJfD20"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os, argparse\n",
        "import cv2\n",
        "\n",
        "def test_arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--testsize', type=int, default=352, help='testing size')\n",
        "  parser.add_argument('--gpu_id',   type=str, default='0', help='select gpu id')\n",
        "  parser.add_argument('--test_path',type=str, default='/content/tmp/testdataset_only_depth/',help='test dataset path')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = test_arguments()\n",
        "\n",
        "dataset_path = opt.test_path\n",
        "\n",
        "#set device for test\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        " \n",
        "\n",
        "#load the model\n",
        "model = SPNet(32,50)\n",
        "model.cuda()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Checkpoint/SPNet_new/SPNet_text_output_graph.pth'))\n",
        "model.eval()\n",
        "\n",
        "#test\n",
        "test_datasets = ['NJU2K','NLPR', 'DES'] \n",
        "\n",
        "test_datasets = ['DES'] \n",
        "\n",
        "\n",
        "for dataset in test_datasets:\n",
        "    save_path = '/content/drive/MyDrive/test_maps/SPNet_new/' + dataset + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        \n",
        "    image_root  = str(dataset_path + dataset + '/RGB/')\n",
        "    gt_root     = str(dataset_path + dataset + '/GT/')\n",
        "    depth_root  = str(dataset_path + dataset + '/depth/')\n",
        "    test_loader = test_dataset(image_root, gt_root,depth_root, opt.testsize)\n",
        "    for i in range(test_loader.size):\n",
        "        image, gt,depth, name, image_for_post = test_loader.load_data()\n",
        "        gt      = np.asarray(gt, np.float32)\n",
        "        gt     /= (gt.max() + 1e-8)\n",
        "        image   = image.cuda()\n",
        "        depth   = depth.cuda()\n",
        "        pre_res = model(image,depth)\n",
        "        res     = pre_res[2]     \n",
        "        res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "        res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "        res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "        \n",
        "        print('save img to: ',save_path+name)\n",
        "        cv2.imwrite(save_path+name,res*255)\n",
        "    print('Test Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQTWmWQ1QAxx",
        "outputId": "31e509c4-556b-4fc9-bbba-34fafd1f5bdd"
      },
      "id": "qQTWmWQ1QAxx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1500.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1501.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1502.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1510.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1511.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1512.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1520.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1521.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1522.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1530.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1531.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1532.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1540.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1541.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1542.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1550.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1551.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1552.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1560.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1561.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1562.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1570.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1571.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1572.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1580.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1581.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1582.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1590.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1591.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1592.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1600.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1601.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1602.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1610.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1611.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1612.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1620.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1621.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1622.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1630.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1631.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1632.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1640.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1641.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1642.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1650.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1651.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1652.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1660.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1661.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1662.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1670.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1671.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1672.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1680.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1681.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1682.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1690.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1691.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1692.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1700.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1701.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/depth_1702.png\n",
            "Test Done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "New_SPNet.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uzErIbtjtb4I",
        "dOJNz-jmt_8t",
        "Jh8YLwd1uQ98",
        "YBlVUwChuigX",
        "Yi0B7EXmtiVb",
        "T7c0BF7hggkP",
        "s4hii4cPtsxM",
        "058fmV_VtzGY",
        "LUJnH8uehSdS",
        "AMemLR14hkVD",
        "NxOlAzw77xmU",
        "lIVqC0YW74vo",
        "aigV_49C8EPw"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b464c9ce322c4deb87401fbdff456e5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c3e68ced9594cb793a8ca627c9fee42",
              "IPY_MODEL_0e6ba296fac249f3a937f81c61002381",
              "IPY_MODEL_a420e380786849bd8c93e5c6dcbe5011"
            ],
            "layout": "IPY_MODEL_2f8e3ac026bd4069a6893ae987e92afa"
          }
        },
        "9c3e68ced9594cb793a8ca627c9fee42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54c22447de834ff4ba3de2e7f493a719",
            "placeholder": "​",
            "style": "IPY_MODEL_4e1eb0ce9eb44959b4f452c2f14955b0",
            "value": "100%"
          }
        },
        "0e6ba296fac249f3a937f81c61002381": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7990db7e0dc94f93aae72693e7e26f37",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_eaba31cb4f9d4afc8d778fa3fea4fbc2",
            "value": 103197949
          }
        },
        "a420e380786849bd8c93e5c6dcbe5011": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b2b824c0e434d6683bfa89198bfadda",
            "placeholder": "​",
            "style": "IPY_MODEL_eb266d83981f4d2597a2bda3c41887a6",
            "value": " 98.4M/98.4M [00:27&lt;00:00, 13.8MB/s]"
          }
        },
        "2f8e3ac026bd4069a6893ae987e92afa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "54c22447de834ff4ba3de2e7f493a719": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e1eb0ce9eb44959b4f452c2f14955b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7990db7e0dc94f93aae72693e7e26f37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaba31cb4f9d4afc8d778fa3fea4fbc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b2b824c0e434d6683bfa89198bfadda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb266d83981f4d2597a2bda3c41887a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8bd7c69089e4bd0b11a23ec27cbffde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e045aa3b74145c39d1799c85fee1e78",
              "IPY_MODEL_466c965df9f24ee3a2b75c6165e5a851",
              "IPY_MODEL_3b2603c87bed40cd8a1fa20588c64051"
            ],
            "layout": "IPY_MODEL_d4bca09a737644d0b20691701b69f104"
          }
        },
        "6e045aa3b74145c39d1799c85fee1e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a1861a7ec2d402db71b1d72b82cf6a7",
            "placeholder": "​",
            "style": "IPY_MODEL_4c0fb88312cc4b5c8253b85cd43b3d20",
            "value": "100%"
          }
        },
        "466c965df9f24ee3a2b75c6165e5a851": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fa5a7b11554f4cd393f77d86fe12dde1",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8ec4343d491746f3bb271c532201078e",
            "value": 103197949
          }
        },
        "3b2603c87bed40cd8a1fa20588c64051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2c2e0ea902d4c768248a852669931a4",
            "placeholder": "​",
            "style": "IPY_MODEL_861c39e852c24ae49c8e22c287fc90cf",
            "value": " 98.4M/98.4M [00:15&lt;00:00, 16.1MB/s]"
          }
        },
        "d4bca09a737644d0b20691701b69f104": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a1861a7ec2d402db71b1d72b82cf6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c0fb88312cc4b5c8253b85cd43b3d20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fa5a7b11554f4cd393f77d86fe12dde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec4343d491746f3bb271c532201078e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2c2e0ea902d4c768248a852669931a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "861c39e852c24ae49c8e22c287fc90cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cebe3a3451114c998e82016ec976baf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a25746cf4cc64c9cb88363dcd6aed367",
              "IPY_MODEL_8ce66d5c2f7345d9af19822d312b0d3f",
              "IPY_MODEL_b24651b34dd6422183daf9edf4d4b8e5"
            ],
            "layout": "IPY_MODEL_6244dc215c6b4d4bb33c771723a23617"
          }
        },
        "a25746cf4cc64c9cb88363dcd6aed367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_753d3d2257b940edadef9bfeb8509e3a",
            "placeholder": "​",
            "style": "IPY_MODEL_f46970b0470443d787a3d5792cd252e7",
            "value": "100%"
          }
        },
        "8ce66d5c2f7345d9af19822d312b0d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ebce79eee354d9ab60fc6bd8ee36cd0",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab56c3d8dda2446cab501d8d15eef2cc",
            "value": 103197949
          }
        },
        "b24651b34dd6422183daf9edf4d4b8e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c3d36a214d49219d57f62d899ca4d8",
            "placeholder": "​",
            "style": "IPY_MODEL_41adb56fa0bd4209ba5572d463283fd2",
            "value": " 98.4M/98.4M [00:07&lt;00:00, 29.9MB/s]"
          }
        },
        "6244dc215c6b4d4bb33c771723a23617": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "753d3d2257b940edadef9bfeb8509e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f46970b0470443d787a3d5792cd252e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ebce79eee354d9ab60fc6bd8ee36cd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab56c3d8dda2446cab501d8d15eef2cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "60c3d36a214d49219d57f62d899ca4d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41adb56fa0bd4209ba5572d463283fd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}