{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_UNet_segmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMF3vFIoS6bMvjBXxoresHh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/-motion-artifacts/blob/master/keras_UNet_segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4) # for crop and copy\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis =3) # Concatenate for localization informantion\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 1)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 1)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'softmax')(conv9)\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0LsP0QZawqGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from random import randint\n",
        "\n",
        "\n",
        "def add_elastic_transform(image, alpha, sigma, pad_size=30, seed=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        alpha : α is a scaling factor\n",
        "        sigma :  σ is an elasticity coefficient\n",
        "        random_state = random integer\n",
        "        Return :\n",
        "        image : elastically transformed numpy array of image\n",
        "    \"\"\"\n",
        "    image_size = int(image.shape[0])\n",
        "    image = np.pad(image, pad_size, mode=\"symmetric\")\n",
        "    if seed is None:\n",
        "        seed = randint(1, 100)\n",
        "        random_state = np.random.RandomState(seed)\n",
        "    else:\n",
        "        random_state = np.random.RandomState(seed)\n",
        "    shape = image.shape\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
        "    return cropping(map_coordinates(image, indices, order=1).reshape(shape), 512, pad_size, pad_size), seed\n",
        "\n",
        "\n",
        "def flip(image, option_value):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        option_value = random integer between 0 to 3\n",
        "    Return :\n",
        "        image : numpy array of flipped image\n",
        "    \"\"\"\n",
        "    if option_value == 0:\n",
        "        # vertical\n",
        "        image = np.flip(image, option_value)\n",
        "    elif option_value == 1:\n",
        "        # horizontal\n",
        "        image = np.flip(image, option_value)\n",
        "    elif option_value == 2:\n",
        "        # horizontally and vertically flip\n",
        "        image = np.flip(image, 0)\n",
        "        image = np.flip(image, 1)\n",
        "    else:\n",
        "        image = image\n",
        "        # no effect\n",
        "    return image\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean=0, std=1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        mean : pixel mean of image\n",
        "        standard deviation : pixel standard deviation of image\n",
        "    Return :\n",
        "        image : numpy array of image with gaussian noise added\n",
        "    \"\"\"\n",
        "    gaus_noise = np.random.normal(mean, std, image.shape)\n",
        "    image = image.astype(\"int16\")\n",
        "    noise_img = image + gaus_noise\n",
        "    image = ceil_floor_image(image)\n",
        "    return noise_img\n",
        "\n",
        "\n",
        "def add_uniform_noise(image, low=-10, high=10):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        low : lower boundary of output interval\n",
        "        high : upper boundary of output interval\n",
        "    Return :\n",
        "        image : numpy array of image with uniform noise added\n",
        "    \"\"\"\n",
        "    uni_noise = np.random.uniform(low, high, image.shape)\n",
        "    image = image.astype(\"int16\")\n",
        "    noise_img = image + uni_noise\n",
        "    image = ceil_floor_image(image)\n",
        "    return noise_img\n",
        "\n",
        "\n",
        "def change_brightness(image, value):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        value : brightness\n",
        "    Return :\n",
        "        image : numpy array of image with brightness added\n",
        "    \"\"\"\n",
        "    image = image.astype(\"int16\")\n",
        "    image = image + value\n",
        "    image = ceil_floor_image(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def ceil_floor_image(image):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image in datatype int16\n",
        "    Return :\n",
        "        image : numpy array of image in datatype uint8 with ceilling(maximum 255) and flooring(minimum 0)\n",
        "    \"\"\"\n",
        "    image[image > 255] = 255\n",
        "    image[image < 0] = 0\n",
        "    image = image.astype(\"uint8\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def approximate_image(image):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image in datatype int16\n",
        "    Return :\n",
        "        image : numpy array of image in datatype uint8 only with 255 and 0\n",
        "    \"\"\"\n",
        "    image[image > 127.5] = 255\n",
        "    image[image < 127.5] = 0\n",
        "    image = image.astype(\"uint8\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def normalization1(image, mean, std):\n",
        "    \"\"\" Normalization using mean and std\n",
        "    Args :\n",
        "        image : numpy array of image\n",
        "        mean :\n",
        "    Return :\n",
        "        image : numpy array of image with values turned into standard scores\n",
        "    \"\"\"\n",
        "\n",
        "    image = image / 255  # values will lie between 0 and 1.\n",
        "    image = (image - mean) / std\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def normalization2(image, max, min):\n",
        "    \"\"\"Normalization to range of [min, max]\n",
        "    Args :\n",
        "        image : numpy array of image\n",
        "        mean :\n",
        "    Return :\n",
        "        image : numpy array of image with values turned into standard scores\n",
        "    \"\"\"\n",
        "    image_new = (image - np.min(image))*(max - min)/(np.max(image)-np.min(image)) + min\n",
        "    return image_new\n",
        "\n",
        "\n",
        "def stride_size(image_len, crop_num, crop_size):\n",
        "    \"\"\"return stride size\n",
        "    Args :\n",
        "        image_len(int) : length of one size of image (width or height)\n",
        "        crop_num(int) : number of crop in certain direction\n",
        "        crop_size(int) : size of crop\n",
        "    Return :\n",
        "        stride_size(int) : stride size\n",
        "    \"\"\"\n",
        "    return int((image_len - crop_size)/(crop_num - 1))\n",
        "\n",
        "\n",
        "def multi_cropping(image, crop_size, crop_num1, crop_num2):\n",
        "    \"\"\"crop the image and pad it to in_size\n",
        "    Args :\n",
        "        images : numpy arrays of images\n",
        "        crop_size(int) : size of cropped image\n",
        "        crop_num2 (int) : number of crop in horizontal way\n",
        "        crop_num1 (int) : number of crop in vertical way\n",
        "    Return :\n",
        "        cropped_imgs : numpy arrays of stacked images\n",
        "    \"\"\"\n",
        "\n",
        "    img_height, img_width = image.shape[0], image.shape[1]\n",
        "    assert crop_size*crop_num1 >= img_width and crop_size * \\\n",
        "        crop_num2 >= img_height, \"Whole image cannot be sufficiently expressed\"\n",
        "    assert crop_num1 <= img_width - crop_size + 1 and crop_num2 <= img_height - \\\n",
        "        crop_size + 1, \"Too many number of crops\"\n",
        "\n",
        "    cropped_imgs = []\n",
        "    # int((img_height - crop_size)/(crop_num1 - 1))\n",
        "    dim1_stride = stride_size(img_height, crop_num1, crop_size)\n",
        "    # int((img_width - crop_size)/(crop_num2 - 1))\n",
        "    dim2_stride = stride_size(img_width, crop_num2, crop_size)\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            cropped_imgs.append(cropping(image, crop_size,\n",
        "                                         dim1_stride*i, dim2_stride*j))\n",
        "    return np.asarray(cropped_imgs)\n",
        "\n",
        "\n",
        "# IT IS NOT USED FOR PAD AND CROP DATA OPERATION\n",
        "# IF YOU WANT TO USE CROP AND PAD USE THIS FUNCTION\n",
        "\"\"\"\n",
        "def multi_padding(images, in_size, out_size, mode):\n",
        "    '''Pad the images to in_size\n",
        "    Args :\n",
        "        images : numpy array of images (CxHxW)\n",
        "        in_size(int) : the input_size of model (512)\n",
        "        out_size(int) : the output_size of model (388)\n",
        "        mode(str) : mode of padding\n",
        "    Return :\n",
        "        padded_imgs: numpy arrays of padded images\n",
        "    '''\n",
        "    pad_size = int((in_size - out_size)/2)\n",
        "    padded_imgs = []\n",
        "    for num in range(images.shape[0]):\n",
        "        padded_imgs.append(add_padding(images[num], in_size, out_size, mode=mode))\n",
        "    return np.asarray(padded_imgs)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def cropping(image, crop_size, dim1, dim2):\n",
        "    \"\"\"crop the image and pad it to in_size\n",
        "    Args :\n",
        "        images : numpy array of images\n",
        "        crop_size(int) : size of cropped image\n",
        "        dim1(int) : vertical location of crop\n",
        "        dim2(int) : horizontal location of crop\n",
        "    Return :\n",
        "        cropped_img: numpy array of cropped image\n",
        "    \"\"\"\n",
        "    cropped_img = image[dim1:dim1+crop_size, dim2:dim2+crop_size]\n",
        "    return cropped_img\n",
        "\n",
        "\n",
        "def add_padding(image, in_size, out_size, mode):\n",
        "    \"\"\"Pad the image to in_size\n",
        "    Args :\n",
        "        images : numpy array of images\n",
        "        in_size(int) : the input_size of model\n",
        "        out_size(int) : the output_size of model\n",
        "        mode(str) : mode of padding\n",
        "    Return :\n",
        "        padded_img: numpy array of padded image\n",
        "    \"\"\"\n",
        "    pad_size = int((in_size - out_size)/2)\n",
        "    padded_img = np.pad(image, pad_size, mode=mode)\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def division_array(crop_size, crop_num1, crop_num2, dim1, dim2):\n",
        "    \"\"\"Make division array\n",
        "    Args :\n",
        "        crop_size(int) : size of cropped image\n",
        "        crop_num2 (int) : number of crop in horizontal way\n",
        "        crop_num1 (int) : number of crop in vertical way\n",
        "        dim1(int) : vertical size of output\n",
        "        dim2(int) : horizontal size_of_output\n",
        "    Return :\n",
        "        div_array : numpy array of numbers of 1,2,4\n",
        "    \"\"\"\n",
        "    div_array = np.zeros([dim1, dim2])  # make division array\n",
        "    one_array = np.ones([crop_size, crop_size])  # one array to be added to div_array\n",
        "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
        "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            # add ones to div_array at specific position\n",
        "            div_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
        "                      dim2_stride*j:dim2_stride*j + crop_size] += one_array\n",
        "    return div_array\n",
        "\n",
        "\n",
        "def image_concatenate(image, crop_num1, crop_num2, dim1, dim2):\n",
        "    \"\"\"concatenate images\n",
        "    Args :\n",
        "        image : output images (should be square)\n",
        "        crop_num2 (int) : number of crop in horizontal way (2)\n",
        "        crop_num1 (int) : number of crop in vertical way (2)\n",
        "        dim1(int) : vertical size of output (512)\n",
        "        dim2(int) : horizontal size_of_output (512)\n",
        "    Return :\n",
        "        div_array : numpy arrays of numbers of 1,2,4\n",
        "    \"\"\"\n",
        "    crop_size = image.shape[1]  # size of crop\n",
        "    empty_array = np.zeros([dim1, dim2]).astype(\"float64\")  # to make sure no overflow\n",
        "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
        "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
        "    index = 0\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            # add image to empty_array at specific position\n",
        "            empty_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
        "                        dim2_stride*j:dim2_stride*j + crop_size] += image[index]\n",
        "            index += 1\n",
        "    return empty_array"
      ],
      "metadata": {
        "id": "BPCLpTrBw0ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start Running From Here**\n"
      ],
      "metadata": {
        "id": "fqy5czBa2N_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/data.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "NT3Jex3VxDcK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d066df-7e43-4012-a7e3-dcde9bd69273"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "66jO0vokv15R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866c0378-93d3-43dd-8a0b-6e9c207a296f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Creating train images...\n",
            "------------------------------\n",
            "original images 3001\n",
            "augmented images 950\n",
            "Done: 3001/3001 images\n",
            "Done: 100/950 images\n",
            "Done: 200/950 images\n",
            "Done: 300/950 images\n",
            "Done: 400/950 images\n",
            "Done: 500/950 images\n",
            "Done: 600/950 images\n",
            "Done: 700/950 images\n",
            "Done: 800/950 images\n",
            "Done: 900/950 images\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "------------------------------\n",
            "Creating test images...\n",
            "------------------------------\n",
            "Done: 50/50 images\n",
            "loading done\n",
            "Saving to .npy files done.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image, ImageSequence\n",
        "import os\n",
        "\n",
        "class dataProcess(object):\n",
        "    def __init__(self, out_rows, out_cols, data_path=\"/content/tmp/data\"):\n",
        "        self.out_rows = out_rows\n",
        "        self.out_cols = out_cols\n",
        "        self.data_path = data_path\n",
        "\n",
        "    def create_train_data(self):\n",
        "        print('-' * 30)\n",
        "        print('Creating train images...')\n",
        "        print('-' * 30)\n",
        "\n",
        "        # Load images and convert to npy\n",
        "        i = 0\n",
        "        j = 0\n",
        "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
        "        aug_imgs = os.listdir(self.data_path + \"/aug/images/\")\n",
        "        print(\"original images\", len(imgs))\n",
        "        print(\"augmented images\", len(aug_imgs))\n",
        "        img_datas = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        img_labels = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        for imgname in imgs:\n",
        "            img = load_img(self.data_path + \"/raw/images/\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            label = load_img(self.data_path + \"/raw/labels/corrupted_\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[j] = img_to_array(img)\n",
        "            img_labels[j] = img_to_array(label)\n",
        "            j += 1\n",
        "            if j % len(imgs) == 0:\n",
        "                print('Done: {0}/{1} images'.format(j, len(imgs)))\n",
        "        for imgname in aug_imgs:\n",
        "            img = load_img(self.data_path + \"/aug/images/\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            label = load_img(self.data_path + \"/aug/labels/corrupted_\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[i + len(imgs)] = img_to_array(img)\n",
        "            img_labels[i + len(imgs)] = img_to_array(label)\n",
        "            i += 1\n",
        "            if i % 100 == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(aug_imgs)))\n",
        "\n",
        "        print('loading done')\n",
        "        np.save(self.data_path + '/npy/imgs_train.npy', img_datas)\n",
        "        np.save(self.data_path + '/npy/imgs_mask_train.npy', img_labels)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "    def create_test_data(self):\n",
        "        print('-' * 30)\n",
        "        print('Creating test images...')\n",
        "        print('-' * 30)\n",
        "\n",
        "        # Create directory\n",
        "        if not os.path.exists(self.data_path + \"/test/images\"):\n",
        "            os.makedirs(self.data_path + \"/test/images\")\n",
        "        if not os.path.exists(self.data_path + \"/test/labels\"):\n",
        "            os.makedirs(self.data_path + \"/test/labels\")\n",
        "\n",
        "        # Split isbi tif image&label to single frame of png images\n",
        "  #      isbi_img = Image.open(self.data_path + \"/test-volume.tif\")  # raw image from isbi dataset\n",
        "   #     for i, page in enumerate(ImageSequence.Iterator(isbi_img)):\n",
        "   #         page.save(self.data_path+\"/test/images/\" + str(i) + \".png\")\n",
        "\n",
        "        imgs = os.listdir(self.data_path + \"/test/images/\")\n",
        "        imgs = sorted([str(i).rstrip('.png').lstrip('GT_') for i in imgs], key=int) # sort accending\n",
        "        img_datas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        i = 0\n",
        "        for imgname in imgs:\n",
        "            img = load_img(self.data_path + \"/test/images/GT_\" + imgname + \".png\", color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[i] = img_to_array(img)\n",
        "            i += 1\n",
        "            if i % len(imgs) == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "        print('loading done')\n",
        "        np.save(self.data_path + '/npy/imgs_test.npy', img_datas)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "    def load_train_data(self):\n",
        "        print('-' * 30)\n",
        "        print('load train images...')\n",
        "        print('-' * 30)\n",
        "        imgs_train = np.load(self.data_path + \"/npy/imgs_train.npy\")\n",
        "        imgs_mask_train = np.load(self.data_path + \"/npy/imgs_mask_train.npy\")\n",
        "        imgs_train = imgs_train.astype('float32')\n",
        "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "        imgs_train /= 255  # RGB 0~1\n",
        "        imgs_mask_train /= 255\n",
        "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
        "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
        "        return imgs_train, imgs_mask_train\n",
        "\n",
        "    def load_test_data(self):\n",
        "        print('-' * 30)\n",
        "        print('load test images...')\n",
        "        print('-' * 30)\n",
        "        imgs_test = np.load(self.data_path + \"/npy/imgs_test.npy\")\n",
        "        imgs_test = imgs_test.astype('float32')\n",
        "        imgs_test /= 255\n",
        "        return imgs_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mydata = dataProcess(256, 256)\n",
        "    mydata.create_train_data()\n",
        "    mydata.create_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "HqvK_sM97EUG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "f1U8WKI8dmZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import *\n",
        "#from model import unet\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tifffile import imsave as tifsave\n",
        "import tensorflow as tf\n",
        "\n",
        "# Use other GPU in our mlti-gpu server\n",
        "# If you have only one GPU, change 1 to 0 or delete below lines\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "class myUnet(object):\n",
        "\n",
        "    def __init__(self, img_rows=256, img_cols=256, save_path=\"/content/tmp/data/results/\"):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def load_data(self):\n",
        "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
        "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
        "        imgs_test = mydata.load_test_data()\n",
        "        return imgs_train, imgs_mask_train, imgs_test\n",
        "\n",
        "    def train(self, load_pretrained):\n",
        "        print(\"loading data\")\n",
        "        model_name = '/content/tmp/data/results/my_model.h5'\n",
        "        log_dir = \"/content/tmp/data/logs/000\"\n",
        "        logging = TensorBoard(log_dir=log_dir)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
        "        print (imgs_train, imgs_mask_train.size)\n",
        "        print(\"loading data done\")\n",
        "        if load_pretrained:\n",
        "            model = load_model(model_name)\n",
        "            model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
        "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=30, verbose=1,\n",
        "                      validation_split=0.2, shuffle=True, callbacks=[logging, model_checkpoint, reduce_lr])\n",
        "            model.save(model_name)\n",
        "        else:\n",
        "            model = unet((256,256,1))\n",
        "            model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
        "            #model = unet()\n",
        "            model.summary()\n",
        "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=10, verbose=1,\n",
        "                      validation_split=0.2, shuffle=True,\n",
        "                      callbacks=[logging, model_checkpoint, reduce_lr, early_stopping])\n",
        "            model.save(model_name)\n",
        "\n",
        "    def test(self):\n",
        "        model_name = '/content/tmp/data/results/my_model.h5'\n",
        "        if not os.path.exists(self.save_path):\n",
        "            os.makedirs(self.save_path)\n",
        "\n",
        "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
        "        model = load_model(model_name)\n",
        "        imgs_mask_test = model.predict(imgs_test, batch_size=2, verbose=1)\n",
        "        np.save(self.save_path + \"imgs_mask_test.npy\", imgs_mask_test)\n",
        "\n",
        "        print(\"array to image\")\n",
        "        imgs = np.load(self.save_path + \"imgs_mask_test.npy\")\n",
        "        total = []\n",
        "        for i in range(imgs.shape[0]):\n",
        "            img = imgs[i]\n",
        "            img[img > 0.5] = 1\n",
        "            img[img <= 0.5] = 0\n",
        "            total.append(img)\n",
        "        np_total = np.array(total)\n",
        "        tifsave(\"/content/tmp/data/results/prediction.tif\", np_total)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      try:\n",
        "          myunet = myUnet()\n",
        "          myunet.train(load_pretrained=False)\n",
        "          myunet.test()\n",
        "      except RuntimeError as e:\n",
        "          print(e)"
      ],
      "metadata": {
        "id": "VSrl6VbvwvUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca135dc-951f-4a48-ab66-0c683106a8ab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "------------------------------\n",
            "load train images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "[[[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.00392157]\n",
            "   ...\n",
            "   [0.00392157]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.00392157]\n",
            "   [0.00392157]\n",
            "   [0.00392157]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]]\n",
            "\n",
            "\n",
            " [[[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.00392157]\n",
            "   [0.        ]\n",
            "   [0.        ]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.        ]\n",
            "   [0.00392157]\n",
            "   [0.00392157]]\n",
            "\n",
            "  [[0.        ]\n",
            "   [0.        ]\n",
            "   [0.        ]\n",
            "   ...\n",
            "   [0.00392157]\n",
            "   [0.        ]\n",
            "   [0.        ]]]] 258932736\n",
            "loading data done\n",
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,054,145\n",
            "Trainable params: 31,042,369\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9526\n",
            "Epoch 1: val_loss improved from inf to 0.01767, saving model to unet.h5\n",
            "790/790 [==============================] - 242s 285ms/step - loss: 0.0389 - accuracy: 0.9526 - val_loss: 0.0177 - val_accuracy: 0.9840 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9601\n",
            "Epoch 2: val_loss improved from 0.01767 to 0.01368, saving model to unet.h5\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0293 - accuracy: 0.9601 - val_loss: 0.0137 - val_accuracy: 0.9873 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 0.9643\n",
            "Epoch 3: val_loss did not improve from 0.01368\n",
            "790/790 [==============================] - 226s 286ms/step - loss: 0.0263 - accuracy: 0.9643 - val_loss: 0.0210 - val_accuracy: 0.9692 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9665\n",
            "Epoch 4: val_loss did not improve from 0.01368\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0245 - accuracy: 0.9665 - val_loss: 0.0197 - val_accuracy: 0.9705 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0221 - accuracy: 0.9698\n",
            "Epoch 5: val_loss did not improve from 0.01368\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0221 - accuracy: 0.9698 - val_loss: 0.0158 - val_accuracy: 0.9784 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0168 - accuracy: 0.9789\n",
            "Epoch 6: val_loss improved from 0.01368 to 0.01117, saving model to unet.h5\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0168 - accuracy: 0.9789 - val_loss: 0.0112 - val_accuracy: 0.9890 - lr: 1.0000e-03\n",
            "Epoch 7/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0162 - accuracy: 0.9803\n",
            "Epoch 7: val_loss did not improve from 0.01117\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0162 - accuracy: 0.9803 - val_loss: 0.0112 - val_accuracy: 0.9888 - lr: 1.0000e-03\n",
            "Epoch 8/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0148 - accuracy: 0.9822\n",
            "Epoch 8: val_loss improved from 0.01117 to 0.01099, saving model to unet.h5\n",
            "790/790 [==============================] - 230s 290ms/step - loss: 0.0148 - accuracy: 0.9822 - val_loss: 0.0110 - val_accuracy: 0.9892 - lr: 1.0000e-03\n",
            "Epoch 9/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0145 - accuracy: 0.9827\n",
            "Epoch 9: val_loss improved from 0.01099 to 0.01039, saving model to unet.h5\n",
            "790/790 [==============================] - 230s 291ms/step - loss: 0.0145 - accuracy: 0.9827 - val_loss: 0.0104 - val_accuracy: 0.9897 - lr: 1.0000e-03\n",
            "Epoch 10/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9836\n",
            "Epoch 10: val_loss improved from 0.01039 to 0.01026, saving model to unet.h5\n",
            "790/790 [==============================] - 229s 290ms/step - loss: 0.0138 - accuracy: 0.9836 - val_loss: 0.0103 - val_accuracy: 0.9896 - lr: 1.0000e-03\n",
            "------------------------------\n",
            "load train images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "25/25 [==============================] - 3s 44ms/step\n",
            "array to image\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "img = plt.imread('/content/tmp/data/results/prediction.tif')\n",
        "plt.imshow(img[:, :, 0])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "PSkChE_gfXMM",
        "outputId": "4509d345-4ad1-449d-8d38-fe6f43f1f980"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}