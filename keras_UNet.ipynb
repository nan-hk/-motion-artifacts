{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_UNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYg9hsvVilR2ECY5BGhVUJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/-motion-artifacts/blob/master/keras_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "\n",
        "def unet(pretrained_weights = None,input_size = (256,256,1)):\n",
        "    inputs = Input(input_size)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
        "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
        "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
        "    drop4 = Dropout(0.5)(conv4) # for crop and copy\n",
        "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
        "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
        "    drop5 = Dropout(0.5)(conv5)\n",
        "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
        "    merge6 = concatenate([drop4,up6], axis =3) # Concatenate for localization informantion\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
        "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
        "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
        "    merge7 = concatenate([conv3,up7], axis = 3)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
        "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
        "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
        "    merge8 = concatenate([conv2,up8], axis = 1)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
        "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
        "    merge9 = concatenate([conv1,up9], axis = 1)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
        "    conv10 = Conv2D(1, 1, activation = 'softmax')(conv9)\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
        "\n",
        "    #model.summary()\n",
        "\n",
        "    if(pretrained_weights):\n",
        "        model.load_weights(pretrained_weights)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0LsP0QZawqGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage.interpolation import map_coordinates\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from random import randint\n",
        "\n",
        "\n",
        "def add_elastic_transform(image, alpha, sigma, pad_size=30, seed=None):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        alpha : α is a scaling factor\n",
        "        sigma :  σ is an elasticity coefficient\n",
        "        random_state = random integer\n",
        "        Return :\n",
        "        image : elastically transformed numpy array of image\n",
        "    \"\"\"\n",
        "    image_size = int(image.shape[0])\n",
        "    image = np.pad(image, pad_size, mode=\"symmetric\")\n",
        "    if seed is None:\n",
        "        seed = randint(1, 100)\n",
        "        random_state = np.random.RandomState(seed)\n",
        "    else:\n",
        "        random_state = np.random.RandomState(seed)\n",
        "    shape = image.shape\n",
        "    dx = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "    dy = gaussian_filter((random_state.rand(*shape) * 2 - 1),\n",
        "                         sigma, mode=\"constant\", cval=0) * alpha\n",
        "    x, y = np.meshgrid(np.arange(shape[1]), np.arange(shape[0]))\n",
        "    indices = np.reshape(y+dy, (-1, 1)), np.reshape(x+dx, (-1, 1))\n",
        "    return cropping(map_coordinates(image, indices, order=1).reshape(shape), 512, pad_size, pad_size), seed\n",
        "\n",
        "\n",
        "def flip(image, option_value):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        option_value = random integer between 0 to 3\n",
        "    Return :\n",
        "        image : numpy array of flipped image\n",
        "    \"\"\"\n",
        "    if option_value == 0:\n",
        "        # vertical\n",
        "        image = np.flip(image, option_value)\n",
        "    elif option_value == 1:\n",
        "        # horizontal\n",
        "        image = np.flip(image, option_value)\n",
        "    elif option_value == 2:\n",
        "        # horizontally and vertically flip\n",
        "        image = np.flip(image, 0)\n",
        "        image = np.flip(image, 1)\n",
        "    else:\n",
        "        image = image\n",
        "        # no effect\n",
        "    return image\n",
        "\n",
        "\n",
        "def add_gaussian_noise(image, mean=0, std=1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        mean : pixel mean of image\n",
        "        standard deviation : pixel standard deviation of image\n",
        "    Return :\n",
        "        image : numpy array of image with gaussian noise added\n",
        "    \"\"\"\n",
        "    gaus_noise = np.random.normal(mean, std, image.shape)\n",
        "    image = image.astype(\"int16\")\n",
        "    noise_img = image + gaus_noise\n",
        "    image = ceil_floor_image(image)\n",
        "    return noise_img\n",
        "\n",
        "\n",
        "def add_uniform_noise(image, low=-10, high=10):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        low : lower boundary of output interval\n",
        "        high : upper boundary of output interval\n",
        "    Return :\n",
        "        image : numpy array of image with uniform noise added\n",
        "    \"\"\"\n",
        "    uni_noise = np.random.uniform(low, high, image.shape)\n",
        "    image = image.astype(\"int16\")\n",
        "    noise_img = image + uni_noise\n",
        "    image = ceil_floor_image(image)\n",
        "    return noise_img\n",
        "\n",
        "\n",
        "def change_brightness(image, value):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image\n",
        "        value : brightness\n",
        "    Return :\n",
        "        image : numpy array of image with brightness added\n",
        "    \"\"\"\n",
        "    image = image.astype(\"int16\")\n",
        "    image = image + value\n",
        "    image = ceil_floor_image(image)\n",
        "    return image\n",
        "\n",
        "\n",
        "def ceil_floor_image(image):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image in datatype int16\n",
        "    Return :\n",
        "        image : numpy array of image in datatype uint8 with ceilling(maximum 255) and flooring(minimum 0)\n",
        "    \"\"\"\n",
        "    image[image > 255] = 255\n",
        "    image[image < 0] = 0\n",
        "    image = image.astype(\"uint8\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def approximate_image(image):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        image : numpy array of image in datatype int16\n",
        "    Return :\n",
        "        image : numpy array of image in datatype uint8 only with 255 and 0\n",
        "    \"\"\"\n",
        "    image[image > 127.5] = 255\n",
        "    image[image < 127.5] = 0\n",
        "    image = image.astype(\"uint8\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def normalization1(image, mean, std):\n",
        "    \"\"\" Normalization using mean and std\n",
        "    Args :\n",
        "        image : numpy array of image\n",
        "        mean :\n",
        "    Return :\n",
        "        image : numpy array of image with values turned into standard scores\n",
        "    \"\"\"\n",
        "\n",
        "    image = image / 255  # values will lie between 0 and 1.\n",
        "    image = (image - mean) / std\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def normalization2(image, max, min):\n",
        "    \"\"\"Normalization to range of [min, max]\n",
        "    Args :\n",
        "        image : numpy array of image\n",
        "        mean :\n",
        "    Return :\n",
        "        image : numpy array of image with values turned into standard scores\n",
        "    \"\"\"\n",
        "    image_new = (image - np.min(image))*(max - min)/(np.max(image)-np.min(image)) + min\n",
        "    return image_new\n",
        "\n",
        "\n",
        "def stride_size(image_len, crop_num, crop_size):\n",
        "    \"\"\"return stride size\n",
        "    Args :\n",
        "        image_len(int) : length of one size of image (width or height)\n",
        "        crop_num(int) : number of crop in certain direction\n",
        "        crop_size(int) : size of crop\n",
        "    Return :\n",
        "        stride_size(int) : stride size\n",
        "    \"\"\"\n",
        "    return int((image_len - crop_size)/(crop_num - 1))\n",
        "\n",
        "\n",
        "def multi_cropping(image, crop_size, crop_num1, crop_num2):\n",
        "    \"\"\"crop the image and pad it to in_size\n",
        "    Args :\n",
        "        images : numpy arrays of images\n",
        "        crop_size(int) : size of cropped image\n",
        "        crop_num2 (int) : number of crop in horizontal way\n",
        "        crop_num1 (int) : number of crop in vertical way\n",
        "    Return :\n",
        "        cropped_imgs : numpy arrays of stacked images\n",
        "    \"\"\"\n",
        "\n",
        "    img_height, img_width = image.shape[0], image.shape[1]\n",
        "    assert crop_size*crop_num1 >= img_width and crop_size * \\\n",
        "        crop_num2 >= img_height, \"Whole image cannot be sufficiently expressed\"\n",
        "    assert crop_num1 <= img_width - crop_size + 1 and crop_num2 <= img_height - \\\n",
        "        crop_size + 1, \"Too many number of crops\"\n",
        "\n",
        "    cropped_imgs = []\n",
        "    # int((img_height - crop_size)/(crop_num1 - 1))\n",
        "    dim1_stride = stride_size(img_height, crop_num1, crop_size)\n",
        "    # int((img_width - crop_size)/(crop_num2 - 1))\n",
        "    dim2_stride = stride_size(img_width, crop_num2, crop_size)\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            cropped_imgs.append(cropping(image, crop_size,\n",
        "                                         dim1_stride*i, dim2_stride*j))\n",
        "    return np.asarray(cropped_imgs)\n",
        "\n",
        "\n",
        "# IT IS NOT USED FOR PAD AND CROP DATA OPERATION\n",
        "# IF YOU WANT TO USE CROP AND PAD USE THIS FUNCTION\n",
        "\"\"\"\n",
        "def multi_padding(images, in_size, out_size, mode):\n",
        "    '''Pad the images to in_size\n",
        "    Args :\n",
        "        images : numpy array of images (CxHxW)\n",
        "        in_size(int) : the input_size of model (512)\n",
        "        out_size(int) : the output_size of model (388)\n",
        "        mode(str) : mode of padding\n",
        "    Return :\n",
        "        padded_imgs: numpy arrays of padded images\n",
        "    '''\n",
        "    pad_size = int((in_size - out_size)/2)\n",
        "    padded_imgs = []\n",
        "    for num in range(images.shape[0]):\n",
        "        padded_imgs.append(add_padding(images[num], in_size, out_size, mode=mode))\n",
        "    return np.asarray(padded_imgs)\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def cropping(image, crop_size, dim1, dim2):\n",
        "    \"\"\"crop the image and pad it to in_size\n",
        "    Args :\n",
        "        images : numpy array of images\n",
        "        crop_size(int) : size of cropped image\n",
        "        dim1(int) : vertical location of crop\n",
        "        dim2(int) : horizontal location of crop\n",
        "    Return :\n",
        "        cropped_img: numpy array of cropped image\n",
        "    \"\"\"\n",
        "    cropped_img = image[dim1:dim1+crop_size, dim2:dim2+crop_size]\n",
        "    return cropped_img\n",
        "\n",
        "\n",
        "def add_padding(image, in_size, out_size, mode):\n",
        "    \"\"\"Pad the image to in_size\n",
        "    Args :\n",
        "        images : numpy array of images\n",
        "        in_size(int) : the input_size of model\n",
        "        out_size(int) : the output_size of model\n",
        "        mode(str) : mode of padding\n",
        "    Return :\n",
        "        padded_img: numpy array of padded image\n",
        "    \"\"\"\n",
        "    pad_size = int((in_size - out_size)/2)\n",
        "    padded_img = np.pad(image, pad_size, mode=mode)\n",
        "    return padded_img\n",
        "\n",
        "\n",
        "def division_array(crop_size, crop_num1, crop_num2, dim1, dim2):\n",
        "    \"\"\"Make division array\n",
        "    Args :\n",
        "        crop_size(int) : size of cropped image\n",
        "        crop_num2 (int) : number of crop in horizontal way\n",
        "        crop_num1 (int) : number of crop in vertical way\n",
        "        dim1(int) : vertical size of output\n",
        "        dim2(int) : horizontal size_of_output\n",
        "    Return :\n",
        "        div_array : numpy array of numbers of 1,2,4\n",
        "    \"\"\"\n",
        "    div_array = np.zeros([dim1, dim2])  # make division array\n",
        "    one_array = np.ones([crop_size, crop_size])  # one array to be added to div_array\n",
        "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
        "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            # add ones to div_array at specific position\n",
        "            div_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
        "                      dim2_stride*j:dim2_stride*j + crop_size] += one_array\n",
        "    return div_array\n",
        "\n",
        "\n",
        "def image_concatenate(image, crop_num1, crop_num2, dim1, dim2):\n",
        "    \"\"\"concatenate images\n",
        "    Args :\n",
        "        image : output images (should be square)\n",
        "        crop_num2 (int) : number of crop in horizontal way (2)\n",
        "        crop_num1 (int) : number of crop in vertical way (2)\n",
        "        dim1(int) : vertical size of output (512)\n",
        "        dim2(int) : horizontal size_of_output (512)\n",
        "    Return :\n",
        "        div_array : numpy arrays of numbers of 1,2,4\n",
        "    \"\"\"\n",
        "    crop_size = image.shape[1]  # size of crop\n",
        "    empty_array = np.zeros([dim1, dim2]).astype(\"float64\")  # to make sure no overflow\n",
        "    dim1_stride = stride_size(dim1, crop_num1, crop_size)  # vertical stride\n",
        "    dim2_stride = stride_size(dim2, crop_num2, crop_size)  # horizontal stride\n",
        "    index = 0\n",
        "    for i in range(crop_num1):\n",
        "        for j in range(crop_num2):\n",
        "            # add image to empty_array at specific position\n",
        "            empty_array[dim1_stride*i:dim1_stride*i + crop_size,\n",
        "                        dim2_stride*j:dim2_stride*j + crop_size] += image[index]\n",
        "            index += 1\n",
        "    return empty_array"
      ],
      "metadata": {
        "id": "BPCLpTrBw0ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Start Running From Here**\n"
      ],
      "metadata": {
        "id": "fqy5czBa2N_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/data.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "NT3Jex3VxDcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66jO0vokv15R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a267844-492b-4df1-f3d2-9ea16dcc5e6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------\n",
            "Creating train images...\n",
            "------------------------------\n",
            "original images 3001\n",
            "augmented images 950\n",
            "Done: 3001/3001 images\n",
            "Done: 100/950 images\n",
            "Done: 200/950 images\n",
            "Done: 300/950 images\n",
            "Done: 400/950 images\n",
            "Done: 500/950 images\n",
            "Done: 600/950 images\n",
            "Done: 700/950 images\n",
            "Done: 800/950 images\n",
            "Done: 900/950 images\n",
            "loading done\n",
            "Saving to .npy files done.\n",
            "------------------------------\n",
            "Creating test images...\n",
            "------------------------------\n",
            "Done: 50/50 images\n",
            "loading done\n",
            "Saving to .npy files done.\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "import numpy as np\n",
        "import glob\n",
        "from PIL import Image, ImageSequence\n",
        "import os\n",
        "\n",
        "class dataProcess(object):\n",
        "    def __init__(self, out_rows, out_cols, data_path=\"/content/tmp/data\"):\n",
        "        self.out_rows = out_rows\n",
        "        self.out_cols = out_cols\n",
        "        self.data_path = data_path\n",
        "\n",
        "    def create_train_data(self):\n",
        "        print('-' * 30)\n",
        "        print('Creating train images...')\n",
        "        print('-' * 30)\n",
        "\n",
        "        # Load images and convert to npy\n",
        "        i = 0\n",
        "        j = 0\n",
        "        imgs = os.listdir(self.data_path + \"/raw/images/\")\n",
        "        aug_imgs = os.listdir(self.data_path + \"/aug/images/\")\n",
        "        print(\"original images\", len(imgs))\n",
        "        print(\"augmented images\", len(aug_imgs))\n",
        "        img_datas = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        img_labels = np.ndarray((len(imgs) + len(aug_imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        for imgname in imgs:\n",
        "            img = load_img(self.data_path + \"/raw/images/\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            label = load_img(self.data_path + \"/raw/labels/corrupted_\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[j] = img_to_array(img)\n",
        "            img_labels[j] = img_to_array(label)\n",
        "            j += 1\n",
        "            if j % len(imgs) == 0:\n",
        "                print('Done: {0}/{1} images'.format(j, len(imgs)))\n",
        "        for imgname in aug_imgs:\n",
        "            img = load_img(self.data_path + \"/aug/images/\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            label = load_img(self.data_path + \"/aug/labels/corrupted_\" + imgname, color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[i + len(imgs)] = img_to_array(img)\n",
        "            img_labels[i + len(imgs)] = img_to_array(label)\n",
        "            i += 1\n",
        "            if i % 100 == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(aug_imgs)))\n",
        "\n",
        "        print('loading done')\n",
        "        np.save(self.data_path + '/npy/imgs_train.npy', img_datas)\n",
        "        np.save(self.data_path + '/npy/imgs_mask_train.npy', img_labels)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "    def create_test_data(self):\n",
        "        print('-' * 30)\n",
        "        print('Creating test images...')\n",
        "        print('-' * 30)\n",
        "\n",
        "        # Create directory\n",
        "        if not os.path.exists(self.data_path + \"/test/images\"):\n",
        "            os.makedirs(self.data_path + \"/test/images\")\n",
        "        if not os.path.exists(self.data_path + \"/test/labels\"):\n",
        "            os.makedirs(self.data_path + \"/test/labels\")\n",
        "\n",
        "        # Split isbi tif image&label to single frame of png images\n",
        "  #      isbi_img = Image.open(self.data_path + \"/test-volume.tif\")  # raw image from isbi dataset\n",
        "   #     for i, page in enumerate(ImageSequence.Iterator(isbi_img)):\n",
        "   #         page.save(self.data_path+\"/test/images/\" + str(i) + \".png\")\n",
        "\n",
        "        imgs = os.listdir(self.data_path + \"/test/images/\")\n",
        "        imgs = sorted([str(i).rstrip('.png').lstrip('GT_') for i in imgs], key=int) # sort accending\n",
        "        img_datas = np.ndarray((len(imgs), self.out_rows, self.out_cols, 1), dtype=np.uint8)\n",
        "        i = 0\n",
        "        for imgname in imgs:\n",
        "            img = load_img(self.data_path + \"/test/images/GT_\" + imgname + \".png\", color_mode=\"grayscale\", target_size=(256,256))\n",
        "            img_datas[i] = img_to_array(img)\n",
        "            i += 1\n",
        "            if i % len(imgs) == 0:\n",
        "                print('Done: {0}/{1} images'.format(i, len(imgs)))\n",
        "        print('loading done')\n",
        "        np.save(self.data_path + '/npy/imgs_test.npy', img_datas)\n",
        "        print('Saving to .npy files done.')\n",
        "\n",
        "    def load_train_data(self):\n",
        "        print('-' * 30)\n",
        "        print('load train images...')\n",
        "        print('-' * 30)\n",
        "        imgs_train = np.load(self.data_path + \"/npy/imgs_train.npy\")\n",
        "        imgs_mask_train = np.load(self.data_path + \"/npy/imgs_mask_train.npy\")\n",
        "        imgs_train = imgs_train.astype('float32')\n",
        "        imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "        imgs_train /= 255  # RGB 0~1\n",
        "        imgs_mask_train /= 255\n",
        "        imgs_mask_train[imgs_mask_train > 0.5] = 1\n",
        "        imgs_mask_train[imgs_mask_train <= 0.5] = 0\n",
        "        return imgs_train, imgs_mask_train\n",
        "\n",
        "    def load_test_data(self):\n",
        "        print('-' * 30)\n",
        "        print('load test images...')\n",
        "        print('-' * 30)\n",
        "        imgs_test = np.load(self.data_path + \"/npy/imgs_test.npy\")\n",
        "        imgs_test = imgs_test.astype('float32')\n",
        "        imgs_test /= 255\n",
        "        return imgs_test\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    mydata = dataProcess(256, 256)\n",
        "    mydata.create_train_data()\n",
        "    mydata.create_test_data()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
        "from tensorflow.keras.models import Model\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def conv_block(input, num_filters):\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(input)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "def encoder_block(input, num_filters):\n",
        "    x = conv_block(input, num_filters)\n",
        "    p = MaxPool2D((2, 2))(x)\n",
        "    return x, p\n",
        "\n",
        "def decoder_block(input, skip_features, num_filters):\n",
        "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(input)\n",
        "    x = Concatenate()([x, skip_features])\n",
        "    x = conv_block(x, num_filters)\n",
        "    return x\n",
        "\n",
        "def unet(input_shape):\n",
        "    inputs = Input(input_shape)\n",
        "\n",
        "    s1, p1 = encoder_block(inputs, 64)\n",
        "    s2, p2 = encoder_block(p1, 128)\n",
        "    s3, p3 = encoder_block(p2, 256)\n",
        "    s4, p4 = encoder_block(p3, 512)\n",
        "\n",
        "    b1 = conv_block(p4, 1024)\n",
        "\n",
        "    d1 = decoder_block(b1, s4, 512)\n",
        "    d2 = decoder_block(d1, s3, 256)\n",
        "    d3 = decoder_block(d2, s2, 128)\n",
        "    d4 = decoder_block(d3, s1, 64)\n",
        "\n",
        "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
        "\n",
        "    model = Model(inputs, outputs, name=\"U-Net\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "HqvK_sM97EUG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New section"
      ],
      "metadata": {
        "id": "f1U8WKI8dmZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing import *\n",
        "#from model import unet\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard, ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tifffile import imsave as tifsave\n",
        "import tensorflow as tf\n",
        "\n",
        "# Use other GPU in our mlti-gpu server\n",
        "# If you have only one GPU, change 1 to 0 or delete below lines\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "\n",
        "class myUnet(object):\n",
        "\n",
        "    def __init__(self, img_rows=256, img_cols=256, save_path=\"/content/tmp/data/results/\"):\n",
        "        self.img_rows = img_rows\n",
        "        self.img_cols = img_cols\n",
        "        self.save_path = save_path\n",
        "\n",
        "    def load_data(self):\n",
        "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
        "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
        "        imgs_test = mydata.load_test_data()\n",
        "        return imgs_train, imgs_mask_train, imgs_test\n",
        "\n",
        "    def train(self, load_pretrained):\n",
        "        print(\"loading data\")\n",
        "        model_name = 'my_model.h5'\n",
        "        log_dir = \"/content/tmp/data/logs/000\"\n",
        "        logging = TensorBoard(log_dir=log_dir)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
        "        print (imgs_train, imgs_mask_train.size)\n",
        "        print(\"loading data done\")\n",
        "        if load_pretrained:\n",
        "            model = load_model(model_name)\n",
        "            model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
        "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=30, verbose=1,\n",
        "                      validation_split=0.2, shuffle=True, callbacks=[logging, model_checkpoint, reduce_lr])\n",
        "            model.save(model_name)\n",
        "        else:\n",
        "            model = unet((256,256,1))\n",
        "            model.compile(optimizer = 'sgd', loss = 'mse', metrics = ['accuracy'])\n",
        "            #model = unet()\n",
        "            model.summary()\n",
        "            model_checkpoint = ModelCheckpoint('unet.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
        "            model.fit(imgs_train, imgs_mask_train, batch_size=4, epochs=10, verbose=1,\n",
        "                      validation_split=0.2, shuffle=True,\n",
        "                      callbacks=[logging, model_checkpoint, reduce_lr, early_stopping])\n",
        "            model.save(model_name)\n",
        "\n",
        "    def test(self):\n",
        "        model_name = 'my_model.h5'\n",
        "        if not os.path.exists(self.save_path):\n",
        "            os.makedirs(self.save_path)\n",
        "\n",
        "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
        "        model = load_model(model_name)\n",
        "        imgs_mask_test = model.predict(imgs_test, batch_size=2, verbose=1)\n",
        "        np.save(self.save_path + \"imgs_mask_test.npy\", imgs_mask_test)\n",
        "\n",
        "        print(\"array to image\")\n",
        "        imgs = np.load(self.save_path + \"imgs_mask_test.npy\")\n",
        "        total = []\n",
        "        for i in range(imgs.shape[0]):\n",
        "            img = imgs[i]\n",
        "            img[img > 0.5] = 1\n",
        "            img[img <= 0.5] = 0\n",
        "            total.append(img)\n",
        "        np_total = np.array(total)\n",
        "        tifsave(\"/content/tmp/data/results/prediction.tif\", np_total)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "      try:\n",
        "          myunet = myUnet()\n",
        "          myunet.train(load_pretrained=False)\n",
        "          myunet.test()\n",
        "      except RuntimeError as e:\n",
        "          print(e)"
      ],
      "metadata": {
        "id": "VSrl6VbvwvUK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1b98d52-36af-41b8-e4c8-198c4562c734"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading data\n",
            "------------------------------\n",
            "load train images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "[[[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]\n",
            "\n",
            "\n",
            " [[[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]\n",
            "\n",
            "  [[0.]\n",
            "   [0.]\n",
            "   [0.]\n",
            "   ...\n",
            "   [0.]\n",
            "   [0.]\n",
            "   [0.]]]] 258932736\n",
            "loading data done\n",
            "Model: \"U-Net\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 256, 256, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 256, 256, 64  640         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 256, 256, 64  256        ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 256, 256, 64  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 256, 256, 64  256        ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['activation_1[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 128, 128, 12  512        ['conv2d_2[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_2[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['activation_2[0][0]']           \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 128, 128, 12  512        ['conv2d_3[0][0]']               \n",
            " rmalization)                   8)                                                                \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_3[0][0]']  \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0          ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0          ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 16, 16, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_8[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_8[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 16, 16, 1024  9438208     ['activation_8[0][0]']           \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 16, 16, 1024  4096       ['conv2d_9[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 1024  0           ['batch_normalization_9[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['activation_9[0][0]']           \n",
            " ose)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
            "                                )                                 'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 512)  2359808     ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 512)  2048       ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 32, 32, 512)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['activation_11[0][0]']          \n",
            " spose)                                                                                           \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
            "                                                                  'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 64, 64, 256)  1179904     ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 64, 64, 256)  590080      ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 64, 64, 256)  1024       ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 64, 64, 256)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['activation_13[0][0]']          \n",
            " spose)                         8)                                                                \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 128, 128, 25  0           ['conv2d_transpose_2[0][0]',     \n",
            "                                6)                                'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 128, 128, 12  295040      ['concatenate_2[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 128, 128, 12  512        ['conv2d_14[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_14[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 128, 128, 12  147584      ['activation_14[0][0]']          \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 128, 128, 12  512        ['conv2d_15[0][0]']              \n",
            " ormalization)                  8)                                                                \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 128, 128, 12  0           ['batch_normalization_15[0][0]'] \n",
            "                                8)                                                                \n",
            "                                                                                                  \n",
            " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['activation_15[0][0]']          \n",
            " spose)                         )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 256, 256, 12  0           ['conv2d_transpose_3[0][0]',     \n",
            "                                8)                                'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 256, 256, 64  73792       ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 256, 256, 64  256        ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 256, 256, 64  36928       ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 256, 256, 64  256        ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 256, 256, 1)  65          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31,054,145\n",
            "Trainable params: 31,042,369\n",
            "Non-trainable params: 11,776\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9492\n",
            "Epoch 1: val_loss improved from inf to 0.02021, saving model to unet.h5\n",
            "790/790 [==============================] - 718s 886ms/step - loss: 0.0444 - accuracy: 0.9492 - val_loss: 0.0202 - val_accuracy: 0.9764 - lr: 0.0100\n",
            "Epoch 2/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9605\n",
            "Epoch 2: val_loss improved from 0.02021 to 0.01486, saving model to unet.h5\n",
            "790/790 [==============================] - 696s 881ms/step - loss: 0.0300 - accuracy: 0.9605 - val_loss: 0.0149 - val_accuracy: 0.9856 - lr: 0.0100\n",
            "Epoch 3/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0277 - accuracy: 0.9624\n",
            "Epoch 3: val_loss did not improve from 0.01486\n",
            "790/790 [==============================] - 695s 880ms/step - loss: 0.0277 - accuracy: 0.9624 - val_loss: 0.0333 - val_accuracy: 0.9479 - lr: 0.0100\n",
            "Epoch 4/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0250 - accuracy: 0.9660\n",
            "Epoch 4: val_loss did not improve from 0.01486\n",
            "790/790 [==============================] - 694s 879ms/step - loss: 0.0250 - accuracy: 0.9660 - val_loss: 0.0176 - val_accuracy: 0.9752 - lr: 0.0100\n",
            "Epoch 5/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0237 - accuracy: 0.9678\n",
            "Epoch 5: val_loss did not improve from 0.01486\n",
            "\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
            "790/790 [==============================] - 697s 882ms/step - loss: 0.0237 - accuracy: 0.9678 - val_loss: 0.0202 - val_accuracy: 0.9706 - lr: 0.0100\n",
            "Epoch 6/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0186 - accuracy: 0.9763\n",
            "Epoch 6: val_loss improved from 0.01486 to 0.01244, saving model to unet.h5\n",
            "790/790 [==============================] - 698s 884ms/step - loss: 0.0186 - accuracy: 0.9763 - val_loss: 0.0124 - val_accuracy: 0.9868 - lr: 1.0000e-03\n",
            "Epoch 7/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.9787\n",
            "Epoch 7: val_loss did not improve from 0.01244\n",
            "790/790 [==============================] - 697s 883ms/step - loss: 0.0173 - accuracy: 0.9787 - val_loss: 0.0153 - val_accuracy: 0.9803 - lr: 1.0000e-03\n",
            "Epoch 8/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9803\n",
            "Epoch 8: val_loss did not improve from 0.01244\n",
            "790/790 [==============================] - 698s 884ms/step - loss: 0.0163 - accuracy: 0.9803 - val_loss: 0.0133 - val_accuracy: 0.9849 - lr: 1.0000e-03\n",
            "Epoch 9/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0152 - accuracy: 0.9820\n",
            "Epoch 9: val_loss improved from 0.01244 to 0.01194, saving model to unet.h5\n",
            "790/790 [==============================] - 699s 885ms/step - loss: 0.0152 - accuracy: 0.9820 - val_loss: 0.0119 - val_accuracy: 0.9883 - lr: 1.0000e-03\n",
            "Epoch 10/10\n",
            "790/790 [==============================] - ETA: 0s - loss: 0.0150 - accuracy: 0.9821\n",
            "Epoch 10: val_loss improved from 0.01194 to 0.01149, saving model to unet.h5\n",
            "790/790 [==============================] - 675s 855ms/step - loss: 0.0150 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9885 - lr: 1.0000e-03\n",
            "------------------------------\n",
            "load train images...\n",
            "------------------------------\n",
            "------------------------------\n",
            "load test images...\n",
            "------------------------------\n",
            "25/25 [==============================] - 8s 161ms/step\n",
            "array to image\n"
          ]
        }
      ]
    }
  ]
}