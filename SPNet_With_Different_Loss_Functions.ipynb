{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nan-hk/-motion-artifacts/blob/master/SPNet_With_Different_Loss_Functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3846c946",
      "metadata": {
        "id": "3846c946"
      },
      "outputs": [],
      "source": [
        "#train\n",
        "!pip install tensorboardX --no-cache-dir"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/TrainDataset_motion.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBtOfacIz2qa",
        "outputId": "63a801ea-21e8-4d0a-939c-c25b70cf8bdf"
      },
      "id": "aBtOfacIz2qa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/TestDataset_motion.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/tmp\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "kgP-kzKD48IW"
      },
      "id": "kgP-kzKD48IW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Rest2Net model"
      ],
      "metadata": {
        "id": "T7c0BF7hggkP"
      },
      "id": "T7c0BF7hggkP"
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9NJ4zYYPgevn"
      },
      "id": "9NJ4zYYPgevn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "068f0375",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "068f0375",
        "outputId": "d7b17544-e2df-4e5a-b6c3-94aa0f020bfd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1000])\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.utils.model_zoo as model_zoo\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "__all__ = ['Res2Net', 'res2net50_v1b', 'res2net101_v1b']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'res2net50_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth',\n",
        "    'res2net101_v1b_26w_4s': 'https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net101_v1b_26w_4s-0812c246.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class Bottle2neck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, baseWidth=26, scale = 4, stype='normal'):\n",
        "        \"\"\" Constructor\n",
        "        Args:\n",
        "            inplanes: input channel dimensionality\n",
        "            planes: output channel dimensionality\n",
        "            stride: conv stride. Replaces pooling layer.\n",
        "            downsample: None when stride = 1\n",
        "            baseWidth: basic width of conv3x3\n",
        "            scale: number of scale.\n",
        "            type: 'normal': normal set. 'stage': first block of a new stage.\n",
        "        \"\"\"\n",
        "        super(Bottle2neck, self).__init__()\n",
        "\n",
        "        width = int(math.floor(planes * (baseWidth/64.0)))\n",
        "        self.conv1 = nn.Conv2d(inplanes, width*scale, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(width*scale)\n",
        "        \n",
        "        if scale == 1:\n",
        "          self.nums = 1\n",
        "        else:\n",
        "          self.nums = scale -1\n",
        "        if stype == 'stage':\n",
        "            self.pool = nn.AvgPool2d(kernel_size=3, stride = stride, padding=1)\n",
        "        convs = []\n",
        "        bns = []\n",
        "        for i in range(self.nums):\n",
        "          convs.append(nn.Conv2d(width, width, kernel_size=3, stride = stride, padding=1, bias=False))\n",
        "          bns.append(nn.BatchNorm2d(width))\n",
        "        self.convs = nn.ModuleList(convs)\n",
        "        self.bns = nn.ModuleList(bns)\n",
        "\n",
        "        self.conv3 = nn.Conv2d(width*scale, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stype = stype\n",
        "        self.scale = scale\n",
        "        self.width  = width\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        spx = torch.split(out, self.width, 1)\n",
        "        for i in range(self.nums):\n",
        "          if i==0 or self.stype=='stage':\n",
        "            sp = spx[i]\n",
        "          else:\n",
        "            sp = sp + spx[i]\n",
        "          sp = self.convs[i](sp)\n",
        "          sp = self.relu(self.bns[i](sp))\n",
        "          if i==0:\n",
        "            out = sp\n",
        "          else:\n",
        "            out = torch.cat((out, sp), 1)\n",
        "        if self.scale != 1 and self.stype=='normal':\n",
        "          out = torch.cat((out, spx[self.nums]),1)\n",
        "        elif self.scale != 1 and self.stype=='stage':\n",
        "          out = torch.cat((out, self.pool(spx[self.nums])),1)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Res2Net(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net, self).__init__()\n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "        x5 = self.avgpool(x4)\n",
        "        x6 = x5.view(x5.size(0), -1)\n",
        "        x7 = self.fc(x6)\n",
        "\n",
        "        return x7\n",
        "\n",
        "\n",
        "\n",
        "class Res2Net_Ours(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, baseWidth = 26, scale = 4, num_classes=1000):\n",
        "        self.inplanes = 64\n",
        "        super(Res2Net_Ours, self).__init__()\n",
        "        \n",
        "        self.baseWidth = baseWidth\n",
        "        self.scale = scale\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1, bias=False)\n",
        "        )\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "       \n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.AvgPool2d(kernel_size=stride, stride=stride, \n",
        "                    ceil_mode=True, count_include_pad=False),\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion, \n",
        "                    kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample=downsample, \n",
        "                        stype='stage', baseWidth = self.baseWidth, scale=self.scale))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes, baseWidth = self.baseWidth, scale=self.scale))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x0 = self.maxpool(x)\n",
        "        \n",
        "\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "\n",
        "\n",
        "        return x0,x1,x2,x3,x4\n",
        "    \n",
        "    \n",
        "\n",
        "def res2net50_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b model.\n",
        "    Res2Net-50 refers to the Res2Net-50_v1b_26w_4s.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_Ours(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net_Ours(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "def res2net50_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 6, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net50_v1b_26w_4s'],map_location='cpu'))\n",
        "    return model\n",
        "\n",
        "def res2net101_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 4, 23, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net101_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "def res2net152_v1b_26w_4s(pretrained=False, **kwargs):\n",
        "    \"\"\"Constructs a Res2Net-50_v1b_26w_4s model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = Res2Net(Bottle2neck, [3, 8, 36, 3], baseWidth = 26, scale = 4, **kwargs)\n",
        "    if pretrained:\n",
        "        model.load_state_dict(model_zoo.load_url(model_urls['res2net152_v1b_26w_4s']))\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "def Res2Net_model(ind=50):\n",
        "    \n",
        "    if ind == 50:\n",
        "        model_base = res2net50_v1b(pretrained=True)\n",
        "        model      = res2net50_v1b_Ours()\n",
        "\n",
        "    if ind == 101:\n",
        "        model_base = res2net101_v1b(pretrained=True)\n",
        "        model      = res2net101_v1b_Ours()\n",
        "        \n",
        "        \n",
        "    pretrained_dict = model_base.state_dict()\n",
        "    model_dict      = model.state_dict()\n",
        "    \n",
        "    pretrained_dict =  {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
        "    \n",
        "    model_dict.update(pretrained_dict)\n",
        "    model.load_state_dict(model_dict)\n",
        "    \n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    images = torch.rand(1, 3, 352, 352)\n",
        "    model = res2net50_v1b_26w_4s(pretrained=False)\n",
        "    model = model\n",
        "    print(model(images).size())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85810b84",
      "metadata": {
        "id": "85810b84"
      },
      "outputs": [],
      "source": [
        "#SPNet Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe5d415",
      "metadata": {
        "id": "bbe5d415"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def maxpool():\n",
        "    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "    return pool\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"3x3 convolution with padding\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicConv2d(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1):\n",
        "        super(BasicConv2d, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_planes, out_planes,\n",
        "                              kernel_size=kernel_size, stride=stride,\n",
        "                              padding=padding, dilation=dilation, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "#Global Contextual module\n",
        "class GCM(nn.Module):\n",
        "    def __init__(self, in_channel, out_channel):\n",
        "        super(GCM, self).__init__()\n",
        "        self.relu = nn.ReLU(True)\n",
        "        self.branch0 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "        )\n",
        "        self.branch1 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 3), padding=(0, 1)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(3, 1), padding=(1, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=3, dilation=3)\n",
        "        )\n",
        "        self.branch2 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 5), padding=(0, 2)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(5, 1), padding=(2, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=5, dilation=5)\n",
        "        )\n",
        "        self.branch3 = nn.Sequential(\n",
        "            BasicConv2d(in_channel, out_channel, 1),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(1, 7), padding=(0, 3)),\n",
        "            BasicConv2d(out_channel, out_channel, kernel_size=(7, 1), padding=(3, 0)),\n",
        "            BasicConv2d(out_channel, out_channel, 3, padding=7, dilation=7)\n",
        "        )\n",
        "        self.conv_cat = BasicConv2d(4*out_channel, out_channel, 3, padding=1)\n",
        "        self.conv_res = BasicConv2d(in_channel, out_channel, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x0 = self.branch0(x)\n",
        "        x1 = self.branch1(x)\n",
        "        x2 = self.branch2(x)\n",
        "        x3 = self.branch3(x)\n",
        "\n",
        "        x_cat = self.conv_cat(torch.cat((x0, x1, x2, x3), 1))\n",
        "\n",
        "        x = self.relu(x_cat + self.conv_res(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "class CIM0(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM0, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "\n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "\n",
        "    def forward(self, rgb, depth):\n",
        "        \n",
        "        ################################\n",
        "        \n",
        "        x_rgb = self.layer_10(rgb)\n",
        "        x_dep = self.layer_20(depth)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb)\n",
        "        dep_w = nn.Sigmoid()(x_dep)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = rgb.mul(dep_w)\n",
        "        x_dep_w = depth.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + rgb\n",
        "        x_dep_r = x_dep_w + depth\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "         \n",
        "        return out1\n",
        "\n",
        "\n",
        "class CIM(nn.Module):    \n",
        "    def __init__(self,in_dim, out_dim):\n",
        "        super(CIM, self).__init__()\n",
        "        \n",
        "        act_fn = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.reduc_1 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        self.reduc_2 = nn.Sequential(nn.Conv2d(in_dim, out_dim, kernel_size=1), act_fn)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        \n",
        "        self.layer_11 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)        \n",
        "        self.layer_21 = nn.Sequential(nn.Conv2d(out_dim, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        \n",
        "        self.gamma1 = nn.Parameter(torch.zeros(1))\n",
        "        self.gamma2 = nn.Parameter(torch.zeros(1))\n",
        "        \n",
        "\n",
        "        self.layer_ful1 = nn.Sequential(nn.Conv2d(out_dim*2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "        self.layer_ful2 = nn.Sequential(nn.Conv2d(out_dim+out_dim//2, out_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(out_dim),act_fn,)\n",
        "\n",
        "    def forward(self, rgb, depth, xx):\n",
        "        \n",
        "        ################################\n",
        "        x_rgb = self.reduc_1(rgb)\n",
        "        x_dep = self.reduc_2(depth)\n",
        "        \n",
        "        x_rgb1 = self.layer_10(x_rgb)\n",
        "        x_dep1 = self.layer_20(x_dep)\n",
        "        \n",
        "        rgb_w = nn.Sigmoid()(x_rgb1)\n",
        "        dep_w = nn.Sigmoid()(x_dep1)\n",
        "        \n",
        "        ##\n",
        "        x_rgb_w = x_rgb.mul(dep_w)\n",
        "        x_dep_w = x_dep.mul(rgb_w)\n",
        "        \n",
        "        x_rgb_r = x_rgb_w + x_rgb\n",
        "        x_dep_r = x_dep_w + x_dep\n",
        "        \n",
        "        ## fusion \n",
        "        x_rgb_r = self.layer_11(x_rgb_r)\n",
        "        x_dep_r = self.layer_21(x_dep_r)\n",
        "        \n",
        "        \n",
        "        ful_mul = torch.mul(x_rgb_r, x_dep_r)         \n",
        "        x_in1   = torch.reshape(x_rgb_r,[x_rgb_r.shape[0],1,x_rgb_r.shape[1],x_rgb_r.shape[2],x_rgb_r.shape[3]])\n",
        "        x_in2   = torch.reshape(x_dep_r,[x_dep_r.shape[0],1,x_dep_r.shape[1],x_dep_r.shape[2],x_dep_r.shape[3]])\n",
        "        x_cat   = torch.cat((x_in1, x_in2),dim=1)\n",
        "        ful_max = x_cat.max(dim=1)[0]\n",
        "        ful_out = torch.cat((ful_mul,ful_max),dim=1)\n",
        "        \n",
        "        out1 = self.layer_ful1(ful_out)\n",
        "        out2 = self.layer_ful2(torch.cat([out1,xx],dim=1))\n",
        "         \n",
        "        return out2\n",
        "\n",
        "\n",
        "\n",
        "class MFA(nn.Module):    \n",
        "    def __init__(self,in_dim):\n",
        "        super(MFA, self).__init__()\n",
        "         \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.layer_10 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)\n",
        "        self.layer_20 = nn.Conv2d(in_dim, in_dim, kernel_size=3, stride=1, padding=1)   \n",
        "        self.layer_cat1 = nn.Sequential(nn.Conv2d(in_dim*2, in_dim, kernel_size=3, stride=1, padding=1),nn.BatchNorm2d(in_dim),)        \n",
        "        \n",
        "    def forward(self, x_ful, x1, x2):\n",
        "        \n",
        "        ################################\n",
        "    \n",
        "        x_ful_1 = x_ful.mul(x1)\n",
        "        x_ful_2 = x_ful.mul(x2)\n",
        "        \n",
        "     \n",
        "        x_ful_w = self.layer_cat1(torch.cat([x_ful_1, x_ful_2],dim=1))\n",
        "        out     = self.relu(x_ful + x_ful_w)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "    \n",
        "\n",
        "  \n",
        "   \n",
        "###############################################################################\n",
        "\n",
        "class SPNet(nn.Module):\n",
        "    def __init__(self, channel=32,ind=50):\n",
        "        super(SPNet, self).__init__()\n",
        "        \n",
        "       \n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.upsample_2 = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.upsample_4 = nn.Upsample(scale_factor=4, mode='bilinear', align_corners=True)\n",
        "        self.upsample_8 = nn.Upsample(scale_factor=8, mode='bilinear', align_corners=True)\n",
        "        \n",
        "        #Backbone model\n",
        "        #Backbone model\n",
        "        self.layer_rgb  = Res2Net_model(ind)\n",
        "        self.layer_dep  = Res2Net_model(ind)\n",
        "        \n",
        "        self.layer_dep0 = nn.Conv2d(1, 3, kernel_size=1)\n",
        "        \n",
        "        ###############################################\n",
        "        # funsion encoders #\n",
        "        ###############################################\n",
        "        self.fu_0 = CIM0(64, 64)#\n",
        "        \n",
        "        self.fu_1 = CIM(256, 128) #MixedFusion_Block_IMfusion\n",
        "        self.pool_fu_1 = maxpool()\n",
        "        \n",
        "        self.fu_2 = CIM(512, 256)\n",
        "        self.pool_fu_2 = maxpool()\n",
        "        \n",
        "        self.fu_3 = CIM(1024, 512)\n",
        "        self.pool_fu_3 = maxpool()\n",
        "\n",
        "        self.fu_4 = CIM(2048, 1024)\n",
        "        self.pool_fu_4 = maxpool()\n",
        "        \n",
        "        \n",
        "        ###############################################\n",
        "        # decoders #\n",
        "        ###############################################\n",
        "        \n",
        "        ## rgb\n",
        "        self.rgb_conv_4   = nn.Sequential(BasicConv2d(2048,    256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.rgb_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.rgb_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.rgb_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.rgb_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.rgb_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.rgb_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## depth\n",
        "        self.dep_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_4    = GCM(2048,  channel)\n",
        "        \n",
        "        self.dep_conv_3   = nn.Sequential(BasicConv2d(1024+32, 256, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_3    = GCM(1024+32,  channel)\n",
        "\n",
        "        self.dep_conv_2   = nn.Sequential(BasicConv2d(512+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_2    = GCM(512+32,  channel)\n",
        "\n",
        "        self.dep_conv_1   = nn.Sequential(BasicConv2d(256+32, 128, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_1    = GCM(256+32,  channel)\n",
        "\n",
        "        self.dep_conv_0   = nn.Sequential(BasicConv2d(64+32, 64, 3, padding=1),self.relu)\n",
        "        self.dep_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.dep_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        ## fusion\n",
        "        self.ful_conv_4   = nn.Sequential(BasicConv2d(2048, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_4    = GCM(1024,  channel)\n",
        "        \n",
        "        self.ful_conv_3   = nn.Sequential(BasicConv2d(1024+32*3, 256, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_3    = GCM(512+32,  channel)\n",
        "\n",
        "        self.ful_conv_2   = nn.Sequential(BasicConv2d(512+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_2    = GCM(256+32,  channel)\n",
        "\n",
        "        self.ful_conv_1   = nn.Sequential(BasicConv2d(256+32*3, 128, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_1    = GCM(128+32,  channel)\n",
        "\n",
        "        self.ful_conv_0   = nn.Sequential(BasicConv2d(128+32*3, 64, 3, padding=1),self.relu)\n",
        "        self.ful_gcm_0    = GCM(64+32,  channel)        \n",
        "        self.ful_conv_out = nn.Conv2d(channel, 1, 1)\n",
        "        \n",
        "        self.ful_layer4   = MFA(channel)\n",
        "        self.ful_layer3   = MFA(channel)\n",
        "        self.ful_layer2   = MFA(channel)\n",
        "        self.ful_layer1   = MFA(channel)\n",
        "        self.ful_layer0   = MFA(channel)\n",
        "        \n",
        "                \n",
        "\n",
        "    def forward(self, imgs, depths):\n",
        "        \n",
        "        img_0, img_1, img_2, img_3, img_4 = self.layer_rgb(imgs)\n",
        "        dep_0, dep_1, dep_2, dep_3, dep_4 = self.layer_dep(self.layer_dep0(depths))\n",
        "        \n",
        "    \n",
        "      \n",
        "        ####################################################\n",
        "        ## fusion\n",
        "        ####################################################\n",
        "        ful_0    = self.fu_0(img_0, dep_0)\n",
        "        ful_1    = self.fu_1(img_1, dep_1, ful_0)\n",
        "        ful_2    = self.fu_2(img_2, dep_2, self.pool_fu_1(ful_1))\n",
        "        ful_3    = self.fu_3(img_3, dep_3, self.pool_fu_2(ful_2))\n",
        "        ful_4    = self.fu_4(img_4, dep_4, self.pool_fu_3(ful_3))\n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder rgb\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_rgb_42    = self.rgb_gcm_4(img_4)\n",
        "        \n",
        "        x_rgb_3_cat = torch.cat([img_3, self.upsample_2(x_rgb_42)], dim=1)\n",
        "        x_rgb_32    = self.rgb_gcm_3(x_rgb_3_cat)\n",
        "        \n",
        "        x_rgb_2_cat = torch.cat([img_2, self.upsample_2(x_rgb_32)], dim=1)\n",
        "        x_rgb_22    = self.rgb_gcm_2(x_rgb_2_cat)        \n",
        "\n",
        "        x_rgb_1_cat = torch.cat([img_1, self.upsample_2(x_rgb_22)], dim=1)\n",
        "        x_rgb_12    = self.rgb_gcm_1(x_rgb_1_cat)     \n",
        "\n",
        "        x_rgb_0_cat = torch.cat([img_0, x_rgb_12], dim=1)\n",
        "        x_rgb_02    = self.rgb_gcm_0(x_rgb_0_cat)     \n",
        "        rgb_out     = self.upsample_4(self.rgb_conv_out(x_rgb_02))\n",
        "        \n",
        "        \n",
        "        ####################################################\n",
        "        ## decoder depth\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_dep_42    = self.dep_gcm_4(dep_4)\n",
        "        \n",
        "        x_dep_3_cat = torch.cat([dep_3, self.upsample_2(x_dep_42)], dim=1)\n",
        "        x_dep_32    = self.dep_gcm_3(x_dep_3_cat)\n",
        "        \n",
        "        x_dep_2_cat = torch.cat([dep_2, self.upsample_2(x_dep_32)], dim=1)\n",
        "        x_dep_22    = self.dep_gcm_2(x_dep_2_cat)        \n",
        "\n",
        "        x_dep_1_cat = torch.cat([dep_1, self.upsample_2(x_dep_22)], dim=1)\n",
        "        x_dep_12    = self.dep_gcm_1(x_dep_1_cat)     \n",
        "\n",
        "        x_dep_0_cat = torch.cat([dep_0, x_dep_12], dim=1)\n",
        "        x_dep_02    = self.dep_gcm_0(x_dep_0_cat)     \n",
        "        dep_out     = self.upsample_4(self.dep_conv_out(x_dep_02))\n",
        "        \n",
        "\n",
        "        ####################################################\n",
        "        ## decoder fusion\n",
        "        ####################################################        \n",
        "        #\n",
        "        x_ful_42    = self.ful_gcm_4(ful_4)\n",
        "        \n",
        "        x_ful_3_cat = torch.cat([ful_3, self.ful_layer3(self.upsample_2(x_ful_42),self.upsample_2(x_rgb_42),self.upsample_2(x_dep_42))], dim=1)\n",
        "        x_ful_32    = self.ful_gcm_3(x_ful_3_cat)\n",
        "        \n",
        "        x_ful_2_cat = torch.cat([ful_2, self.ful_layer2(self.upsample_2(x_ful_32),self.upsample_2(x_rgb_32),self.upsample_2(x_dep_32))], dim=1)\n",
        "        x_ful_22    = self.ful_gcm_2(x_ful_2_cat)        \n",
        "\n",
        "        x_ful_1_cat = torch.cat([ful_1, self.ful_layer1(self.upsample_2(x_ful_22),self.upsample_2(x_rgb_22),self.upsample_2(x_dep_22))], dim=1)\n",
        "        x_ful_12    = self.ful_gcm_1(x_ful_1_cat)     \n",
        "\n",
        "        x_ful_0_cat = torch.cat([ful_0, self.ful_layer0(x_ful_12, x_rgb_12, x_dep_12)], dim=1)\n",
        "        x_ful_02    = self.ful_gcm_0(x_ful_0_cat)     \n",
        "        ful_out     = self.upsample_4(self.ful_conv_out(x_ful_02))\n",
        "\n",
        "\n",
        "        return rgb_out, dep_out, ful_out\n",
        "    \n",
        "    \n",
        "\n",
        "    def _make_agant_layer(self, inplanes, planes):\n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv2d(inplanes, planes, kernel_size=1,\n",
        "                      stride=1, padding=0, bias=False),\n",
        "            nn.BatchNorm2d(planes),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        return layers\n",
        "\n",
        "    def _make_transpose(self, block, planes, blocks, stride=1):\n",
        "        upsample = None\n",
        "        if stride != 1:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.ConvTranspose2d(self.inplanes, planes,\n",
        "                                   kernel_size=2, stride=stride,\n",
        "                                   padding=0, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "        elif self.inplanes != planes:\n",
        "            upsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, self.inplanes))\n",
        "\n",
        "        layers.append(block(self.inplanes, planes, stride, upsample))\n",
        "        self.inplanes = planes\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "   \n",
        "\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d39ea02d",
      "metadata": {
        "id": "d39ea02d"
      },
      "outputs": [],
      "source": [
        "#ResNet model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1dfdaf50",
      "metadata": {
        "id": "1dfdaf50"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self,mode='rgb'):\n",
        "        self.inplanes = 64\n",
        "        super(ResNet50, self).__init__()\n",
        "        if(mode=='rgb'):\n",
        "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        elif(mode=='rgbd'):\n",
        "            self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        elif(mode==\"share\"):\n",
        "            self.conv1=nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "            self.conv1_d=nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3,\n",
        "                               bias=False)\n",
        "        else:\n",
        "            raise \n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(Bottleneck, 64, 3)\n",
        "        self.layer2 = self._make_layer(Bottleneck, 128, 4, stride=2)\n",
        "        self.layer3_1 = self._make_layer(Bottleneck, 256, 6, stride=2)\n",
        "        self.layer4_1 = self._make_layer(Bottleneck, 512, 3, stride=2)\n",
        "\n",
        "        self.inplanes = 512\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x1 = self.layer3_1(x)\n",
        "        x1 = self.layer4_1(x1)\n",
        "\n",
        "        return x1, x1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c67c8a5",
      "metadata": {
        "id": "3c67c8a5"
      },
      "outputs": [],
      "source": [
        "#Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8d4d20a",
      "metadata": {
        "id": "e8d4d20a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "import random\n",
        "import numpy as np\n",
        "from PIL import ImageEnhance\n",
        "\n",
        "#several data augumentation strategies\n",
        "def cv_random_flip(img, label,depth):\n",
        "    flip_flag = random.randint(0, 1)\n",
        "    # flip_flag2= random.randint(0,1)\n",
        "    #left right flip\n",
        "    if flip_flag == 1:\n",
        "        img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        label = label.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "        depth = depth.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "    #top bottom flip\n",
        "    # if flip_flag2==1:\n",
        "    #     img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     label = label.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    #     depth = depth.transpose(Image.FLIP_TOP_BOTTOM)\n",
        "    return img, label, depth\n",
        "def randomCrop(image, label,depth):\n",
        "    border=30\n",
        "    image_width = image.size[0]\n",
        "    image_height = image.size[1]\n",
        "    crop_win_width = np.random.randint(image_width-border , image_width)\n",
        "    crop_win_height = np.random.randint(image_height-border , image_height)\n",
        "    random_region = (\n",
        "        (image_width - crop_win_width) >> 1, (image_height - crop_win_height) >> 1, (image_width + crop_win_width) >> 1,\n",
        "        (image_height + crop_win_height) >> 1)\n",
        "    return image.crop(random_region), label.crop(random_region),depth.crop(random_region)\n",
        "def randomRotation(image,label,depth):\n",
        "    mode=Image.BICUBIC\n",
        "    if random.random()>0.8:\n",
        "        random_angle = np.random.randint(-15, 15)\n",
        "        image=image.rotate(random_angle, mode)\n",
        "        label=label.rotate(random_angle, mode)\n",
        "        depth=depth.rotate(random_angle, mode)\n",
        "    return image,label,depth\n",
        "def colorEnhance(image):\n",
        "    bright_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Brightness(image).enhance(bright_intensity)\n",
        "    contrast_intensity=random.randint(5,15)/10.0\n",
        "    image=ImageEnhance.Contrast(image).enhance(contrast_intensity)\n",
        "    color_intensity=random.randint(0,20)/10.0\n",
        "    image=ImageEnhance.Color(image).enhance(color_intensity)\n",
        "    sharp_intensity=random.randint(0,30)/10.0\n",
        "    image=ImageEnhance.Sharpness(image).enhance(sharp_intensity)\n",
        "    return image\n",
        "def randomGaussian(image, mean=0.1, sigma=0.35):\n",
        "    def gaussianNoisy(im, mean=mean, sigma=sigma):\n",
        "        for _i in range(len(im)):\n",
        "            im[_i] += random.gauss(mean, sigma)\n",
        "        return im\n",
        "    img = np.asarray(image)\n",
        "    width, height = img.shape\n",
        "    img = gaussianNoisy(img[:].flatten(), mean, sigma)\n",
        "    img = img.reshape([width, height])\n",
        "    return Image.fromarray(np.uint8(img))\n",
        "def randomPeper(img):\n",
        "\n",
        "    img=np.array(img)\n",
        "    noiseNum=int(0.0015*img.shape[0]*img.shape[1])\n",
        "    for i in range(noiseNum):\n",
        "\n",
        "        randX=random.randint(0,img.shape[0]-1)  \n",
        "\n",
        "        randY=random.randint(0,img.shape[1]-1)  \n",
        "\n",
        "        if random.randint(0,1)==0:  \n",
        "\n",
        "            img[randX,randY]=0  \n",
        "\n",
        "        else:  \n",
        "\n",
        "            img[randX,randY]=255 \n",
        "    return Image.fromarray(img)  \n",
        "\n",
        "# dataset for training\n",
        "#The current loader is not using the normalized depth maps for training and test. If you use the normalized depth maps\n",
        "#(e.g., 0 represents background and 1 represents foreground.), the performance will be further improved.\n",
        "\n",
        "class SalObjDataset(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                    or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        print('SalObjDat', )\n",
        "        self.filter_files()\n",
        "        self.size = len(self.images)\n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        image = self.rgb_loader(self.images[index])\n",
        "        gt = self.binary_loader(self.gts[index])\n",
        "        depth=self.binary_loader(self.depths[index])\n",
        "        image,gt,depth =cv_random_flip(image,gt,depth)\n",
        "        image,gt,depth=randomCrop(image, gt,depth)\n",
        "        image,gt,depth=randomRotation(image, gt,depth)\n",
        "        image=colorEnhance(image)\n",
        "        # gt=randomGaussian(gt)\n",
        "        gt=randomPeper(gt)\n",
        "        image = self.img_transform(image)\n",
        "        gt = self.gt_transform(gt)\n",
        "        depth=self.depths_transform(depth)\n",
        "        \n",
        "        return image, gt, depth\n",
        "\n",
        "    def filter_files(self):\n",
        "        print('SalObjDataset', self.images, self.gts)\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# 0919\n",
        "#\n",
        "\n",
        "class SalObjDataset_var(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        \n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "\n",
        "\n",
        "class SalObjDataset_var_unlabel(data.Dataset):\n",
        "    def __init__(self, image_root, gt_root,depth_root, trainsize):\n",
        "        \n",
        "        self.trainsize = trainsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.png')]\n",
        "        self.gts    = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.depths = [depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp') or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts    = sorted(self.gts)\n",
        "        self.depths = sorted(self.depths)\n",
        "        self.filter_files()\n",
        "        self.size   = len(self.images)\n",
        "        \n",
        "        self.img_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.Compose([\n",
        "            transforms.Resize((self.trainsize, self.trainsize)),\n",
        "            transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.trainsize, self.trainsize)),transforms.ToTensor()])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        ## read imag, gt, depth\n",
        "        image0 = self.rgb_loader(self.images[index])\n",
        "        gt0    = self.binary_loader(self.gts[index])\n",
        "        depth0 = self.binary_loader(self.depths[index])\n",
        "        \n",
        "        \n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image,gt,depth = cv_random_flip(image0,gt0,depth0)\n",
        "        image,gt,depth = randomCrop(image, gt,depth)\n",
        "        image,gt,depth = randomRotation(image, gt,depth)\n",
        "        image          = colorEnhance(image)\n",
        "        gt             = randomPeper(gt)\n",
        "        image          = self.img_transform(image)\n",
        "        gt             = self.gt_transform(gt)\n",
        "        depth          = self.depths_transform(depth)\n",
        "\n",
        "        ##################################################\n",
        "        ## out1\n",
        "        ##################################################\n",
        "        image2,gt2,depth2 = cv_random_flip(image0,gt0,depth0)\n",
        "        image2,gt2,depth2 = randomCrop(image2, gt2,depth2)\n",
        "        image2,gt2,depth2 = randomRotation(image2, gt2,depth2)\n",
        "        image2          = colorEnhance(image2)\n",
        "        gt2             = randomPeper(gt2)\n",
        "        image2          = self.img_transform(image2)\n",
        "        gt2             = self.gt_transform(gt2)\n",
        "        depth2          = self.depths_transform(depth2)\n",
        "\n",
        "        \n",
        "        return image, gt, depth, image2, gt2, depth2\n",
        "\n",
        "    def filter_files(self):\n",
        "\n",
        "        assert len(self.images) == len(self.gts) and len(self.gts)==len(self.images)\n",
        "        images = []\n",
        "        gts = []\n",
        "        depths=[]\n",
        "        for img_path, gt_path,depth_path in zip(self.images, self.gts, self.depths):\n",
        "            img = Image.open(img_path)\n",
        "            gt = Image.open(gt_path)\n",
        "            depth= Image.open(depth_path)\n",
        "            if img.size == gt.size and gt.size==depth.size:\n",
        "                images.append(img_path)\n",
        "                gts.append(gt_path)\n",
        "                depths.append(depth_path)\n",
        "        self.images = images\n",
        "        self.gts = gts\n",
        "        self.depths=depths\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "\n",
        "    def resize(self, img, gt, depth):\n",
        "        assert img.size == gt.size and gt.size==depth.size\n",
        "        w, h = img.size\n",
        "        if h < self.trainsize or w < self.trainsize:\n",
        "            h = max(h, self.trainsize)\n",
        "            w = max(w, self.trainsize)\n",
        "            return img.resize((w, h), Image.BILINEAR), gt.resize((w, h), Image.NEAREST),depth.resize((w, h), Image.NEAREST)\n",
        "        else:\n",
        "            return img, gt, depth\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "#dataloader for training\n",
        "def get_loader(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "    print(image_root, gt_root, depth_root)\n",
        "    dataset = SalObjDataset(image_root, gt_root, depth_root,trainsize)\n",
        "    print(dataset)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#dataloader for training2\n",
        "## 09-19-2020\n",
        "def get_loader_var(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "def get_loader_var_unlabel(image_root, gt_root,depth_root, batchsize, trainsize, shuffle=True, num_workers=12, pin_memory=False):\n",
        "\n",
        "    dataset = SalObjDataset_var_unlabel(image_root, gt_root, depth_root,trainsize)\n",
        "    data_loader = data.DataLoader(dataset=dataset,\n",
        "                                  batch_size=batchsize,\n",
        "                                  shuffle=shuffle,\n",
        "                                  num_workers=num_workers,\n",
        "                                  pin_memory=pin_memory)\n",
        "    return data_loader\n",
        "\n",
        "\n",
        "#test dataset and loader\n",
        "class test_dataset:\n",
        "    def __init__(self, image_root, gt_root,depth_root, testsize):\n",
        "        self.testsize = testsize\n",
        "        self.images = [image_root + f for f in os.listdir(image_root) if f.endswith('.jpg') or f.endswith('.png')]\n",
        "        self.gts = [gt_root + f for f in os.listdir(gt_root) if f.endswith('.jpg')\n",
        "                       or f.endswith('.png')]\n",
        "        self.depths=[depth_root + f for f in os.listdir(depth_root) if f.endswith('.bmp')\n",
        "                    or f.endswith('.png')]\n",
        "        self.images = sorted(self.images)\n",
        "        self.gts = sorted(self.gts)\n",
        "        self.depths=sorted(self.depths)\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.Resize((self.testsize, self.testsize)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
        "        self.gt_transform = transforms.ToTensor()\n",
        "        # self.gt_transform = transforms.Compose([\n",
        "        #     transforms.Resize((self.trainsize, self.trainsize)),\n",
        "        #     transforms.ToTensor()])\n",
        "        self.depths_transform = transforms.Compose([transforms.Resize((self.testsize, self.testsize)),transforms.ToTensor()])\n",
        "        self.size = len(self.images)\n",
        "        self.index = 0\n",
        "\n",
        "    def load_data(self):\n",
        "        image = self.rgb_loader(self.images[self.index])\n",
        "        image = self.transform(image).unsqueeze(0)\n",
        "        gt = self.binary_loader(self.gts[self.index])\n",
        "        depth=self.binary_loader(self.depths[self.index])\n",
        "        depth=self.depths_transform(depth).unsqueeze(0)\n",
        "        name = self.images[self.index].split('/')[-1]\n",
        "        image_for_post=self.rgb_loader(self.images[self.index])\n",
        "        image_for_post=image_for_post.resize(gt.size)\n",
        "        if name.endswith('.jpg'):\n",
        "            name = name.split('.jpg')[0] + '.png'\n",
        "        self.index += 1\n",
        "        self.index = self.index % self.size\n",
        "        return image, gt,depth, name,np.array(image_for_post)\n",
        "\n",
        "    def rgb_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('RGB')\n",
        "\n",
        "    def binary_loader(self, path):\n",
        "        with open(path, 'rb') as f:\n",
        "            img = Image.open(f)\n",
        "            return img.convert('L')\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c5b61bc",
      "metadata": {
        "id": "4c5b61bc"
      },
      "outputs": [],
      "source": [
        "# Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea0d700f",
      "metadata": {
        "id": "ea0d700f"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "class EvalDataset(data.Dataset):\n",
        "    def __init__(self, img_root, label_root):\n",
        "        \n",
        "        self.image_path = list(map(lambda x: os.path.join(img_root, x), sorted(os.listdir(img_root))))\n",
        "        self.label_path = list(map(lambda x: os.path.join(label_root, x), sorted(os.listdir(label_root))))\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        pred = Image.open(self.image_path[item]).convert('L')\n",
        "\n",
        "        gt = Image.open(self.label_path[item]).convert('L')\n",
        "        # print(self.image_path[item], self.label_path[item])\n",
        "        if pred.size != gt.size:\n",
        "            pred = pred.resize(gt.size, Image.BILINEAR)\n",
        "        return pred, gt\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_path)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d90242c7",
      "metadata": {
        "id": "d90242c7"
      },
      "outputs": [],
      "source": [
        "#eva_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f85ca25c",
      "metadata": {
        "id": "f85ca25c"
      },
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Tue Sep 29 17:21:18 2020\n",
        "\n",
        "@author: taozhou\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "## basic funcs\n",
        "###############################################################################\n",
        "\n",
        "def fun_eval_e(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        score = torch.zeros(num).cuda()\n",
        "    else:\n",
        "        score = torch.zeros(num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        \n",
        "        fm = y_pred - y_pred.mean()\n",
        "        gt = y - y.mean()\n",
        "        align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "        enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "        score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)        \n",
        "    return score.max()\n",
        "\n",
        "\n",
        "def fun_eval_pr(y_pred, y, num, cuda=True):\n",
        "    \n",
        "    if cuda:\n",
        "        prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "    else:\n",
        "        prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "        thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "    \n",
        "    for i in range(num):\n",
        "        y_temp = (y_pred >= thlist[i]).float()\n",
        "        tp = (y_temp * y).sum()\n",
        "        prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "    return prec, recall\n",
        "    \n",
        "\n",
        "def fun_S_object(pred, gt):\n",
        "        \n",
        "    fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "    bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "    o_fg = fun_object(fg, gt)\n",
        "    o_bg = fun_object(bg, 1-gt)\n",
        "    u = gt.mean()\n",
        "    Q = u * o_fg + (1-u) * o_bg\n",
        "    return Q\n",
        "\n",
        "\n",
        "def fun_object(pred, gt):\n",
        "    \n",
        "    temp = pred[gt == 1]\n",
        "    x = temp.mean()\n",
        "    sigma_x = temp.std()\n",
        "    score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "    return score\n",
        "\n",
        "\n",
        "def fun_S_region(pred, gt):\n",
        "    \n",
        "    X, Y = fun_centroid(gt)\n",
        "    gt1, gt2, gt3, gt4, w1, w2, w3, w4 = fun_divideGT(gt, X, Y)\n",
        "    p1, p2, p3, p4 = fun_dividePrediction(pred, X, Y)\n",
        "    Q1 = fun_ssim(p1, gt1)\n",
        "    Q2 = fun_ssim(p2, gt2)\n",
        "    Q3 = fun_ssim(p3, gt3)\n",
        "    Q4 = fun_ssim(p4, gt4)\n",
        "    Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "    \n",
        "    return Q\n",
        "    \n",
        "def fun_centroid(gt, cuda=True):\n",
        "    \n",
        "    rows, cols = gt.size()[-2:]\n",
        "    gt = gt.view(rows, cols)\n",
        "    \n",
        "    if gt.sum() == 0:\n",
        "        \n",
        "        if cuda:\n",
        "            X = torch.eye(1).cuda() * round(cols / 2)\n",
        "            Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "        else:\n",
        "            X = torch.eye(1) * round(cols / 2)\n",
        "            Y = torch.eye(1) * round(rows / 2)\n",
        "    \n",
        "    else:\n",
        "        total = gt.sum()\n",
        "        \n",
        "        if cuda:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "        else:\n",
        "            i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "            j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            \n",
        "        X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "        Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        \n",
        "    return X.long(), Y.long()\n",
        "  \n",
        "    \n",
        "def fun_divideGT(gt, X, Y):\n",
        "    \n",
        "    h, w = gt.size()[-2:]\n",
        "    area = h*w\n",
        "    gt   = gt.view(h, w)\n",
        "    LT   = gt[:Y, :X]\n",
        "    RT   = gt[:Y, X:w]\n",
        "    LB   = gt[Y:h, :X]\n",
        "    RB   = gt[Y:h, X:w]\n",
        "    X    = X.float()\n",
        "    Y    = Y.float()\n",
        "    w1   = X * Y / area\n",
        "    w2   = (w - X) * Y / area\n",
        "    w3   = X * (h - Y) / area\n",
        "    w4   = 1 - w1 - w2 - w3\n",
        "    \n",
        "    return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "def fun_dividePrediction(pred, X, Y):\n",
        "    \n",
        "    h, w = pred.size()[-2:]\n",
        "    pred = pred.view(h, w)\n",
        "    LT = pred[:Y, :X]\n",
        "    RT = pred[:Y, X:w]\n",
        "    LB = pred[Y:h, :X]\n",
        "    RB = pred[Y:h, X:w]\n",
        "        \n",
        "    return LT, RT, LB, RB\n",
        "\n",
        "\n",
        "def fun_ssim(pred, gt):\n",
        "    \n",
        "    gt       = gt.float()\n",
        "    h, w     = pred.size()[-2:]\n",
        "    N        = h*w\n",
        "    x        = pred.mean()\n",
        "    y        = gt.mean()\n",
        "    sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "    sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "    aplha = 4 * x * y *sigma_xy\n",
        "    beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "    \n",
        "    if aplha != 0:\n",
        "        Q = aplha / (beta + 1e-20)\n",
        "    elif aplha == 0 and beta == 0:\n",
        "        Q = 1.0\n",
        "    else:\n",
        "        Q = 0\n",
        "    \n",
        "    return Q\n",
        "\n",
        "###############################################################################\n",
        "## metric funcs\n",
        "###############################################################################\n",
        "def eval_mae(pred,gt,cuda=True):\n",
        "    \n",
        "    with torch.no_grad():\n",
        "    \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "#        else:\n",
        "#            pred = trans(pred)\n",
        "#            gt = trans(gt)\n",
        "                \n",
        "        mae = torch.abs(pred - gt).mean()\n",
        "        \n",
        "    return mae.cpu().detach().numpy()\n",
        "                \n",
        "\n",
        "def eval_Smeasure(pred,gt,cuda=True):\n",
        "    \n",
        "    alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "   \n",
        "    with torch.no_grad():\n",
        "        \n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        \n",
        "        if cuda:\n",
        "            pred = pred.cuda()\n",
        "            gt   = gt.cuda()\n",
        "\n",
        "        \n",
        "        y = gt.mean()\n",
        "        \n",
        "        ##\n",
        "        if y == 0:\n",
        "            x = pred.mean()\n",
        "            Q = 1.0 - x\n",
        "        elif y == 1:\n",
        "            x = pred.mean()\n",
        "            Q = x\n",
        "        else:\n",
        "            Q = alpha * fun_S_object(pred, gt) + (1-alpha) * fun_S_region(pred, gt)\n",
        "            if Q.item() < 0:\n",
        "                Q = torch.FLoatTensor([0.0])\n",
        "                \n",
        "    return Q.item()\n",
        "\n",
        "                \n",
        "def eval_fmeasure(pred, gt, cuda=True):\n",
        "    print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "    \n",
        "    beta2 = 0.3\n",
        "    avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "    \n",
        "    ##    \n",
        "    with torch.no_grad():\n",
        "        trans = transforms.Compose([transforms.ToTensor()])\n",
        "        if cuda:\n",
        "            pred = trans(pred).cuda()\n",
        "            gt = trans(gt).cuda()\n",
        "        else:\n",
        "            pred = trans(pred)\n",
        "            gt = trans(gt)\n",
        "                \n",
        "        prec, recall = fun_eval_pr(pred, gt, 255)\n",
        "\n",
        "    return prec, recall\n",
        "              \n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        return mae,s\n",
        "        \n",
        "        #max_f = self.Eval_fmeasure()\n",
        "        #max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    \n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa5ceaa",
      "metadata": {
        "id": "1fa5ceaa"
      },
      "outputs": [],
      "source": [
        "#evaluater"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8f7b939",
      "metadata": {
        "id": "d8f7b939"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "class Eval_thread():\n",
        "    def __init__(self, loader, method, dataset, output_dir, cuda):\n",
        "        self.loader = loader\n",
        "        self.method = method\n",
        "        self.dataset = dataset\n",
        "        self.cuda = cuda\n",
        "        self.logfile = os.path.join(output_dir, 'result.txt')\n",
        "    def run(self):\n",
        "        start_time = time.time()\n",
        "        mae = self.Eval_mae()\n",
        "        s = self.Eval_Smeasure()\n",
        "        \n",
        "        \n",
        "        \n",
        "        max_f = self.Eval_fmeasure()\n",
        "        max_e = self.Eval_Emeasure()\n",
        "        \n",
        "        return mae,s,max_f,max_e\n",
        "    \n",
        "        \n",
        "        #self.LOG('{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..\\n'.format(self.dataset, self.method, mae, max_f, max_e, s))\n",
        "        #return '[cost:{:.4f}s]{} dataset with {} method get {:.4f} mae, {:.4f} max-fmeasure, {:.4f} max-Emeasure, {:.4f} S-measure..'.format(time.time()-start_time, self.dataset, self.method, mae, max_f, max_e, s)\n",
        "    \n",
        "    def Eval_mae(self):\n",
        "        #print('eval[MAE]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_mae, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                mea = torch.abs(pred - gt).mean()\n",
        "                if mea == mea: # for Nan\n",
        "                    avg_mae += mea\n",
        "                    img_num += 1.0\n",
        "            avg_mae /= img_num\n",
        "            \n",
        "            return avg_mae.item()\n",
        "    \n",
        "    def Eval_fmeasure(self):\n",
        "        print('eval[FMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        beta2 = 0.3\n",
        "        avg_p, avg_r, img_num = 0.0, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                prec, recall = self._eval_pr(pred, gt, 255)\n",
        "                avg_p += prec\n",
        "                avg_r += recall\n",
        "                img_num += 1.0\n",
        "            avg_p /= img_num\n",
        "            avg_r /= img_num\n",
        "            score = (1 + beta2) * avg_p * avg_r / (beta2 * avg_p + avg_r)\n",
        "            score[score != score] = 0 # for Nan\n",
        "            \n",
        "            return score.max().item()\n",
        "    def Eval_Emeasure(self):\n",
        "        print('eval[EMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        avg_e, img_num = 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                max_e = self._eval_e(pred, gt, 255)\n",
        "                if max_e == max_e:\n",
        "                    avg_e += max_e\n",
        "                    img_num += 1.0\n",
        "                \n",
        "            avg_e /= img_num\n",
        "            return avg_e.item()\n",
        "    def Eval_Smeasure(self):\n",
        "        #print('eval[SMeasure]:{} dataset with {} method.'.format(self.dataset, self.method))\n",
        "        alpha, avg_q, img_num = 0.5, 0.0, 0.0\n",
        "        with torch.no_grad():\n",
        "            trans = transforms.Compose([transforms.ToTensor()])\n",
        "            for pred, gt in self.loader:\n",
        "                if self.cuda:\n",
        "                    pred = trans(pred).cuda()\n",
        "                    gt = trans(gt).cuda()\n",
        "                else:\n",
        "                    pred = trans(pred)\n",
        "                    gt = trans(gt)\n",
        "                y = gt.mean()\n",
        "                if y == 0:\n",
        "                    x = pred.mean()\n",
        "                    Q = 1.0 - x\n",
        "                elif y == 1:\n",
        "                    x = pred.mean()\n",
        "                    Q = x\n",
        "                else:\n",
        "                    Q = alpha * self._S_object(pred, gt) + (1-alpha) * self._S_region(pred, gt)\n",
        "                    if Q.item() < 0:\n",
        "                        Q = torch.FLoatTensor([0.0])\n",
        "                img_num += 1.0\n",
        "                avg_q += Q.item()\n",
        "            avg_q /= img_num\n",
        "            \n",
        "            return avg_q\n",
        "    def LOG(self, output):\n",
        "        with open(self.logfile, 'a') as f:\n",
        "            f.write(output)\n",
        "\n",
        "    def _eval_e(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            score = torch.zeros(num).cuda()\n",
        "        else:\n",
        "            score = torch.zeros(num)\n",
        "        for i in range(num):\n",
        "            fm = y_pred - y_pred.mean()\n",
        "            gt = y - y.mean()\n",
        "            align_matrix = 2 * gt * fm / (gt * gt + fm * fm + 1e-20)\n",
        "            enhanced = ((align_matrix + 1) * (align_matrix + 1)) / 4\n",
        "            score[i] = torch.sum(enhanced) / (y.numel() - 1 + 1e-20)\n",
        "        return score.max()\n",
        "\n",
        "    def _eval_pr(self, y_pred, y, num):\n",
        "        if self.cuda:\n",
        "            prec, recall = torch.zeros(num).cuda(), torch.zeros(num).cuda()\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num).cuda()\n",
        "        else:\n",
        "            prec, recall = torch.zeros(num), torch.zeros(num)\n",
        "            thlist = torch.linspace(0, 1 - 1e-10, num)\n",
        "        for i in range(num):\n",
        "            y_temp = (y_pred >= thlist[i]).float()\n",
        "            tp = (y_temp * y).sum()\n",
        "            prec[i], recall[i] = tp / (y_temp.sum() + 1e-20), tp / (y.sum() + 1e-20)\n",
        "        return prec, recall\n",
        "    \n",
        "    def _S_object(self, pred, gt):\n",
        "        fg = torch.where(gt==0, torch.zeros_like(pred), pred)\n",
        "        bg = torch.where(gt==1, torch.zeros_like(pred), 1-pred)\n",
        "        o_fg = self._object(fg, gt)\n",
        "        o_bg = self._object(bg, 1-gt)\n",
        "        u = gt.mean()\n",
        "        Q = u * o_fg + (1-u) * o_bg\n",
        "        return Q\n",
        "\n",
        "    def _object(self, pred, gt):\n",
        "        temp = pred[gt == 1]\n",
        "        x = temp.mean()\n",
        "        sigma_x = temp.std()\n",
        "        score = 2.0 * x / (x * x + 1.0 + sigma_x + 1e-20)\n",
        "        \n",
        "        return score\n",
        "\n",
        "    def _S_region(self, pred, gt):\n",
        "        X, Y = self._centroid(gt)\n",
        "        gt1, gt2, gt3, gt4, w1, w2, w3, w4 = self._divideGT(gt, X, Y)\n",
        "        p1, p2, p3, p4 = self._dividePrediction(pred, X, Y)\n",
        "        Q1 = self._ssim(p1, gt1)\n",
        "        Q2 = self._ssim(p2, gt2)\n",
        "        Q3 = self._ssim(p3, gt3)\n",
        "        Q4 = self._ssim(p4, gt4)\n",
        "        Q = w1*Q1 + w2*Q2 + w3*Q3 + w4*Q4\n",
        "        # print(Q)\n",
        "        return Q\n",
        "    \n",
        "    def _centroid(self, gt):\n",
        "        rows, cols = gt.size()[-2:]\n",
        "        gt = gt.view(rows, cols)\n",
        "        if gt.sum() == 0:\n",
        "            if self.cuda:\n",
        "                X = torch.eye(1).cuda() * round(cols / 2)\n",
        "                Y = torch.eye(1).cuda() * round(rows / 2)\n",
        "            else:\n",
        "                X = torch.eye(1) * round(cols / 2)\n",
        "                Y = torch.eye(1) * round(rows / 2)\n",
        "        else:\n",
        "            total = gt.sum()\n",
        "            if self.cuda:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).cuda().float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).cuda().float()\n",
        "            else:\n",
        "                i = torch.from_numpy(np.arange(0,cols)).float()\n",
        "                j = torch.from_numpy(np.arange(0,rows)).float()\n",
        "            X = torch.round((gt.sum(dim=0)*i).sum() / total)\n",
        "            Y = torch.round((gt.sum(dim=1)*j).sum() / total)\n",
        "        return X.long(), Y.long()\n",
        "    \n",
        "    def _divideGT(self, gt, X, Y):\n",
        "        h, w = gt.size()[-2:]\n",
        "        area = h*w\n",
        "        gt = gt.view(h, w)\n",
        "        LT = gt[:Y, :X]\n",
        "        RT = gt[:Y, X:w]\n",
        "        LB = gt[Y:h, :X]\n",
        "        RB = gt[Y:h, X:w]\n",
        "        X = X.float()\n",
        "        Y = Y.float()\n",
        "        w1 = X * Y / area\n",
        "        w2 = (w - X) * Y / area\n",
        "        w3 = X * (h - Y) / area\n",
        "        w4 = 1 - w1 - w2 - w3\n",
        "        return LT, RT, LB, RB, w1, w2, w3, w4\n",
        "\n",
        "    def _dividePrediction(self, pred, X, Y):\n",
        "        h, w = pred.size()[-2:]\n",
        "        pred = pred.view(h, w)\n",
        "        LT = pred[:Y, :X]\n",
        "        RT = pred[:Y, X:w]\n",
        "        LB = pred[Y:h, :X]\n",
        "        RB = pred[Y:h, X:w]\n",
        "        return LT, RT, LB, RB\n",
        "\n",
        "    def _ssim(self, pred, gt):\n",
        "        gt = gt.float()\n",
        "        h, w = pred.size()[-2:]\n",
        "        N = h*w\n",
        "        x = pred.mean()\n",
        "        y = gt.mean()\n",
        "        sigma_x2 = ((pred - x)*(pred - x)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_y2 = ((gt - y)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        sigma_xy = ((pred - x)*(gt - y)).sum() / (N - 1 + 1e-20)\n",
        "        \n",
        "        aplha = 4 * x * y *sigma_xy\n",
        "        beta = (x*x + y*y) * (sigma_x2 + sigma_y2)\n",
        "\n",
        "        if aplha != 0:\n",
        "            Q = aplha / (beta + 1e-20)\n",
        "        elif aplha == 0 and beta == 0:\n",
        "            Q = 1.0\n",
        "        else:\n",
        "            Q = 0\n",
        "        return Q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dfe6b9bc",
      "metadata": {
        "id": "dfe6b9bc"
      },
      "outputs": [],
      "source": [
        "#options"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b9aaf3c",
      "metadata": {
        "id": "8b9aaf3c"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "def arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--epoch',       type=int,   default=30,   help='epoch number')\n",
        "  parser.add_argument('--lr',          type=float, default=1e-4,  help='learning rate')\n",
        "  parser.add_argument('--batchsize',   type=int,   default=4,    help='training batch size')\n",
        "  parser.add_argument('--trainsize',   type=int,   default=352,   help='training dataset size')\n",
        "  parser.add_argument('--clip',        type=float, default=0.5,   help='gradient clipping margin')\n",
        "  parser.add_argument('--lw',          type=float, default=0.001, help='weight')\n",
        "  parser.add_argument('--decay_rate',  type=float, default=0.1,   help='decay rate of learning rate')\n",
        "  parser.add_argument('--decay_epoch', type=int,   default=60,    help='every n epochs decay learning rate')\n",
        "  parser.add_argument('--load',        type=str,   default=None,  help='train from checkpoints')\n",
        "  parser.add_argument('--gpu_id',      type=str,   default='0',   help='train use gpu')\n",
        "\n",
        "  parser.add_argument('--rgb_label_root',      type=str, default='/content/tmp/TrainDataset/RGB/',           help='the training rgb images root')\n",
        "  parser.add_argument('--depth_label_root',    type=str, default='/content/tmp/TrainDataset/depth/',         help='the training depth images root')\n",
        "  parser.add_argument('--gt_label_root',       type=str, default='/content/tmp/TrainDataset/GT/',            help='the training gt images root')\n",
        "\n",
        "  parser.add_argument('--val_rgb_root',        type=str, default='/content/tmp/TestDataset/NJU2K/RGB/',      help='the test rgb images root')\n",
        "  parser.add_argument('--val_depth_root',      type=str, default='/content/tmp/TestDataset/NJU2K/depth/',    help='the test depth images root')\n",
        "  parser.add_argument('--val_gt_root',         type=str, default='/content/tmp/TestDataset/NJU2K/GT/',       help='the test gt images root')\n",
        "\n",
        "  parser.add_argument('--save_path',           type=str, default='/content/drive/MyDrive/Checkpoint/SPNet_new/',    help='the path to save models and logs')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = arguments()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec6f6e8f",
      "metadata": {
        "id": "ec6f6e8f"
      },
      "outputs": [],
      "source": [
        "#utils "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ff850acd",
      "metadata": {
        "id": "ff850acd"
      },
      "outputs": [],
      "source": [
        "def clip_gradient(optimizer, grad_clip):\n",
        "    for group in optimizer.param_groups:\n",
        "        for param in group['params']:\n",
        "            if param.grad is not None:\n",
        "                param.grad.data.clamp_(-grad_clip, grad_clip)\n",
        "\n",
        "\n",
        "def adjust_lr(optimizer, init_lr, epoch, decay_rate=0.1, decay_epoch=30):\n",
        "    decay = decay_rate ** (epoch // decay_epoch)\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = decay*init_lr\n",
        "        lr=param_group['lr']\n",
        "    return lr\n",
        "\n",
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        " \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ce9b3f65",
      "metadata": {
        "id": "ce9b3f65",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "3b7c5a5cb3ef4145b601609f4e982dd5",
            "b5d3f7696d814e63a5522a640c80280a",
            "416fd3d246b94a5696af4f7994204fa4",
            "ab6cfa4e80b74edf96afc7f08ff49131",
            "33e6662048cb43bd98c89ab41edf977a",
            "1cef5d09b2034f4db0e04a3dba1b7c08",
            "262c3e73ac5e4e90a6220e42b2d81c63",
            "c2b9e5a512634f0bb6bc997f2bc5de08",
            "b8466e964bb2496ea1e61160e5371709",
            "1dd241a0d46e46a095b06e98e11c9f11",
            "2eb16e12dd3e4f3dae29e1dbe1e964cf"
          ]
        },
        "outputId": "f8545f1a-6295-4430-b42c-9394c38858b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://shanghuagao.oss-cn-beijing.aliyuncs.com/res2net/res2net50_v1b_26w_4s-3cf99910.pth\" to /root/.cache/torch/hub/checkpoints/res2net50_v1b_26w_4s-3cf99910.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/98.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3b7c5a5cb3ef4145b601609f4e982dd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load data...\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset/RGB/corrupted_RGB_00.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_01.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_02.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_10.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_100.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_101.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_102.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_11.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_110.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_111.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_112.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_12.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_120.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_121.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_122.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_130.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_131.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_132.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_140.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_141.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_142.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_150.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_151.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_152.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_160.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_161.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_162.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_170.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_171.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_172.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_180.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_181.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_182.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_190.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_191.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_192.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_20.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_200.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_201.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_202.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_21.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_210.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_211.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_212.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_22.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_220.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_221.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_222.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_230.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_231.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_232.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_240.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_241.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_242.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_250.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_251.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_252.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_260.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_261.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_262.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_270.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_271.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_272.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_280.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_281.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_282.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_290.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_291.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_292.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_30.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_300.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_301.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_302.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_31.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_310.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_311.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_312.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_32.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_320.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_321.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_322.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_330.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_331.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_332.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_340.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_341.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_342.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_350.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_351.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_352.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_360.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_361.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_362.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_370.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_371.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_372.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_380.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_381.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_382.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_390.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_391.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_392.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_40.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_400.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_401.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_402.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_41.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_410.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_411.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_412.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_42.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_420.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_421.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_422.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_430.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_431.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_432.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_440.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_441.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_442.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_450.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_451.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_452.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_460.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_461.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_462.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_470.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_471.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_472.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_480.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_481.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_482.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_490.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_491.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_492.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_50.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_500.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_501.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_502.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_51.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_510.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_511.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_512.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_52.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_520.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_521.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_522.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_530.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_531.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_532.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_540.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_541.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_542.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_550.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_551.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_552.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_560.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_561.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_562.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_570.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_571.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_572.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_580.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_581.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_582.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_590.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_591.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_592.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_60.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_600.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_601.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_602.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_61.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_610.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_611.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_612.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_62.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_620.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_621.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_622.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_630.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_631.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_632.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_640.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_641.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_642.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_650.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_651.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_652.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_660.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_661.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_662.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_670.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_671.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_672.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_680.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_681.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_682.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_690.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_691.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_692.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_70.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_700.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_701.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_702.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_71.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_710.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_711.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_712.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_72.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_720.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_721.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_722.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_730.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_731.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_732.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_740.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_741.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_742.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_750.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_751.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_752.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_760.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_761.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_762.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_770.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_771.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_772.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_780.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_781.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_782.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_790.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_791.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_792.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_80.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_81.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_82.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_90.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_91.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_92.png'] ['/content/tmp/TrainDataset/GT/GT_00.png', '/content/tmp/TrainDataset/GT/GT_01.png', '/content/tmp/TrainDataset/GT/GT_02.png', '/content/tmp/TrainDataset/GT/GT_10.png', '/content/tmp/TrainDataset/GT/GT_100.png', '/content/tmp/TrainDataset/GT/GT_101.png', '/content/tmp/TrainDataset/GT/GT_102.png', '/content/tmp/TrainDataset/GT/GT_11.png', '/content/tmp/TrainDataset/GT/GT_110.png', '/content/tmp/TrainDataset/GT/GT_111.png', '/content/tmp/TrainDataset/GT/GT_112.png', '/content/tmp/TrainDataset/GT/GT_12.png', '/content/tmp/TrainDataset/GT/GT_120.png', '/content/tmp/TrainDataset/GT/GT_121.png', '/content/tmp/TrainDataset/GT/GT_122.png', '/content/tmp/TrainDataset/GT/GT_130.png', '/content/tmp/TrainDataset/GT/GT_131.png', '/content/tmp/TrainDataset/GT/GT_132.png', '/content/tmp/TrainDataset/GT/GT_140.png', '/content/tmp/TrainDataset/GT/GT_141.png', '/content/tmp/TrainDataset/GT/GT_142.png', '/content/tmp/TrainDataset/GT/GT_150.png', '/content/tmp/TrainDataset/GT/GT_151.png', '/content/tmp/TrainDataset/GT/GT_152.png', '/content/tmp/TrainDataset/GT/GT_160.png', '/content/tmp/TrainDataset/GT/GT_161.png', '/content/tmp/TrainDataset/GT/GT_162.png', '/content/tmp/TrainDataset/GT/GT_170.png', '/content/tmp/TrainDataset/GT/GT_171.png', '/content/tmp/TrainDataset/GT/GT_172.png', '/content/tmp/TrainDataset/GT/GT_180.png', '/content/tmp/TrainDataset/GT/GT_181.png', '/content/tmp/TrainDataset/GT/GT_182.png', '/content/tmp/TrainDataset/GT/GT_190.png', '/content/tmp/TrainDataset/GT/GT_191.png', '/content/tmp/TrainDataset/GT/GT_192.png', '/content/tmp/TrainDataset/GT/GT_20.png', '/content/tmp/TrainDataset/GT/GT_200.png', '/content/tmp/TrainDataset/GT/GT_201.png', '/content/tmp/TrainDataset/GT/GT_202.png', '/content/tmp/TrainDataset/GT/GT_21.png', '/content/tmp/TrainDataset/GT/GT_210.png', '/content/tmp/TrainDataset/GT/GT_211.png', '/content/tmp/TrainDataset/GT/GT_212.png', '/content/tmp/TrainDataset/GT/GT_22.png', '/content/tmp/TrainDataset/GT/GT_220.png', '/content/tmp/TrainDataset/GT/GT_221.png', '/content/tmp/TrainDataset/GT/GT_222.png', '/content/tmp/TrainDataset/GT/GT_230.png', '/content/tmp/TrainDataset/GT/GT_231.png', '/content/tmp/TrainDataset/GT/GT_232.png', '/content/tmp/TrainDataset/GT/GT_240.png', '/content/tmp/TrainDataset/GT/GT_241.png', '/content/tmp/TrainDataset/GT/GT_242.png', '/content/tmp/TrainDataset/GT/GT_250.png', '/content/tmp/TrainDataset/GT/GT_251.png', '/content/tmp/TrainDataset/GT/GT_252.png', '/content/tmp/TrainDataset/GT/GT_260.png', '/content/tmp/TrainDataset/GT/GT_261.png', '/content/tmp/TrainDataset/GT/GT_262.png', '/content/tmp/TrainDataset/GT/GT_270.png', '/content/tmp/TrainDataset/GT/GT_271.png', '/content/tmp/TrainDataset/GT/GT_272.png', '/content/tmp/TrainDataset/GT/GT_280.png', '/content/tmp/TrainDataset/GT/GT_281.png', '/content/tmp/TrainDataset/GT/GT_282.png', '/content/tmp/TrainDataset/GT/GT_290.png', '/content/tmp/TrainDataset/GT/GT_291.png', '/content/tmp/TrainDataset/GT/GT_292.png', '/content/tmp/TrainDataset/GT/GT_30.png', '/content/tmp/TrainDataset/GT/GT_300.png', '/content/tmp/TrainDataset/GT/GT_301.png', '/content/tmp/TrainDataset/GT/GT_302.png', '/content/tmp/TrainDataset/GT/GT_31.png', '/content/tmp/TrainDataset/GT/GT_310.png', '/content/tmp/TrainDataset/GT/GT_311.png', '/content/tmp/TrainDataset/GT/GT_312.png', '/content/tmp/TrainDataset/GT/GT_32.png', '/content/tmp/TrainDataset/GT/GT_320.png', '/content/tmp/TrainDataset/GT/GT_321.png', '/content/tmp/TrainDataset/GT/GT_322.png', '/content/tmp/TrainDataset/GT/GT_330.png', '/content/tmp/TrainDataset/GT/GT_331.png', '/content/tmp/TrainDataset/GT/GT_332.png', '/content/tmp/TrainDataset/GT/GT_340.png', '/content/tmp/TrainDataset/GT/GT_341.png', '/content/tmp/TrainDataset/GT/GT_342.png', '/content/tmp/TrainDataset/GT/GT_350.png', '/content/tmp/TrainDataset/GT/GT_351.png', '/content/tmp/TrainDataset/GT/GT_352.png', '/content/tmp/TrainDataset/GT/GT_360.png', '/content/tmp/TrainDataset/GT/GT_361.png', '/content/tmp/TrainDataset/GT/GT_362.png', '/content/tmp/TrainDataset/GT/GT_370.png', '/content/tmp/TrainDataset/GT/GT_371.png', '/content/tmp/TrainDataset/GT/GT_372.png', '/content/tmp/TrainDataset/GT/GT_380.png', '/content/tmp/TrainDataset/GT/GT_381.png', '/content/tmp/TrainDataset/GT/GT_382.png', '/content/tmp/TrainDataset/GT/GT_390.png', '/content/tmp/TrainDataset/GT/GT_391.png', '/content/tmp/TrainDataset/GT/GT_392.png', '/content/tmp/TrainDataset/GT/GT_40.png', '/content/tmp/TrainDataset/GT/GT_400.png', '/content/tmp/TrainDataset/GT/GT_401.png', '/content/tmp/TrainDataset/GT/GT_402.png', '/content/tmp/TrainDataset/GT/GT_41.png', '/content/tmp/TrainDataset/GT/GT_410.png', '/content/tmp/TrainDataset/GT/GT_411.png', '/content/tmp/TrainDataset/GT/GT_412.png', '/content/tmp/TrainDataset/GT/GT_42.png', '/content/tmp/TrainDataset/GT/GT_420.png', '/content/tmp/TrainDataset/GT/GT_421.png', '/content/tmp/TrainDataset/GT/GT_422.png', '/content/tmp/TrainDataset/GT/GT_430.png', '/content/tmp/TrainDataset/GT/GT_431.png', '/content/tmp/TrainDataset/GT/GT_432.png', '/content/tmp/TrainDataset/GT/GT_440.png', '/content/tmp/TrainDataset/GT/GT_441.png', '/content/tmp/TrainDataset/GT/GT_442.png', '/content/tmp/TrainDataset/GT/GT_450.png', '/content/tmp/TrainDataset/GT/GT_451.png', '/content/tmp/TrainDataset/GT/GT_452.png', '/content/tmp/TrainDataset/GT/GT_460.png', '/content/tmp/TrainDataset/GT/GT_461.png', '/content/tmp/TrainDataset/GT/GT_462.png', '/content/tmp/TrainDataset/GT/GT_470.png', '/content/tmp/TrainDataset/GT/GT_471.png', '/content/tmp/TrainDataset/GT/GT_472.png', '/content/tmp/TrainDataset/GT/GT_480.png', '/content/tmp/TrainDataset/GT/GT_481.png', '/content/tmp/TrainDataset/GT/GT_482.png', '/content/tmp/TrainDataset/GT/GT_490.png', '/content/tmp/TrainDataset/GT/GT_491.png', '/content/tmp/TrainDataset/GT/GT_492.png', '/content/tmp/TrainDataset/GT/GT_50.png', '/content/tmp/TrainDataset/GT/GT_500.png', '/content/tmp/TrainDataset/GT/GT_501.png', '/content/tmp/TrainDataset/GT/GT_502.png', '/content/tmp/TrainDataset/GT/GT_51.png', '/content/tmp/TrainDataset/GT/GT_510.png', '/content/tmp/TrainDataset/GT/GT_511.png', '/content/tmp/TrainDataset/GT/GT_512.png', '/content/tmp/TrainDataset/GT/GT_52.png', '/content/tmp/TrainDataset/GT/GT_520.png', '/content/tmp/TrainDataset/GT/GT_521.png', '/content/tmp/TrainDataset/GT/GT_522.png', '/content/tmp/TrainDataset/GT/GT_530.png', '/content/tmp/TrainDataset/GT/GT_531.png', '/content/tmp/TrainDataset/GT/GT_532.png', '/content/tmp/TrainDataset/GT/GT_540.png', '/content/tmp/TrainDataset/GT/GT_541.png', '/content/tmp/TrainDataset/GT/GT_542.png', '/content/tmp/TrainDataset/GT/GT_550.png', '/content/tmp/TrainDataset/GT/GT_551.png', '/content/tmp/TrainDataset/GT/GT_552.png', '/content/tmp/TrainDataset/GT/GT_560.png', '/content/tmp/TrainDataset/GT/GT_561.png', '/content/tmp/TrainDataset/GT/GT_562.png', '/content/tmp/TrainDataset/GT/GT_570.png', '/content/tmp/TrainDataset/GT/GT_571.png', '/content/tmp/TrainDataset/GT/GT_572.png', '/content/tmp/TrainDataset/GT/GT_580.png', '/content/tmp/TrainDataset/GT/GT_581.png', '/content/tmp/TrainDataset/GT/GT_582.png', '/content/tmp/TrainDataset/GT/GT_590.png', '/content/tmp/TrainDataset/GT/GT_591.png', '/content/tmp/TrainDataset/GT/GT_592.png', '/content/tmp/TrainDataset/GT/GT_60.png', '/content/tmp/TrainDataset/GT/GT_600.png', '/content/tmp/TrainDataset/GT/GT_601.png', '/content/tmp/TrainDataset/GT/GT_602.png', '/content/tmp/TrainDataset/GT/GT_61.png', '/content/tmp/TrainDataset/GT/GT_610.png', '/content/tmp/TrainDataset/GT/GT_611.png', '/content/tmp/TrainDataset/GT/GT_612.png', '/content/tmp/TrainDataset/GT/GT_62.png', '/content/tmp/TrainDataset/GT/GT_620.png', '/content/tmp/TrainDataset/GT/GT_621.png', '/content/tmp/TrainDataset/GT/GT_622.png', '/content/tmp/TrainDataset/GT/GT_630.png', '/content/tmp/TrainDataset/GT/GT_631.png', '/content/tmp/TrainDataset/GT/GT_632.png', '/content/tmp/TrainDataset/GT/GT_640.png', '/content/tmp/TrainDataset/GT/GT_641.png', '/content/tmp/TrainDataset/GT/GT_642.png', '/content/tmp/TrainDataset/GT/GT_650.png', '/content/tmp/TrainDataset/GT/GT_651.png', '/content/tmp/TrainDataset/GT/GT_652.png', '/content/tmp/TrainDataset/GT/GT_660.png', '/content/tmp/TrainDataset/GT/GT_661.png', '/content/tmp/TrainDataset/GT/GT_662.png', '/content/tmp/TrainDataset/GT/GT_670.png', '/content/tmp/TrainDataset/GT/GT_671.png', '/content/tmp/TrainDataset/GT/GT_672.png', '/content/tmp/TrainDataset/GT/GT_680.png', '/content/tmp/TrainDataset/GT/GT_681.png', '/content/tmp/TrainDataset/GT/GT_682.png', '/content/tmp/TrainDataset/GT/GT_690.png', '/content/tmp/TrainDataset/GT/GT_691.png', '/content/tmp/TrainDataset/GT/GT_692.png', '/content/tmp/TrainDataset/GT/GT_70.png', '/content/tmp/TrainDataset/GT/GT_700.png', '/content/tmp/TrainDataset/GT/GT_701.png', '/content/tmp/TrainDataset/GT/GT_702.png', '/content/tmp/TrainDataset/GT/GT_71.png', '/content/tmp/TrainDataset/GT/GT_710.png', '/content/tmp/TrainDataset/GT/GT_711.png', '/content/tmp/TrainDataset/GT/GT_712.png', '/content/tmp/TrainDataset/GT/GT_72.png', '/content/tmp/TrainDataset/GT/GT_720.png', '/content/tmp/TrainDataset/GT/GT_721.png', '/content/tmp/TrainDataset/GT/GT_722.png', '/content/tmp/TrainDataset/GT/GT_730.png', '/content/tmp/TrainDataset/GT/GT_731.png', '/content/tmp/TrainDataset/GT/GT_732.png', '/content/tmp/TrainDataset/GT/GT_740.png', '/content/tmp/TrainDataset/GT/GT_741.png', '/content/tmp/TrainDataset/GT/GT_742.png', '/content/tmp/TrainDataset/GT/GT_750.png', '/content/tmp/TrainDataset/GT/GT_751.png', '/content/tmp/TrainDataset/GT/GT_752.png', '/content/tmp/TrainDataset/GT/GT_760.png', '/content/tmp/TrainDataset/GT/GT_761.png', '/content/tmp/TrainDataset/GT/GT_762.png', '/content/tmp/TrainDataset/GT/GT_770.png', '/content/tmp/TrainDataset/GT/GT_771.png', '/content/tmp/TrainDataset/GT/GT_772.png', '/content/tmp/TrainDataset/GT/GT_780.png', '/content/tmp/TrainDataset/GT/GT_781.png', '/content/tmp/TrainDataset/GT/GT_782.png', '/content/tmp/TrainDataset/GT/GT_790.png', '/content/tmp/TrainDataset/GT/GT_791.png', '/content/tmp/TrainDataset/GT/GT_792.png', '/content/tmp/TrainDataset/GT/GT_80.png', '/content/tmp/TrainDataset/GT/GT_81.png', '/content/tmp/TrainDataset/GT/GT_82.png', '/content/tmp/TrainDataset/GT/GT_90.png', '/content/tmp/TrainDataset/GT/GT_91.png', '/content/tmp/TrainDataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7f1a6a433ed0>\n",
            "60\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-02 15:50:18.516760 Epoch [001/030], Step [0001/0060], Loss1: 0.5872 Loss2: 0.3054 Loss3: 0.3426\n",
            "2022-06-02 15:50:40.657802 Epoch [001/030], Step [0050/0060], Loss1: 0.2195 Loss2: 0.1271 Loss3: 0.1219\n",
            "2022-06-02 15:50:45.088289 Epoch [001/030], Step [0060/0060], Loss1: 0.1822 Loss2: 0.1187 Loss3: 0.1093\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.3497211851897064 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-02 15:50:54.604456 Epoch [002/030], Step [0001/0060], Loss1: 0.1578 Loss2: 0.1116 Loss3: 0.0932\n",
            "2022-06-02 15:51:16.493599 Epoch [002/030], Step [0050/0060], Loss1: 0.1076 Loss2: 0.0916 Loss3: 0.0781\n",
            "2022-06-02 15:51:20.924829 Epoch [002/030], Step [0060/0060], Loss1: 0.0979 Loss2: 0.0843 Loss3: 0.0744\n",
            "Epoch: 2 MAE: 0.31160939130833537 ####  bestMAE: 0.3497211851897064 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-02 15:51:29.376212 Epoch [003/030], Step [0001/0060], Loss1: 0.1057 Loss2: 0.0932 Loss3: 0.0765\n",
            "2022-06-02 15:51:51.242801 Epoch [003/030], Step [0050/0060], Loss1: 0.0865 Loss2: 0.0793 Loss3: 0.0632\n",
            "2022-06-02 15:51:55.672847 Epoch [003/030], Step [0060/0060], Loss1: 0.0857 Loss2: 0.0749 Loss3: 0.0608\n",
            "Epoch: 3 MAE: 0.32960042559911346 ####  bestMAE: 0.31160939130833537 bestEpoch: 2\n",
            "2022-06-02 15:52:01.789768 Epoch [004/030], Step [0001/0060], Loss1: 0.0992 Loss2: 0.0822 Loss3: 0.0718\n",
            "2022-06-02 15:52:23.574369 Epoch [004/030], Step [0050/0060], Loss1: 0.0945 Loss2: 0.0680 Loss3: 0.0559\n",
            "2022-06-02 15:52:28.024080 Epoch [004/030], Step [0060/0060], Loss1: 0.0718 Loss2: 0.0690 Loss3: 0.0640\n",
            "Epoch: 4 MAE: 0.31195925919467177 ####  bestMAE: 0.31160939130833537 bestEpoch: 2\n",
            "2022-06-02 15:52:33.957624 Epoch [005/030], Step [0001/0060], Loss1: 0.0755 Loss2: 0.0694 Loss3: 0.0565\n",
            "2022-06-02 15:52:55.791444 Epoch [005/030], Step [0050/0060], Loss1: 0.0706 Loss2: 0.0578 Loss3: 0.0506\n",
            "2022-06-02 15:53:00.207104 Epoch [005/030], Step [0060/0060], Loss1: 0.0653 Loss2: 0.0610 Loss3: 0.0514\n",
            "Epoch: 5 MAE: 0.3113510329635056 ####  bestMAE: 0.31160939130833537 bestEpoch: 2\n",
            "best epoch:5\n",
            "2022-06-02 15:53:12.851669 Epoch [006/030], Step [0001/0060], Loss1: 0.0589 Loss2: 0.0575 Loss3: 0.0495\n",
            "2022-06-02 15:53:34.838935 Epoch [006/030], Step [0050/0060], Loss1: 0.0620 Loss2: 0.0582 Loss3: 0.0512\n",
            "2022-06-02 15:53:39.330077 Epoch [006/030], Step [0060/0060], Loss1: 0.0626 Loss2: 0.0548 Loss3: 0.0470\n",
            "Epoch: 6 MAE: 0.30825240725562697 ####  bestMAE: 0.3113510329635056 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-06-02 15:53:47.840299 Epoch [007/030], Step [0001/0060], Loss1: 0.0607 Loss2: 0.0545 Loss3: 0.0466\n",
            "2022-06-02 15:54:09.811908 Epoch [007/030], Step [0050/0060], Loss1: 0.0495 Loss2: 0.0486 Loss3: 0.0435\n",
            "2022-06-02 15:54:14.258643 Epoch [007/030], Step [0060/0060], Loss1: 0.0589 Loss2: 0.0531 Loss3: 0.0452\n",
            "Epoch: 7 MAE: 0.3037189895387679 ####  bestMAE: 0.30825240725562697 bestEpoch: 6\n",
            "best epoch:7\n",
            "2022-06-02 15:54:22.786678 Epoch [008/030], Step [0001/0060], Loss1: 0.0526 Loss2: 0.0497 Loss3: 0.0449\n",
            "2022-06-02 15:54:44.689079 Epoch [008/030], Step [0050/0060], Loss1: 0.0632 Loss2: 0.0498 Loss3: 0.0440\n",
            "2022-06-02 15:54:49.104247 Epoch [008/030], Step [0060/0060], Loss1: 0.0453 Loss2: 0.0473 Loss3: 0.0405\n",
            "Epoch: 8 MAE: 0.309086591528837 ####  bestMAE: 0.3037189895387679 bestEpoch: 7\n",
            "2022-06-02 15:54:54.990177 Epoch [009/030], Step [0001/0060], Loss1: 0.0501 Loss2: 0.0444 Loss3: 0.0398\n",
            "2022-06-02 15:55:16.710944 Epoch [009/030], Step [0050/0060], Loss1: 0.0448 Loss2: 0.0433 Loss3: 0.0375\n",
            "2022-06-02 15:55:21.139856 Epoch [009/030], Step [0060/0060], Loss1: 0.0504 Loss2: 0.0406 Loss3: 0.0372\n",
            "Epoch: 9 MAE: 0.30489207111338457 ####  bestMAE: 0.3037189895387679 bestEpoch: 7\n",
            "2022-06-02 15:55:27.134596 Epoch [010/030], Step [0001/0060], Loss1: 0.0505 Loss2: 0.0426 Loss3: 0.0377\n",
            "2022-06-02 15:55:48.854142 Epoch [010/030], Step [0050/0060], Loss1: 0.0403 Loss2: 0.0426 Loss3: 0.0365\n",
            "2022-06-02 15:55:53.280845 Epoch [010/030], Step [0060/0060], Loss1: 0.0471 Loss2: 0.0381 Loss3: 0.0351\n",
            "Epoch: 10 MAE: 0.29910425499002785 ####  bestMAE: 0.3037189895387679 bestEpoch: 7\n",
            "best epoch:10\n",
            "2022-06-02 15:56:04.238931 Epoch [011/030], Step [0001/0060], Loss1: 0.0508 Loss2: 0.0389 Loss3: 0.0365\n",
            "2022-06-02 15:56:26.130498 Epoch [011/030], Step [0050/0060], Loss1: 0.0439 Loss2: 0.0388 Loss3: 0.0348\n",
            "2022-06-02 15:56:30.579603 Epoch [011/030], Step [0060/0060], Loss1: 0.0432 Loss2: 0.0357 Loss3: 0.0333\n",
            "Epoch: 11 MAE: 0.3021404314798023 ####  bestMAE: 0.29910425499002785 bestEpoch: 10\n",
            "2022-06-02 15:56:37.012190 Epoch [012/030], Step [0001/0060], Loss1: 0.0582 Loss2: 0.0413 Loss3: 0.0397\n",
            "2022-06-02 15:56:58.809607 Epoch [012/030], Step [0050/0060], Loss1: 0.0514 Loss2: 0.0385 Loss3: 0.0369\n",
            "2022-06-02 15:57:03.252754 Epoch [012/030], Step [0060/0060], Loss1: 0.0452 Loss2: 0.0386 Loss3: 0.0328\n",
            "Epoch: 12 MAE: 0.30193724818961326 ####  bestMAE: 0.29910425499002785 bestEpoch: 10\n",
            "2022-06-02 15:57:09.217342 Epoch [013/030], Step [0001/0060], Loss1: 0.0382 Loss2: 0.0352 Loss3: 0.0307\n",
            "2022-06-02 15:57:30.965978 Epoch [013/030], Step [0050/0060], Loss1: 0.0496 Loss2: 0.0352 Loss3: 0.0324\n",
            "2022-06-02 15:57:35.397455 Epoch [013/030], Step [0060/0060], Loss1: 0.0473 Loss2: 0.0344 Loss3: 0.0322\n",
            "Epoch: 13 MAE: 0.30878529987637965 ####  bestMAE: 0.29910425499002785 bestEpoch: 10\n",
            "2022-06-02 15:57:41.449499 Epoch [014/030], Step [0001/0060], Loss1: 0.0367 Loss2: 0.0321 Loss3: 0.0282\n",
            "2022-06-02 15:58:03.222352 Epoch [014/030], Step [0050/0060], Loss1: 0.0427 Loss2: 0.0317 Loss3: 0.0299\n",
            "2022-06-02 15:58:07.646091 Epoch [014/030], Step [0060/0060], Loss1: 0.0361 Loss2: 0.0300 Loss3: 0.0284\n",
            "Epoch: 14 MAE: 0.2953326036564257 ####  bestMAE: 0.29910425499002785 bestEpoch: 10\n",
            "best epoch:14\n",
            "2022-06-02 15:58:16.150871 Epoch [015/030], Step [0001/0060], Loss1: 0.0405 Loss2: 0.0327 Loss3: 0.0272\n",
            "2022-06-02 15:58:38.028030 Epoch [015/030], Step [0050/0060], Loss1: 0.0370 Loss2: 0.0283 Loss3: 0.0265\n",
            "2022-06-02 15:58:42.468051 Epoch [015/030], Step [0060/0060], Loss1: 0.0314 Loss2: 0.0289 Loss3: 0.0251\n",
            "Epoch: 15 MAE: 0.29520742951246814 ####  bestMAE: 0.2953326036564257 bestEpoch: 14\n",
            "best epoch:15\n",
            "2022-06-02 15:58:53.286004 Epoch [016/030], Step [0001/0060], Loss1: 0.0316 Loss2: 0.0272 Loss3: 0.0243\n",
            "2022-06-02 15:59:15.188648 Epoch [016/030], Step [0050/0060], Loss1: 0.0416 Loss2: 0.0327 Loss3: 0.0304\n",
            "2022-06-02 15:59:19.659143 Epoch [016/030], Step [0060/0060], Loss1: 0.0306 Loss2: 0.0269 Loss3: 0.0240\n",
            "Epoch: 16 MAE: 0.2921371546750346 ####  bestMAE: 0.29520742951246814 bestEpoch: 15\n",
            "best epoch:16\n",
            "2022-06-02 15:59:28.678768 Epoch [017/030], Step [0001/0060], Loss1: 0.0377 Loss2: 0.0262 Loss3: 0.0256\n",
            "2022-06-02 15:59:50.583575 Epoch [017/030], Step [0050/0060], Loss1: 0.0329 Loss2: 0.0315 Loss3: 0.0274\n",
            "2022-06-02 15:59:55.067395 Epoch [017/030], Step [0060/0060], Loss1: 0.0314 Loss2: 0.0251 Loss3: 0.0225\n",
            "Epoch: 17 MAE: 0.2969982760797733 ####  bestMAE: 0.2921371546750346 bestEpoch: 16\n",
            "2022-06-02 16:00:00.983360 Epoch [018/030], Step [0001/0060], Loss1: 0.0313 Loss2: 0.0237 Loss3: 0.0229\n",
            "2022-06-02 16:00:22.785495 Epoch [018/030], Step [0050/0060], Loss1: 0.0313 Loss2: 0.0253 Loss3: 0.0234\n",
            "2022-06-02 16:00:27.240817 Epoch [018/030], Step [0060/0060], Loss1: 0.0339 Loss2: 0.0260 Loss3: 0.0230\n",
            "Epoch: 18 MAE: 0.2931558905707466 ####  bestMAE: 0.2921371546750346 bestEpoch: 16\n",
            "2022-06-02 16:00:33.172915 Epoch [019/030], Step [0001/0060], Loss1: 0.0394 Loss2: 0.0287 Loss3: 0.0284\n",
            "2022-06-02 16:00:54.924942 Epoch [019/030], Step [0050/0060], Loss1: 0.0302 Loss2: 0.0229 Loss3: 0.0218\n",
            "2022-06-02 16:00:59.355769 Epoch [019/030], Step [0060/0060], Loss1: 0.0297 Loss2: 0.0234 Loss3: 0.0222\n",
            "Epoch: 19 MAE: 0.2901261102585565 ####  bestMAE: 0.2921371546750346 bestEpoch: 16\n",
            "best epoch:19\n",
            "2022-06-02 16:01:07.991976 Epoch [020/030], Step [0001/0060], Loss1: 0.0279 Loss2: 0.0249 Loss3: 0.0233\n",
            "2022-06-02 16:01:30.048027 Epoch [020/030], Step [0050/0060], Loss1: 0.0288 Loss2: 0.0225 Loss3: 0.0207\n",
            "2022-06-02 16:01:34.509092 Epoch [020/030], Step [0060/0060], Loss1: 0.0301 Loss2: 0.0224 Loss3: 0.0207\n",
            "Epoch: 20 MAE: 0.29189044165232814 ####  bestMAE: 0.2901261102585565 bestEpoch: 19\n",
            "2022-06-02 16:01:43.127050 Epoch [021/030], Step [0001/0060], Loss1: 0.0342 Loss2: 0.0279 Loss3: 0.0262\n",
            "2022-06-02 16:02:05.166776 Epoch [021/030], Step [0050/0060], Loss1: 0.0316 Loss2: 0.0241 Loss3: 0.0235\n",
            "2022-06-02 16:02:09.584306 Epoch [021/030], Step [0060/0060], Loss1: 0.0333 Loss2: 0.0235 Loss3: 0.0225\n",
            "Epoch: 21 MAE: 0.2937668181727172 ####  bestMAE: 0.2901261102585565 bestEpoch: 19\n",
            "2022-06-02 16:02:15.634433 Epoch [022/030], Step [0001/0060], Loss1: 0.0301 Loss2: 0.0229 Loss3: 0.0231\n",
            "2022-06-02 16:02:37.451284 Epoch [022/030], Step [0050/0060], Loss1: 0.0264 Loss2: 0.0209 Loss3: 0.0193\n",
            "2022-06-02 16:02:41.880703 Epoch [022/030], Step [0060/0060], Loss1: 0.0309 Loss2: 0.0236 Loss3: 0.0225\n",
            "Epoch: 22 MAE: 0.28728217069434114 ####  bestMAE: 0.2901261102585565 bestEpoch: 19\n",
            "best epoch:22\n",
            "2022-06-02 16:02:50.544481 Epoch [023/030], Step [0001/0060], Loss1: 0.0333 Loss2: 0.0216 Loss3: 0.0200\n",
            "2022-06-02 16:03:12.371292 Epoch [023/030], Step [0050/0060], Loss1: 0.0227 Loss2: 0.0196 Loss3: 0.0181\n",
            "2022-06-02 16:03:16.816943 Epoch [023/030], Step [0060/0060], Loss1: 0.0255 Loss2: 0.0206 Loss3: 0.0180\n",
            "Epoch: 23 MAE: 0.2899511722786717 ####  bestMAE: 0.28728217069434114 bestEpoch: 22\n",
            "2022-06-02 16:03:22.740916 Epoch [024/030], Step [0001/0060], Loss1: 0.0298 Loss2: 0.0230 Loss3: 0.0215\n",
            "2022-06-02 16:03:44.497010 Epoch [024/030], Step [0050/0060], Loss1: 0.0262 Loss2: 0.0199 Loss3: 0.0193\n",
            "2022-06-02 16:03:48.930171 Epoch [024/030], Step [0060/0060], Loss1: 0.0248 Loss2: 0.0203 Loss3: 0.0189\n",
            "Epoch: 24 MAE: 0.28281646889984285 ####  bestMAE: 0.28728217069434114 bestEpoch: 22\n",
            "best epoch:24\n",
            "2022-06-02 16:03:57.451073 Epoch [025/030], Step [0001/0060], Loss1: 0.0252 Loss2: 0.0185 Loss3: 0.0177\n",
            "2022-06-02 16:04:19.531368 Epoch [025/030], Step [0050/0060], Loss1: 0.0280 Loss2: 0.0198 Loss3: 0.0187\n",
            "2022-06-02 16:04:23.968788 Epoch [025/030], Step [0060/0060], Loss1: 0.0238 Loss2: 0.0185 Loss3: 0.0177\n",
            "Epoch: 25 MAE: 0.2852347092401413 ####  bestMAE: 0.28281646889984285 bestEpoch: 24\n",
            "2022-06-02 16:04:32.479162 Epoch [026/030], Step [0001/0060], Loss1: 0.0320 Loss2: 0.0195 Loss3: 0.0186\n",
            "2022-06-02 16:04:54.233311 Epoch [026/030], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0184 Loss3: 0.0172\n",
            "2022-06-02 16:04:58.643377 Epoch [026/030], Step [0060/0060], Loss1: 0.0222 Loss2: 0.0179 Loss3: 0.0182\n",
            "Epoch: 26 MAE: 0.28260154360816603 ####  bestMAE: 0.28281646889984285 bestEpoch: 24\n",
            "best epoch:26\n",
            "2022-06-02 16:05:07.027605 Epoch [027/030], Step [0001/0060], Loss1: 0.0309 Loss2: 0.0228 Loss3: 0.0208\n",
            "2022-06-02 16:05:28.738667 Epoch [027/030], Step [0050/0060], Loss1: 0.0252 Loss2: 0.0172 Loss3: 0.0169\n",
            "2022-06-02 16:05:33.155224 Epoch [027/030], Step [0060/0060], Loss1: 0.0283 Loss2: 0.0214 Loss3: 0.0195\n",
            "Epoch: 27 MAE: 0.27737309410458516 ####  bestMAE: 0.28260154360816603 bestEpoch: 26\n",
            "best epoch:27\n",
            "2022-06-02 16:05:41.708074 Epoch [028/030], Step [0001/0060], Loss1: 0.0285 Loss2: 0.0169 Loss3: 0.0179\n",
            "2022-06-02 16:06:03.473433 Epoch [028/030], Step [0050/0060], Loss1: 0.0296 Loss2: 0.0167 Loss3: 0.0169\n",
            "2022-06-02 16:06:07.889839 Epoch [028/030], Step [0060/0060], Loss1: 0.0252 Loss2: 0.0176 Loss3: 0.0165\n",
            "Epoch: 28 MAE: 0.2785957465600715 ####  bestMAE: 0.27737309410458516 bestEpoch: 27\n",
            "2022-06-02 16:06:13.809823 Epoch [029/030], Step [0001/0060], Loss1: 0.0219 Loss2: 0.0162 Loss3: 0.0145\n",
            "2022-06-02 16:06:35.703813 Epoch [029/030], Step [0050/0060], Loss1: 0.0274 Loss2: 0.0202 Loss3: 0.0217\n",
            "2022-06-02 16:06:40.254488 Epoch [029/030], Step [0060/0060], Loss1: 0.0197 Loss2: 0.0165 Loss3: 0.0155\n",
            "Epoch: 29 MAE: 0.2786909452569548 ####  bestMAE: 0.27737309410458516 bestEpoch: 27\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.MSELoss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = CE(pre_res[0], gts) \n",
        "            loss2    = CE(pre_res[1], gts)\n",
        "            loss3    = CE(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_MSE_Loss_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.MSELoss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "print(len(train_loader))\n",
        "\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(pre_res[0], gts) \n",
        "            loss2    = fun_ssim(pre_res[1], gts)\n",
        "            loss3    = fun_ssim(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_SSIM_Loss_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJC-ZSpcG9mS",
        "outputId": "f97a1b40-a2c3-4ece-bbf8-7488aeb29e96"
      },
      "id": "PJC-ZSpcG9mS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset/RGB/corrupted_RGB_00.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_01.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_02.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_10.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_100.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_101.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_102.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_11.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_110.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_111.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_112.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_12.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_120.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_121.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_122.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_130.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_131.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_132.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_140.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_141.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_142.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_150.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_151.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_152.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_160.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_161.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_162.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_170.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_171.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_172.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_180.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_181.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_182.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_190.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_191.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_192.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_20.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_200.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_201.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_202.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_21.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_210.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_211.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_212.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_22.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_220.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_221.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_222.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_230.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_231.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_232.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_240.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_241.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_242.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_250.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_251.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_252.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_260.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_261.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_262.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_270.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_271.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_272.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_280.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_281.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_282.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_290.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_291.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_292.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_30.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_300.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_301.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_302.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_31.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_310.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_311.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_312.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_32.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_320.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_321.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_322.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_330.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_331.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_332.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_340.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_341.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_342.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_350.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_351.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_352.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_360.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_361.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_362.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_370.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_371.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_372.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_380.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_381.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_382.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_390.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_391.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_392.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_40.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_400.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_401.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_402.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_41.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_410.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_411.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_412.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_42.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_420.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_421.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_422.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_430.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_431.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_432.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_440.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_441.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_442.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_450.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_451.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_452.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_460.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_461.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_462.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_470.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_471.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_472.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_480.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_481.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_482.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_490.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_491.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_492.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_50.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_500.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_501.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_502.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_51.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_510.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_511.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_512.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_52.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_520.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_521.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_522.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_530.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_531.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_532.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_540.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_541.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_542.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_550.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_551.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_552.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_560.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_561.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_562.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_570.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_571.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_572.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_580.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_581.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_582.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_590.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_591.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_592.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_60.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_600.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_601.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_602.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_61.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_610.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_611.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_612.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_62.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_620.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_621.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_622.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_630.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_631.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_632.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_640.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_641.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_642.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_650.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_651.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_652.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_660.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_661.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_662.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_670.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_671.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_672.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_680.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_681.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_682.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_690.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_691.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_692.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_70.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_700.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_701.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_702.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_71.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_710.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_711.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_712.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_72.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_720.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_721.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_722.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_730.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_731.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_732.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_740.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_741.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_742.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_750.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_751.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_752.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_760.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_761.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_762.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_770.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_771.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_772.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_780.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_781.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_782.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_790.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_791.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_792.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_80.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_81.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_82.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_90.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_91.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_92.png'] ['/content/tmp/TrainDataset/GT/GT_00.png', '/content/tmp/TrainDataset/GT/GT_01.png', '/content/tmp/TrainDataset/GT/GT_02.png', '/content/tmp/TrainDataset/GT/GT_10.png', '/content/tmp/TrainDataset/GT/GT_100.png', '/content/tmp/TrainDataset/GT/GT_101.png', '/content/tmp/TrainDataset/GT/GT_102.png', '/content/tmp/TrainDataset/GT/GT_11.png', '/content/tmp/TrainDataset/GT/GT_110.png', '/content/tmp/TrainDataset/GT/GT_111.png', '/content/tmp/TrainDataset/GT/GT_112.png', '/content/tmp/TrainDataset/GT/GT_12.png', '/content/tmp/TrainDataset/GT/GT_120.png', '/content/tmp/TrainDataset/GT/GT_121.png', '/content/tmp/TrainDataset/GT/GT_122.png', '/content/tmp/TrainDataset/GT/GT_130.png', '/content/tmp/TrainDataset/GT/GT_131.png', '/content/tmp/TrainDataset/GT/GT_132.png', '/content/tmp/TrainDataset/GT/GT_140.png', '/content/tmp/TrainDataset/GT/GT_141.png', '/content/tmp/TrainDataset/GT/GT_142.png', '/content/tmp/TrainDataset/GT/GT_150.png', '/content/tmp/TrainDataset/GT/GT_151.png', '/content/tmp/TrainDataset/GT/GT_152.png', '/content/tmp/TrainDataset/GT/GT_160.png', '/content/tmp/TrainDataset/GT/GT_161.png', '/content/tmp/TrainDataset/GT/GT_162.png', '/content/tmp/TrainDataset/GT/GT_170.png', '/content/tmp/TrainDataset/GT/GT_171.png', '/content/tmp/TrainDataset/GT/GT_172.png', '/content/tmp/TrainDataset/GT/GT_180.png', '/content/tmp/TrainDataset/GT/GT_181.png', '/content/tmp/TrainDataset/GT/GT_182.png', '/content/tmp/TrainDataset/GT/GT_190.png', '/content/tmp/TrainDataset/GT/GT_191.png', '/content/tmp/TrainDataset/GT/GT_192.png', '/content/tmp/TrainDataset/GT/GT_20.png', '/content/tmp/TrainDataset/GT/GT_200.png', '/content/tmp/TrainDataset/GT/GT_201.png', '/content/tmp/TrainDataset/GT/GT_202.png', '/content/tmp/TrainDataset/GT/GT_21.png', '/content/tmp/TrainDataset/GT/GT_210.png', '/content/tmp/TrainDataset/GT/GT_211.png', '/content/tmp/TrainDataset/GT/GT_212.png', '/content/tmp/TrainDataset/GT/GT_22.png', '/content/tmp/TrainDataset/GT/GT_220.png', '/content/tmp/TrainDataset/GT/GT_221.png', '/content/tmp/TrainDataset/GT/GT_222.png', '/content/tmp/TrainDataset/GT/GT_230.png', '/content/tmp/TrainDataset/GT/GT_231.png', '/content/tmp/TrainDataset/GT/GT_232.png', '/content/tmp/TrainDataset/GT/GT_240.png', '/content/tmp/TrainDataset/GT/GT_241.png', '/content/tmp/TrainDataset/GT/GT_242.png', '/content/tmp/TrainDataset/GT/GT_250.png', '/content/tmp/TrainDataset/GT/GT_251.png', '/content/tmp/TrainDataset/GT/GT_252.png', '/content/tmp/TrainDataset/GT/GT_260.png', '/content/tmp/TrainDataset/GT/GT_261.png', '/content/tmp/TrainDataset/GT/GT_262.png', '/content/tmp/TrainDataset/GT/GT_270.png', '/content/tmp/TrainDataset/GT/GT_271.png', '/content/tmp/TrainDataset/GT/GT_272.png', '/content/tmp/TrainDataset/GT/GT_280.png', '/content/tmp/TrainDataset/GT/GT_281.png', '/content/tmp/TrainDataset/GT/GT_282.png', '/content/tmp/TrainDataset/GT/GT_290.png', '/content/tmp/TrainDataset/GT/GT_291.png', '/content/tmp/TrainDataset/GT/GT_292.png', '/content/tmp/TrainDataset/GT/GT_30.png', '/content/tmp/TrainDataset/GT/GT_300.png', '/content/tmp/TrainDataset/GT/GT_301.png', '/content/tmp/TrainDataset/GT/GT_302.png', '/content/tmp/TrainDataset/GT/GT_31.png', '/content/tmp/TrainDataset/GT/GT_310.png', '/content/tmp/TrainDataset/GT/GT_311.png', '/content/tmp/TrainDataset/GT/GT_312.png', '/content/tmp/TrainDataset/GT/GT_32.png', '/content/tmp/TrainDataset/GT/GT_320.png', '/content/tmp/TrainDataset/GT/GT_321.png', '/content/tmp/TrainDataset/GT/GT_322.png', '/content/tmp/TrainDataset/GT/GT_330.png', '/content/tmp/TrainDataset/GT/GT_331.png', '/content/tmp/TrainDataset/GT/GT_332.png', '/content/tmp/TrainDataset/GT/GT_340.png', '/content/tmp/TrainDataset/GT/GT_341.png', '/content/tmp/TrainDataset/GT/GT_342.png', '/content/tmp/TrainDataset/GT/GT_350.png', '/content/tmp/TrainDataset/GT/GT_351.png', '/content/tmp/TrainDataset/GT/GT_352.png', '/content/tmp/TrainDataset/GT/GT_360.png', '/content/tmp/TrainDataset/GT/GT_361.png', '/content/tmp/TrainDataset/GT/GT_362.png', '/content/tmp/TrainDataset/GT/GT_370.png', '/content/tmp/TrainDataset/GT/GT_371.png', '/content/tmp/TrainDataset/GT/GT_372.png', '/content/tmp/TrainDataset/GT/GT_380.png', '/content/tmp/TrainDataset/GT/GT_381.png', '/content/tmp/TrainDataset/GT/GT_382.png', '/content/tmp/TrainDataset/GT/GT_390.png', '/content/tmp/TrainDataset/GT/GT_391.png', '/content/tmp/TrainDataset/GT/GT_392.png', '/content/tmp/TrainDataset/GT/GT_40.png', '/content/tmp/TrainDataset/GT/GT_400.png', '/content/tmp/TrainDataset/GT/GT_401.png', '/content/tmp/TrainDataset/GT/GT_402.png', '/content/tmp/TrainDataset/GT/GT_41.png', '/content/tmp/TrainDataset/GT/GT_410.png', '/content/tmp/TrainDataset/GT/GT_411.png', '/content/tmp/TrainDataset/GT/GT_412.png', '/content/tmp/TrainDataset/GT/GT_42.png', '/content/tmp/TrainDataset/GT/GT_420.png', '/content/tmp/TrainDataset/GT/GT_421.png', '/content/tmp/TrainDataset/GT/GT_422.png', '/content/tmp/TrainDataset/GT/GT_430.png', '/content/tmp/TrainDataset/GT/GT_431.png', '/content/tmp/TrainDataset/GT/GT_432.png', '/content/tmp/TrainDataset/GT/GT_440.png', '/content/tmp/TrainDataset/GT/GT_441.png', '/content/tmp/TrainDataset/GT/GT_442.png', '/content/tmp/TrainDataset/GT/GT_450.png', '/content/tmp/TrainDataset/GT/GT_451.png', '/content/tmp/TrainDataset/GT/GT_452.png', '/content/tmp/TrainDataset/GT/GT_460.png', '/content/tmp/TrainDataset/GT/GT_461.png', '/content/tmp/TrainDataset/GT/GT_462.png', '/content/tmp/TrainDataset/GT/GT_470.png', '/content/tmp/TrainDataset/GT/GT_471.png', '/content/tmp/TrainDataset/GT/GT_472.png', '/content/tmp/TrainDataset/GT/GT_480.png', '/content/tmp/TrainDataset/GT/GT_481.png', '/content/tmp/TrainDataset/GT/GT_482.png', '/content/tmp/TrainDataset/GT/GT_490.png', '/content/tmp/TrainDataset/GT/GT_491.png', '/content/tmp/TrainDataset/GT/GT_492.png', '/content/tmp/TrainDataset/GT/GT_50.png', '/content/tmp/TrainDataset/GT/GT_500.png', '/content/tmp/TrainDataset/GT/GT_501.png', '/content/tmp/TrainDataset/GT/GT_502.png', '/content/tmp/TrainDataset/GT/GT_51.png', '/content/tmp/TrainDataset/GT/GT_510.png', '/content/tmp/TrainDataset/GT/GT_511.png', '/content/tmp/TrainDataset/GT/GT_512.png', '/content/tmp/TrainDataset/GT/GT_52.png', '/content/tmp/TrainDataset/GT/GT_520.png', '/content/tmp/TrainDataset/GT/GT_521.png', '/content/tmp/TrainDataset/GT/GT_522.png', '/content/tmp/TrainDataset/GT/GT_530.png', '/content/tmp/TrainDataset/GT/GT_531.png', '/content/tmp/TrainDataset/GT/GT_532.png', '/content/tmp/TrainDataset/GT/GT_540.png', '/content/tmp/TrainDataset/GT/GT_541.png', '/content/tmp/TrainDataset/GT/GT_542.png', '/content/tmp/TrainDataset/GT/GT_550.png', '/content/tmp/TrainDataset/GT/GT_551.png', '/content/tmp/TrainDataset/GT/GT_552.png', '/content/tmp/TrainDataset/GT/GT_560.png', '/content/tmp/TrainDataset/GT/GT_561.png', '/content/tmp/TrainDataset/GT/GT_562.png', '/content/tmp/TrainDataset/GT/GT_570.png', '/content/tmp/TrainDataset/GT/GT_571.png', '/content/tmp/TrainDataset/GT/GT_572.png', '/content/tmp/TrainDataset/GT/GT_580.png', '/content/tmp/TrainDataset/GT/GT_581.png', '/content/tmp/TrainDataset/GT/GT_582.png', '/content/tmp/TrainDataset/GT/GT_590.png', '/content/tmp/TrainDataset/GT/GT_591.png', '/content/tmp/TrainDataset/GT/GT_592.png', '/content/tmp/TrainDataset/GT/GT_60.png', '/content/tmp/TrainDataset/GT/GT_600.png', '/content/tmp/TrainDataset/GT/GT_601.png', '/content/tmp/TrainDataset/GT/GT_602.png', '/content/tmp/TrainDataset/GT/GT_61.png', '/content/tmp/TrainDataset/GT/GT_610.png', '/content/tmp/TrainDataset/GT/GT_611.png', '/content/tmp/TrainDataset/GT/GT_612.png', '/content/tmp/TrainDataset/GT/GT_62.png', '/content/tmp/TrainDataset/GT/GT_620.png', '/content/tmp/TrainDataset/GT/GT_621.png', '/content/tmp/TrainDataset/GT/GT_622.png', '/content/tmp/TrainDataset/GT/GT_630.png', '/content/tmp/TrainDataset/GT/GT_631.png', '/content/tmp/TrainDataset/GT/GT_632.png', '/content/tmp/TrainDataset/GT/GT_640.png', '/content/tmp/TrainDataset/GT/GT_641.png', '/content/tmp/TrainDataset/GT/GT_642.png', '/content/tmp/TrainDataset/GT/GT_650.png', '/content/tmp/TrainDataset/GT/GT_651.png', '/content/tmp/TrainDataset/GT/GT_652.png', '/content/tmp/TrainDataset/GT/GT_660.png', '/content/tmp/TrainDataset/GT/GT_661.png', '/content/tmp/TrainDataset/GT/GT_662.png', '/content/tmp/TrainDataset/GT/GT_670.png', '/content/tmp/TrainDataset/GT/GT_671.png', '/content/tmp/TrainDataset/GT/GT_672.png', '/content/tmp/TrainDataset/GT/GT_680.png', '/content/tmp/TrainDataset/GT/GT_681.png', '/content/tmp/TrainDataset/GT/GT_682.png', '/content/tmp/TrainDataset/GT/GT_690.png', '/content/tmp/TrainDataset/GT/GT_691.png', '/content/tmp/TrainDataset/GT/GT_692.png', '/content/tmp/TrainDataset/GT/GT_70.png', '/content/tmp/TrainDataset/GT/GT_700.png', '/content/tmp/TrainDataset/GT/GT_701.png', '/content/tmp/TrainDataset/GT/GT_702.png', '/content/tmp/TrainDataset/GT/GT_71.png', '/content/tmp/TrainDataset/GT/GT_710.png', '/content/tmp/TrainDataset/GT/GT_711.png', '/content/tmp/TrainDataset/GT/GT_712.png', '/content/tmp/TrainDataset/GT/GT_72.png', '/content/tmp/TrainDataset/GT/GT_720.png', '/content/tmp/TrainDataset/GT/GT_721.png', '/content/tmp/TrainDataset/GT/GT_722.png', '/content/tmp/TrainDataset/GT/GT_730.png', '/content/tmp/TrainDataset/GT/GT_731.png', '/content/tmp/TrainDataset/GT/GT_732.png', '/content/tmp/TrainDataset/GT/GT_740.png', '/content/tmp/TrainDataset/GT/GT_741.png', '/content/tmp/TrainDataset/GT/GT_742.png', '/content/tmp/TrainDataset/GT/GT_750.png', '/content/tmp/TrainDataset/GT/GT_751.png', '/content/tmp/TrainDataset/GT/GT_752.png', '/content/tmp/TrainDataset/GT/GT_760.png', '/content/tmp/TrainDataset/GT/GT_761.png', '/content/tmp/TrainDataset/GT/GT_762.png', '/content/tmp/TrainDataset/GT/GT_770.png', '/content/tmp/TrainDataset/GT/GT_771.png', '/content/tmp/TrainDataset/GT/GT_772.png', '/content/tmp/TrainDataset/GT/GT_780.png', '/content/tmp/TrainDataset/GT/GT_781.png', '/content/tmp/TrainDataset/GT/GT_782.png', '/content/tmp/TrainDataset/GT/GT_790.png', '/content/tmp/TrainDataset/GT/GT_791.png', '/content/tmp/TrainDataset/GT/GT_792.png', '/content/tmp/TrainDataset/GT/GT_80.png', '/content/tmp/TrainDataset/GT/GT_81.png', '/content/tmp/TrainDataset/GT/GT_82.png', '/content/tmp/TrainDataset/GT/GT_90.png', '/content/tmp/TrainDataset/GT/GT_91.png', '/content/tmp/TrainDataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fa1612fc390>\n",
            "60\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-02 16:33:39.678094 Epoch [001/030], Step [0001/0060], Loss1: 0.0415 Loss2: 0.0187 Loss3: -0.0202\n",
            "2022-06-02 16:34:02.456913 Epoch [001/030], Step [0050/0060], Loss1: -0.4206 Loss2: -0.4639 Loss3: -0.5570\n",
            "2022-06-02 16:34:07.032261 Epoch [001/030], Step [0060/0060], Loss1: -0.5069 Loss2: -0.5132 Loss3: -0.5907\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.5506062300747664 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-02 16:34:14.646647 Epoch [002/030], Step [0001/0060], Loss1: -0.5167 Loss2: -0.5455 Loss3: -0.6108\n",
            "2022-06-02 16:34:37.304057 Epoch [002/030], Step [0050/0060], Loss1: -0.6152 Loss2: -0.6112 Loss3: -0.6565\n",
            "2022-06-02 16:34:41.872181 Epoch [002/030], Step [0060/0060], Loss1: -0.6324 Loss2: -0.6693 Loss3: -0.7069\n",
            "Epoch: 2 MAE: 0.5258710685608878 ####  bestMAE: 0.5506062300747664 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-02 16:34:52.011850 Epoch [003/030], Step [0001/0060], Loss1: -0.5418 Loss2: -0.5867 Loss3: -0.6309\n",
            "2022-06-02 16:35:15.507696 Epoch [003/030], Step [0050/0060], Loss1: -0.6321 Loss2: -0.6690 Loss3: -0.7067\n",
            "2022-06-02 16:35:20.083249 Epoch [003/030], Step [0060/0060], Loss1: -0.5920 Loss2: -0.6371 Loss3: -0.6737\n",
            "Epoch: 3 MAE: 0.5261074578825128 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:35:27.698656 Epoch [004/030], Step [0001/0060], Loss1: -0.6679 Loss2: -0.6851 Loss3: -0.7203\n",
            "2022-06-02 16:35:50.201838 Epoch [004/030], Step [0050/0060], Loss1: -0.7386 Loss2: -0.7482 Loss3: -0.7733\n",
            "2022-06-02 16:35:54.831356 Epoch [004/030], Step [0060/0060], Loss1: -0.7247 Loss2: -0.7422 Loss3: -0.7570\n",
            "Epoch: 4 MAE: 0.5275129974203764 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:36:02.415748 Epoch [005/030], Step [0001/0060], Loss1: -0.7327 Loss2: -0.7674 Loss3: -0.7830\n",
            "2022-06-02 16:36:25.058370 Epoch [005/030], Step [0050/0060], Loss1: -0.7330 Loss2: -0.7660 Loss3: -0.7919\n",
            "2022-06-02 16:36:29.682014 Epoch [005/030], Step [0060/0060], Loss1: -0.7714 Loss2: -0.8188 Loss3: -0.8249\n",
            "Epoch: 5 MAE: 0.5423307122124565 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:36:39.840646 Epoch [006/030], Step [0001/0060], Loss1: -0.7864 Loss2: -0.8078 Loss3: -0.8336\n",
            "2022-06-02 16:37:02.490527 Epoch [006/030], Step [0050/0060], Loss1: -0.8346 Loss2: -0.8431 Loss3: -0.8615\n",
            "2022-06-02 16:37:07.062582 Epoch [006/030], Step [0060/0060], Loss1: -0.7926 Loss2: -0.8337 Loss3: -0.8488\n",
            "Epoch: 6 MAE: 0.5381577200107472 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:37:15.893674 Epoch [007/030], Step [0001/0060], Loss1: -0.8000 Loss2: -0.8362 Loss3: -0.8512\n",
            "2022-06-02 16:37:39.878303 Epoch [007/030], Step [0050/0060], Loss1: -0.8172 Loss2: -0.8362 Loss3: -0.8569\n",
            "2022-06-02 16:37:44.455687 Epoch [007/030], Step [0060/0060], Loss1: -0.8554 Loss2: -0.8756 Loss3: -0.8869\n",
            "Epoch: 7 MAE: 0.5413746974077175 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:37:52.145999 Epoch [008/030], Step [0001/0060], Loss1: -0.8526 Loss2: -0.8716 Loss3: -0.8855\n",
            "2022-06-02 16:38:14.901138 Epoch [008/030], Step [0050/0060], Loss1: -0.8267 Loss2: -0.8609 Loss3: -0.8689\n",
            "2022-06-02 16:38:19.498292 Epoch [008/030], Step [0060/0060], Loss1: -0.8053 Loss2: -0.8683 Loss3: -0.8687\n",
            "Epoch: 8 MAE: 0.5483359685019843 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:38:27.153857 Epoch [009/030], Step [0001/0060], Loss1: -0.8445 Loss2: -0.8792 Loss3: -0.8905\n",
            "2022-06-02 16:38:49.737829 Epoch [009/030], Step [0050/0060], Loss1: -0.8691 Loss2: -0.8926 Loss3: -0.9066\n",
            "2022-06-02 16:38:54.338343 Epoch [009/030], Step [0060/0060], Loss1: -0.8321 Loss2: -0.8782 Loss3: -0.8801\n",
            "Epoch: 9 MAE: 0.5461222758621136 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:39:01.944047 Epoch [010/030], Step [0001/0060], Loss1: -0.8776 Loss2: -0.9029 Loss3: -0.9141\n",
            "2022-06-02 16:39:24.489724 Epoch [010/030], Step [0050/0060], Loss1: -0.8803 Loss2: -0.9180 Loss3: -0.9233\n",
            "2022-06-02 16:39:29.290282 Epoch [010/030], Step [0060/0060], Loss1: -0.8633 Loss2: -0.9118 Loss3: -0.9157\n",
            "Epoch: 10 MAE: 0.5510331096346418 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:39:40.203502 Epoch [011/030], Step [0001/0060], Loss1: -0.8700 Loss2: -0.9092 Loss3: -0.9177\n",
            "2022-06-02 16:40:02.830762 Epoch [011/030], Step [0050/0060], Loss1: -0.8766 Loss2: -0.9170 Loss3: -0.9209\n",
            "2022-06-02 16:40:07.416050 Epoch [011/030], Step [0060/0060], Loss1: -0.8896 Loss2: -0.9177 Loss3: -0.9269\n",
            "Epoch: 11 MAE: 0.5545778216003742 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:40:15.024370 Epoch [012/030], Step [0001/0060], Loss1: -0.8694 Loss2: -0.9219 Loss3: -0.9242\n",
            "2022-06-02 16:40:37.669244 Epoch [012/030], Step [0050/0060], Loss1: -0.8855 Loss2: -0.9214 Loss3: -0.9311\n",
            "2022-06-02 16:40:42.254842 Epoch [012/030], Step [0060/0060], Loss1: -0.8865 Loss2: -0.9239 Loss3: -0.9279\n",
            "Epoch: 12 MAE: 0.5548244988981379 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:40:49.865954 Epoch [013/030], Step [0001/0060], Loss1: -0.8986 Loss2: -0.9244 Loss3: -0.9285\n",
            "2022-06-02 16:41:12.459051 Epoch [013/030], Step [0050/0060], Loss1: -0.8816 Loss2: -0.9266 Loss3: -0.9361\n",
            "2022-06-02 16:41:17.047230 Epoch [013/030], Step [0060/0060], Loss1: -0.8512 Loss2: -0.9005 Loss3: -0.9057\n",
            "Epoch: 13 MAE: 0.5625277338583003 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:41:24.686357 Epoch [014/030], Step [0001/0060], Loss1: -0.8572 Loss2: -0.9279 Loss3: -0.9352\n",
            "2022-06-02 16:41:48.438025 Epoch [014/030], Step [0050/0060], Loss1: -0.8776 Loss2: -0.9320 Loss3: -0.9352\n",
            "2022-06-02 16:41:53.750081 Epoch [014/030], Step [0060/0060], Loss1: -0.8885 Loss2: -0.9347 Loss3: -0.9373\n",
            "Epoch: 14 MAE: 0.5636610186541523 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:42:01.541388 Epoch [015/030], Step [0001/0060], Loss1: -0.8882 Loss2: -0.9331 Loss3: -0.9371\n",
            "2022-06-02 16:42:24.105704 Epoch [015/030], Step [0050/0060], Loss1: -0.9059 Loss2: -0.9421 Loss3: -0.9484\n",
            "2022-06-02 16:42:28.685473 Epoch [015/030], Step [0060/0060], Loss1: -0.8944 Loss2: -0.9412 Loss3: -0.9447\n",
            "Epoch: 15 MAE: 0.5723747883145771 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:42:38.979803 Epoch [016/030], Step [0001/0060], Loss1: -0.8721 Loss2: -0.9319 Loss3: -0.9344\n",
            "2022-06-02 16:43:01.580210 Epoch [016/030], Step [0050/0060], Loss1: -0.8979 Loss2: -0.9375 Loss3: -0.9386\n",
            "2022-06-02 16:43:06.168285 Epoch [016/030], Step [0060/0060], Loss1: -0.8845 Loss2: -0.9430 Loss3: -0.9459\n",
            "Epoch: 16 MAE: 0.5726767072728072 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:43:13.743963 Epoch [017/030], Step [0001/0060], Loss1: -0.8879 Loss2: -0.9150 Loss3: -0.9239\n",
            "2022-06-02 16:43:36.377865 Epoch [017/030], Step [0050/0060], Loss1: -0.9157 Loss2: -0.9443 Loss3: -0.9486\n",
            "2022-06-02 16:43:40.971641 Epoch [017/030], Step [0060/0060], Loss1: -0.9229 Loss2: -0.9440 Loss3: -0.9529\n",
            "Epoch: 17 MAE: 0.575571410971344 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:43:48.582485 Epoch [018/030], Step [0001/0060], Loss1: -0.9074 Loss2: -0.9457 Loss3: -0.9459\n",
            "2022-06-02 16:44:13.248974 Epoch [018/030], Step [0050/0060], Loss1: -0.8637 Loss2: -0.9346 Loss3: -0.9318\n",
            "2022-06-02 16:44:17.847044 Epoch [018/030], Step [0060/0060], Loss1: -0.8763 Loss2: -0.9375 Loss3: -0.9437\n",
            "Epoch: 18 MAE: 0.5793338020768747 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:44:25.401262 Epoch [019/030], Step [0001/0060], Loss1: -0.9076 Loss2: -0.9457 Loss3: -0.9523\n",
            "2022-06-02 16:44:47.980296 Epoch [019/030], Step [0050/0060], Loss1: -0.8649 Loss2: -0.9346 Loss3: -0.9434\n",
            "2022-06-02 16:44:52.567885 Epoch [019/030], Step [0060/0060], Loss1: -0.9186 Loss2: -0.9474 Loss3: -0.9472\n",
            "Epoch: 19 MAE: 0.5801191227019777 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:45:00.190769 Epoch [020/030], Step [0001/0060], Loss1: -0.8202 Loss2: -0.9086 Loss3: -0.9024\n",
            "2022-06-02 16:45:22.733961 Epoch [020/030], Step [0050/0060], Loss1: -0.8939 Loss2: -0.9329 Loss3: -0.9333\n",
            "2022-06-02 16:45:27.313327 Epoch [020/030], Step [0060/0060], Loss1: -0.8907 Loss2: -0.9374 Loss3: -0.9420\n",
            "Epoch: 20 MAE: 0.5852519605525586 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:45:37.804559 Epoch [021/030], Step [0001/0060], Loss1: -0.8483 Loss2: -0.9463 Loss3: -0.9500\n",
            "2022-06-02 16:46:00.367141 Epoch [021/030], Step [0050/0060], Loss1: -0.8771 Loss2: -0.9316 Loss3: -0.9295\n",
            "2022-06-02 16:46:04.942526 Epoch [021/030], Step [0060/0060], Loss1: -0.9115 Loss2: -0.9541 Loss3: -0.9539\n",
            "Epoch: 21 MAE: 0.5884896584162636 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:46:12.529572 Epoch [022/030], Step [0001/0060], Loss1: -0.8835 Loss2: -0.9434 Loss3: -0.9493\n",
            "2022-06-02 16:46:37.077322 Epoch [022/030], Step [0050/0060], Loss1: -0.8825 Loss2: -0.9532 Loss3: -0.9531\n",
            "2022-06-02 16:46:41.650197 Epoch [022/030], Step [0060/0060], Loss1: -0.8970 Loss2: -0.9528 Loss3: -0.9527\n",
            "Epoch: 22 MAE: 0.5880754573761469 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:46:49.244930 Epoch [023/030], Step [0001/0060], Loss1: -0.9178 Loss2: -0.9579 Loss3: -0.9573\n",
            "2022-06-02 16:47:11.874476 Epoch [023/030], Step [0050/0060], Loss1: -0.9197 Loss2: -0.9590 Loss3: -0.9597\n",
            "2022-06-02 16:47:16.465425 Epoch [023/030], Step [0060/0060], Loss1: -0.9131 Loss2: -0.9456 Loss3: -0.9449\n",
            "Epoch: 23 MAE: 0.5927014894838687 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:47:24.135616 Epoch [024/030], Step [0001/0060], Loss1: -0.8653 Loss2: -0.9506 Loss3: -0.9507\n",
            "2022-06-02 16:47:46.754195 Epoch [024/030], Step [0050/0060], Loss1: -0.9211 Loss2: -0.9579 Loss3: -0.9599\n",
            "2022-06-02 16:47:51.351938 Epoch [024/030], Step [0060/0060], Loss1: -0.8504 Loss2: -0.9216 Loss3: -0.9201\n",
            "Epoch: 24 MAE: 0.5953775492673198 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:47:59.004030 Epoch [025/030], Step [0001/0060], Loss1: -0.8741 Loss2: -0.9432 Loss3: -0.9390\n",
            "2022-06-02 16:48:21.585050 Epoch [025/030], Step [0050/0060], Loss1: -0.9161 Loss2: -0.9615 Loss3: -0.9623\n",
            "2022-06-02 16:48:26.172024 Epoch [025/030], Step [0060/0060], Loss1: -0.8858 Loss2: -0.9228 Loss3: -0.9414\n",
            "Epoch: 25 MAE: 0.5968336890488072 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:48:38.138681 Epoch [026/030], Step [0001/0060], Loss1: -0.9196 Loss2: -0.9616 Loss3: -0.9619\n",
            "2022-06-02 16:49:01.421761 Epoch [026/030], Step [0050/0060], Loss1: -0.8773 Loss2: -0.9410 Loss3: -0.9440\n",
            "2022-06-02 16:49:05.996476 Epoch [026/030], Step [0060/0060], Loss1: -0.9134 Loss2: -0.9467 Loss3: -0.9424\n",
            "Epoch: 26 MAE: 0.5921125462446266 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:49:13.568862 Epoch [027/030], Step [0001/0060], Loss1: -0.9274 Loss2: -0.9587 Loss3: -0.9597\n",
            "2022-06-02 16:49:36.363336 Epoch [027/030], Step [0050/0060], Loss1: -0.9254 Loss2: -0.9559 Loss3: -0.9532\n",
            "2022-06-02 16:49:40.960318 Epoch [027/030], Step [0060/0060], Loss1: -0.8854 Loss2: -0.9484 Loss3: -0.9490\n",
            "Epoch: 27 MAE: 0.6032165600004651 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:49:48.603065 Epoch [028/030], Step [0001/0060], Loss1: -0.9246 Loss2: -0.9601 Loss3: -0.9619\n",
            "2022-06-02 16:50:11.233342 Epoch [028/030], Step [0050/0060], Loss1: -0.9210 Loss2: -0.9640 Loss3: -0.9644\n",
            "2022-06-02 16:50:15.810099 Epoch [028/030], Step [0060/0060], Loss1: -0.9233 Loss2: -0.9552 Loss3: -0.9564\n",
            "Epoch: 28 MAE: 0.601934047476955 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n",
            "2022-06-02 16:50:23.383602 Epoch [029/030], Step [0001/0060], Loss1: -0.8797 Loss2: -0.9367 Loss3: -0.9329\n",
            "2022-06-02 16:50:46.506007 Epoch [029/030], Step [0050/0060], Loss1: -0.8585 Loss2: -0.9423 Loss3: -0.9336\n",
            "2022-06-02 16:50:51.419775 Epoch [029/030], Step [0060/0060], Loss1: -0.8856 Loss2: -0.9425 Loss3: -0.9343\n",
            "Epoch: 29 MAE: 0.60271891598979 ####  bestMAE: 0.5258710685608878 bestEpoch: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import numpy as np\n",
        "from datetime import datetime\n",
        "from torchvision.utils import make_grid\n",
        "from tensorboardX import SummaryWriter\n",
        "import logging\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "\n",
        "#set the device for training\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        "\n",
        "  \n",
        "cudnn.benchmark = True\n",
        "\n",
        "#build the model\n",
        "model = SPNet(32,50)\n",
        "if(opt.load is not None):\n",
        "    model.load_state_dict(torch.load(opt.load))\n",
        "    print('load model from ',opt.load)\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "if torch.cuda.is_available():  \n",
        "  model.cuda()\n",
        "params    = model.parameters()\n",
        "optimizer = torch.optim.Adam(params, opt.lr)\n",
        "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "#set the path\n",
        "train_image_root = opt.rgb_label_root\n",
        "train_gt_root    = opt.gt_label_root\n",
        "train_depth_root = opt.depth_label_root\n",
        "\n",
        "val_image_root   = opt.val_rgb_root\n",
        "val_gt_root      = opt.val_gt_root\n",
        "val_depth_root   = opt.val_depth_root\n",
        "save_path        = opt.save_path\n",
        "\n",
        "\n",
        "if not os.path.exists(save_path):\n",
        "    os.makedirs(save_path)\n",
        "\n",
        "#load data\n",
        "print('load data...')\n",
        "print(train_image_root, train_gt_root, train_depth_root)\n",
        "train_loader = get_loader(train_image_root, train_gt_root,train_depth_root, batchsize=opt.batchsize, trainsize=opt.trainsize)\n",
        "test_loader  = test_dataset(val_image_root, val_gt_root,val_depth_root, opt.trainsize)\n",
        "total_step   = len(train_loader)\n",
        "\n",
        "\n",
        "logging.basicConfig(filename=save_path+'log.log',format='[%(asctime)s-%(filename)s-%(levelname)s:%(message)s]', level = logging.INFO,filemode='a',datefmt='%Y-%m-%d %I:%M:%S %p')\n",
        "logging.info(\"BBSNet_unif-Train\")\n",
        "logging.info(\"Config\")\n",
        "logging.info('epoch:{};lr:{};batchsize:{};trainsize:{};clip:{};decay_rate:{};load:{};save_path:{};decay_epoch:{}'.format(opt.epoch,opt.lr,opt.batchsize,opt.trainsize,opt.clip,opt.decay_rate,opt.load,save_path,opt.decay_epoch))\n",
        "\n",
        "#set loss function\n",
        "CE   = torch.nn.L1Loss()\n",
        "\n",
        "step = 0\n",
        "writer     = SummaryWriter(save_path+'summary')\n",
        "best_mae   = 1\n",
        "best_epoch = 0\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    weit  = 1+5*torch.abs(F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15)-mask)\n",
        "    wbce  = F.binary_cross_entropy_with_logits(pred, mask, reduce='none')\n",
        "    wbce  = (weit*wbce).sum(dim=(2,3))/weit.sum(dim=(2,3))\n",
        "\n",
        "    pred  = torch.sigmoid(pred)\n",
        "    inter = ((pred*mask)*weit).sum(dim=(2,3))\n",
        "    union = ((pred+mask)*weit).sum(dim=(2,3))\n",
        "    wiou  = 1-(inter+1)/(union-inter+1)\n",
        "    return (wbce+wiou).mean()\n",
        "\n",
        "def perceptual_loss(pred, mask):\n",
        "    loss = torch.nn.functional.l1_loss(pred, mask)\n",
        "    return loss\n",
        "\n",
        "def train(train_loader, model, optimizer, epoch,save_path):\n",
        "    global step\n",
        "    model.train()\n",
        "    loss_all=0\n",
        "    epoch_step=0\n",
        "    try:\n",
        "        for i, (images, gts, depths) in enumerate(train_loader, start=1):\n",
        "            optimizer.zero_grad()\n",
        "            if torch.cuda.is_available():\n",
        "              images   = images.cuda()\n",
        "              gts      = gts.cuda()\n",
        "              depths   = depths.cuda()\n",
        "\n",
        "            ##\n",
        "            pre_res  = model(images,depths)\n",
        "            loss1    = fun_ssim(pre_res[0], gts) \n",
        "            loss2    = fun_ssim(pre_res[1], gts)\n",
        "            loss3    = fun_ssim(pre_res[2], gts) \n",
        "            \n",
        "            loss_seg = loss1 + loss2 + loss3\n",
        "\n",
        "            loss = loss_seg \n",
        "            loss.backward()\n",
        "\n",
        "            clip_gradient(optimizer, opt.clip)\n",
        "            optimizer.step()\n",
        "            step+=1\n",
        "            epoch_step+=1\n",
        "            loss_all+=loss.data\n",
        "            if i % 50 == 0 or i == total_step or i==1:\n",
        "                print('{} Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format(datetime.now(), epoch, opt.epoch, i, total_step, loss1.data, loss2.data,  loss3.data))\n",
        "                logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Step [{:04d}/{:04d}], Loss1: {:.4f} Loss2: {:0.4f} Loss3: {:0.4f}'.\n",
        "                    format( epoch, opt.epoch, i, total_step, loss1.data, loss2.data, loss3.data))\n",
        "                \n",
        "        loss_all/=epoch_step\n",
        "        logging.info('#TRAIN#:Epoch [{:03d}/{:03d}], Loss_AVG: {:.4f}'.format( epoch, opt.epoch, loss_all))\n",
        "        writer.add_scalar('Loss-epoch', loss_all, global_step=epoch)\n",
        "        \n",
        "        if (epoch) % 5 == 0:\n",
        "            torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch))\n",
        "            \n",
        "    except KeyboardInterrupt: \n",
        "        print('Keyboard Interrupt: save model and exit.')\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "        torch.save(model.state_dict(), save_path+'HyperNet_epoch_{}.pth'.format(epoch+1))\n",
        "        print('save checkpoints successfully!')\n",
        "        raise\n",
        "        \n",
        "        \n",
        "        \n",
        "#test function\n",
        "def val(test_loader,model,epoch,save_path):\n",
        "    global best_mae,best_epoch\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        mae_sum=0\n",
        "        for i in range(test_loader.size):\n",
        "            image, gt,depth, name,img_for_post = test_loader.load_data()\n",
        "            gt      = np.asarray(gt, np.float32)\n",
        "            gt     /= (gt.max() + 1e-8)\n",
        "            if torch.cuda.is_available():\n",
        "              image   = image.cuda()\n",
        "              depth   = depth.cuda()\n",
        "            pre_res = model(image,depth)\n",
        "            res     = pre_res[2]\n",
        "            res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "            res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "            res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "            mae_sum += np.sum(np.abs(res-gt))*1.0/(gt.shape[0]*gt.shape[1])\n",
        "        #to prevent zero_division error\n",
        "        if test_loader.size == 0:\n",
        "          mae = test_loader.size\n",
        "        else:    \n",
        "          mae = mae_sum/test_loader.size\n",
        "        writer.add_scalar('MAE', torch.tensor(mae), global_step=epoch)\n",
        "        print('Epoch: {} MAE: {} ####  bestMAE: {} bestEpoch: {}'.format(epoch,mae,best_mae,best_epoch))\n",
        "        if epoch==1:\n",
        "            best_mae = mae\n",
        "        else:\n",
        "            if mae<best_mae:\n",
        "                best_mae   = mae\n",
        "                best_epoch = epoch\n",
        "                torch.save(model.state_dict(), save_path+'SPNet_epoch_best_L1_Loss_with_Adam.pth')\n",
        "                print('best epoch:{}'.format(epoch))\n",
        "                \n",
        "        logging.info('#TEST#:Epoch:{} MAE:{} bestEpoch:{} bestMAE:{}'.format(epoch,mae,best_epoch,best_mae))\n",
        " \n",
        "if __name__ == '__main__':\n",
        "    print(\"Start train...\")\n",
        "    \n",
        "    for epoch in range(1, opt.epoch):\n",
        "        \n",
        "        cur_lr = adjust_lr(optimizer, opt.lr, epoch, opt.decay_rate, opt.decay_epoch)\n",
        "        writer.add_scalar('learning_rate', cur_lr, global_step=epoch)\n",
        "        # train\n",
        "        train(train_loader, model, optimizer, epoch,save_path)\n",
        "        \n",
        "        #test\n",
        "        val(test_loader,model,epoch,save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC-xrFosWE6R",
        "outputId": "6d397a8b-537e-4c15-c825-31d09e7dd95f"
      },
      "id": "VC-xrFosWE6R",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n",
            "load data...\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "/content/tmp/TrainDataset/RGB/ /content/tmp/TrainDataset/GT/ /content/tmp/TrainDataset/depth/\n",
            "SalObjDat\n",
            "SalObjDataset ['/content/tmp/TrainDataset/RGB/corrupted_RGB_00.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_01.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_02.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_10.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_100.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_101.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_102.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_11.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_110.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_111.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_112.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_12.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_120.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_121.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_122.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_130.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_131.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_132.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_140.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_141.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_142.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_150.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_151.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_152.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_160.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_161.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_162.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_170.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_171.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_172.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_180.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_181.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_182.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_190.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_191.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_192.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_20.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_200.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_201.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_202.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_21.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_210.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_211.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_212.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_22.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_220.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_221.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_222.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_230.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_231.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_232.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_240.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_241.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_242.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_250.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_251.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_252.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_260.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_261.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_262.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_270.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_271.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_272.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_280.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_281.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_282.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_290.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_291.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_292.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_30.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_300.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_301.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_302.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_31.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_310.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_311.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_312.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_32.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_320.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_321.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_322.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_330.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_331.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_332.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_340.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_341.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_342.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_350.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_351.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_352.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_360.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_361.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_362.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_370.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_371.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_372.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_380.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_381.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_382.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_390.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_391.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_392.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_40.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_400.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_401.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_402.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_41.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_410.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_411.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_412.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_42.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_420.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_421.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_422.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_430.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_431.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_432.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_440.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_441.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_442.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_450.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_451.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_452.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_460.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_461.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_462.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_470.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_471.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_472.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_480.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_481.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_482.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_490.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_491.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_492.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_50.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_500.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_501.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_502.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_51.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_510.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_511.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_512.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_52.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_520.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_521.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_522.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_530.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_531.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_532.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_540.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_541.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_542.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_550.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_551.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_552.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_560.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_561.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_562.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_570.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_571.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_572.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_580.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_581.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_582.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_590.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_591.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_592.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_60.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_600.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_601.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_602.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_61.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_610.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_611.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_612.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_62.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_620.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_621.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_622.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_630.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_631.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_632.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_640.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_641.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_642.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_650.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_651.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_652.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_660.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_661.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_662.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_670.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_671.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_672.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_680.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_681.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_682.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_690.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_691.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_692.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_70.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_700.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_701.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_702.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_71.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_710.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_711.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_712.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_72.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_720.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_721.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_722.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_730.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_731.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_732.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_740.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_741.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_742.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_750.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_751.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_752.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_760.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_761.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_762.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_770.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_771.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_772.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_780.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_781.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_782.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_790.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_791.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_792.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_80.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_81.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_82.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_90.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_91.png', '/content/tmp/TrainDataset/RGB/corrupted_RGB_92.png'] ['/content/tmp/TrainDataset/GT/GT_00.png', '/content/tmp/TrainDataset/GT/GT_01.png', '/content/tmp/TrainDataset/GT/GT_02.png', '/content/tmp/TrainDataset/GT/GT_10.png', '/content/tmp/TrainDataset/GT/GT_100.png', '/content/tmp/TrainDataset/GT/GT_101.png', '/content/tmp/TrainDataset/GT/GT_102.png', '/content/tmp/TrainDataset/GT/GT_11.png', '/content/tmp/TrainDataset/GT/GT_110.png', '/content/tmp/TrainDataset/GT/GT_111.png', '/content/tmp/TrainDataset/GT/GT_112.png', '/content/tmp/TrainDataset/GT/GT_12.png', '/content/tmp/TrainDataset/GT/GT_120.png', '/content/tmp/TrainDataset/GT/GT_121.png', '/content/tmp/TrainDataset/GT/GT_122.png', '/content/tmp/TrainDataset/GT/GT_130.png', '/content/tmp/TrainDataset/GT/GT_131.png', '/content/tmp/TrainDataset/GT/GT_132.png', '/content/tmp/TrainDataset/GT/GT_140.png', '/content/tmp/TrainDataset/GT/GT_141.png', '/content/tmp/TrainDataset/GT/GT_142.png', '/content/tmp/TrainDataset/GT/GT_150.png', '/content/tmp/TrainDataset/GT/GT_151.png', '/content/tmp/TrainDataset/GT/GT_152.png', '/content/tmp/TrainDataset/GT/GT_160.png', '/content/tmp/TrainDataset/GT/GT_161.png', '/content/tmp/TrainDataset/GT/GT_162.png', '/content/tmp/TrainDataset/GT/GT_170.png', '/content/tmp/TrainDataset/GT/GT_171.png', '/content/tmp/TrainDataset/GT/GT_172.png', '/content/tmp/TrainDataset/GT/GT_180.png', '/content/tmp/TrainDataset/GT/GT_181.png', '/content/tmp/TrainDataset/GT/GT_182.png', '/content/tmp/TrainDataset/GT/GT_190.png', '/content/tmp/TrainDataset/GT/GT_191.png', '/content/tmp/TrainDataset/GT/GT_192.png', '/content/tmp/TrainDataset/GT/GT_20.png', '/content/tmp/TrainDataset/GT/GT_200.png', '/content/tmp/TrainDataset/GT/GT_201.png', '/content/tmp/TrainDataset/GT/GT_202.png', '/content/tmp/TrainDataset/GT/GT_21.png', '/content/tmp/TrainDataset/GT/GT_210.png', '/content/tmp/TrainDataset/GT/GT_211.png', '/content/tmp/TrainDataset/GT/GT_212.png', '/content/tmp/TrainDataset/GT/GT_22.png', '/content/tmp/TrainDataset/GT/GT_220.png', '/content/tmp/TrainDataset/GT/GT_221.png', '/content/tmp/TrainDataset/GT/GT_222.png', '/content/tmp/TrainDataset/GT/GT_230.png', '/content/tmp/TrainDataset/GT/GT_231.png', '/content/tmp/TrainDataset/GT/GT_232.png', '/content/tmp/TrainDataset/GT/GT_240.png', '/content/tmp/TrainDataset/GT/GT_241.png', '/content/tmp/TrainDataset/GT/GT_242.png', '/content/tmp/TrainDataset/GT/GT_250.png', '/content/tmp/TrainDataset/GT/GT_251.png', '/content/tmp/TrainDataset/GT/GT_252.png', '/content/tmp/TrainDataset/GT/GT_260.png', '/content/tmp/TrainDataset/GT/GT_261.png', '/content/tmp/TrainDataset/GT/GT_262.png', '/content/tmp/TrainDataset/GT/GT_270.png', '/content/tmp/TrainDataset/GT/GT_271.png', '/content/tmp/TrainDataset/GT/GT_272.png', '/content/tmp/TrainDataset/GT/GT_280.png', '/content/tmp/TrainDataset/GT/GT_281.png', '/content/tmp/TrainDataset/GT/GT_282.png', '/content/tmp/TrainDataset/GT/GT_290.png', '/content/tmp/TrainDataset/GT/GT_291.png', '/content/tmp/TrainDataset/GT/GT_292.png', '/content/tmp/TrainDataset/GT/GT_30.png', '/content/tmp/TrainDataset/GT/GT_300.png', '/content/tmp/TrainDataset/GT/GT_301.png', '/content/tmp/TrainDataset/GT/GT_302.png', '/content/tmp/TrainDataset/GT/GT_31.png', '/content/tmp/TrainDataset/GT/GT_310.png', '/content/tmp/TrainDataset/GT/GT_311.png', '/content/tmp/TrainDataset/GT/GT_312.png', '/content/tmp/TrainDataset/GT/GT_32.png', '/content/tmp/TrainDataset/GT/GT_320.png', '/content/tmp/TrainDataset/GT/GT_321.png', '/content/tmp/TrainDataset/GT/GT_322.png', '/content/tmp/TrainDataset/GT/GT_330.png', '/content/tmp/TrainDataset/GT/GT_331.png', '/content/tmp/TrainDataset/GT/GT_332.png', '/content/tmp/TrainDataset/GT/GT_340.png', '/content/tmp/TrainDataset/GT/GT_341.png', '/content/tmp/TrainDataset/GT/GT_342.png', '/content/tmp/TrainDataset/GT/GT_350.png', '/content/tmp/TrainDataset/GT/GT_351.png', '/content/tmp/TrainDataset/GT/GT_352.png', '/content/tmp/TrainDataset/GT/GT_360.png', '/content/tmp/TrainDataset/GT/GT_361.png', '/content/tmp/TrainDataset/GT/GT_362.png', '/content/tmp/TrainDataset/GT/GT_370.png', '/content/tmp/TrainDataset/GT/GT_371.png', '/content/tmp/TrainDataset/GT/GT_372.png', '/content/tmp/TrainDataset/GT/GT_380.png', '/content/tmp/TrainDataset/GT/GT_381.png', '/content/tmp/TrainDataset/GT/GT_382.png', '/content/tmp/TrainDataset/GT/GT_390.png', '/content/tmp/TrainDataset/GT/GT_391.png', '/content/tmp/TrainDataset/GT/GT_392.png', '/content/tmp/TrainDataset/GT/GT_40.png', '/content/tmp/TrainDataset/GT/GT_400.png', '/content/tmp/TrainDataset/GT/GT_401.png', '/content/tmp/TrainDataset/GT/GT_402.png', '/content/tmp/TrainDataset/GT/GT_41.png', '/content/tmp/TrainDataset/GT/GT_410.png', '/content/tmp/TrainDataset/GT/GT_411.png', '/content/tmp/TrainDataset/GT/GT_412.png', '/content/tmp/TrainDataset/GT/GT_42.png', '/content/tmp/TrainDataset/GT/GT_420.png', '/content/tmp/TrainDataset/GT/GT_421.png', '/content/tmp/TrainDataset/GT/GT_422.png', '/content/tmp/TrainDataset/GT/GT_430.png', '/content/tmp/TrainDataset/GT/GT_431.png', '/content/tmp/TrainDataset/GT/GT_432.png', '/content/tmp/TrainDataset/GT/GT_440.png', '/content/tmp/TrainDataset/GT/GT_441.png', '/content/tmp/TrainDataset/GT/GT_442.png', '/content/tmp/TrainDataset/GT/GT_450.png', '/content/tmp/TrainDataset/GT/GT_451.png', '/content/tmp/TrainDataset/GT/GT_452.png', '/content/tmp/TrainDataset/GT/GT_460.png', '/content/tmp/TrainDataset/GT/GT_461.png', '/content/tmp/TrainDataset/GT/GT_462.png', '/content/tmp/TrainDataset/GT/GT_470.png', '/content/tmp/TrainDataset/GT/GT_471.png', '/content/tmp/TrainDataset/GT/GT_472.png', '/content/tmp/TrainDataset/GT/GT_480.png', '/content/tmp/TrainDataset/GT/GT_481.png', '/content/tmp/TrainDataset/GT/GT_482.png', '/content/tmp/TrainDataset/GT/GT_490.png', '/content/tmp/TrainDataset/GT/GT_491.png', '/content/tmp/TrainDataset/GT/GT_492.png', '/content/tmp/TrainDataset/GT/GT_50.png', '/content/tmp/TrainDataset/GT/GT_500.png', '/content/tmp/TrainDataset/GT/GT_501.png', '/content/tmp/TrainDataset/GT/GT_502.png', '/content/tmp/TrainDataset/GT/GT_51.png', '/content/tmp/TrainDataset/GT/GT_510.png', '/content/tmp/TrainDataset/GT/GT_511.png', '/content/tmp/TrainDataset/GT/GT_512.png', '/content/tmp/TrainDataset/GT/GT_52.png', '/content/tmp/TrainDataset/GT/GT_520.png', '/content/tmp/TrainDataset/GT/GT_521.png', '/content/tmp/TrainDataset/GT/GT_522.png', '/content/tmp/TrainDataset/GT/GT_530.png', '/content/tmp/TrainDataset/GT/GT_531.png', '/content/tmp/TrainDataset/GT/GT_532.png', '/content/tmp/TrainDataset/GT/GT_540.png', '/content/tmp/TrainDataset/GT/GT_541.png', '/content/tmp/TrainDataset/GT/GT_542.png', '/content/tmp/TrainDataset/GT/GT_550.png', '/content/tmp/TrainDataset/GT/GT_551.png', '/content/tmp/TrainDataset/GT/GT_552.png', '/content/tmp/TrainDataset/GT/GT_560.png', '/content/tmp/TrainDataset/GT/GT_561.png', '/content/tmp/TrainDataset/GT/GT_562.png', '/content/tmp/TrainDataset/GT/GT_570.png', '/content/tmp/TrainDataset/GT/GT_571.png', '/content/tmp/TrainDataset/GT/GT_572.png', '/content/tmp/TrainDataset/GT/GT_580.png', '/content/tmp/TrainDataset/GT/GT_581.png', '/content/tmp/TrainDataset/GT/GT_582.png', '/content/tmp/TrainDataset/GT/GT_590.png', '/content/tmp/TrainDataset/GT/GT_591.png', '/content/tmp/TrainDataset/GT/GT_592.png', '/content/tmp/TrainDataset/GT/GT_60.png', '/content/tmp/TrainDataset/GT/GT_600.png', '/content/tmp/TrainDataset/GT/GT_601.png', '/content/tmp/TrainDataset/GT/GT_602.png', '/content/tmp/TrainDataset/GT/GT_61.png', '/content/tmp/TrainDataset/GT/GT_610.png', '/content/tmp/TrainDataset/GT/GT_611.png', '/content/tmp/TrainDataset/GT/GT_612.png', '/content/tmp/TrainDataset/GT/GT_62.png', '/content/tmp/TrainDataset/GT/GT_620.png', '/content/tmp/TrainDataset/GT/GT_621.png', '/content/tmp/TrainDataset/GT/GT_622.png', '/content/tmp/TrainDataset/GT/GT_630.png', '/content/tmp/TrainDataset/GT/GT_631.png', '/content/tmp/TrainDataset/GT/GT_632.png', '/content/tmp/TrainDataset/GT/GT_640.png', '/content/tmp/TrainDataset/GT/GT_641.png', '/content/tmp/TrainDataset/GT/GT_642.png', '/content/tmp/TrainDataset/GT/GT_650.png', '/content/tmp/TrainDataset/GT/GT_651.png', '/content/tmp/TrainDataset/GT/GT_652.png', '/content/tmp/TrainDataset/GT/GT_660.png', '/content/tmp/TrainDataset/GT/GT_661.png', '/content/tmp/TrainDataset/GT/GT_662.png', '/content/tmp/TrainDataset/GT/GT_670.png', '/content/tmp/TrainDataset/GT/GT_671.png', '/content/tmp/TrainDataset/GT/GT_672.png', '/content/tmp/TrainDataset/GT/GT_680.png', '/content/tmp/TrainDataset/GT/GT_681.png', '/content/tmp/TrainDataset/GT/GT_682.png', '/content/tmp/TrainDataset/GT/GT_690.png', '/content/tmp/TrainDataset/GT/GT_691.png', '/content/tmp/TrainDataset/GT/GT_692.png', '/content/tmp/TrainDataset/GT/GT_70.png', '/content/tmp/TrainDataset/GT/GT_700.png', '/content/tmp/TrainDataset/GT/GT_701.png', '/content/tmp/TrainDataset/GT/GT_702.png', '/content/tmp/TrainDataset/GT/GT_71.png', '/content/tmp/TrainDataset/GT/GT_710.png', '/content/tmp/TrainDataset/GT/GT_711.png', '/content/tmp/TrainDataset/GT/GT_712.png', '/content/tmp/TrainDataset/GT/GT_72.png', '/content/tmp/TrainDataset/GT/GT_720.png', '/content/tmp/TrainDataset/GT/GT_721.png', '/content/tmp/TrainDataset/GT/GT_722.png', '/content/tmp/TrainDataset/GT/GT_730.png', '/content/tmp/TrainDataset/GT/GT_731.png', '/content/tmp/TrainDataset/GT/GT_732.png', '/content/tmp/TrainDataset/GT/GT_740.png', '/content/tmp/TrainDataset/GT/GT_741.png', '/content/tmp/TrainDataset/GT/GT_742.png', '/content/tmp/TrainDataset/GT/GT_750.png', '/content/tmp/TrainDataset/GT/GT_751.png', '/content/tmp/TrainDataset/GT/GT_752.png', '/content/tmp/TrainDataset/GT/GT_760.png', '/content/tmp/TrainDataset/GT/GT_761.png', '/content/tmp/TrainDataset/GT/GT_762.png', '/content/tmp/TrainDataset/GT/GT_770.png', '/content/tmp/TrainDataset/GT/GT_771.png', '/content/tmp/TrainDataset/GT/GT_772.png', '/content/tmp/TrainDataset/GT/GT_780.png', '/content/tmp/TrainDataset/GT/GT_781.png', '/content/tmp/TrainDataset/GT/GT_782.png', '/content/tmp/TrainDataset/GT/GT_790.png', '/content/tmp/TrainDataset/GT/GT_791.png', '/content/tmp/TrainDataset/GT/GT_792.png', '/content/tmp/TrainDataset/GT/GT_80.png', '/content/tmp/TrainDataset/GT/GT_81.png', '/content/tmp/TrainDataset/GT/GT_82.png', '/content/tmp/TrainDataset/GT/GT_90.png', '/content/tmp/TrainDataset/GT/GT_91.png', '/content/tmp/TrainDataset/GT/GT_92.png']\n",
            "<__main__.SalObjDataset object at 0x7fa10e768f90>\n",
            "Start train...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-06-02 17:23:13.704667 Epoch [001/030], Step [0001/0060], Loss1: -0.0837 Loss2: 0.0796 Loss3: 0.0150\n",
            "2022-06-02 17:23:42.470965 Epoch [001/030], Step [0050/0060], Loss1: -0.8505 Loss2: -0.9158 Loss3: -0.9276\n",
            "2022-06-02 17:23:48.055885 Epoch [001/030], Step [0060/0060], Loss1: -0.8318 Loss2: -0.8996 Loss3: -0.9131\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 MAE: 0.23932709446659792 ####  bestMAE: 1 bestEpoch: 0\n",
            "2022-06-02 17:23:56.040152 Epoch [002/030], Step [0001/0060], Loss1: -0.8890 Loss2: -0.9404 Loss3: -0.9520\n",
            "2022-06-02 17:24:23.719230 Epoch [002/030], Step [0050/0060], Loss1: -0.9096 Loss2: -0.9600 Loss3: -0.9696\n",
            "2022-06-02 17:24:29.329167 Epoch [002/030], Step [0060/0060], Loss1: -0.9082 Loss2: -0.9447 Loss3: -0.9583\n",
            "Epoch: 2 MAE: 0.17790758869635362 ####  bestMAE: 0.23932709446659792 bestEpoch: 0\n",
            "best epoch:2\n",
            "2022-06-02 17:24:40.145239 Epoch [003/030], Step [0001/0060], Loss1: -0.9372 Loss2: -0.9695 Loss3: -0.9763\n",
            "2022-06-02 17:25:07.676145 Epoch [003/030], Step [0050/0060], Loss1: -0.9513 Loss2: -0.9721 Loss3: -0.9781\n",
            "2022-06-02 17:25:13.257160 Epoch [003/030], Step [0060/0060], Loss1: -0.9084 Loss2: -0.9571 Loss3: -0.9675\n",
            "Epoch: 3 MAE: 0.18872726278961027 ####  bestMAE: 0.17790758869635362 bestEpoch: 2\n",
            "2022-06-02 17:25:21.297875 Epoch [004/030], Step [0001/0060], Loss1: -0.9393 Loss2: -0.9676 Loss3: -0.9714\n",
            "2022-06-02 17:25:49.193745 Epoch [004/030], Step [0050/0060], Loss1: -0.9443 Loss2: -0.9755 Loss3: -0.9794\n",
            "2022-06-02 17:25:56.520727 Epoch [004/030], Step [0060/0060], Loss1: -0.9076 Loss2: -0.9614 Loss3: -0.9608\n",
            "Epoch: 4 MAE: 0.16686248315074456 ####  bestMAE: 0.17790758869635362 bestEpoch: 2\n",
            "best epoch:4\n",
            "2022-06-02 17:26:09.501875 Epoch [005/030], Step [0001/0060], Loss1: -0.9301 Loss2: -0.9695 Loss3: -0.9735\n",
            "2022-06-02 17:26:37.136207 Epoch [005/030], Step [0050/0060], Loss1: -0.9197 Loss2: -0.9673 Loss3: -0.9694\n",
            "2022-06-02 17:26:42.722590 Epoch [005/030], Step [0060/0060], Loss1: -0.9104 Loss2: -0.9642 Loss3: -0.9757\n",
            "Epoch: 5 MAE: 0.1484687559945243 ####  bestMAE: 0.16686248315074456 bestEpoch: 4\n",
            "best epoch:5\n",
            "2022-06-02 17:26:56.397945 Epoch [006/030], Step [0001/0060], Loss1: -0.9336 Loss2: -0.9743 Loss3: -0.9729\n",
            "2022-06-02 17:27:23.794608 Epoch [006/030], Step [0050/0060], Loss1: -0.9570 Loss2: -0.9792 Loss3: -0.9838\n",
            "2022-06-02 17:27:29.353842 Epoch [006/030], Step [0060/0060], Loss1: -0.9475 Loss2: -0.9765 Loss3: -0.9772\n",
            "Epoch: 6 MAE: 0.12096479930574931 ####  bestMAE: 0.1484687559945243 bestEpoch: 5\n",
            "best epoch:6\n",
            "2022-06-02 17:27:40.041387 Epoch [007/030], Step [0001/0060], Loss1: -0.9506 Loss2: -0.9815 Loss3: -0.9836\n",
            "2022-06-02 17:28:08.487891 Epoch [007/030], Step [0050/0060], Loss1: -0.9629 Loss2: -0.9803 Loss3: -0.9850\n",
            "2022-06-02 17:28:14.147103 Epoch [007/030], Step [0060/0060], Loss1: -0.9350 Loss2: -0.9749 Loss3: -0.9777\n",
            "Epoch: 7 MAE: 0.12867262078340722 ####  bestMAE: 0.12096479930574931 bestEpoch: 6\n",
            "2022-06-02 17:28:22.156604 Epoch [008/030], Step [0001/0060], Loss1: -0.9599 Loss2: -0.9843 Loss3: -0.9871\n",
            "2022-06-02 17:28:49.588413 Epoch [008/030], Step [0050/0060], Loss1: -0.9611 Loss2: -0.9800 Loss3: -0.9815\n",
            "2022-06-02 17:28:55.176004 Epoch [008/030], Step [0060/0060], Loss1: -0.9665 Loss2: -0.9824 Loss3: -0.9866\n",
            "Epoch: 8 MAE: 0.11817498797462105 ####  bestMAE: 0.12096479930574931 bestEpoch: 6\n",
            "best epoch:8\n",
            "2022-06-02 17:29:06.102013 Epoch [009/030], Step [0001/0060], Loss1: -0.9373 Loss2: -0.9710 Loss3: -0.9756\n",
            "2022-06-02 17:29:33.607906 Epoch [009/030], Step [0050/0060], Loss1: -0.9655 Loss2: -0.9839 Loss3: -0.9873\n",
            "2022-06-02 17:29:39.207599 Epoch [009/030], Step [0060/0060], Loss1: -0.9211 Loss2: -0.9631 Loss3: -0.9710\n",
            "Epoch: 9 MAE: 0.11891577665137236 ####  bestMAE: 0.11817498797462105 bestEpoch: 8\n",
            "2022-06-02 17:29:47.241593 Epoch [010/030], Step [0001/0060], Loss1: -0.9493 Loss2: -0.9798 Loss3: -0.9845\n",
            "2022-06-02 17:30:15.077076 Epoch [010/030], Step [0050/0060], Loss1: -0.9621 Loss2: -0.9786 Loss3: -0.9832\n",
            "2022-06-02 17:30:21.308584 Epoch [010/030], Step [0060/0060], Loss1: -0.9402 Loss2: -0.9727 Loss3: -0.9787\n",
            "Epoch: 10 MAE: 0.13150699110888928 ####  bestMAE: 0.11817498797462105 bestEpoch: 8\n",
            "2022-06-02 17:30:32.014352 Epoch [011/030], Step [0001/0060], Loss1: -0.9586 Loss2: -0.9848 Loss3: -0.9863\n",
            "2022-06-02 17:30:59.421796 Epoch [011/030], Step [0050/0060], Loss1: -0.9653 Loss2: -0.9820 Loss3: -0.9858\n",
            "2022-06-02 17:31:05.041547 Epoch [011/030], Step [0060/0060], Loss1: -0.9651 Loss2: -0.9838 Loss3: -0.9884\n",
            "Epoch: 11 MAE: 0.10309376237253665 ####  bestMAE: 0.11817498797462105 bestEpoch: 8\n",
            "best epoch:11\n",
            "2022-06-02 17:31:16.698836 Epoch [012/030], Step [0001/0060], Loss1: -0.9546 Loss2: -0.9793 Loss3: -0.9832\n",
            "2022-06-02 17:31:44.532911 Epoch [012/030], Step [0050/0060], Loss1: -0.9699 Loss2: -0.9822 Loss3: -0.9879\n",
            "2022-06-02 17:31:50.095965 Epoch [012/030], Step [0060/0060], Loss1: -0.9528 Loss2: -0.9810 Loss3: -0.9799\n",
            "Epoch: 12 MAE: 0.09833212897891092 ####  bestMAE: 0.10309376237253665 bestEpoch: 11\n",
            "best epoch:12\n",
            "2022-06-02 17:32:01.505378 Epoch [013/030], Step [0001/0060], Loss1: -0.9630 Loss2: -0.9853 Loss3: -0.9859\n",
            "2022-06-02 17:32:30.469885 Epoch [013/030], Step [0050/0060], Loss1: -0.9472 Loss2: -0.9748 Loss3: -0.9784\n",
            "2022-06-02 17:32:36.105814 Epoch [013/030], Step [0060/0060], Loss1: -0.9740 Loss2: -0.9863 Loss3: -0.9902\n",
            "Epoch: 13 MAE: 0.10584299299452038 ####  bestMAE: 0.09833212897891092 bestEpoch: 12\n",
            "2022-06-02 17:32:44.081249 Epoch [014/030], Step [0001/0060], Loss1: -0.9638 Loss2: -0.9828 Loss3: -0.9846\n",
            "2022-06-02 17:33:11.594133 Epoch [014/030], Step [0050/0060], Loss1: -0.9668 Loss2: -0.9869 Loss3: -0.9891\n",
            "2022-06-02 17:33:17.217818 Epoch [014/030], Step [0060/0060], Loss1: -0.9657 Loss2: -0.9850 Loss3: -0.9875\n",
            "Epoch: 14 MAE: 0.09888197147026268 ####  bestMAE: 0.09833212897891092 bestEpoch: 12\n",
            "2022-06-02 17:33:25.277465 Epoch [015/030], Step [0001/0060], Loss1: -0.9381 Loss2: -0.9756 Loss3: -0.9807\n",
            "2022-06-02 17:33:52.849844 Epoch [015/030], Step [0050/0060], Loss1: -0.9571 Loss2: -0.9842 Loss3: -0.9834\n",
            "2022-06-02 17:33:58.406398 Epoch [015/030], Step [0060/0060], Loss1: -0.9432 Loss2: -0.9780 Loss3: -0.9808\n",
            "Epoch: 15 MAE: 0.09949916304734643 ####  bestMAE: 0.09833212897891092 bestEpoch: 12\n",
            "2022-06-02 17:34:09.494306 Epoch [016/030], Step [0001/0060], Loss1: -0.9717 Loss2: -0.9878 Loss3: -0.9882\n",
            "2022-06-02 17:34:37.594548 Epoch [016/030], Step [0050/0060], Loss1: -0.9709 Loss2: -0.9867 Loss3: -0.9889\n",
            "2022-06-02 17:34:43.616848 Epoch [016/030], Step [0060/0060], Loss1: -0.9522 Loss2: -0.9785 Loss3: -0.9813\n",
            "Epoch: 16 MAE: 0.09127913469990726 ####  bestMAE: 0.09833212897891092 bestEpoch: 12\n",
            "best epoch:16\n",
            "2022-06-02 17:34:54.547587 Epoch [017/030], Step [0001/0060], Loss1: -0.9634 Loss2: -0.9849 Loss3: -0.9861\n",
            "2022-06-02 17:35:22.756686 Epoch [017/030], Step [0050/0060], Loss1: -0.9660 Loss2: -0.9865 Loss3: -0.9885\n",
            "2022-06-02 17:35:28.331288 Epoch [017/030], Step [0060/0060], Loss1: -0.9481 Loss2: -0.9753 Loss3: -0.9797\n",
            "Epoch: 17 MAE: 0.0917144510985682 ####  bestMAE: 0.09127913469990726 bestEpoch: 16\n",
            "2022-06-02 17:35:36.297206 Epoch [018/030], Step [0001/0060], Loss1: -0.9739 Loss2: -0.9876 Loss3: -0.9888\n",
            "2022-06-02 17:36:03.635471 Epoch [018/030], Step [0050/0060], Loss1: -0.9714 Loss2: -0.9868 Loss3: -0.9882\n",
            "2022-06-02 17:36:09.230261 Epoch [018/030], Step [0060/0060], Loss1: -0.9713 Loss2: -0.9869 Loss3: -0.9847\n",
            "Epoch: 18 MAE: 0.10065787966289216 ####  bestMAE: 0.09127913469990726 bestEpoch: 16\n",
            "2022-06-02 17:36:17.258858 Epoch [019/030], Step [0001/0060], Loss1: -0.9624 Loss2: -0.9835 Loss3: -0.9848\n",
            "2022-06-02 17:36:44.955464 Epoch [019/030], Step [0050/0060], Loss1: -0.9670 Loss2: -0.9867 Loss3: -0.9884\n",
            "2022-06-02 17:36:51.145300 Epoch [019/030], Step [0060/0060], Loss1: -0.9665 Loss2: -0.9865 Loss3: -0.9873\n",
            "Epoch: 19 MAE: 0.09416303069503218 ####  bestMAE: 0.09127913469990726 bestEpoch: 16\n",
            "2022-06-02 17:36:59.260059 Epoch [020/030], Step [0001/0060], Loss1: -0.9688 Loss2: -0.9879 Loss3: -0.9896\n",
            "2022-06-02 17:37:26.846632 Epoch [020/030], Step [0050/0060], Loss1: -0.9730 Loss2: -0.9872 Loss3: -0.9897\n",
            "2022-06-02 17:37:32.450998 Epoch [020/030], Step [0060/0060], Loss1: -0.9779 Loss2: -0.9894 Loss3: -0.9913\n",
            "Epoch: 20 MAE: 0.0838540015649543 ####  bestMAE: 0.09127913469990726 bestEpoch: 16\n",
            "best epoch:20\n",
            "2022-06-02 17:37:47.238540 Epoch [021/030], Step [0001/0060], Loss1: -0.9649 Loss2: -0.9862 Loss3: -0.9882\n",
            "2022-06-02 17:38:14.627828 Epoch [021/030], Step [0050/0060], Loss1: -0.9762 Loss2: -0.9894 Loss3: -0.9916\n",
            "2022-06-02 17:38:20.214360 Epoch [021/030], Step [0060/0060], Loss1: -0.9627 Loss2: -0.9844 Loss3: -0.9871\n",
            "Epoch: 21 MAE: 0.08205673071442458 ####  bestMAE: 0.0838540015649543 bestEpoch: 20\n",
            "best epoch:21\n",
            "2022-06-02 17:38:30.806339 Epoch [022/030], Step [0001/0060], Loss1: -0.9746 Loss2: -0.9866 Loss3: -0.9888\n",
            "2022-06-02 17:38:58.144304 Epoch [022/030], Step [0050/0060], Loss1: -0.9713 Loss2: -0.9873 Loss3: -0.9896\n",
            "2022-06-02 17:39:04.919792 Epoch [022/030], Step [0060/0060], Loss1: -0.9735 Loss2: -0.9885 Loss3: -0.9904\n",
            "Epoch: 22 MAE: 0.08341264129315736 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:39:13.825474 Epoch [023/030], Step [0001/0060], Loss1: -0.9731 Loss2: -0.9870 Loss3: -0.9887\n",
            "2022-06-02 17:39:44.063566 Epoch [023/030], Step [0050/0060], Loss1: -0.9748 Loss2: -0.9898 Loss3: -0.9916\n",
            "2022-06-02 17:39:49.661940 Epoch [023/030], Step [0060/0060], Loss1: -0.9694 Loss2: -0.9847 Loss3: -0.9872\n",
            "Epoch: 23 MAE: 0.09118950061697174 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:39:57.726924 Epoch [024/030], Step [0001/0060], Loss1: -0.9698 Loss2: -0.9867 Loss3: -0.9872\n",
            "2022-06-02 17:40:25.256945 Epoch [024/030], Step [0050/0060], Loss1: -0.9677 Loss2: -0.9863 Loss3: -0.9885\n",
            "2022-06-02 17:40:30.843192 Epoch [024/030], Step [0060/0060], Loss1: -0.9691 Loss2: -0.9877 Loss3: -0.9896\n",
            "Epoch: 24 MAE: 0.0843741851887375 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:40:38.883574 Epoch [025/030], Step [0001/0060], Loss1: -0.9701 Loss2: -0.9873 Loss3: -0.9890\n",
            "2022-06-02 17:41:06.473028 Epoch [025/030], Step [0050/0060], Loss1: -0.9790 Loss2: -0.9878 Loss3: -0.9906\n",
            "2022-06-02 17:41:12.056835 Epoch [025/030], Step [0060/0060], Loss1: -0.9665 Loss2: -0.9861 Loss3: -0.9879\n",
            "Epoch: 25 MAE: 0.08668554891354194 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:41:22.961688 Epoch [026/030], Step [0001/0060], Loss1: -0.9701 Loss2: -0.9879 Loss3: -0.9899\n",
            "2022-06-02 17:41:50.761618 Epoch [026/030], Step [0050/0060], Loss1: -0.9713 Loss2: -0.9869 Loss3: -0.9884\n",
            "2022-06-02 17:41:57.131617 Epoch [026/030], Step [0060/0060], Loss1: -0.9657 Loss2: -0.9800 Loss3: -0.9804\n",
            "Epoch: 26 MAE: 0.08779134195317666 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:42:05.166276 Epoch [027/030], Step [0001/0060], Loss1: -0.9678 Loss2: -0.9866 Loss3: -0.9890\n",
            "2022-06-02 17:42:32.670142 Epoch [027/030], Step [0050/0060], Loss1: -0.9730 Loss2: -0.9884 Loss3: -0.9881\n",
            "2022-06-02 17:42:38.258722 Epoch [027/030], Step [0060/0060], Loss1: -0.9807 Loss2: -0.9891 Loss3: -0.9901\n",
            "Epoch: 27 MAE: 0.08574550830497943 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:42:46.309734 Epoch [028/030], Step [0001/0060], Loss1: -0.9701 Loss2: -0.9841 Loss3: -0.9860\n",
            "2022-06-02 17:43:13.963506 Epoch [028/030], Step [0050/0060], Loss1: -0.9739 Loss2: -0.9895 Loss3: -0.9912\n",
            "2022-06-02 17:43:19.583890 Epoch [028/030], Step [0060/0060], Loss1: -0.9728 Loss2: -0.9864 Loss3: -0.9890\n",
            "Epoch: 28 MAE: 0.08574984878459305 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n",
            "2022-06-02 17:43:27.606233 Epoch [029/030], Step [0001/0060], Loss1: -0.9751 Loss2: -0.9873 Loss3: -0.9883\n",
            "2022-06-02 17:43:55.198828 Epoch [029/030], Step [0050/0060], Loss1: -0.9763 Loss2: -0.9861 Loss3: -0.9879\n",
            "2022-06-02 17:44:01.193183 Epoch [029/030], Step [0060/0060], Loss1: -0.9657 Loss2: -0.9854 Loss3: -0.9876\n",
            "Epoch: 29 MAE: 0.08349946905065467 ####  bestMAE: 0.08205673071442458 bestEpoch: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Test Model**"
      ],
      "metadata": {
        "id": "TIg6PIBJfD20"
      },
      "id": "TIg6PIBJfD20"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import sys\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os, argparse\n",
        "import cv2\n",
        "\n",
        "def test_arguments():\n",
        "  parser = argparse.ArgumentParser()\n",
        "  parser.add_argument('--testsize', type=int, default=352, help='testing size')\n",
        "  parser.add_argument('--gpu_id',   type=str, default='0', help='select gpu id')\n",
        "  parser.add_argument('--test_path',type=str, default='/content/tmp/TestDataset/',help='test dataset path')\n",
        "  return parser.parse_args(\"\")\n",
        "\n",
        "opt = test_arguments()\n",
        "\n",
        "dataset_path = opt.test_path\n",
        "\n",
        "#set device for test\n",
        "if opt.gpu_id=='0':\n",
        "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "    print('USE GPU 0')\n",
        " \n",
        "\n",
        "#load the model\n",
        "model = SPNet(32,50)\n",
        "model.cuda()\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Checkpoint/SPNet_new/SPNet_epoch_best_L1_Loss_with_Adam.pth'))\n",
        "model.eval()\n",
        "\n",
        "#test\n",
        "test_datasets = ['NJU2K','NLPR', 'DES'] \n",
        "\n",
        "test_datasets = ['DES'] \n",
        "\n",
        "\n",
        "for dataset in test_datasets:\n",
        "    save_path = '/content/drive/MyDrive/test_maps/SPNet_new/' + dataset + '/'\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        \n",
        "    image_root  = str(dataset_path + dataset + '/RGB/')\n",
        "    gt_root     = str(dataset_path + dataset + '/GT/')\n",
        "    depth_root  = str(dataset_path + dataset + '/depth/')\n",
        "    test_loader = test_dataset(image_root, gt_root,depth_root, opt.testsize)\n",
        "    for i in range(test_loader.size):\n",
        "        image, gt,depth, name, image_for_post = test_loader.load_data()\n",
        "        gt      = np.asarray(gt, np.float32)\n",
        "        gt     /= (gt.max() + 1e-8)\n",
        "        image   = image.cuda()\n",
        "        depth   = depth.cuda()\n",
        "        pre_res = model(image,depth)\n",
        "        res     = pre_res[2]     \n",
        "        res     = F.upsample(res, size=gt.shape, mode='bilinear', align_corners=False)\n",
        "        res     = res.sigmoid().data.cpu().numpy().squeeze()\n",
        "        res     = (res - res.min()) / (res.max() - res.min() + 1e-8)\n",
        "        \n",
        "        print('save img to: ',save_path+name)\n",
        "        cv2.imwrite(save_path+name,res*255)\n",
        "    print('Test Done!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQTWmWQ1QAxx",
        "outputId": "886b002b-4928-4a44-af88-a6b0fc3590e9"
      },
      "id": "qQTWmWQ1QAxx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USE GPU 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:3704: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1500.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1501.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1502.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1510.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1511.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1512.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1520.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1521.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1522.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1530.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1531.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1532.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1540.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1541.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1542.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1550.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1551.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1552.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1560.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1561.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1562.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1570.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1571.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1572.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1580.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1581.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1582.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1590.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1591.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1592.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1600.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1601.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1602.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1610.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1611.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1612.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1620.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1621.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1622.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1630.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1631.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1632.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1640.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1641.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1642.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1650.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1651.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1652.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1660.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1661.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1662.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1670.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1671.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1672.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1680.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1681.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1682.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1690.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1691.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1692.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1700.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1701.png\n",
            "save img to:  /content/drive/MyDrive/test_maps/SPNet_new/DES/corrupted_RGB_1702.png\n",
            "Test Done!\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "New_SPNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3b7c5a5cb3ef4145b601609f4e982dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5d3f7696d814e63a5522a640c80280a",
              "IPY_MODEL_416fd3d246b94a5696af4f7994204fa4",
              "IPY_MODEL_ab6cfa4e80b74edf96afc7f08ff49131"
            ],
            "layout": "IPY_MODEL_33e6662048cb43bd98c89ab41edf977a"
          }
        },
        "b5d3f7696d814e63a5522a640c80280a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cef5d09b2034f4db0e04a3dba1b7c08",
            "placeholder": "​",
            "style": "IPY_MODEL_262c3e73ac5e4e90a6220e42b2d81c63",
            "value": "100%"
          }
        },
        "416fd3d246b94a5696af4f7994204fa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2b9e5a512634f0bb6bc997f2bc5de08",
            "max": 103197949,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b8466e964bb2496ea1e61160e5371709",
            "value": 103197949
          }
        },
        "ab6cfa4e80b74edf96afc7f08ff49131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1dd241a0d46e46a095b06e98e11c9f11",
            "placeholder": "​",
            "style": "IPY_MODEL_2eb16e12dd3e4f3dae29e1dbe1e964cf",
            "value": " 98.4M/98.4M [00:05&lt;00:00, 30.3MB/s]"
          }
        },
        "33e6662048cb43bd98c89ab41edf977a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cef5d09b2034f4db0e04a3dba1b7c08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "262c3e73ac5e4e90a6220e42b2d81c63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2b9e5a512634f0bb6bc997f2bc5de08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8466e964bb2496ea1e61160e5371709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1dd241a0d46e46a095b06e98e11c9f11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2eb16e12dd3e4f3dae29e1dbe1e964cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}